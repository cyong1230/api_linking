Change	O
dataframe	B-API
index	O
values	O
while	O
keeping	O
other	O
column	O
data	O
same	O

I	O
have	O
a	O
DataFrame	B-API
with	O
4	O
columns	O
and	O
251	O
rows	O
and	O
an	O
index	O
that	O
is	O
a	O
progression	O
of	O
numbers	O
e.g.	O
1000	O
to	O
1250	O
.	O

The	O
index	O
was	O
initially	O
necessary	O
to	O
aid	O
in	O
joining	O
data	O
from	O
4	O
different	O
dataframes	O
.	O

However	O
,	O
once	O
i	O
get	O
the	O
4	O
columns	O
together	O
,	O
i	O
would	O
like	O
to	O
change	O
the	O
index	O
to	O
a	O
number	O
progression	O
from	O
250	O
to	O
0	O
.	O

This	O
is	O
because	O
i	O
would	O
be	O
performing	O
the	O
same	O
operation	O
on	O
different	O
sets	O
of	O
data	O
(	O
in	O
groups	O
of	O
4	O
)	O
that	O
would	O
have	O
different	O
indices	O
,	O
e.g.	O
2000	O
to	O
2250	O
or	O
500	O
to	O
750	O
,	O
but	O
would	O
all	O
have	O
the	O
same	O
number	O
of	O
rows	O
.	O

250	O
to	O
0	O
is	O
a	O
way	O
of	O
unifying	O
these	O
data	O
sets	O
,	O
but	O
i	O
can't	O
figure	O
out	O
how	O
to	O
do	O
this	O
.	O

i.e.	O
i'm	O
looking	O
for	O
something	O
that	O
replaces	O
any	O
existing	O
index	O
with	O
the	O
function	O
range	O
(	O
250	O
,	O
0	O
,	O
-1	O
)	O

I've	O
tried	O
using	O
set_index	B-API
below	O
and	O
a	O
whole	O
bunch	O
of	O
other	O
attempts	O
that	O
invariably	O
return	O
errors	O
,	O
#CODE	O

and	O
in	O
the	O
instance	O
when	O
i	O
am	O
able	O
to	O
set	O
the	O
index	O
of	O
the	O
df	O
to	O
the	O
range	O
,	O
the	O
data	O
in	O
the	O
4	O
columns	O
change	O
to	O
NaN	O
since	O
they	O
have	O
no	O
data	O
that	O
matches	O
the	O
new	O
index	O
.	O

I	O
apologize	O
if	O
this	O
is	O
rudimentary	O
,	O
but	O
i'm	O
a	O
week	O
old	O
in	O
the	O
world	O
of	O
python	O
/	O
pandas	O
,	O
haven't	O
programmed	O
in	O
+10yrs	O
,	O
and	O
have	O
taken	O
2	O
days	O
to	O
try	O
to	O
figure	O
this	O
out	O
for	O
myself	O
as	O
an	O
exercise	O
,	O
but	O
its	O
time	O
to	O
cry	O
...	O

Uncle	O
!!	O

Try	O
introducing	O
the	O
250:0	O
indices	O
as	O
a	O
column	O
first	O
,	O
then	O
setting	O
them	O
as	O
the	O
index	O
:	O
#CODE	O

Before	O
:	O
#CODE	O

After	O
:	O
#CODE	O

Thanks	O
for	O
the	O
quick	O
response	O
,	O
I	O
just	O
tried	O
it	O
,	O
and	O
i	O
believe	O
i'm	O
getting	O
a	O
datatype	O
conflict	O
of	O
some	O
sort	O
.	O

I	O
am	O
able	O
to	O
add	O
250:0	O
as	O
a	O
column	O
to	O
the	O
dataset	O
,	O
the	O
set_index	B-API
command	O
doesn't	O
throw	O
any	O
errors	O
,	O
but	O
when	O
i	O
look	O
at	O
the	O
dataframe	B-API
,	O
i	O
still	O
have	O
the	O
old	O
index	O
with	O
the	O
250:0	O
as	O
the	O
last	O
column	O
.	O

Below	O
is	O
the	O
output	O
i	O
got	O
on	O
executing	O
the	O
set_index	B-API
command	O

I	O
didn't	O
use	O
the	O
`	O
inplace=True	O
`	O
argument	O
in	O
my	O
code	O
like	O
you	O
did	O
,	O
so	O
it	O
doesn't	O
actually	O
modify	O
`	O
df	O
`	O
,	O
just	O
returns	O
a	O
new	O
dataframe	B-API
with	O
those	O
indexes	O
set	O
.	O

Add	O
that	O
argument	O
,	O
or	O
assign	B-API
the	O
result	O
to	O
a	O
new	O
variable	O
,	O
and	O
you	O
should	O
be	O
good	O
.	O

All	O
solved	O
.	O

Thanks	O
and	O
sorry	O
for	O
my	O
incomplete	O
response	O
earlier	O
.	O

You	O
can	O
just	O
do	O
#CODE	O

or	O
am	O
I	O
missing	O
something	O
?	O

how	O
to	O
concat	B-API
sets	O
when	O
using	O
groupby	B-API
in	O
pandas	O
dataframe	B-API
?	O

This	O
is	O
my	O
dataframe	B-API
:	O
#CODE	O

Now	O
when	O
I	O
`	O
groupby	B-API
`	O
,	O
I	O
want	O
to	O
update	O
sets	O
.	O

If	O
it	O
was	O
a	O
`	O
list	O
`	O
there	O
was	O
no	O
problem	O
.	O

But	O
the	O
output	O
of	O
my	O
command	O
is	O
:	O
#CODE	O

What	O
should	O
I	O
do	O
in	O
groupby	B-API
to	O
update	O
sets	O
?	O

The	O
output	O
I'm	O
looking	O
for	O
is	O
as	O
below	O
:	O
#CODE	O

This	O
might	O
be	O
close	O
to	O
what	O
you	O
want	O
#CODE	O

In	O
this	O
case	O
it	O
takes	O
the	O
union	O
of	O
the	O
sets	O
.	O

If	O
you	O
need	O
to	O
keep	O
the	O
column	O
names	O
you	O
could	O
use	O
:	O
#CODE	O

Result	O
:	O
#CODE	O

Thanks	O
,	O
It	O
solved	O
set	O
problem	O
,	O
but	O
column	O
name	O
renamed	O
to	O
0	O
.	O

Why	O
that	O
happened	O
?	O

It's	O
because	O
the	O
result	O
is	O
a	O
Series	B-API
so	O
no	O
column	O
name	O
.	O

I've	O
added	O
a	O
method	O
for	O
keeping	O
the	O
column	O
name	O
if	O
you	O
need	O
it	O
.	O

Take	O
a	O
Pandas	O
Series	B-API
where	O
each	O
element	O
is	O
a	O
DataFrame	B-API
and	O
combine	O
them	O
to	O
one	O
big	O
DataFrame	B-API

I	O
have	O
a	O
Pandas	O
Series	B-API
where	O
each	O
element	O
of	O
the	O
series	B-API
is	O
a	O
one	O
row	O
Pandas	O
DataFrame	B-API
which	O
I	O
would	O
like	O
to	O
append	B-API
together	O
into	O
one	O
big	O
DataFrame	B-API
.	O

For	O
example	O
:	O
#CODE	O

so	O
how	O
do	O
I	O
take	O
`	O
myResult	O
`	O
and	O
combine	O
all	O
the	O
little	O
dataframes	O
into	O
one	O
big	O
dataframe	B-API
?	O

#CODE	O

yields	O
#CODE	O

was	O
just	O
about	O
to	O
post	O
very	O
similar	O
....	O
fyi	O
,	O
you	O
function	O
could	O
return	O
the	O
column	O
labels	O
as	O
the	O
index	O
of	O
the	O
function	O
series	B-API
,	O
e.g.	O
``	O
pd.Series	B-API
([	O
val**2	O
,	O
val**3	O
,	O
index	O
=[	O
'	O
square	O
'	O
,	O
'	O
cube	O
'])``	O
will	O
work	O
as	O
well	O

@USER	O
:	O
Ah	O
,	O
much	O
better	O
.	O

Thank	O
you	O
.	O

Its	O
seems	O
overly	O
complicated	O
,	O
although	O
you	O
probably	O
posted	O
a	O
simplified	O
example	O
.	O

Creating	O
a	O
new	O
Series	B-API
for	O
each	O
row	O
creates	O
a	O
lot	O
of	O
overhead	O
.	O

This	O
for	O
example	O
is	O
over	O
200	O
times	O
faster	O
(	O
for	O
n=500	O
)	O
on	O
my	O
machine	O
:	O
#CODE	O

your	O
intuition	O
is	O
correct	O
.	O

My	O
example	O
is	O
a	O
bit	O
of	O
an	O
extreme	O
simplification	O
.	O

concat	B-API
them	O
:	O
#CODE	O

Since	O
the	O
original	O
indexes	O
are	O
all	O
0	O
,	O
I	O
also	O
reset	O
them	O
.	O

You	O
can	O
also	O
do	O
`	O
pd.concat	B-API
(	O
myResult	O
,	O
ignore_index=True	O
)`	O

pandas	O
:	O
Multiply	O
MultiIndex	O
DataFrame	B-API
with	O
Series	B-API

I	O
have	O
a	O
MultiIndex	O
DataFrame	B-API
that	O
contains	O
these	O
values	O
:	O
#CODE	O

--	O

and	O
a	O
Series	B-API
that	O
contains	O
these	O
values	O
:	O
#CODE	O

I'd	O
like	O
to	O
multiply	O
all	O
of	O
the	O
minor	O
index	O
CC	O
values	O
by	O
the	O
CC	O
value	O
in	O
the	O
Series	B-API
,	O
and	O
the	O
same	O
with	O
the	O
other	O
values	O
.	O

I	O
saw	O
another	O
question	O
on	O
here	O
that	O
gave	O
me	O
the	O
.mul	B-API
method	O
,	O
but	O
when	O
I	O
try	O
that	O
,	O
even	O
with	O
the	O
level=	O
'	O
minor	O
'	O
,	O
it	O
tells	O
me	O
:	O

TypeError	O
:	O
can	O
only	O
call	O
with	O
other	O
hierarchical	O
index	O
objects	O

I've	O
unstacked	O
the	O
minor	O
index	O
to	O
make	O
it	O
columns	O
,	O
and	O
specified	O
level=	O
'	O
minor	O
'	O
,	O
axis=	O
'	O
columns	O
'	O
with	O
the	O
same	O
result	O
.	O

Finally	O
,	O
the	O
end	O
result	O
is	O
to	O
be	O
able	O
to	O
run	O
this	O
same	O
calculation	O
on	O
a	O
DataFrame	B-API
where	O
the	O
major	O
columns	O
are	O
several	O
equities	O
--	O
in	O
that	O
instance	O
,	O
would	O
.mul()	B-API
work	O
against	O
each	O
equity	O
as	O
well	O
?	O

Thanks	O
for	O
your	O
assistance	O
!	O

If	O
you	O
add	O
the	O
output	O
of	O
the	O
DateFrame	O
and	O
Series	B-API
`	O
.to_dict()	B-API
`	O
then	O
it	O
is	O
much	O
easier	O
for	O
us	O
to	O
solve	O
these	O
type	O
of	O
questions	O
:)	O
What	O
code	O
are	O
you	O
using	O
to	O
multiplying	O
the	O
"	O
minor	O
index	O
CC	O
by	O
the	O
CC	O
value	O
"	O
?	O

I	O
updated	O
it	O
to	O
add	O
to_dict()	B-API
output	O
.	O

Series	B-API
based	O
it	O
works	O
with	O
`	O
level	O
`	O
:	O
#CODE	O

Then	O
you	O
can	O
insert	B-API
it	O
again	O
into	O
your	O
DataFrame	B-API
.	O

But	O
that	O
should	O
work	O
with	O
DataFrames	O
too	O
,	O
maybe	O
you	O
can	O
suggest	O
it	O
.	O

I	O
used	O
this	O
and	O
DataFrame.apply	B-API
to	O
apply	B-API
it	O
to	O
all	O
major	O
columns	O
in	O
the	O
dataframe	B-API
.	O

After	O
thinking	O
about	O
it	O
a	O
bit	O
more	O
,	O
I	O
think	O
this	O
is	O
the	O
intended	O
design	O
,	O
and	O
it	O
perfectly	O
accomplishes	O
the	O
goal	O
.	O

Merging	O
two	O
pandas	O
timeseries	O
shifted	O
by	O
1	O
second	O

I	O
have	O
two	O
sets	O
of	O
time	O
series	B-API
like	O
this	O
.	O

One	O
:	O
#CODE	O

The	O
other	O
:	O
#CODE	O

As	O
you	O
can	O
see	O
one	O
of	O
them	O
is	O
shifted	O
by	O
1	O
second	O
.	O

But	O
I	O
would	O
like	O
to	O
treat	O
them	O
as	O
same	O
bucket	O
.	O

For	O
instance	O
,	O
2014-03-17	O
13:25	O
:	O
01	O
should	O
be	O
same	O
as	O
2014-03-17	O
13:25	O
:	O
00	O
.	O

How	O
can	O
i	O
achieve	O
this	O
?	O

Nevermind	O
figured	O
out	O
one	O
way	O
to	O
do	O
it	O
.	O

#CODE	O

And	O
then	O
I	O
merge	B-API
the	O
two	O
..	O

If	O
there	O
are	O
better	O
ways	O
please	O
do	O
let	O
me	O
know	O
.	O

Seems	O
a	O
reasonable	O
way	O
.	O

You	O
could	O
also	O
do	O
:	O
`	O
df.index	O
=	O
df.index.values.astype	O
(	O
'	O
datetime64	O
[	O
m	O
]')`	O
.	O

you	O
can	O
also	O
round	O
the	O
as	O
well	O
,	O
see	O
here	O
:	O
#URL	O

Python	O
/	O
Pandas	O
-	O
GUI	O
for	O
viewing	O
a	O
DataFrame	B-API
or	O
Matrix	O

I'm	O
using	O
the	O
Pandas	O
package	O
and	O
it	O
creates	O
a	O
DataFrame	B-API
object	O
,	O
which	O
is	O
basically	O
a	O
labeled	O
matrix	O
.	O

Often	O
I	O
have	O
columns	O
that	O
have	O
long	O
string	O
fields	O
,	O
or	O
dataframes	O
with	O
many	O
columns	O
,	O
so	O
the	O
simple	O
print	O
command	O
doesn't	O
work	O
well	O
.	O

I've	O
written	O
some	O
text	O
output	O
functions	O
,	O
but	O
they	O
aren't	O
great	O
.	O

What	O
I'd	O
really	O
love	O
is	O
a	O
simple	O
GUI	O
that	O
lets	O
me	O
interact	O
with	O
a	O
dataframe	B-API
/	O
matrix	O
/	O
table	O
.	O

Just	O
like	O
you	O
would	O
find	O
in	O
a	O
SQL	O
tool	O
.	O

Basically	O
a	O
window	O
that	O
has	O
a	O
read-only	O
spreadsheet	O
like	O
view	O
into	O
the	O
data	O
.	O

I	O
can	O
expand	O
columns	O
,	O
page	O
up	O
and	O
down	O
through	O
long	O
tables	O
,	O
etc	O
.	O

I	O
would	O
suspect	O
something	O
like	O
this	O
exists	O
,	O
but	O
I	O
must	O
be	O
Googling	O
with	O
the	O
wrong	O
terms	O
.	O

It	O
would	O
be	O
great	O
if	O
it	O
is	O
pandas	O
specific	O
,	O
but	O
I	O
would	O
guess	O
I	O
could	O
use	O
any	O
matrix-accepting	O
tool	O
.	O

(	O
BTW	O
-	O
I'm	O
on	O
Windows	O
.	O
)	O

Any	O
pointers	O
?	O

Or	O
,	O
conversely	O
,	O
if	O
someone	O
knows	O
this	O
space	O
well	O
and	O
knows	O
this	O
probably	O
doesn't	O
exist	O
,	O
any	O
suggestions	O
on	O
if	O
there	O
is	O
a	O
simple	O
GUI	O
framework	O
/	O
widget	O
I	O
could	O
use	O
to	O
roll	O
my	O
own	O
?	O

(	O
But	O
since	O
my	O
needs	O
are	O
limited	O
,	O
I'm	O
reluctant	O
to	O
have	O
to	O
learn	O
a	O
big	O
GUI	O
framework	O
and	O
do	O
a	O
bunch	O
of	O
coding	O
for	O
this	O
one	O
piece	O
.	O
)	O

Thanks	O
.	O

Would	O
Pyspread	O
be	O
of	O
any	O
assistance	O
?	O

Looks	O
like	O
overkill	O
for	O
my	O
need	O
,	O
but	O
I'll	O
look	O
into	O
it	O
if	O
there's	O
nothing	O
easier	O
.	O

Thanks	O
.	O

can	O
this	O
be	O
done	O
in	O
spyder	O
(	O
#URL	O
)	O
?	O

I	O
have	O
been	O
using	O
Rstudio	O
with	O
R	O
and	O
I	O
like	O
being	O
able	O
to	O
see	O
the	O
data	O
with	O
a	O
single	O
click	O
.	O

I	O
totally	O
agree	O
that	O
a	O
comparable	O
tool	O
for	O
Python	O
/	O
Pandas	O
is	O
missing	O
and	O
iPython	O
is	O
great	O
but	O
not	O
in	O
this	O
area	O
.	O

i've	O
found	O
that	O
the	O
ipython	O
notebook	O
is	O
pretty	O
good	O
for	O
this	O
.	O

I'm	O
not	O
a	O
Pandas	O
user	O
myself	O
,	O
but	O
a	O
quick	O
search	O
for	O
"	O
pandas	O
gui	O
"	O
turns	O
up	O
the	O
Pandas	O
project's	O
GSOC	O
2012	O
proposal	O
:	O

Currently	O
the	O
only	O
way	O
to	O
interact	O
with	O
these	O
objects	O
is	O
through	O
the	O
API	O
.	O

This	O
project	O
proposes	O
to	O
add	O
a	O
simple	O
Qt	O
or	O
Tk	O
GUI	O
with	O
which	O
to	O
view	O
and	O
manipulate	O
these	O
objects	O
.	O

So	O
,	O
there's	O
no	O
GUI	O
,	O
but	O
if	O
you'd	O
write	O
one	O
using	O
Qt	O
or	O
Tk	O
,	O
the	O
project	O
might	O
be	O
interested	O
in	O
your	O
code	O
.	O

Thanks	O
,	O
but	O
I	O
think	O
building	O
a	O
generally	O
usable	O
tool	O
would	O
be	O
above	O
my	O
skill	O
level	O
!	O

It	O
seems	O
there	O
is	O
no	O
easy	O
solution	O
.	O

So	O
,	O
below	O
is	O
a	O
little	O
function	O
to	O
open	O
a	O
dataframe	B-API
in	O
Excel	O
.	O

It's	O
probably	O
not	O
production	O
quality	O
code	O
,	O
but	O
it	O
works	O
for	O
me	O
!	O

#CODE	O

I	O
use	O
`	O
QTableWidget	O
`	O
from	O
PyQt	O
to	O
display	O
a	O
`	O
DataFrame	B-API
`	O
.	O

I	O
create	O
a	O
`	O
QTableWidgetObject	O
`	O
and	O
then	O
populate	O
with	O
`	O
QTableWidgetItems	O
`	O
created	O
with	O
`	O
DataFrame	B-API
`	O
values	O
.	O

Following	O
is	O
the	O
snippet	O
of	O
code	O
that	O
reads	O
a	O
CSV	O
file	O
,	O
create	O
a	O
`	O
DataFrame	B-API
`	O
,	O
then	O
display	O
in	O
a	O
GUI	O
:	O
#CODE	O

That's	O
awesome	O
.	O

I	O
will	O
definitely	O
try	O
this	O
next	O
time	O
.	O

I	O
use	O
ipython	O
notebooks	O
to	O
drive	O
pandas	O
--	O
notebooks	O
provide	O
a	O
nice	O
clean	O
way	O
of	O
incrementally	O
building	O
and	O
interacting	O
with	O
pandas	O
data	O
structures	O
,	O
including	O
HTML-ized	O
display	O
of	O
dataframes	O
:	O
#URL	O

You	O
could	O
use	O
the	O
to_html()	B-API
dataframe	B-API
method	O
to	O
convert	O
the	O
dataframe	B-API
to	O
html	O
and	O
display	O
it	O
in	O
your	O
browser	O
.	O

Here	O
is	O
an	O
example	O
assuming	O
you	O
have	O
a	O
dataframe	B-API
called	O
df	O
.	O

You	O
should	O
check	O
the	O
documentation	O
to	O
see	O
what	O
other	O
options	O
are	O
available	O
in	O
the	O
to_html()	B-API
method	O
.	O

#CODE	O

If	O
you	O
want	O
to	O
get	O
the	O
table	O
to	O
be	O
nicely	O
formatted	O
and	O
scrollable	O
then	O
you	O
can	O
use	O
the	O
datatables	O
plug-in	O
for	O
jQuery	O
#URL	O
.	O

Here	O
is	O
the	O
javascript	O
I	O
use	O
to	O
display	O
a	O
table	O
the	O
scrolls	O
in	O
both	O
x	O
and	O
y	O
directiions	O
.	O

#CODE	O

Hey	O
-	O
this	O
looks	O
great	O
.	O

I'll	O
try	O
that	O
next	O
time	O
I	O
need	O
to	O
look	O
at	O
data	O
.	O

Pandas	O
0.13	O
provides	O
as	O
an	O
experimental	O
feature	O
:	O

PySide	O
support	O
for	O
the	O
qtpandas	O
`	O
DataFrameModel	O
`	O
and	O
`	O
DataFrameWidget	O
`	O

see	O
#URL	O

you	O
can	O
add	O
this	O
feature	O
using	O
#CODE	O

Thank	O
you	O
for	O
this	O
!	O

There's	O
now	O
a	O
working	O
sample	O
in	O
the	O
Pandas	O
docs	O
:	O
#URL	O

There's	O
tkintertable	O
for	O
python2.7	O
and	O
pandastable	O
for	O
python3	O
.	O

I've	O
been	O
working	O
on	O
a	O
PyQt	O
GUI	O
for	O
pandas	O
DataFrame	B-API
you	O
might	O
find	O
useful	O
.	O

It	O
includes	O
copying	O
,	O
filtering	O
,	O
and	O
sorting	O
.	O

#URL	O

The	O
nicest	O
solution	O
I've	O
found	O
is	O
using	O
`	O
qgrid	O
`	O
(	O
see	O
here	O
,	O
and	O
also	O
mentioned	O
in	O
the	O
pandas	O
docs	O
)	O
.	O

You	O
can	O
install	O
by	O
#CODE	O

and	O
then	O
you	O
need	O
to	O
do	O
a	O
further	O
install	O
(	O
just	O
once	O
)	O
in	O
your	O
`	O
IPython	O
`	O
notebook	O
#CODE	O

Afterwards	O
,	O
it's	O
as	O
easy	O
as	O
taking	O
your	O
`	O
pandas	O
`	O
`	O
df	O
`	O
and	O
running	O
#CODE	O

The	O
other	O
nice	O
thing	O
is	O
that	O
it	O
renders	O
in	O
`	O
nbviewer	O
`	O
too	O
.	O

See	O
it	O
in	O
action	O
here	O

Convert	O
one	O
row	O
of	O
a	O
pandas	O
dataframe	B-API
into	O
multiple	O
rows	O

I	O
want	O
to	O
turn	O
this	O
:	O
#CODE	O

Into	O
this	O
:	O
#CODE	O

Context	O
:	O
I	O
have	O
data	O
stored	O
with	O
one	O
value	O
coded	O
for	O
all	O
ages	O
(	O
age	O
=	O
99	O
)	O
.	O

However	O
,	O
the	O
application	O
I	O
am	O
developing	O
for	O
needs	O
the	O
value	O
explicitly	O
stated	O
for	O
every	O
id-age	O
pair	O
(	O
id	O
=1	O
,	O
age	O
=	O
25	O
,	O
50	O
,	O
and	O
75	O
)	O
.	O

There	O
are	O
simple	O
solutions	O
to	O
this	O
:	O
iterate	O
over	O
id's	O
and	O
append	B-API
a	O
bunch	O
of	O
dataframes	O
,	O
but	O
I'm	O
looking	O
for	O
something	O
elegant	O
.	O

I'd	O
like	O
to	O
do	O
a	O
#URL	O
merge	B-API
from	O
my	O
original	O
dataframe	B-API
to	O
a	O
template	O
containing	O
all	O
the	O
ages	O
,	O
but	O
I	O
would	O
still	O
have	O
to	O
loop	O
over	O
id's	O
to	O
create	O
the	O
template	O
.	O

Don't	O
know	O
,	O
may	O
be	O
there's	O
more	O
elegant	O
approach	O
,	O
but	O
you	O
can	O
do	O
something	O
like	O
cross	O
join	O
(	O
or	O
cartesian	O
product	O
):	O
#CODE	O

Thanks	O
!	O

This	O
is	O
exactly	O
what	O
I	O
was	O
looking	O
for	O
,	O
and	O
I	O
guess	O
I	O
even	O
said	O
the	O
words	O
many	O
to	O
one	O
in	O
my	O
question	O
,	O
but	O
I	O
didn't	O
understand	O
that	O
you	O
could	O
merge	B-API
like	O
that	O

@USER	O
I	O
think	O
code	O
could	O
be	O
cleaned	O
a	O
bit	O
,	O
but	O
you've	O
got	O
overall	O
idea	O

use	O
for	O
loop	O
to	O
concat	B-API
dataframe	B-API
to	O
a	O
larger	O
dataframe	B-API

my	O
question	O
is	O
for	O
every	O
step	O
of	O
for	O
loop	O
,	O
a	O
new	O
dataframe	B-API
will	O
be	O
generated	O
.	O

I	O
want	O
to	O
concat	B-API
the	O
data	O
frames	O
together	O
to	O
have	O
a	O
larger	O
one	O
but	O
somehow	O
my	O
function	O
will	O
only	O
return	O
the	O
last	O
step	O
of	O
the	O
result	O
rather	O
than	O
the	O
merged	O
result	O
#CODE	O

Thanks	O
!	O

maybe	O
result	O
=	O
pd.concat	B-API
(	O
[	O
result	O
,	O
rate	O
]	O
,	O
ignore_index=True	O
)	O
??	O

BTW	O
:	O
add	O
`	O
spaces	O
`	O
around	O
`	O
=	O
`	O
and	O
after	O
`	O
,	O
`	O
to	O
make	O
code	O
more	O
readable	O
-	O
see	O
:	O
[	O
PEP	O
8	O
--	O
Style	O
Guide	O
for	O
Python	O
Code	O
]	O
(	O
#URL	O
)	O

@USER	O
unfortunately	O
it	O
does	O
not	O
work	O
:(	O

@USER	O
thank	O
you	O
so	O
much	O
!	O

I	O
am	O
really	O
new	O
to	O
Python	O
will	O
def	O
pay	O
attention	O
to	O
that	O
next	O
time	O
.	O
bad	O
habit	O
in	O
R	O
lol	O

This	O
might	O
not	O
be	O
the	O
right	O
answer	O
,	O
it	O
is	O
more	O
readable	O
written	O
as	O
answer	O
.	O

I	O
think	O
the	O
right	O
logic	O
should	O
be	O
(	O
but	O
I	O
can	O
be	O
very	O
wrong	O
):	O
#CODE	O

Can	O
you	O
please	O
try	O
this	O
and	O
let	O
us	O
know	O
if	O
it	O
works	O
?	O

I	O
think	O
one	O
of	O
your	O
problem	O
is	O
the	O
way	O
you	O
use	O
pd.concat	B-API
(	O
obj	O
)	O
,	O
the	O
obj	O
should	O
be	O
a	O
list	O
of	O
item	O
or	O
a	O
dict	O
of	O
pd.Series	B-API
....	O

but	O
you	O
didn't	O
concat	B-API
rate	O
with	O
anything	O
else	O
.	O

and	O
the	O
use	O
of	O
variable	O
"	O
result	O
"	O
is	O
unnecessary	O
to	O
me	O
.	O

but	O
,	O
again	O
,	O
I	O
could	O
be	O
wrong	O
.	O

I	O
agree	O
-	O
`	O
result	O
`	O
is	O
unnecessary	O
.	O

`	O
cvResult	O
`	O
should	O
be	O
used	O
in	O
place	O
of	O
`	O
result	O
`	O
.	O

it	O
still	O
did	O
not	O
work	O
the	O
error	O
is	O
"	O
cannot	O
concatenate	O
a	O
non-NDFrame	O
object	O
"	O
but	O
thx	O
@USER	O
:)	O

oh	O
,	O
you	O
need	O
to	O
do	O
rate	O
=	O
pd.DataFrame	B-API
(	O
{	O
"	O
classfier	O
"	O
:	O
classifier_i	O
,	O
"	O
model	O
"	O
:	O
index_i	O
,	O
"	O
recall	O
"	O
:	O
recall_rate	O
,	O
"	O
precision	O
"	O
:p	O
recision_rate	O
,	O
"	O
accuracy	O
"	O
:	O
accuracy_rate	O
}	O
)	O
to	O
make	O
it	O
a	O
DataFrame	B-API
before	O
you	O
concat	B-API
it	O
.	O

pandas.to_html()	O
returning	O
None	O

I'm	O
trying	O
to	O
use	O
the	O
formatters	O
argument	O
to	O
add	O
a	O
html	O
property	O
to	O
a	O
specific	O
cell	O
/	O
text	O
.	O

I've	O
found	O
an	O
answer	O
that	O
fits	O
completely	O
my	O
request	O
.	O

However	O
trying	O
it	O
,	O
results	O
in	O
returning	O
None	O
.	O

The	O
example	O
that	O
I'm	O
trying	O
:	O
#CODE	O

This	O
question	O
is	O
from	O
2013	O
.	O

Does	O
the	O
syntax	O
changed	O
from	O
one	O
version	O
to	O
another	O
?	O

I'm	O
using	O
python	O
Python	O
2.7.9	O
pandas	O
0.16.0	O
.	O

Meybe	O
result	O
is	O
in	O
`	O
buf	O
`	O
?	O

As	O
above	O
:	O
the	O
to_x	O
methods	O
return	O
None	O
,	O
the	O
results	O
will	O
be	O
visible	O
in	O
whatever	O
file-like	O
you	O
pass	O
as	O
the	O
first	O
parameter	O

Ok	O
,	O
I	O
wasn't	O
understanding	O
the	O
stringIo	O
use	O
.	O

I	O
was	O
thinking	O
the	O
formatter	O
argument	O
required	O
a	O
stringIo	O
object	O
.	O

The	O
result	O
that	O
I	O
was	O
expecting	O
was	O
simply	O
:	O
df.to_html	B-API
(	O
formatters={	O
'	O
p_value	O
'	O
:	O
significant}	O
,	O
escape=False	O
)	O

The	O
df.to_html()	B-API
method	O
is	O
not	O
returning	O
the	O
output	O
,	O
the	O
output	O
is	O
returned	O
to	O
the	O
buf	O
stringIo	O
object	O
wich	O
can	O
be	O
conveniently	O
written	O
later	O
.	O

What	O
I	O
was	O
expecting	O
:	O
#CODE	O

You	O
have	O
given	O
the	O
DataFrame.to_html	B-API
function	O
a	O
StringIO	O
buffer	O
,	O
which	O
means	O
that	O
the	O
result	O
is	O
written	O
to	O
it	O
,	O
not	O
returned	O
as	O
a	O
string	O
.	O

This	O
has	O
not	O
changed	O
since	O
Pandas	O
version	O
0.10	O
of	O
DataFrame.to_html()	B-API
function	O

To	O
get	O
the	O
output	O
as	O
a	O
returned	O
string	O
,	O
simply	O
remove	O
the	O
buffer	O
:	O
#CODE	O

OR	O
,	O
if	O
you	O
want	O
to	O
use	O
a	O
buffer	O
,	O
this	O
is	O
how	O
to	O
print	O
the	O
value	O
of	O
it	O
:	O
#CODE	O

pandas	O
resample	B-API
MAX-VALUE	O
with	O
corresponding	O
ANGLE-VALUE	O

I	O
have	O
to	O
resample	B-API
wind_velocity	O
and	O
wind_angle	O
from	O
the	O
2	O
sec	O
period	O
to	O
2min	O
and	O
receive	O
the	O
maximum	O
wind_velocity	O
(=	O
MAX	O
)	O
with	O
the	O
corresponding	O
wind_angle	O
(	O
not	O
MAX	O
)	O
.	O

The	O
lines	O
below	O
give	O
me	O
the	O
maximum	O
of	O
both	O
columns	O
.	O

#CODE	O

the	O
data	O
looks	O
like	O
#CODE	O

Any	O
help	O
?	O

This	O
answer	O
has	O
a	O
couple	O
strategies	O
-	O
#URL	O

Thank	O
you	O
.	O

This	O
helped	O
.	O

lg	O
,	O
s	O

HDFStore	O
error	O
appending	O
-	O
"	O
Cannot	O
serialize	O
the	O
column	O
"	O

I	O
have	O
a	O
dataframe	B-API
,	O
df	O
:	O
#CODE	O

Trying	O
to	O
append	B-API
this	O
to	O
a	O
new	O
datastore	O
.	O

The	O
datastore	O
does	O
not	O
exist	O
so	O
I	O
use	O
the	O
following	O
to	O
create	O
and	O
append	B-API
the	O
data	O
;	O
#CODE	O

I	B-API
get	O
this	O
error	O
:	O
on	O
the	O
`	O
store.append	O
`	O
line	O
.	O

#CODE	O

How	O
do	O
I	O
get	O
the	O
data	O
to	O
store	O
properly	O
?	O

do	O
``	O
df.dtypes	B-API
``	O
.	O
you	O
have	O
``	O
object	O
``	O
dtypes	B-API
on	O
the	O
columns	O
(	O
the	O
message	O
indicates	O
that	O
they	O
look	O
like	O
``	O
float	O
``	O
type	O
,	O
but	O
they	O
are	O
not	O
typed	O
that	O
way	O
.	O

You	O
need	O
to	O
convert	O
as	O
@USER	O
Cloud	O
suggest	O
below	O
(	O
or	O
event	O
better	O
convert	O
when	O
you	O
are	O
reading	O
them	O
in	O
)	O
.	O

It	O
is	O
hard	O
to	O
create	O
object	O
dtyped	O
floating	O
values	O
unless	O
you	O
are	O
doing	O
it	O
on	O
purpose	O
(	O
that's	O
why	O
I	O
say	O
when	O
you	O
read	O
it	O
in	O
)	O

Call	O
`	O
DataFrame.convert_objects()	B-API
`	O
:	O
#CODE	O

It	O
might	O
be	O
worth	O
checking	O
to	O
see	O
if	O
you	O
can	O
get	O
your	O
data	O
in	O
the	O
correct	O
format	O
before	O
you	O
start	O
saving	O
to	O
HDF5	O
.	O

For	O
example	O
,	O
wherever	O
`	O
df	O
`	O
is	O
created	O
,	O
convert	O
the	O
objects	O
there	O
,	O
instead	O
of	O
converting	O
them	O
when	O
you	O
save	O
.	O

In	O
general	O
,	O
operations	O
in	O
pandas	O
will	O
be	O
very	O
cumbersome	O
with	O
a	O
`	O
Series	B-API
`	O
of	O
`	O
float	O
`	O
s	O
with	O
a	O
`	O
dtype	B-API
`	O
of	O
`	O
object	O
`	O
.	O

Your	O
life	O
will	O
be	O
much	O
easier	O
if	O
you	O
convert	O
your	O
object	O
arrays	O
(	O
where	O
possible	O
)	O
as	O
soon	O
as	O
you	O
need	O
to	O
do	O
anything	O
with	O
them	O
.	O

Thanks	O
.	O

What's	O
the	O
advantage	O
to	O
using	O
`	O
dtype	B-API
=o	O
bject	O
`	O
here	O
rather	O
than	O
,	O
say	O
,	O
`	O
dtype=	O
numpy.float64	O
`	O
?	O

Nothing	O
.	O

You	O
shouldn't	O
use	O
`	O
object	O
`	O
.	O

I	O
was	O
using	O
it	O
to	O
reproduce	O
the	O
issue	O
.	O

If	O
you	O
have	O
floating	O
point	O
values	O
,	O
avoid	O
the	O
`	O
object	O
`	O
dtype	B-API
.	O

When	O
facing	O
"	O
TypeError	O
:	O
Cannot	O
serialize	O
the	O
column	O
[	O
myvar	O
]	O
because	O
its	O
data	O
contents	O
are	O
[	O
mixed	O
]	O
object	O
dtype	B-API
"	O
,	O
I	O
tried	O
.convert_objects()	B-API
,	O
and	O
that	O
too	O
failed	O
,	O
with	O
"	O
***	O
AssertionError	O
:	O
Block	O
ref_items	O
must	O
be	O
BlockManager	O
items	O
"	O

That	O
might	O
be	O
a	O
bug	O
.	O

Can	O
you	O
post	O
a	O
reproducible	O
example	O
over	O
at	O
the	O
pandas	O
github	O
and	O
I'll	O
take	O
a	O
look	O
?	O

Pvalues	O
of	O
Coeffcients	O
in	O
Lasso	O
in	O
scikit-learn	O

I	O
ran	O
a	O
L1	O
regularisation	O
on	O
19	O
features	O
with	O
143	O
observations	O
.	O

While	O
Lasso	O
did	O
give	O
me	O
coefficients	O
with	O
zero	O
value	O
thereby	O
helping	O
in	O
further	O
reduce	O
features	O
(	O
I	O
had	O
initially	O
done	O
a	O
preliminary	O
feature	O
reduction	O
by	O
running	O
a	O
combination	O
of	O
random	O
forests	O
and	O
LARS	O
.	O

But	O
the	O
problem	O
is	O
while	O
it	O
does	O
tell	O
me	O
coefficient	O
estimates	O
and	O
I	O
can	O
get	O
a	O
regression	O
equation	O
,	O
if	O
I	O
have	O
to	O
explain	O
the	O
feature	O
importance	O
to	O
someone	O
,	O
they	O
would	O
want	O
to	O
see	O
how	O
much	O
confidence	O
is	O
there	O
on	O
those	O
coefficients	O
.	O

Like	O
without	O
showing	O
any	O
p	O
value	O
of	O
coefficient	O
ppl	O
are	O
sceptical	O
.	O

So	O
is	O
there	O
a	O
way	O
to	O
get	O
pvalue	O
for	O
Lasso	O
coefficients	O
from	O
scikit	O
learn	O
?	O

Or	O
in	O
R	O
.	O

I	O
guess	O
even	O
R	O
does	O
not	O
give	O
that	O
.	O

You	O
will	O
have	O
better	O
luck	O
with	O
this	O
question	O
on	O
#URL	O

Also	O
p-value	O
or	O
significance	O
with	O
respect	O
to	O
lasso	O
is	O
a	O
new	O
thing	O
#URL	O

How	O
about	O
bootstrapping	O
and	O
getting	O
the	O
frequency	O
at	O
which	O
each	O
variable	O
is	O
included	O
in	O
LASSO-ed	O
model	O
?	O

Don't	O
perpetuate	O
the	O
problems	O
with	O
using	O
p-values	O
to	O
determine	O
importance	O
.	O

The	O
coefficients	O
are	O
estimates	O
of	O
effect	O
size	O
.	O

If	O
you	O
standardise	O
your	O
features	O
so	O
they're	O
all	O
on	O
the	O
same	O
scale	O
,	O
coefficients	O
can	O
be	O
compared	O
to	O
one	O
another	O
for	O
"	O
importance	O
"	O
.	O

For	O
uncertainty	O
in	O
effect	O
,	O
use	O
bootstrapping	O
to	O
produce	O
intervals	O
for	O
the	O
coefficients	O
.	O

pandas	O
reindex	B-API
DataFrame	B-API
with	O
datetime	O
objects	O

Is	O
it	O
possible	O
to	O
reindex	B-API
a	O
pandas	O
DataFrame	B-API
using	O
a	O
column	O
made	O
up	O
of	O
datetime	O
objects	O
?	O

I	O
have	O
a	O
DataFrame	B-API
`	O
df	O
`	O
with	O
the	O
following	O
columns	O
:	O
#CODE	O

I	O
can	O
reindex	B-API
the	O
`	O
df	O
`	O
easily	O
along	O
`	O
DOYtimestamp	O
`	O
with	O
:	O
`	O
df.reindex	B-API
(	O
index	O
=d	O
f.dtstamp	O
)`	O

and	O
`	O
DOYtimestamp	O
`	O
has	O
the	O
following	O
values	O
:	O
#CODE	O

but	O
I'd	O
like	O
to	O
reindex	B-API
the	O
DataFrame	B-API
along	O
`	O
dtstamp	O
`	O
which	O
is	O
made	O
up	O
of	O
datetime	O
objects	O
so	O
that	O
I	O
generate	O
different	O
timestamps	O
directly	O
from	O
the	O
index	O
.	O

The	O
`	O
dtstamp	O
`	O
column	O
has	O
values	O
which	O
look	O
like	O
:	O
#CODE	O

When	O
I	O
try	O
and	O
reindex	B-API
`	O
df	O
`	O
along	O
`	O
dtstamp	O
`	O
I	O
get	O
the	O
following	O
:	O
#CODE	O

I'm	O
just	O
not	O
sure	O
what	O
I	O
need	O
to	O
do	O
get	O
the	O
index	O
to	O
be	O
of	O
a	O
datetime	O
type	O
.	O

Any	O
thoughts	O
?	O

It	O
sounds	O
like	O
you	O
don't	O
want	O
reindex	B-API
.	O

Somewhat	O
confusingly	O
`	O
reindex	B-API
`	O
is	O
not	O
for	O
defining	O
a	O
new	O
index	O
,	O
exactly	O
;	O
rather	O
,	O
it	O
looks	O
for	O
rows	O
that	O
have	O
the	O
specified	O
indices	O
.	O

So	O
if	O
you	O
have	O
a	O
DataFrame	B-API
with	O
index	O
`	O
[	O
0	O
,	O
1	O
,	O
2	O
]`	O
,	O
then	O
doing	O
a	O
`	O
reindex	B-API
([	O
2	O
,	O
1	O
,	O
0	O
])`	O
will	O
return	O
the	O
rows	O
in	O
reverse	O
order	O
.	O

Doing	O
something	O
like	O
`	O
reindex	B-API
([8	O
,	O
9	O
,	O
10	O
])`	O
does	O
not	O
make	O
a	O
new	O
index	O
for	O
the	O
rows	O
;	O
rather	O
,	O
it	O
will	O
return	O
a	O
DataFrame	B-API
with	O
`	O
NaN	O
`	O
values	O
,	O
since	O
there	O
are	O
no	O
rows	O
with	O
indices	O
8	O
,	O
9	O
,	O
or	O
10	O
.	O

It	O
seems	O
like	O
what	O
you	O
want	O
is	O
to	O
just	O
keep	O
the	O
same	O
rows	O
,	O
but	O
make	O
a	O
totally	O
new	O
index	O
for	O
them	O
.	O

For	O
that	O
you	O
can	O
just	O
assign	B-API
to	O
the	O
index	O
directly	O
.	O

So	O
try	O
doing	O
`	O
df.index	O
=	O
df	O
[	O
'	O
dtstamp	O
']`	O
.	O

Thanks	O
,	O
that	O
does	O
exactly	O
what	O
I	O
need	O
.	O

Somehow	O
it	O
wasn't	O
clear	O
to	O
me	O
that	O
I	O
could	O
assign	B-API
one	O
of	O
the	O
columns	O
to	O
the	O
index	O
.	O

You	O
can	O
also	O
use	O
the	O
`	O
set_index	B-API
`	O
method	O

autoscaling	O
in	O
matplotlib	O
,	O
plotting	O
different	O
time	O
series	B-API
in	O
same	O
chart	O

I	O
have	O
a	O
'	O
master	O
'	O
panda	O
dataframe	B-API
that	O
has	O
a	O
time	O
series	B-API
of	O
'	O
polarity	O
'	O
values	O
for	O
several	O
terms	O
.	O

I	O
want	O
to	O
work	O
with	O
4	O
of	O
them	O
,	O
so	O
I	O
extracted	O
4	O
separate	O
dataframes	O
,	O
containing	O
the	O
time	O
series	B-API
(	O
same	O
time	O
series	B-API
for	O
all	O
of	O
the	O
terms	O
,	O
but	O
different	O
polarity	O
values	O
.	O
)	O

I	O
plotted	O
them	O
in	O
4	O
separate	O
matplotlib	O
graphs	O
,	O
using	O
the	O
code	O
below	O
#CODE	O

Now	O
,	O
I	O
want	O
to	O
graph	O
them	O
all	O
in	O
the	O
same	O
graph	O
so	O
I	O
have	O
an	O
idea	O
of	O
the	O
magnitude	O
of	O
each	O
graph	O
,	O
because	O
the	O
auto	O
scaling	O
of	O
matplotlib	O
can	O
give	O
the	O
wrong	O
impression	O
about	O
the	O
magnitude	O
by	O
just	O
looking	O
at	O
the	O
graphs	O
.	O

Two	O
questions	O
:	O

1	O
)	O
Is	O
there	O
are	O
way	O
to	O
set	O
the	O
min	O
and	O
max	O
values	O
of	O
the	O
Y-axis	O
when	O
plotting	O
?	O

2	O
)	O
I	O
am	O
not	O
an	O
expert	O
in	O
matplotlib	O
,	O
so	O
I	O
am	O
not	O
sure	O
how	O
to	O
plot	O
the	O
4	O
variables	O
in	O
the	O
same	O
graph	O
using	O
different	O
colors	O
,	O
markers	O
,	O
labels	O
,	O
etc	O
.	O

I	O
tried	O
nrows	O
=	O
1	O
,	O
ncols	O
=	O
1	O
but	O
can't	O
plot	O
anything	O
.	O

Thank	O
you	O

did	O
you	O
check	O
the	O
approach	O
of	O
the	O
answer	O
below	O
?	O

`	O
axes	O
[	O
i	O
,	O
j	O
]	O
.set_ylim	O
([	O
min	O
,	O
max	O
]	O
,	O
auto=False	O
)`	O
will	O
set	O
the	O
y-limits	O
of	O
the	O
plot	O
in	O
the	O
`	O
i	O
,	O
j	O
`	O
th	O
plot	O
.	O

`	O
auto=False	O
`	O
keeps	O
it	O
from	O
clobbering	O
your	O
settings	O
.	O

You	O
can	O
plot	O
multiple	O
lines	O
on	O
the	O
same	O
graph	O
by	O
calling	O
`	O
plt.hold	O
(	O
True	O
)`	O
,	O
drawing	O
a	O
bunch	O
of	O
plots	O
,	O
and	O
then	O
calling	O
`	O
plt.show()	O
`	O
or	O
`	O
plt.savefig	O
(	O
filename	O
)`	O
.	O

You	O
can	O
pass	O
a	O
color	O
code	O
into	O
`	O
plt.plot()	O
`	O
as	O
a	O
third	O
positional	O
argument	O
.	O

The	O
syntax	O
is	O
a	O
little	O
byzantine	O
(	O
it's	O
inherited	O
from	O
MATLAB	O
);	O
it's	O
documented	O
in	O
the	O
matplotlib.pyplot.plot	O
documentation	O
.	O

You	O
can	O
pass	O
this	O
argument	O
to	O
`	O
DataFrame.plot	B-API
`	O
as	O
(	O
for	O
example	O
)	O
`	O
style=	O
'	O
k	O
--	O
'`	O
.	O

For	O
your	O
case	O
,	O
I	O
would	O
try	O
#CODE	O

You	O
can	O
perhaps	O
loop	O
into	O
your	O
`	O
AxesSubplot	O
`	O
objects	O
and	O
call	O
`	O
autoscale	O
`	O
passing	O
the	O
`	O
axis	O
`	O
parameter	O
:	O
#CODE	O

Thank	O
you	O
!	O

A	O
combination	O
/	O
hybrid	O
of	O
the	O
two	O
suggestions	O
worked	O
for	O
me	O
.	O

Thank	O
you	O
.	O

pandas	O
rearrange	O
dataframe	B-API
to	O
have	O
all	O
values	O
in	O
ascending	O
order	O
per	O
every	O
column	O
independently	O

The	O
title	O
should	O
say	O
it	O
all	O
,	O
I	O
want	O
to	O
turn	O
this	O
DataFrame	B-API
:	O
#CODE	O

into	O
this	O
DataFrame	B-API
:	O
#CODE	O

And	O
I	O
want	O
to	O
do	O
it	O
in	O
a	O
nice	O
manner	O
.	O

The	O
ugly	O
solution	O
would	O
be	O
to	O
take	O
every	O
column	O
and	O
form	O
a	O
new	O
DataFrame	B-API
.	O

To	O
test	O
,	O
use	O
:	O
#CODE	O

This	O
is	O
a	O
bit	O
tricky	O
due	O
to	O
the	O
presence	O
of	O
the	O
`	O
NaN	O
`	O
,	O
one	O
method	O
would	O
be	O
to	O
sort	O
the	O
columns	O
that	O
have	O
no	O
NaNs	O
and	O
then	O
sort	O
the	O
columns	O
with	O
NaN	O
and	O
concat	B-API
them	O
together	O
,	O
does	O
that	O
sound	O
reasonable	O
?	O

If	O
you	O
can	O
give	O
a	O
solution	O
that	O
is	O
better	O
than	O
using	O
df.values	B-API
in	O
np	O
(	O
that	O
is	O
without	O
leaving	O
pandas	O
)	O
then	O
go	O
ahead	O
.	O

The	O
desired	O
sort	O
ignores	O
the	O
index	O
values	O
,	O
so	O
the	O
operation	O
appears	O
to	O
be	O
more	O

like	O
a	O
NumPy	O
operation	O
than	O
a	O
Pandas	O
one	O
:	O
#CODE	O

yields	O
#CODE	O

awesome	O
,	O
thanks	O
!	O

Inconsistent	O
Nan	O
Key	O
Error	O
using	O
Pandas	O
Apply	B-API

I'm	O
recoding	O
multiple	O
columns	O
in	O
a	O
dataframe	B-API
and	O
have	O
come	O
across	O
a	O
strange	O
result	O
that	O
I	O
can't	O
quite	O
figure	O
out	O
.	O

I'm	O
probably	O
not	O
recoding	O
in	O
the	O
most	O
efficient	O
manner	O
possible	O
,	O
but	O
it's	O
mostly	O
the	O
error	O
that	O
I'm	O
hoping	O
someone	O
can	O
explain	O
.	O

#CODE	O

s1	O
works	O
fine	O
,	O
but	O
when	O
I	O
try	O
to	O
do	O
the	O
same	O
thing	O
with	O
a	O
list	O
of	O
integers	O
and	O
a	O
np.nan	O
,	O
I	O
get	O
`	O
KeyError	O
:	O
nan	O
`	O
which	O
is	O
confusing	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
.	O

A	O
workaround	O
is	O
to	O
use	O
the	O
get	O
dict	O
method	O
,	O
rather	O
than	O
the	O
lambda	O
:	O
#CODE	O

It's	O
not	O
clear	O
to	O
me	O
right	O
now	O
why	O
this	O
is	O
different	O
...	O

Note	O
:	O
the	O
dicts	O
can	O
be	O
accessed	O
by	O
nan	O
:	O
#CODE	O

and	O
`	O
hash	O
(	O
np.nan	O
)	O
==	O
0	O
`	O
so	O
it's	O
not	O
that	O
...	O

Update	O
:	O
Apparently	O
the	O
issue	O
is	O
with	O
`	O
np.nan	O
`	O
vs	O
`	O
np.float64	O
(	O
np.nan	O
)`	O
,	O
the	O
former	O
has	O
`	O
np.nan	O
is	O
np.nan	O
`	O
(	O
because	O
`	O
np.nan	O
`	O
is	O
bound	O
to	O
a	O
specific	O
instantiated	O
nan	O
object	O
)	O
whilst	O
`	O
float	O
(	O
'	O
nan	O
')	O
is	O
not	O
float	O
(	O
'	O
nan	O
')`	O
:	O

This	O
means	O
that	O
get	O
won't	O
find	O
`	O
float	O
(	O
'	O
nan	O
')`	O
:	O
#CODE	O

This	O
means	O
you	O
can	O
actually	O
retrieve	O
the	O
nans	O
from	O
a	O
dict	O
,	O
any	O
such	O
retrieval	O
would	O
be	O
implementation	O
specific	O
!	O

In	O
fact	O
,	O
as	O
the	O
dict	O
uses	O
the	O
id	O
of	O
these	O
nans	O
,	O
this	O
entire	O
behavior	O
above	O
may	O
be	O
implementation	O
specific	O
(	O
if	O
nan	O
shared	O
the	O
same	O
id	O
,	O
as	O
they	O
may	O
do	O
in	O
a	O
REPL	O
/	O
ipython	O
session	O
)	O
.	O

You	O
can	O
catch	O
the	O
nullness	O
beforehand	O
:	O
#CODE	O

But	O
I	O
think	O
the	O
original	O
suggestion	O
of	O
using	O
.get	B-API
is	O
a	O
better	O
option	O
.	O

I	O
think	O
this	O
may	O
be	O
a	O
bug	O
in	O
apply	B-API
/	O
map_infer	O
,	O
definitely	O
worth	O
a	O
github	O
issue	O
.	O

Thanks	O
for	O
the	O
sanity	O
check	O
.	O

I	O
opened	O
an	O
issue	O
on	O
github	O
.	O

Great	O
,	O
thanks	O
!	O

#URL	O

@USER	O
Ah	O
yes	O
,	O
I	O
meant	O
is	O
.	O

Thanks	O
!!	O

Pandas	O
DataFrame	B-API
index	O
by	O
belonging	O
to	O
a	O
set	O

I	O
have	O
a	O
Pandas	O
DataFrame	B-API
that	O
,	O
among	O
the	O
columns	O
,	O
has	O
one	O
called	O
Phone_Number	O
.	O

I	O
want	O
to	O
get	O
just	O
the	O
rows	O
that	O
have	O
a	O
phone	O
number	O
that	O
shows	O
50	O
times	O
or	O
more	O
.	O

My	O
best	O
attempt	O
was	O
this	O
:	O
#CODE	O

I	O
get	O
,	O
however	O
,	O
this	O
error	O
:	O
TypeError	O
:	O
'	O
Series	B-API
'	O
objects	O
are	O
mutable	O
,	O
thus	O
they	O
cannot	O
be	O
hashed	O

What	O
would	O
be	O
the	O
best	O
way	O
to	O
get	O
the	O
rows	O
in	O
the	O
data	O
frame	O
for	O
this	O
situation	O
?	O

Thank	O
you	O
very	O
much	O
!	O

Use	O
`	O
isin()	B-API
`	O
:	O
#URL	O

Thank	O
you	O
,	O
@USER	O
!	O

It	O
does	O
not	O
throw	O
an	O
error	O
,	O
but	O
I	O
get	O
an	O
empty	O
set	O
,	O
which	O
I	O
thought	O
wasn't	O
possible	O
(	O
the	O
counts	O
set	O
is	O
not	O
empty	O
,	O
and	O
was	O
generated	O
from	O
the	O
phone	O
numbers	O
contained	O
in	O
'	O
data	O
')	O

That's	O
odd	O
,	O
I	O
would	O
have	O
thought	O
`	O
data	O
[	O
data.Phone_Number.isin	O
(	O
counts.index	O
)]`	O
would	O
work	O
.	O

Are	O
you	O
able	O
to	O
post	O
a	O
small	O
sample	O
of	O
your	O
data	O
?	O

@USER	O
thanks	O
again	O
,	O
my	O
mistake	O
was	O
not	O
to	O
use	O
isin	B-API
(	O
counts.index	O
)	O
but	O
just	O
isin	B-API
(	O
counts	O
)	O
,	O
this	O
is	O
also	O
a	O
valid	O
solution	O
for	O
the	O
problem	O
.	O

You	O
can	O
use	O
`	O
groupby	B-API
`	O
with	O
`	O
filter	B-API
`	O
.	O

#CODE	O

Thank	O
you	O
,	O
@USER	O
-li	O
!	O

Python	O
Pandas	O
hdfstore's	O
select	O
(	O
where=	O
'')	O
return	O
unqualified	O
results	O

When	O
I	O
query	O
a	O
large	O
hdfstore	O
file	O
(	O
>	O
10G	O
)	O
like	O
this	O
:	O
#CODE	O

I	O
got	O
results	O
where	O
most	O
entries	O
'	O
node_id	O
is	O
1	O
,	O
but	O
some	O
entries	O
have	O
node_id	O
other	O
than	O
1	O
.	O

So	O
is	O
it	O
a	O
hdfstore	O
glitch	O
,	O
or	O
I	O
did	O
something	O
wrong	O
?	O

Here	O
is	O
part	O
of	O
the	O
results	O
you	O
can	O
see	O
there	O
are	O
some	O
entries	O
with	O
node_id	O
other	O
than	O
1	O
.	O

#CODE	O

Noticing	O
row	O
300002	O
is	O
an	O
unwanted	O
result	O
,	O
I	O
try	O
to	O
select	O
node	O
1	O
around	O
that	O
particular	O
area	O
like	O
this	O
:	O
#CODE	O

Only	O
node	O
3	O
is	O
returned	O
in	O
the	O
result	O
:	O
#CODE	O

Then	O
I	O
try	O
use	O
index	O
instead	O
of	O
start	O
/	O
stop	O
like	O
this	O
:	O
#CODE	O

And	O
this	O
time	O
it	O
returned	O
correct	O
results	O
:	O
#CODE	O

I	O
guess	O
I	O
might	O
walk	O
around	O
this	O
problem	O
with	O
selection	O
on	O
index	O
,	O
but	O
I	O
am	O
not	O
completely	O
sure	O
because	O
the	O
method	O
with	O
start	O
/	O
stop	O
also	O
get	O
the	O
correct	O
results	O
most	O
of	O
the	O
time	O
,	O
so	O
even	O
though	O
the	O
method	O
with	O
index	O
got	O
it	O
right	O
where	O
start	O
/	O
stop	O
failed	O
,	O
it	O
might	O
fail	O
somewhere	O
else	O
.	O

And	O
I	O
would	O
really	O
like	O
the	O
start	O
/	O
stop	O
method	O
to	O
work	O
,	O
because	O
it	O
is	O
much	O
faster	O
,	O
and	O
I	O
have	O
a	O
large	O
data	O
set	O
,	O
a	O
slow	O
method	O
is	O
really	O
time-consuming	O
.	O

BTW	O
,	O
In	O
case	O
you	O
are	O
wondering	O
,	O
I	O
cannot	O
use	O
'	O
chunksize	O
'	O
like	O
this	O
:	O
#CODE	O

Every	O
time	O
I	O
try	O
chunksize	O
I	O
got	O
a	O
MemoryError	O
like	O
this	O
.	O

Struggling	O
with	O
many	O
problems	O
,	O
Pandas	O
is	O
really	O
tough	O
for	O
a	O
newbie	O
like	O
me	O
.	O

Any	O
help	O
is	O
greatly	O
appreciated	O
.	O

This	O
was	O
a	O
recently	O
fixed	O
bug	O
in	O
`	O
PyTables	O
`	O
,	O
see	O
the	O
related	O
issue	O
here	O
.	O

In	O
effect	O
on	O
some	O
larger	O
stores	O
the	O
indexers	O
where	O
not	O
computed	O
correctly	O
when	O
using	O
a	O
`	O
where	B-API
`	O
and	O
`	O
start	O
/	O
stop	O
`	O
.	O

You	O
will	O
need	O
to	O
update	O
to	O
`	O
PyTables	O
`	O
3.2	O
,	O
then	O
re-write	O
the	O
store	O
itself	O
.	O

You	O
can	O
either	O
recreate	O
it	O
how	O
you	O
did	O
the	O
first	O
time	O
,	O
or	O
use	O
ptrepack	O

I	O
use	O
anaconda	O
,	O
and	O
I	O
cannot	O
upgrade	O
with	O
`	O
conda	O
update	O
pytables	O
`	O
,	O
it	O
says	O
"	O
already	O
installed	O
"	O
.	O

Then	O
I	O
tried	O
`	O
pip	O
install	O
--	O
upgrade	O
tables	O
`	O
,	O
it	O
says	O
`	O
LINK	O
:	O
fatal	O
error	O
LNK1181	O
:	O
cannot	O
open	O
input	O
file	O
'	O
hdf5dll.lib	O
'	O
...	O

ERROR	O
::	O
Could	O
not	O
find	O
a	O
local	O
HDF5	O
installation	O
.	O

`	O
I	O
searched	O
my	O
harddisk	O
,	O
and	O
couldn't	O
find	O
hdf5dll.lib	O
file	O
.	O

Pandas	O
:	O
Crash	O
when	O
dividing	O
one	O
column	O
by	O
the	O
other	O
with	O
index	O
set	O

I	O
have	O
a	O
larger	O
data	O
set	O
,	O
with	O
121232	O
rows	O
and	O
many	O
columns	O
:	O
#CODE	O

If	O
I	O
do	O
#CODE	O

pandas	O
,	O
python	O
,	O
my	O
editor	O
(	O
PyCharm	O
)	O
and	O
Windows	O
7	O
all	O
together	O
crash	O
,	O
one	O
after	O
the	O
other	O
.	O

I	O
guess	O
there	O
is	O
an	O
additional	O
issue	O
related	O
to	O
PyCharm	O
and	O
its	O
memory	O
usage	O
,	O
but	O
this	O
should	O
not	O
be	O
happening	O
inside	O
pandas	O
in	O
the	O
first	O
place	O
,	O
should	O
it	O
?	O

By	O
the	O
way	O
,	O
if	O
I	O
reset	O
the	O
index	O
before	O
the	O
division	O
,	O
`	O
pandas	O
`	O
does	O
not	O
crash	O
.	O

My	O
pandas	O
version	O
is	O
`	O
0.13.1	O
`	O
.	O

My	O
Python	O
system	O
:	O
`	O
2.7.3	O
|	O
64-bit	O
|	O
(	O
default	O
,	O
Aug	O
8	O
2013	O
,	O
05:30	O
:	O
12	O
)	O
[	O
MSC	O
v.1500	O
64	O
bit	O
(	O
AMD64	O
)`	O

How	O
many	O
rows	O
and	O
are	O
you	O
using	O
64-bit	O
python	O
?	O

updated	O
the	O
question	O

This	O
worked	O
fine	O
for	O
me	O
using	O
ipython	O
2.0	O
python	O
3.3	O
64-bit	O
pandas	O
0.13.1	O
,	O
maybe	O
a	O
problem	O
with	O
pycharm	O
,	O
I	O
have	O
16gb	O
on	O
my	O
machine	O
but	O
I	O
don't	O
think	O
that	O
should	O
make	O
a	O
difference	O
as	O
your	O
dataset	O
size	O
is	O
small	O
.	O

Not	O
sure	O
why	O
resetting	O
the	O
index	O
would	O
suddenly	O
make	O
it	O
work	O

Skip	O
last	O
row	O
when	O
importing	O
CSV	O
into	O
Pandas.DataFrame	B-API

`	O
pd.read_csv	B-API
(	O
f	O
,	O
skiprows=n	O
)`	O
skips	O
only	O
the	O
first	O
`	O
n	O
`	O
rows	O
of	O
the	O
CSV	O
.	O

Is	O
it	O
possible	O
to	O
skip	O
the	O
last	O
X	O
rows	O
of	O
a	O
CSV	O
file	O
when	O
importing	O
it	O
into	O
a	O
`	O
pandas.DataFrame	B-API
`	O
?	O

See	O
the	O
other	O
answer	O
for	O
the	O
question	O
just	O
pass	O
`	O
skipfooter=n	O
`	O
to	O
`	O
read_csv	B-API
`	O

How	O
to	O
remove	O
the	O
u	O
'	O
and	O
some	O
other	O
information	O
from	O
Ipython	O
/	O
Pandas	O
output	O

I've	O
been	O
reading	O
the	O
great	O
Python	O
for	O
Data	O
Analysis	O
book	O
and	O
following	O
its	O
exercises	O
along	O
,	O
but	O
my	O
outputs	O
are	O
not	O
the	O
same	O
that	O
the	O
outputs	O
shown	O
in	O
the	O
book	O
.	O

One	O
of	O
them	O
happens	O
when	O
I	O
want	O
to	O
print	O
the	O
indices	O
of	O
a	O
data	O
frame	O
object	O
.	O

For	O
example	O
:	O
#CODE	O

When	O
I	O
call	O
data.index	O
,	O
I	O
get	O
a	O
output	O
different	O
from	O
the	O
book	O
.	O

Here's	O
the	O
output	O
shown	O
in	O
the	O
book	O
:	O
#CODE	O

And	O
this	O
is	O
my	O
output	O
:	O
#CODE	O

How	O
do	O
I	O
configure	O
either	O
Ipython	O
or	O
Pandas	O
to	O
change	O
the	O
output	O
formatting	O
?	O

At	O
least	O
the	O
u	O
'	O
piece	O
of	O
string	O
.	O

Edit	O
:	O
I'm	O
using	O
Python	O
2.7	O
.	O

It	O
just	O
means	O
its	O
a	O
unicode	O
string	O
,	O
it	O
shouldn't	O
affect	O
any	O
operations	O
so	O
it's	O
a	O
display	O
thing	O
,	O
see	O
this	O
:	O
#URL	O

Also	O
,	O
that	O
book	O
is	O
based	O
on	O
a	O
somewhat	O
older	O
version	O
of	O
pandas	O
and	O
some	O
things	O
(	O
like	O
indexes	O
)	O
have	O
changed	O
in	O
the	O
meantime	O
.	O

It	O
shouldn't	O
be	O
a	O
problem	O
for	O
the	O
most	O
part	O
,	O
as	O
old	O
ways	O
of	O
doing	O
things	O
will	O
mostly	O
continue	O
to	O
work	O
even	O
as	O
better	O
ways	O
to	O
do	O
them	O
are	O
provided	O
.	O

You	O
can	O
look	O
at	O
the	O
release	O
notes	O
in	O
the	O
docs	O
if	O
you	O
want	O
to	O
see	O
how	O
things	O
have	O
changed	O

your	O
output	O
is	O
different	O
from	O
what	O
you	O
can	O
see	O
in	O
the	O
structure	O
itself	O
,	O
see	O
answer	O
below	O
.	O

EdChum	O
summarized	O
about	O
the	O
unicode	O
character	O
before	O
each	O
string	O
.	O

Using	O
Python	O
3	O
would	O
be	O
one	O
way	O
to	O
get	O
rid	O
of	O
the	O
`	O
u	O
`	O
prefixes	O
,	O
though	O
perhaps	O
a	O
bit	O
of	O
a	O
drastic	O
one	O
.	O

You	O
can	O
have	O
this	O
display	O
if	O
you	O
do	O
a	O
`	O
list	O
`	O
conversion	O
:	O
#CODE	O

How	O
to	O
get	O
the	O
reverse	O
percentile	O
for	O
a	O
list	O
of	O
scores	O
from	O
a	O
huge	O
txt	O
file	O
?	O

I	O
have	O
a	O
very	O
big	O
text	O
file	O
(	O
>	O
80Gb	O
)	O
.	O

It	O
contains	O
tab-delimited	O
values	O
.	O

I	O
am	O
interested	O
only	O
in	O
one	O
column	O
.	O

For	O
that	O
specific	O
column	O
,	O
I	O
want	O
to	O
get	O
the	O
reverse	O
percentile	O
for	O
~10	O
thresholds	O
.	O

So	O
basically	O
,	O
my	O
questions	O
look	O
like	O
this	O
:	O
"	O
What	O
is	O
the	O
percentage	O
of	O
rows	O
where	O
the	O
value	O
of	O
column	O
x	O
is	O
below	O
$threshold	O
?	O

"	O
.	O

Thresholds	O
are	O
roughly	O
1	O
,	O
5	O
,	O
10	O
,	O
100	O
,	O
500	O
,	O
1000	O
.	O

Sample	O
data	O
:	O
#CODE	O

In	O
the	O
above	O
case	O
,	O
I	O
would	O
like	O
to	O
ask	O
"	O
What	O
is	O
the	O
percentage	O
of	O
values	O
below	O
500	O
?	O

"	O
and	O
the	O
answer	O
would	O
be	O
80%	O
.	O

How	O
would	O
I	O
do	O
this	O
?	O

Notes	O
:	O

Using	O
awk	O
to	O
filter	O
the	O
file	O
first	O
for	O
the	O
interesting	O
column	O
took	O
~26mins	O
which	O
is	O
fine	O
speed-wise	O
(	O
ended	O
up	O
with	O
a	O
file	O
10Gb	O
)	O
.	O

Reading	O
the	O
resulting	O
file	O
into	O
a	O
pandas	O
data	O
frame	O
takes	O
~7	O
mins	O
;	O
but	O
the	O
calculation	O
(	O
`	O
df	O
[	O
df	O
threshold	O
]	O
.shape	B-API
(	O
0	O
)	O
/	O
total_length	O
`)	O
takes	O
way	O
too	O
long	O
.	O

I	O
stopped	O
calculations	O
after	O
a	O
couple	O
of	O
hours	O
.	O

I	O
guess	O
~1h	O
would	O
be	O
okay	O
.	O

`	O
wc	O
-l	O
filename	O
`	O
and	O
`	O
df	O
=	O
pd.read_csv	B-API
(	O
filename	O
,	O
sep=	O
'	O
\t	O
'	O
,	O
header=None	O
);	O
print	O
(	O
pandasdataframe	O
)`	O
yielded	O
a	O
different	O
number	O
of	O
rows	O
which	O
astonished	O
me	O
.	O

(	O
I'm	O
new	O
to	O
Pandas	O
,	O
though	O
)	O
.	O

I'd	O
prefer	O
a	O
solution	O
in	O
Python	O
/	O
Shell	O
but	O
I'm	O
open	O
for	O
any	O
ideas	O
.	O

EDIT	O
:	O

The	O
answer	O
below	O
is	O
correct	O
.	O

I	O
came	O
up	O
with	O
the	O
script	O
below	O
.	O

FYI	O
,	O
reading	O
the	O
prefiltered	O
file	O
(	O
one	O
column	O
only	O
,	O
10G	O
)	O
took	O
1h02	O
and	O
reading	O
the	O
original	O
file	O
(	O
5	O
cols	O
,	O
>	O
80G	O
)	O
took	O
1h16	O
.	O

For	O
the	O
sake	O
of	O
simplicity	O
,	O
I	O
won't	O
prefilter	O
the	O
file	O
then	O
.	O
mawk	O
was	O
2x	O
better	O
than	O
gawk	O
in	O
my	O
tests	O
.	O

I	O
used	O
`	O
NR	O
`	O
instead	O
of	O
`	O
(	O
NR-1	O
)`	O
as	O
there	O
is	O
no	O
header	O
row	O
.	O

#CODE	O

This	O
code	O
should	O
be	O
fast	O
enough	O
:	O
`	O
awk	O
'	O
BEGIN	O
{	O
n=0	O
;	O
getline}	O
;	O
{	O
if	O
(	O
$3	O
<	O
500	O
)	O
{	O
n+=1	O
}}	O
END	O
{	O
print	O
n	O
/(	O
NR-1	O
)	O
*100	O
}	O
'	O
x.txt	O
`	O

@USER	O
What	O
is	O
the	O
point	O
of	O
that	O
begin	O
block	O
?	O

@USER	O
,	O
to	O
skip	O
the	O
header	O
line	O

@USER	O
ahh	O
okay	O
,	O
don't	O
need	O
the	O
n=0	O
though	O
.	O

All	O
variables	O
are	O
initialised	O
at	O
0	O
anyway	O
in	O
awk	O
.	O

@USER	O
,	O
yes	O
,	O
that's	O
true	O
.	O

Explicit	O
is	O
better	O
than	O
implicit	O
...	O

No	O
,	O
explicit	O
is	O
NOT	O
better	O
than	O
implicit	O
.	O

If	O
it	O
were	O
we'd	O
all	O
be	O
writing	O
assembly	O
code	O
.	O

Conciseness	O
is	O
an	O
attribute	O
of	O
good	O
software	O
.	O

@USER	O
Thanks	O
,	O
that	O
helped	O
.	O

I	O
would	O
suggest	O
using	O
awk	O
to	O
do	O
this	O
:	O
#CODE	O

For	O
all	O
lines	O
after	O
the	O
first	O
one	O
where	O
the	O
third	O
field	O
is	O
less	O
than	O
500	O
,	O
increment	O
`	O
n	O
`	O
.	O

Once	O
the	O
file	O
has	O
been	O
processed	O
,	O
print	O
the	O
percentage	O
,	O
as	O
long	O
as	O
one	O
or	O
more	O
records	O
have	O
been	O
read	O
(	O
this	O
avoids	O
a	O
division	O
by	O
0	O
)	O
.	O

Pandas	O
FloatingPoint	O
Error	O

I'm	O
getting	O
a	O
floating	O
point	O
error	O
on	O
a	O
simple	O
time	O
series	B-API
in	O
pandas	O
.	O

I'm	O
trying	O
to	O
do	O
shift	O
operations	O
...	O
but	O
this	O
also	O
happens	O
with	O
the	O
window	O
functions	O
like	O
`	O
rolling_mean	B-API
`	O
.	O

EDIT	O
:	O
For	O
some	O
more	O
info	O
...	O

I	O
tried	O
to	O
actually	O
build	O
this	O
from	O
source	O
yesterday	O
prior	O
to	O
the	O
error	O
.	O

I'm	O
not	O
sure	O
if	O
the	O
error	O
would've	O
occurred	O
prior	O
the	O
build	O
attempt	O
,	O
as	O
I'd	O
never	O
messed	O
around	O
w	O
these	O
functions	O
.	O

EDIT2	O
:	O
I	O
thought	O
I'd	O
fixed	O
this	O
,	O
but	O
when	O
I	O
run	O
this	O
inside	O
python	O
it	O
works	O
,	O
but	O
when	O
it's	O
in	O
ipython	O
I	O
get	O
the	O
error	O
.	O

EDIT3	O
:	O
Numpy	O
1.7.0	O
,	O
iPython	O
0.13	O
,	O
pandas	O
0.7.3	O
#CODE	O

Works	O
fine	O
for	O
me	O
.	O

Python	O
2.7.3	O
,	O
pandas	O
0.7.0	O

Thanks	O
-	O
are	O
did	O
you	O
try	O
this	O
in	O
ipython	O
or	O
python	O
?	O

What	O
version	O
of	O
NumPy	O
?	O

1.7.0	O
,	O
installed	O
using	O
the	O
scipysuperpack	O

PS	O
,	O
just	O
bought	O
your	O
Python	O
for	O
Data	O
Analysis	O
early	O
release	O
,	O
which	O
is	O
great	O
,	O
but	O
also	O
how	O
I	O
ran	O
into	O
this	O
.	O

Yes	O
,	O
I	O
tried	O
with	O
ipython	O
without	O
any	O
problems	O
.	O

Though	O
mine	O
was	O
0.12.1	O
.	O

You	O
are	O
using	O
a	O
development	O
version	O
,	O
both	O
for	O
ipython	O
and	O
numpy	O
.	O

It's	O
highly	O
possible	O
that	O
those	O
are	O
unstable	O
.	O

That	O
might	O
be	O
the	O
problem	O
.	O

I	O
would	O
add	O
this	O
as	O
a	O
comment	O
,	O
but	O
I	O
don't	O
have	O
the	O
privilege	O
to	O
do	O
that	O
yet	O
:)	O

It	O
works	O
for	O
me	O
in	O
python	O
and	O
iPython	O
0.12	O
;	O
iPython	O
0.13	O
is	O
still	O
in	O
development	O
(	O
see	O
#URL	O
)	O
,	O
and	O
,	O
since	O
the	O
errors	O
you're	O
getting	O
seem	O
to	O
involve	O
formatting	O
in	O
the	O
iPython	O
0.13	O
egg	O
,	O
I	O
suspect	O
that	O
might	O
be	O
the	O
cause	O
.	O

Try	O
with	O
iPython	O
0.12	O
instead	O
--	O
if	O
it	O
works	O
,	O
file	O
a	O
bug	O
report	O
with	O
iPython	O
and	O
then	O
probably	O
stick	O
with	O
0.12	O
until	O
0.13	O
is	O
(	O
more	O
)	O
stable	O
.	O

Thanks	O
for	O
the	O
reply	O
,	O
I'm	O
still	O
getting	O
the	O
error	O
on	O
0.12	O
.	O

So	O
it	O
seems	O
to	O
be	O
more	O
pervasive	O
in	O
my	O
system	O
.	O

Oddly	O
works	O
in	O
bpython	O
.	O

Hm	O
.	O

Just	O
a	O
stab	O
,	O
but	O
,	O
what	O
happens	O
if	O
you	O
try	O
np.abs	O
([	O
np.nan	O
,	O
1	O
,	O
2	O
,	O
3	O
])	O
in	O
iPython	O
?	O

Good	O
catch	O
...	O
throws	O
the	O
same	O
error	O
.	O

Thought	O
so	O
.	O

Are	O
you	O
sure	O
your	O
iPython	O
numpy	O
is	O
the	O
same	O
as	O
the	O
other	O
installs	O
?	O

Try	O
np.__version__	O
in	O
the	O
working	O
vs	O
.	O
nonworking	O
environments	O
.	O

It	O
is	O
the	O
same	O
version	O
`	O
1.7.0.dev-3cb783e	O
`	O
.	O

I'm	O
guessing	O
your	O
iPython	O
for	O
some	O
reason	O
is	O
operating	O
with	O
a	O
lower	O
error	O
threshold	O
.	O

The	O
FloatingPointError	O
about	O
the	O
NaN	O
raises	O
an	O
"	O
invalid	O
"	O
flag	O
which	O
is	O
usually	O
ignored	O
,	O
but	O
can	O
be	O
raised	O
if	O
desired	O
.	O

Check	O
out	O
the	O
docs	O
here	O
:	O
#URL	O
,	O
and	O
play	O
around	O
with	O
resetting	O
the	O
numpy	O
errors	O
as	O
in	O
the	O
examples	O
.	O

Does	O
that	O
fix	O
it	O
?	O

If	O
so	O
,	O
there	O
must	O
be	O
some	O
way	O
to	O
configure	O
the	O
error	O
levels	O
for	O
iPython	O
...	O

I've	O
solved	O
this	O
...	O
even	O
though	O
the	O
version	O
numbers	O
were	O
some	O
build	O
issues	O
I	O
guess	O
.	O

I	O
cleaned	O
up	O
the	O
packages	O
I	O
had	O
and	O
it	O
works	O
now	O
...	O
thanks	O
for	O
all	O
them	O
help	O
.	O

Get	O
last	O
"	O
column	O
"	O
after	O
.str	B-API
.split()	B-API
operation	O
on	O
column	O
in	O
pandas	O
DataFrame	B-API

I	O
have	O
a	O
column	O
in	O
a	O
pandas	O
DataFrame	B-API
that	O
I	O
would	O
like	O
to	O
split	O
on	O
a	O
single	O
space	O
.	O

The	O
splitting	O
is	O
simple	O
enough	O
with	O
`	O
DataFrame.str.split	O
(	O
'	O
')`	O
,	O
but	O
I	O
can't	O
make	O
a	O
new	O
column	O
from	O
the	O
last	O
entry	O
.	O

When	O
I	O
`	O
.str	B-API
.split()	B-API
`	O
the	O
column	O
I	O
get	O
a	O
list	O
of	O
arrays	O
and	O
I	O
don't	O
know	O
how	O
to	O
manipulate	O
this	O
to	O
get	O
a	O
new	O
column	O
for	O
my	O
DataFrame	B-API
.	O

Here	O
is	O
an	O
example	O
.	O

Each	O
entry	O
in	O
the	O
column	O
contains	O
'	O
symbol	O
data	O
price	O
'	O
and	O
I	O
would	O
like	O
to	O
split	O
off	O
the	O
price	O
(	O
and	O
eventually	O
remove	O
the	O
"	O
p	O
"	O
...	O
or	O
"	O
c	O
"	O
in	O
half	O
the	O
cases	O
)	O
.	O

#CODE	O

which	O
yields	O
#CODE	O

But	O
`	O
temp2	O
[	O
0	O
]`	O
just	O
gives	O
one	O
list	O
entry's	O
array	O
and	O
`	O
temp2	O
[:	O
]	O
[	O
-1	O
]`	O
fails	O
.	O

How	O
can	O
I	O
convert	O
the	O
last	O
entry	O
in	O
each	O
array	O
to	O
a	O
new	O
column	O
?	O

Thanks	O
!	O

You	O
could	O
use	O
the	O
`	O
tolist	B-API
`	O
method	O
as	O
an	O
intermediary	O
:	O
#CODE	O

From	O
which	O
you	O
could	O
make	O
a	O
new	O
DataFrame	B-API
:	O
#CODE	O

For	O
good	O
measure	O
,	O
you	O
could	O
fix	O
the	O
price	O
:	O
#CODE	O

PS	O
:	O
but	O
if	O
you	O
really	O
just	O
want	O
the	O
last	O
column	O
,	O
`	O
apply	B-API
`	O
would	O
suffice	O
:	O
#CODE	O

Thanks	O
for	O
the	O
education	O
!	O

Do	O
this	O
:	O
#CODE	O

Love	O
the	O
clean	O
solution	O
!	O

from	O
the	O
author	O
of	O
"	O
Pandas	O
"	O
:)	O
