In	O
[	O
8]	O
:	O
%timeit	O
df	O
[	O
'	O
r	O
']	O
=	O
df	O
[[	O
'	O
minor	O
'	O
,	O
'	O
major	O
']]	O
.abs()	B-API
.max	B-API
(	O
axis=1	O
)	O

You	O
can	O
do	O
this	O
by	O
using	O
a	O
`	O
groupby()	B-API
.transform()	B-API
`	O
,	O
see	O
#URL	O

Specifying	O
dtype	B-API
in	O
pandas	O

Pandas	O
dropna	B-API
-	O
store	O
dropped	O
rows	O

I've	O
been	O
through	O
the	O
`	O
to_json	B-API
`	O
and	O
`	O
json.dumps	O
`	O
documentation	O
and	O
tried	O
different	O
kinds	O
of	O
indexes	O
and	O
dicts	O
,	O
and	O
I'm	O
getting	O
lost	O
...	O

EDIT	O
:	O
The	O
problem	O
stems	O
from	O
that	O
fact	O
that	O
I	O
am	O
using	O
an	O
irregular	O
calendar	O
in	O
`	O
num2date	B-API
`	O
which	O
violates	O
the	O
fact	O
that	O
`	O
pandas.PeriodIndex	O
`	O
needs	O
to	O
have	O
regular	O
intervals	O

`	O
df	O
[	O
"	O
YTD	O
"]	O
=	O
GroupedDat	O
[	O
'	O
CLOSE_SPX	O
']	O
.transform	B-API
(	O
lambda	O
x	O
:	O
x	O
/	O
x.iloc	O
[	O
0	O
]	O
-	O
1.0	O
)`	O

I'm	O
pretty	O
sure	O
there	O
is	O
a	O
way	O
to	O
do	O
this	O
with	O
apply()	B-API
but	O
I'm	O
not	O
getting	O
anywhere	O
.	O

when	O
specifying	O
dtypes	B-API
to	O
pass	O
to	O
`	O
read_csv	B-API
`	O
,	O
they	O
must	O
be	O
numpy	O
dtypes	B-API
;	O
and	O
string	O
dtypes	B-API
are	O
converted	O
to	O
`	O
object	O
`	O
dtype	B-API
(	O
so	O
the	O
`	O
s64	O
`	O
doesn't	O
do	O
anything	O
)	O
.	O
nor	O
does	O
the	O
`	O
datetime	O
`	O
,	O
that's	O
what	O
`	O
parse_dates	O
`	O
is	O
used	O
.	O

Without	O
the	O
dtype	B-API
parameter	O
,	O
the	O
column	O
is	O
imported	O
as	O
an	O
'	O
object	O
'	O
dtype	B-API
.	O

As	O
this	O
seems	O
a	O
bug	O
,	O
I	O
opened	O
an	O
issue	O
about	O
this	O
here	O
:	O
#URL	O
Workaround	O
for	O
now	O
is	O
indeed	O
using	O
`	O
.agg	B-API
(	O
lambda	O
x	O
:	O
x.idxmax()	O
)`	O
instead	O
of	O
using	O
`	O
.idxmax()	B-API
`	O

hi	O
Alexander	O
-	O
I	O
see	O
the	O
problem	O
with	O
my	O
iloc	B-API
columns	O
,	O
sorry	O
for	O
that	O
.	O

Pandas	O
module	O
read_csv	B-API
reads	O
file	O
within	O
Eclipse+pydev	O
while	O
fail	O
if	O
I	O
run	O
standalone	O

I've	O
tried	O
again	O
and	O
same	O
thing	O
,	O
it's	O
really	O
strange	O
because	O
set_index	B-API
has	O
the	O
inplace	O
argument	O
.	O

Was	O
too	O
lazy	O
too	O
lazy	O
to	O
do	O
an	O
actual	O
example	O
since	O
read_clipboard	B-API
doesn't	O
handle	O
MultiIndexes	O
:)	O
I'll	O
post	O
it	O
up	O
formally	O
later	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
`	O
.	O

`	O
(	O
although	O
the	O
`	O
.dt	B-API
`	O
part	O
might	O
only	O
work	O
if	O
you're	O
using	O
v0.15	O
of	O
Pandas	O
)	O

The	O
problem	O
can	O
be	O
fixed	O
by	O
converting	O
`	O
ts.index	O
`	O
to	O
a	O
`	O
DatetimeIndex	B-API
`	O
:	O
#CODE	O

It	O
is	O
still	O
a	O
numpy	O
object	O
,	O
regardless	O
of	O
`	O
dtype	B-API
`	O
.	O

Thanks	O
,	O
get_loc	B-API
is	O
what	O
I	O
need	O
.	O

You	O
can	O
`	O
get_level_values	B-API
`	O
in	O
conjunction	O
with	O
Boolean	O
slicing	O
.	O

Other	O
approaches	O
include	O
using	O
`	O
applymap	B-API
`	O
or	O
boolean	O
indexing	O
,	O
i.e.	O
#CODE	O

There's	O
a	O
good	O
chance	O
I'm	O
getting	O
lost	O
in	O
the	O
linspace	B-API
part	O
.	O

I	O
don't	O
think	O
.shift()	B-API
works	O
in	O
this	O
case	O
as	O
'	O
rule3	O
'	O
is	O
a	O
calculated	O
column	O
with	O
each	O
row	O
value	O
dependant	O
on	O
the	O
previous	O
row	O
value	O
.	O

And	O
even	O
when	O
I	O
follow	O
experienced	O
programmers	O
'	O
suggestions	O
of	O
using	O
.loc	B-API
,	O
same	O
warnings	O
persist	O
(	O
as	O
below	O
)	O
.	O

More	O
generally	O
,	O
what	O
is	O
the	O
syntax	O
for	O
`	O
iloc	B-API
`	O
for	O
Multi-level	O
DataFrames	O
?	O

The	O
(	O
dtype	B-API
)	O
line	O
is	O
useful	O
to	O
enforce	O
the	O
columns	O
type	O
to	O
not	O
fail	O
on	O
assert	O
(	O
could	O
be	O
optional	O
)	O
.	O

That	O
said	O
,	O
it	O
seems	O
to	O
have	O
a	O
form	O
(	O
see	O
edit	O
)	O
that	O
isn't	O
easily	O
passed	O
into	O
`	O
cumprod	B-API
`	O
.	O

And	O
using	O
pandas.Series.map	B-API
:	O
#CODE	O

In	O
your	O
example	O
,	O
try	O
df	O
[	O
df	O
[	O
0	O
]	O
>	O
8]	O
.ix	B-API
[	O
0	O
,	O
1	O
]	O
,	O
it	O
will	O
return	O
NaN	O
,	O
although	O
we	O
have	O
two	O
rows	O
in	O
the	O
result	O
and	O
we	O
should	O
be	O
able	O
to	O
access	O
them	O
using	O
.ix	B-API
[	O
0	O
,	O
1	O
]	O
.	O

Fairly	O
certain	O
from_product()	B-API
is	O
the	O
problem	O
.	O

To	O
summarize	O
:	O
Without	O
using	O
`	O
head()	B-API
`	O
the	O
`	O
merge()	B-API
`	O
output	O
is	O
showing	O
reduced	O
rows	O
(	O
#	O
rows	O
=	O
#	O
right	O
side	O
rows	O
)	O
and	O
each	O
ingredient	O
ID	O
is	O
simply	O
"	O
pasted	O
"	O
on	O
there	O
in	O
a	O
serial	O
manner	O
.	O

bookings	O
rolling_mean	B-API
rolling_std_dev	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

In	O
fact	O
,	O
for	O
some	O
types	O
,	O
`	O
str()	B-API
`	O
may	O
not	O
produce	O
anything	O
useful	O
for	O
you	O
.	O

`	O
pivot5min1.loc	O
[(	O
'	O
2013-06-19	O
09:30	O
:	O
00	O
'	O
,	O
'	O
ACCT1	O
')]	O
.loc	B-API
[	O
'	O
ABC	O
']`	O

When	O
you	O
say	O
it's	O
not	O
supported	O
,	O
are	O
you	O
specifically	O
talking	O
about	O
to_hdf	B-API
/	O
read_hdf	B-API
not	O
supporting	O
it	O
,	O
or	O
are	O
you	O
actually	O
saying	O
that	O
Pandas	O
in	O
general	O
doesn't	O
support	O
it	O
?	O

Can	O
you	O
confirm	O
that	O
the	O
dtype	B-API
is	O
a	O
datetime	O
based	O
one	O

apply()	B-API
with	O
trimming	O
and	O
custom	O
padding	O
worked	O
perfectly	O
.	O

Would	O
you	O
edit	O
your	O
answer	O
so	O
it	O
includes	O
the	O
`	O
dtype	B-API
=o	O
bject	O
`	O
suggestion	O
?	O

I	O
might	O
be	O
missing	O
something	O
,	O
but	O
this	O
seems	O
like	O
it	O
could	O
be	O
fully	O
vectorized	O
with	O
`	O
rolling_mean	B-API
`	O
and	O
`	O
rolling_std	B-API
`	O
?	O

Why	O
is	O
Pandas	O
Concatenation	O
(	O
pandas.concat	B-API
)	O
so	O
Memory	O
Inefficient	O
?	O

As	O
Andy	O
pointed	O
out	O
,	O
you	O
can	O
do	O
this	O
using	O
`	O
bdate_range	B-API
`	O
,	O
but	O
I	O
prefer	O
this	O
method	O
due	O
to	O
its	O
simplicity	O
and	O
readability	O

I'm	O
trying	O
to	O
monkeypatch	O
how	O
`	O
pandas	O
`	O
Panel's	O
slicing	O
(	O
`	O
__getitem__	B-API
`)	O
.	O

g.ax_joint.xaxis.set_major_locator	O
(	O
ticker.MultipleLocator	B-API
(	O
90	O
))	O

There	O
are	O
a	O
host	O
more	O
of	O
these	O
.dt	B-API
accessors	O
...	O

If	O
I	O
understand	O
you	O
correctly	O
,	O
`	O
pivot_table	B-API
`	O
might	O
be	O
closer	O
to	O
what	O
you	O
need	O
:	O
#CODE	O

---->	O
8	O
quarter_score_diff	O
=	O
region	O
[(	O
region.Quradate	O
==	O
most_recent_date	O
)	O
or	O
(	O
region.Quradate	O
==	O
last_quarter	O
)]	O
.diff()	B-API

Ok	O
I	O
managed	O
to	O
upgrade	O
to	O
Pandas	O
0.13.1	O
numpy	O
1.8.0	O
I	O
can	O
now	O
run	O
your	O
example	O
code	O
up	O
to	O
`	O
split_times	O
(	O
row	O
)`	O
which	O
returns	O
:	O
`	O
TypeError	O
:	O
cannot	O
astype	B-API
a	O
timedelta	O
from	O
[	O
timedelta64	O
[	O
ns	O
]]	O
to	O
[	O
int32	O
]`	O

Maybe	O
you're	O
looking	O
for	O
[	O
`	O
pivot_table	B-API
`]	O
(	O
#URL	O
)	O
?	O

I	O
had	O
missed	O
that	O
Pandas	O
is	O
converting	O
the	O
mixed	O
timezone	O
column	O
to	O
dtype	B-API
`	O
object	O
`	O
.	O

This	O
needs	O
to	O
work	O
with	O
pandas	O
0.10	O
,	O
so	O
using	O
`	O
the_series.to_frame()	O
.transpose()	B-API
`	O
is	O
not	O
an	O
option	O
.	O

As	O
mentioned	O
in	O
your	O
answer	O
,	O
this	O
is	O
a	O
little	O
cleaner	O
(	O
though	O
there	O
is	O
no	O
ambiguity	O
in	O
this	O
case	O
)	O
as	O
`	O
.loc	B-API
`	O
rather	O
than	O
`	O
.ix	B-API
`	O
.	O

Is	O
concat()	B-API
with	O
axis=1	O
equivalent	O
to	O
merge()	B-API
?	O

An	O
alternative	O
would	O
be	O
to	O
make	O
a	O
`	O
ndarray	B-API
`	O
of	O
`	O
datetime	O
`	O
objects	O
by	O
choosing	O
`	O
dtype	B-API
=o	O
bject	O
`	O
.	O

I	O
was	O
writing	O
functions	O
and	O
doing	O
an	O
dataframe.apply	B-API

However	O
,	O
trying	O
to	O
print	O
the	O
dtype	B-API
of	O
`	O
AllAlexaAndGoogleInfo	O
`	O
like	O
so	O
:	O
#CODE	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
.	O

You	O
can	O
see	O
that	O
the	O
dtype	B-API
for	O
Desired	O
Output	O
is	O
not	O
`	O
datetime.time	O
`	O
:	O
#CODE	O

.agg	B-API

`	O
df	O
[	O
0	O
]	O
.iloc	B-API
[	O
0	O
]	O
.year	B-API
`	O

That's	O
why	O
I	O
used	O
notnull()	B-API
and	O
lenX	O
in	O
my	O
original	O
question	O
.	O

rolling_mean	B-API
instability	O
in	O
pandas	O

I	O
think	O
this	O
is	O
leaking	O
implementation	O
details	O
about	O
exactly	O
the	O
way	O
in	O
which	O
(	O
as	O
the	O
docs	O
say	O
)	O
"	O
iterrows	B-API
does	O
**	O
not	O
**	O
preserve	O
dtypes	B-API
across	O
the	O
rows	O
"	O
.	O

Starting	O
from	O
0.15	O
,	O
`	O
to_sql	B-API
`	O
has	O
a	O
`	O
chunksize	O
`	O
option	O
(	O
0.15	O
is	O
still	O
in	O
development	O
,	O
but	O
the	O
feature	O
is	O
merged	O
in	O
master	O
)	O

try	O
with	O
grp	O
[	O
'	O
temp_3	O
']	O
.dropna()	B-API
.index	B-API

I	O
had	O
to	O
slip	O
that	O
`	O
fillna	B-API
(	O
0	O
)`	O
in	O
the	O
middle	O
there	O
so	O
that	O
the	O
`	O
NaN	O
`	O
s	O
weren't	O
dropped	O
.	O

For	O
some	O
reason	O
using	O
axis=0	O
in	O
the	O
`	O
pandas.concat	B-API
`	O
does	O
not	O
do	O
what	O
I'd	O
expect	O
.	O

@USER	O
:	O
If	O
I	O
dropna	B-API
,	O
I	O
am	O
assuming	O
that	O
Pandas	O
still	O
treats	O
the	O
column	O
as	O
float	O
.	O

Out	O
of	O
memory	O
when	O
DataFrame.resample()	B-API
is	O
called	O
in	O
pandas	O
on	O
small	O
dataset	O

Here	O
are	O
the	O
dtypes	B-API
for	O
each	O
of	O
these	O
columns	O
:	O
#CODE	O

`	O
.iloc	B-API
`	O
selects	O
rows	O
by	O
ordinal	O
position	O
.	O

You	O
should	O
be	O
using	O
the	O
`	O
DataFrame.loc	B-API
`	O
method	O
,	O
as	O
the	O
warning	O
suggests	O
,	O
like	O
this	O
:	O
#CODE	O

Argh	O
,	O
that	O
still	O
gives	O
me	O
`	O
dtype	B-API
(	O
'	O
datetime64	O
[	O
us	O
]')`	O
.	O

I	O
didn't	O
want	O
`	O
iloc	B-API
`	O
I	O
was	O
specifically	O
testing	O
the	O
behavior	O
of	O
duplicate-duplicate	O
indexing	O
.	O

Yea	O
,	O
seems	O
like	O
set_value	B-API
and	O
get_value	B-API
are	O
the	O
best	O
performers	O
.	O

`	O
.iloc	B-API
`	O
selects	O
rows	O
by	O
ordinal	O
position	O
.	O

This	O
works	O
fine	O
using	O
.concat	B-API
.	O

data.groupby	O
(	O
level=0	O
)	O
.apply	B-API
(	O
lambda	O
d	O
:	O
d.reset_index	O
(	O
level=0	O
,	O
drop=True	O
)	O
.resample	B-API
(	O
"	O
M	O
"	O
,	O
how=	O
""))	O

In	O
effect	O
are	O
you	O
expecting	O
no	O
change	O
or	O
that	O
`	O
NaN	O
`	O
is	O
replaced	O
with	O
`	O
None	O
`	O
which	O
doesn't	O
make	O
sense	O
for	O
numerical	O
dtypes	B-API

It	O
looks	O
like	O
the	O
`	O
pandas.merge()	B-API
`	O
method	O
is	O
restricted	O
to	O
working	O
with	O
only	O
two	O
dataframes	O
.	O

dtypes	B-API
:	O
float64	O
(	O
1	O
)	O
,	O
object	O
(	O
3	O
)	O

Maybe	O
you're	O
looking	O
for	O
[	O
`	O
pivot_table	B-API
`]	O
(	O
#URL	O
)	O
?	O

File	O
"	O
C	O
:\	O
Users\Owner\AppData\Local\Continuum\Anaconda3\Lib\	O
site-packages	O
\pandas\io\	O
sql.py	O
"	O
,	O
line	O
534	O
,	O
in	O
to_sql	B-API

pandas	O
rolling_apply	B-API
pass	O
memo	O
to	O
udf	O

@USER	O
ah	O
yes	O
,	O
I	O
missed	O
that	O
,	O
doing	O
it	O
column-wise	O
*	O
may	O
*	O
be	O
better	O
option	O
as	O
you	O
avoid	O
possibly	O
upcasting	O
the	O
dtype	B-API
(	O
e.g.	O
from	O
int	O
to	O
float	O
)	O
,	O
depends	O
...	O
probably	O
much	O
of	O
a	O
muchness	O
.	O

I	O
could	O
specify	O
the	O
dtype	B-API
of	O
the	O
specific	O
columns	O
as	O
int	O
with	O
the	O
`	O
dtype	B-API
`	O
keyword	O
.	O

Its	O
`	O
dtype	B-API
`	O
by	O
default	O
is	O
`	O
object	O
`	O
.	O

dtype	B-API
:	O
float64	O

I'm	O
not	O
sure	O
if	O
the	O
get_dummies()	B-API
allows	O
me	O
to	O
do	O
that	O
?	O

I	O
didn't	O
realize	O
that	O
the	O
qcut()	B-API
output	O
had	O
labels	O
.	O

The	O
dtype	B-API
conversion	O
is	O
not	O
done	O
here	O
because	O
you	O
could	O
be	O
potentially	O
doing	O
a	O
very	O
expensive	O
operation	O
.	O

`	O
s	O
=	O
s.resample	O
(	O
'	O
M	O
'	O
,	O
fill_method=	O
'	O
ffill	B-API
')`	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

This	O
works	O
well	O
,	O
although	O
`	O
numpy.unpackbits	B-API
`	O
only	O
seems	O
to	O
work	O
on	O
8-b	O
it	O
integers	O
.	O

yeah	O
i	O
like	O
your	O
answer	O
better	O
,	O
i've	O
never	O
seen	O
`	O
select_dtypes	B-API
`	O
before	O

df_g	O
[	O
'	O
Mem	O
']	O
=d	O
f_g	O
[	O
'	O
Mem	O
']	O
.map	B-API
(	O
'	O
{	O
:	O
4d}	O
'	O
.format	B-API
)	O
#CODE	O

Note	O
:	O
In	O
soon	O
to	O
be	O
released	O
0.13	O
a	O
`	O
drop_level	O
`	O
argument	O
has	O
been	O
added	O
to	O
xs	B-API
(	O
thanks	O
to	O
this	O
question	O
!	O
):	O
#CODE	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O

pandas	O
read_csv()	B-API
input	O
local	O
datetime	O
strings	O
,	O
tz_convert	B-API
to	O
UTC	O

Trying	O
the	O
same	O
with	O
`	O
.apply	B-API
`	O
would	O
give	O
`	O
NaNs	O
`	O
in	O
`	O
sum_C	O
`	O
.	O

and	O
,	O
`	O
ts.asfreq	O
(	O
'	O
H	O
'	O
,	O
method=	O
'	O
ffill	B-API
')`	O
to	O
have	O
hourly	O
frequency	O
.	O

The	O
`	O
.copy()	B-API
`	O
suggestion	O
indeed	O
solves	O
the	O
issue	O
.	O

Do	O
I	O
have	O
to	O
specific	O
the	O
dtypes	B-API
to	O
make	O
this	O
work	O
?	O

@USER	O
:	O
there	O
is	O
no	O
other	O
answer	O
that	O
I	O
can	O
see	O
that	O
mentions	O
`	O
.get	B-API
(	O
0	O
)`	O
.	O

`	O
string	O
`	O
is	O
not	O
a	O
dtype	B-API

What	O
is	O
the	O
dtype	B-API
of	O
`	O
year_week	O
`	O
?	O

I'm	O
trying	O
to	O
monkeypatch	O
how	O
`	O
pandas	O
`	O
Panel's	O
slicing	O
(	O
`	O
__getitem__	B-API
`)	O
.	O

Doing	O
so	O
changes	O
the	O
column's	O
dtype	B-API
to	O
`	O
object	O
`	O
.	O

That	O
doesn't	O
actually	O
surprise	O
me	O
too	O
much	O
,	O
to	O
be	O
honest	O
,	O
because	O
going	O
via	O
a	O
`	O
lambda	O
`	O
is	O
likely	O
to	O
be	O
slower	O
than	O
using	O
`	O
str.startswith	B-API
`	O
directly	O
,	O
but	O
it's	O
really	O
hard	O
to	O
guess	O
.	O

The	O
work-around	O
is	O
that	O
a	O
`	O
FixedLocator	B-API
`	O
should	O
also	O
be	O
used	O
.	O

On	O
my	O
machine	O
.iloc	B-API
tends	O
to	O
be	O
about	O
twice	O
as	O
fast	O
as	O
.loc	B-API
.	O

Automatically	O
inferring	O
dtypes	B-API
and	O
min_itemsize	O
on	O
large	O
datasets	O
iteratively	O

You	O
probably	O
want	O
`	O
dtypes	B-API
`	O
#CODE	O

Here	O
is	O
one	O
way	O
using	O
`	O
stack()	B-API
`	O
.	O

Interesting	O
,	O
so	O
is	O
`	O
.ix	B-API
`	O
the	O
only	O
way	O
of	O
changing	O
it	O
?	O

`	O
df	O
[	O
entities	O
]	O
.tolist()	B-API
`	O
seems	O
to	O
be	O
getting	O
me	O
somewhere	O
.	O

Can	O
I	O
just	O
ask	O
you	O
,	O
what	O
does	O
`	O
apply()	B-API
`	O
specifically	O
do	O
?	O

Gah	O
,	O
you're	O
right	O
--	O
I	O
took	O
your	O
advice	O
too	O
literally	O
and	O
called	O
`	O
fillna	B-API
`	O
_before_	O
`	O
assert_frame_check	O
`	O
,	O
so	O
I	O
missed	O
that	O
it	O
works	O
out	O
the	O
differences	O
.	O

y_labs	O
is	O
numpy.ndarray	B-API

I	O
try	O
to	O
specify	O
the	O
dtypes	B-API
when	O
converting	O
to	O
DF	O
,	O
but	O
not	O
quite	O
getting	O
it	O
:	O
#CODE	O

How	O
to	O
change	O
Pandas.DataFrame.resample	B-API
default	O
holiday	O
calendar	O
?	O

Pandas	O
package	O
offers	O
DataFrame.to_html()	B-API
method	O
.	O

(	O
when	O
using	O
`	O
asfreq	B-API
`	O
the	O
keyword	O
seems	O
to	O
be	O
`	O
method	O
`	O
(	O
not	O
`	O
fill_method	O
`	O
in	O
0.10	O
)	O

You	O
can	O
determine	O
which	O
backend	O
you	O
are	O
using	O
with	O
the	O
command	O
`	O
matplotlib.get_backend()	B-API
`	O
.	O

Compute	O
rolling_mean()	B-API
for	O
midpoints	O

using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

`	O
DataFrame.drop_duplicates	B-API
`	O
is	O
a	O
method	O
,	O
you	O
need	O
to	O
call	O
it	O
.	O

File	O
"	O
C	O
:\	O
Python27\lib\	O
site-packages	O
\pandas\core\	O
groupby.py	O
"	O
,	O
line	O
278	O
,	O
in	O
get_group	B-API

`	O
df1	O
/	O
df2.ix	O
[:	O
,	O
df1.columns	O
]	O
.squeeze()	B-API
`	O
also	O
works	O
but	O
@USER	O
'	O
s	O
answer	O
is	O
much	O
nicer	O

`	O
subset	O
`	O
->	O
`	O
DataFrame.query()	B-API
`	O
and	O
`	O
with	O
`	O
->	O
`	O
DataFrame.eval()	B-API
`	O
is	O
the	O
way	O
I	O
was	O
thinking	O
about	O
how	O
the	O
`	O
pandas	O
`	O
methods	O
relate	O
to	O
the	O
corresponding	O
R	O
versions	O
.	O

Not	O
really	O
-	O
the	O
API	O
change	O
you're	O
referring	O
to	O
just	O
means	O
that	O
`	O
pandas.Series	B-API
`	O
subclasses	O
`	O
NDFrame	O
`	O
rather	O
than	O
directly	O
subclassing	O
`	O
numpy.ndarray	B-API
`	O
,	O
but	O
internal	O
storage	O
used	O
by	O
`	O
NDFrame	O
`	O
still	O
consists	O
of	O
`	O
numpy.ndarrays	O
`	O
.	O

In	O
R	O
,	O
I	O
can	O
do	O
this	O
simply	O
by	O
taking	O
the	O
`	O
outer()	B-API
`	O
products	O
:	O
#CODE	O

---->	O
8	O
quarter_score_diff	O
=	O
region	O
[(	O
region.Quradate	O
==	O
most_recent_date	O
)	O
or	O
(	O
region.Quradate	O
==	O
last_quarter	O
)]	O
.diff()	B-API

s_mask	O
=	O
pandas.concat	B-API
((	O
msk1	O
,	O
msk2	O
)	O
,	O
axis=1	O
)	O

@USER	O
This	O
was	O
a	O
Python	O
3	O
question	O
,	O
so	O
map()	B-API
isn't	O
good	O
enough	O
.	O

I	O
read	O
a	O
bit	O
about	O
the	O
category	O
dtype	B-API
in	O
pandas	O
-	O
does	O
this	O
make	O
output	O
file	O
sizes	O
smaller	O
too	O
or	O
just	O
in-memory	O
?	O

dtype	B-API
,	O
copy=copy	O
,	O
raise_on_error=raise_on_error	O
)	O

'	O
rpt_date	O
'	O
is	O
from	O
'	O
rpt_date	O
=	O
ori_rpt.groupby	O
(	O
'	O
STK_ID	O
')	O
.RPT_Date	O
.apply	B-API
(	O
__makeup_rpt_date_list__	O
)'	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

I	O
think	O
that	O
predicting	O
the	O
dtype	B-API
may	O
not	O
be	O
possible	O
/	O
reasonable	O
on	O
larger	O
dataframes	O
,	O
especially	O
if	O
there	O
were	O
many	O
more	O
columns	O
than	O
in	O
this	O
toy	O
example	O
...	O

I	O
think	O
this	O
must	O
be	O
a	O
bug	O
with	O
MultiIndex.from_product()	B-API
because	O
the	O
long	O
version	O
,	O
using	O
MultiIndex.from_tuples()	B-API
works	O
:	O
#CODE	O

Doing	O
so	O
changes	O
the	O
column's	O
dtype	B-API
to	O
`	O
object	O
`	O
.	O

My	O
experience	O
has	O
been	O
with	O
`	O
read_csv	B-API
`	O
,	O
one	O
has	O
to	O
try	O
a	O
few	O
combinations	O
before	O
one	O
gets	O
what	O
one	O
wants	O
.	O

When	O
running	O
timeit's	O
on	O
numpy	O
ndarrays	O
or	O
matrices	O
of	O
dtype	B-API
int64	O
,	O
you	O
see	O
the	O
same	O
performance	O
lag	O
.	O

Essentially	O
,	O
the	O
``	O
hstack	B-API
``	O
approach	O
is	O
the	O
same	O
as	O
you	O
doing	O
the	O
job	O
of	O
``	O
FeatureUnion	O
``	O
manually	O
.	O

In	O
that	O
case	O
would	O
I	O
just	O
defer	O
to	O
it	O
for	O
boolean	O
vectors	O
and	O
things	O
like	O
`	O
iloc	B-API
`	O
?	O

I	O
was	O
just	O
going	O
to	O
suggest	O
rolling_apply	B-API
as	O
well	O
.	O

I'm	O
just	O
trying	O
to	O
replicate	O
behavior	O
of	O
the	O
`	O
drop_duplicates	B-API
`	O
,	O
except	O
that	O
original	O
row	O
should	O
also	O
be	O
dropped	O
.	O

No	O
,	O
it	O
just	O
can't	O
handle	O
the	O
string	O
dtypes	B-API
.	O

If	O
I	O
do	O
`	O
concs.iloc	O
[:	O
100000	O
]	O
.resample	B-API
(	O
'	O
5min	O
')`	O
the	O
problem	O
persists	O
.	O

Note	O
that	O
point	O
are	O
generated	O
with	O
linear	O
dependency	O
due	O
to	O
nontrivial	O
covariance	O
paramether	O
for	O
multivariate_normal	B-API
.	O

What	O
errors	O
are	O
you	O
getting	O
for	O
the	O
category	O
dtypes	B-API
?	O

your	O
timeit	O
with	O
.loc	B-API
is	O
VERY	O
odd	O
.	O
what	O
version	O
are	O
you	O
using	O
?	O

So	O
essentially	O
`	O
to_native_types	B-API
`	O
can	O
be	O
replaced	O
with	O
`	O
tolist	B-API
`	O
in	O
the	O
above	O
code	O
.	O

Perhaps	O
`	O
qcut()	B-API
`	O
is	O
what	O
you're	O
seeking	O
.	O

In	O
addition	O
these	O
dtypes	B-API

Shouldn't	O
`	O
df	O
[[	O
'	O
week1	O
'	O
,	O
'	O
week2	O
']]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
(	O
x	O
-	O
x.mean()	O
)	O
/	O
x.std()	O
)`	O
work	O
?	O

As	O
an	O
alternative	O
you	O
can	O
do	O
this	O
as	O
a	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

this	O
suggests	O
a	O
feature	O
:	O
``	O
.resample	B-API
(	O
'	O
D	O
'	O
,	O
how=	O
'	O
range	O
'	O
,	O
start=0	O
,	O
stop=3	O
)	O
.median()	B-API
``	O

using	O
`	O
.pivot	B-API
`	O
:	O
#CODE	O

You	O
can	O
achieve	O
desired	O
effect	O
using	O
agg()	B-API
.	O

This	O
Code	O
plots	O
some	O
boxplots	O
in	O
a	O
row	O
for	O
every	O
weekday	B-API
.	O

print	O
(	O
col	O
,	O
df	O
[	O
col	O
]	O
.dtype	B-API
)`	O
?	O

Have	O
you	O
tried	O
g_test.get_group	O
((	O
1	O
,	O
5	O
,	O
13	O
,	O
8))	O
[	O
"'	O
monthly_sales	O
"]	O
=	O
g_train.get_group	O
((	O
1	O
,	O
5	O
,	O
13	O
,	O
8))	O
.monthly_sales	O
.mean()	B-API
?	O

I	O
found	O
"	O
rolling_corr_pairwise	B-API
"	O
in	O
the	O
Pandas	O
documentation	O
.	O

Can	O
you	O
check	O
the	O
dtype	B-API
on	O
your	O
`	O
converted_dates	O
`	O
and	O
`	O
today_date	O
`	O
?	O

try	O
using	O
something	O
like	O
:	O
`	O
resampled_data.fillna	O
(	O
0	O
)	O
.plot()	B-API
`	O
and	O
i	O
think	O
you'll	O
see	O
what	O
you're	O
expecting	O
.	O

try	O
using	O
[	O
`	O
.apply	B-API
`]	O
(	O
#URL	O
)	O
,	O
with	O
`	O
axis=1	O
`	O

Wes's	O
answer	O
to	O
the	O
other	O
one	O
is	O
also	O
very	O
informative	O
(	O
although	O
iterrows	B-API
gets	O
the	O
job	O
done	O
for	O
now	O
)	O

I'm	O
working	O
with	O
really	O
large	O
CSV	O
files	O
and	O
want	O
to	O
know	O
if	O
pandas	O
'	O
`	O
to_sql	B-API
`	O
can	O
efficiently	O
handle	O
gigabytes	O
worth	O
of	O
CSV	O
?	O

These	O
solutions	O
worked	O
,	O
but	O
pandas	O
.cumprod()	B-API
turned	O
out	O
to	O
be	O
the	O
easiest	O
solution	O
.	O

table2	O
[	O
'	O
SUBDIVISION	O
']	O
.replace	B-API
(	O
df	O
[	O
'	O
NSUBDIVISION	O
']	O
.to_dict()	B-API
,	O
inplace=True	O
)	O

I	O
might	O
be	O
overlooking	O
something	O
,	O
but	O
I	O
think	O
using	O
`	O
.shift()	B-API
`	O
should	O
do	O
it	O
.	O

the	O
`	O
dtype=None	O
`	O
tells	O
`	O
genfromtxt	B-API
`	O
to	O
make	O
an	O
intelligent	O
guess	O
about	O
the	O
type	O
of	O
each	O
column	O
--	O
so	O
your	O
float-like	O
numbers	O
will	O
automatically	O
have	O
dtype	B-API
float	O
.	O

C	O
)	O
Pandas	O
'	O
`	O
get_dummies	B-API
`	O
#CODE	O

I	O
think	O
you	O
don't	O
need	O
the	O
`	O
to_datetime	B-API
`	O
bit	O
could	O
you	O
try	O
`	O
df	O
[	O
'	O
OEDatum	O
']	O
=	O
df	O
[[	O
'	O
OEDatum	O
'	O
,	O
'	O
OEUhrzeit	O
']]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
dt.datetime.combine	O
(	O
x	O
[	O
'	O
OEDatum	O
']	O
.date()	B-API
,	O
x	O
[	O
'	O
OEUhrzeit	O
'])	O
,	O
axis=1	O
)`	O

dtype	B-API
=d	O
type	O
)	O

metals.ix	O
[	O
'	O
BI	O
'	O
,	O
'	O
Arsenic	O
,	O
Dissolved	O
']	O
.ix	B-API
[:	O
,	O
1	O
]	O

I	O
think	O
it's	O
more	O
pandorable	O
to	O
write	O
`	O
aapl.index.to_series()	O
.diff()	B-API
.mean()	B-API
`	O
or	O
`	O
.median()	B-API
`	O
.	O

I've	O
tried	O
.shift	B-API
(	O
1	O
)	O
within	O
the	O
for	O
loop	O
,	O
to	O
no	O
avail	O
:	O
#CODE	O

Could	O
you	O
edit	O
your	O
question	O
to	O
include	O
the	O
result	O
of	O
`	O
df	O
[	O
"	O
sex	O
"]	O
.head()	B-API
.values	B-API
`	O
before	O
you	O
do	O
your	O
mapping	O
?	O

b	O
=b	O
.as_matrix()	B-API
`	O

`	O
s	O
=	O
s.resample	O
(	O
'	O
M	O
'	O
,	O
fill_method=	O
'	O
ffill	B-API
')`	O

Oh	O
,	O
I	O
misunderstood	O
,	O
`	O
pct_change	B-API
`	O
calculates	O
the	O
row-over-row	O
change	O
.	O

Perhaps	O
`	O
.transform	B-API
`	O
can	O
help	O
with	O
this	O
:	O
#CODE	O

Using	O
`	O
DataFrame.where	B-API
`	O
'	O
s	O
`	O
other	O
`	O
argument	O
and	O
`	O
pandas.concat	B-API
`	O
:	O
#CODE	O

set_index	B-API
equivalent	O
for	O
columns	O
headings	O

I	O
was	O
assuming	O
that	O
under	O
the	O
hood	O
pandas	O
was	O
using	O
agg_general	O
and	O
simply	O
only	O
calling	O
it	O
with	O
numeric	O
dtypes	B-API
.	O

Is	O
there	O
a	O
way	O
to	O
manually	O
change	O
the	O
dtype	B-API
to	O
numeric	O
?	O

`	O
nx.set_edge_attributes	O
(	O
G	O
,	O
'	O
myattr	O
'	O
,	O
df	O
[	O
'	O
attribute	O
']	O
.astype	B-API
(	O
int	O
)	O
.to_dict()	B-API
)`	O
works	O
fine	O
but	O
then	O
`	O
nx.write_gexf()	O
`	O
complains	O
.	O

I	O
did	O
turn	O
the	O
`	O
activity_month	O
`	O
column	O
in	O
to	O
a	O
datetime	O
dtype	B-API
.	O

Do	O
you	O
maybe	O
have	O
insight	O
why	O
the	O
groupby()	B-API
.apply()	B-API
allows	O
different	O
dimensions	O
to	O
be	O
returned	O
,	O
while	O
the	O
DataFrame.apply()	B-API
does	O
not	O
?	O

dtype	B-API
=	O
'	O
object	O
')`	O

Note	O
:	O
you	O
need	O
pandas	O
0.15.2	O
+	O
for	O
this	O
`	O
dtype	B-API
`	O
argument	O
.	O

However	O
,	O
I	O
would	O
like	O
the	O
layout	O
to	O
be	O
generated	O
from	O
the	O
number	O
of	O
levels	O
in	O
the	O
categorical	B-API
conditioning	O
(	O
or	O
"	O
by	O
")	O
variable	O
(	O
s	O
)	O
.	O

`	O
grouped.unstack	O
(	O
'	O
two	O
')	O
.fillna	B-API
(	O
0	O
)	O
.stack()	B-API
`	O

I'm	O
getting	O
"	O
AttributeError	O
:	O
'	O
StringMethods	O
'	O
object	O
has	O
no	O
attribute	O
'	O
get_dummies	B-API
'"	O
.	O

Python	O
Pandas	O
:	O
rolling_kurt	B-API
vs	O
.	O
scipy.stats.kurtosis	O

I	O
tried	O
using	O
DataFrame.replace()	B-API
and	O
DataFrame.assign()	B-API
methods	O
.	O

Below	O
is	O
the	O
quotation	O
for	O
what	O
pandas.Series.apply	B-API
should	O
expect	O
:	O

`	O
.ix	B-API
`	O
is	O
actual	O
integer-based	O
indexing	O
.	O

Specifying	O
dtypes	B-API
worked	O
.	O

It's	O
much	O
easier	O
just	O
to	O
let	O
`	O
read_csv	B-API
`	O
infer	O
the	O
column	O
dtypes	B-API
.	O

You	O
need	O
`	O
.loc	B-API
`	O
(	O
label-based	O
)	O
instead	O
of	O
`	O
.iloc	B-API
`	O
(	O
position-based	O
)	O
.	O

`	O
x	O
=	O
eq_data	O
[	O
'	O
longitude	O
']	O
.values	B-API
;	O
y=	O
eq_data	O
[	O
'	O
latitude	O
']	O
.values	B-API
;	O
map2.plot	O
(	O
x	O
,	O
y	O
,	O
marker=	O
'	O
0	O
'	O
,	O
markercolor=	O
'	O
red	O
'	O
,	O
markersize=6	O
);	O
`	O

@USER	O
yes	O
that	O
would	O
not	O
work	O
,	O
I	O
think	O
what	O
you	O
want	O
is	O
just	O
g	O
=	O
df	O
[	O
df	O
[	O
'	O
rating	O
']	O
.notnull()	B-API
]	O
.groupby	B-API
(	O
'	O
movie	O
')	O
.mean()	B-API
.	O

@USER	O
btw	O
,	O
not	O
sure	O
why	O
,	O
but	O
`	O
read_fwf	B-API
`	O
doesn't	O
seem	O
to	O
support	O
`	O
dtype	B-API
`	O
even	O
though	O
it's	O
in	O
the	O
document	O
#URL	O

`	O
--->	O
11	O
UngroupedResGenesLineage.groupby	O
(	O
'	O
Lineage	O
')	O
.apply	B-API
(	O
func	O
)	O
.reset_index()	B-API
.drop	B-API
(	O
'	O
level_1	O
'	O
,	O
axis=1	O
)	O

The	O
behavior	O
of	O
`	O
pandas.DataFrame.apply	B-API
(	O
myfunc	O
)`	O
is	O
application	O
of	O
`	O
myfunc	O
`	O
along	O
columns	O
.	O

As	O
a	O
bonus	O
,	O
I	O
still	O
see	O
different	O
recommendation	O
results	O
when	O
using	O
fillna	B-API
(	O
0	O
)	O
with	O
Pearson	O
correlation	O
.	O

btw	O
,	O
is	O
.agg()	B-API
the	O
same	O
as	O
.aggregate()	B-API
?	O

Of	O
course	O
you	O
can	O
`	O
drop_duplicates	B-API
`	O
before	O
of	O
after	O
joining	O

Let's	O
say	O
I	O
create	O
5	O
quantiles	O
using	O
pandas.qcut	B-API
:	O
#CODE	O

:)	O
I	O
was	O
just	O
about	O
to	O
comment	O
that	O
pivot_table	B-API
is	O
much	O
nicer	O
before	O
you	O
deleted	O
your	O
answer	O
!!	O

see	O
[	O
.filter	B-API
]	O
(	O
#URL	O
);	O
it	O
has	O
support	O
for	O
regex	O

This	O
effectively	O
replaces	O
the	O
need	O
for	O
`	O
.xs	B-API
`	O
.	O

Is	O
there	O
a	O
way	O
to	O
obtain	O
non-negative	O
integers	O
as	O
the	O
interval	O
boundaries	O
directly	O
with	O
`	O
pandas.cut()	B-API
`	O
without	O
using	O
numpy	O
?	O

RESOLVE	O
D:	O
I	O
was	O
making	O
another	O
,	O
equally	O
clowny	O
,	O
mistake	O
and	O
calling	O
all()	B-API
before	O
calling	O
fillna	B-API
so	O
many	O
of	O
the	O
rows	O
were	O
blank	O
.	O

Now	O
,	O
adding	O
the	O
cumsum	B-API
of	O
this	O
gets	O
you	O
the	O
result	O
you're	O
after	O
:	O
#CODE	O

@USER	O
Using	O
JohnE's	O
suggestions	O
I	O
appended	O
my	O
original	O
post	O
with	O
.info()	B-API
.	O

Just	O
updated	O
so	O
that	O
there	O
is	O
only	O
one	O
call	O
to	O
`	O
stack()	B-API
`	O
.	O

The	O
rolling_mean	B-API
and	O
ewma	B-API
functions	O
in	O
pandas	O
are	O
not	O
meant	O
for	O
randomly	O
spaced	O
x-values	O
,	O
so	O
they	O
are	O
not	O
really	O
appropriate	O
.	O

Alternatively	O
,	O
you	O
could	O
access	O
`	O
df	O
[	O
'	O
Weekdays	O
']`	O
before	O
using	O
`	O
.loc	B-API
`	O
:	O
#CODE	O

I	O
have	O
run	O
into	O
an	O
issue	O
when	O
comparing	O
two	O
`	O
DatetimeIndex	B-API
`'	O
s	O
with	O
different	O
lengths	O
in	O
an	O
`	O
assert	O
`	O
like	O
the	O
following	O
:	O
#CODE	O

but	O
I	O
would	O
like	O
to	O
understand	O
why	O
this	O
behavior	O
happens	O
when	O
doing	O
dict-like	O
slicing	O
(	O
e.g.	O
`	O
df	O
[	O
'	O
L	O
']	O
[	O
'	O
Five	O
']`)	O
and	O
not	O
when	O
using	O
the	O
`	O
.loc	B-API
`	O
slicing	O
.	O

I	O
couldn't	O
think	O
of	O
a	O
nice	O
way	O
to	O
vectorize	B-API
the	O
answer	O
,	O
but	O
here's	O
a	O
hack	O
that	O
gets	O
the	O
basic	O
logic	O
.	O

Oh	O
cripes	O
it	O
looks	O
like	O
there	O
is	O
a	O
bug	O
in	O
`	O
get_dummies	B-API
`	O
,	O
it's	O
not	O
ignoring	O
the	O
NaN	O
but	O
rather	O
doing	O
something	O
strange	O
...	O

`	O
dropna	B-API
`	O
takes	O
care	O
of	O
the	O
nulls	O
produced	O
for	O
gene	O
c	O
.	O

dtype	B-API
:	O
category	O

Was	O
thinking	O
to	O
a	O
reindex_like	B-API
perhaps	O
?	O

See	O
also	O
the	O
documentation	O
page	O
of	O
`	O
to_sql	B-API
`	O
.	O

pandas	O
rolling_mean	B-API
of	O
timedelta64	O
produces	O
float64	O

That	O
is	O
what	O
`	O
pandas.factorize	B-API
`	O
does	O
:	O
#CODE	O

@USER	O
.m	O
I	O
need	O
a	O
runnable	O
example	O
that	O
uses	O
`	O
applymap	B-API
`	O
to	O
assist	O
further	O
.	O

Using	O
an	O
`	O
HDFStore	B-API
`	O
like	O
below	O
changes	O
nothing	O
.	O

@USER	O
I	O
want	O
to	O
do	O
something	O
very	O
similar	O
to	O
this	O
however	O
I	O
am	O
using	O
dataframe.boxplot	B-API
(	O
by=	O
'	O
column1	O
')	O
this	O
grouping	O
doesn't	O
seem	O
to	O
work	O
with	O
your	O
example	O
.	O

I	O
tried	O
using	O
any()	B-API
and	O
am	O
having	O
immense	O
difficulty	O
with	O
this	O
.	O

I	O
tried	O
what	O
many	O
other	O
answers	O
suggested	O
with	O
`	O
figure.tight_layout()	B-API
`	O
to	O
no	O
avail	O
.	O

I	O
also	O
tried	O
specifying	O
dtype	B-API
by	O
column	O
using	O
a	O
dictionary	O
:	O
#CODE	O

Then	O
I	O
create	O
the	O
pivot_table	B-API
shown	O
above	O
.	O

So	O
depending	O
on	O
what	O
you	O
want	O
to	O
achieve	O
,	O
its	O
easy	O
to	O
do	O
an	O
overlap	O
,	O
by	O
using	O
rolling_mean	B-API

I	O
learned	O
this	O
cute	O
utilization	O
of	O
`	O
concat()	B-API
`	O
from	O
HYRY	O
here	O
.	O

I	O
have	O
tried	O
a	O
`	O
.replace	B-API
`	O
however	O
it	O
did	O
not	O
work	O
.	O

`	O
cat2	O
`	O
is	O
an	O
`	O
object	O
`	O
`	O
dtype	B-API
`	O
so	O
it	O
is	O
probably	O
a	O
string	O
,	O
I	O
think	O
you	O
want	O
:	O
#CODE	O

`	O
pandas.qcut	B-API
`	O
has	O
a	O
`	O
precision	O
`	O
parameter	O
for	O
the	O
bin	O
representation	O
that	O
defaults	O
to	O
3	O
-	O
you	O
may	O
need	O
a	O
higher	O
number	O
(	O
see	O
docs	O
)	O
.	O

Then	O
modify	O
with	O
`	O
iloc	B-API
`	O
and	O
integer	O
indexes	O
:	O
#CODE	O

`	O
dropna	B-API
`	O
takes	O
care	O
of	O
the	O
nulls	O
produced	O
for	O
gene	O
c	O
.	O

would	O
resample()	B-API
be	O
able	O
to	O
create	O
the	O
5min	O
bins	O
?	O

Specifying	O
dtype	B-API
in	O
pandas	O

Can	O
you	O
call	O
the	O
python	O
built-in	O
`	O
type()	O
`	O
on	O
one	O
of	O
these	O
elements	O
(	O
`	O
type	O
(	O
element	O
)`)	O
that	O
has	O
`	O
dtype	B-API
(	O
'	O
O	O
')`	O
--	O
It	O
doesn't	O
look	O
like	O
numpy	O
knows	O
it's	O
a	O
string	O
.	O

Meanwhile	O
,	O
I	O
would	O
suggest	O
using	O
the	O
`	O
Panel.select	B-API
`	O
method	O
:	O
#CODE	O

`	O
DataFrame.replace()	B-API
`	O
:	O
#CODE	O

In	O
Pandas	O
,	O
how	O
to	O
re-determine	O
the	O
dtypes	B-API
of	O
columns	O
after	O
dropna	B-API
?	O

*	O
`	O
include_start	O
`	O
and	O
`	O
include_end	O
`	O
are	O
optional	O
boolean	O
arguments	O
of	O
`	O
indexer_between_time	B-API
`	O
.	O

Trying	O
the	O
same	O
with	O
`	O
.apply	B-API
`	O
would	O
give	O
`	O
NaNs	O
`	O
in	O
`	O
sum_C	O
`	O
.	O

`'	O
,	O
'	O
.join	B-API
(	O
df	O
[	O
"	O
city	O
"]	O
.values	B-API
)`	O
--	O
this	O
will	O
return	O
a	O
comma-separated	O
string	O
.	O

---->	O
2	O
s=	O
"	O
"	O
.join	B-API
(	O
x	O
)	O

An	O
alterantive	O
is	O
to	O
give	O
a	O
dtype	B-API
for	O
each	O
column	O
.	O

I	O
also	O
check	O
the	O
dtype	B-API
of	O
the	O
problem	O
column	O
:	O

HDFStore	B-API
:	O
table.select	O
and	O
RAM	O
usage	O

HDFStore	B-API
(	O
and	O
HDF5	O
in	O
general	O
)	O
are	O
row	O
oriented	O
.	O

loadtxt	B-API
is	O
working	O
great	O
!	O

Certain	O
serialization	O
formats	O
,	O
e.g.	O
`	O
HDFStore	B-API
`	O
stores	O
the	O
strings	O
as	O
fixed-length	O
strings	O
on	O
disk	O
though	O
.	O

Note	O
:	O
the	O
increase	O
in	O
performance	O
depends	O
on	O
dtypes	B-API
.	O

This	O
might	O
also	O
be	O
helpful	O
for	O
reading	O
strings	O
with	O
`	O
genfromtxt	B-API
`	O
:	O
#URL	O

[	O
PeriodIndex	O
]	O
(	O
#URL	O
)	O
can	O
represent	O
longer	O
timespans	O
than	O
DatetimeIndex	B-API
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

numpy.sum	B-API
behaves	O
differently	O
on	O
numpy.array	B-API
vs	O
pandas.DataFrame	B-API

iloc	B-API
:	O
work	O
on	O
position	O

Also	O
,	O
what	O
about	O
.map	B-API
vs	O
.apply	B-API
?	O

Try	O
using	O
.loc	B-API
[	O
row_index	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

so	O
``	O
df	O
[	O
col	O
]	O
.loc	B-API
[	O
i	O
]``	O
is	O
*	O
chained	O
assignment*	O
.	O

Pandas	O
DataFrame.apply()	B-API
and	O
mibian	O

``	O
p.loc	O
[:	O
,	O
:	O
,	O
indexer	O
]	O
=	O
value	O
``	O
is	O
what	O
you	O
want	O
(	O
``	O
minor_xs	B-API
``	O
is	O
a	O
convience	O
feature	O
)	O

As	O
requested	O
in	O
the	O
comments	O
,	O
subset	O
[:	O
1	O
]	O
.to_dict()	B-API
outputs	O
:	O
#CODE	O

`	O
df	O
[	O
"	O
col2	O
"]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
di.get	O
(	O
x	O
,	O
x	O
))`	O
works	O
!	O

Does	O
using	O
pandas.cut	B-API
change	O
the	O
structure	O
of	O
a	O
data.frame	O
.	O

For	O
some	O
reason	O
it	O
is	O
related	O
to	O
the	O
line	O
you	O
just	O
removed	O
`	O
labels	O
=	O
[	O
"	O
{	O
left	O
:	O
,.	O
0f	O
}	O
to	O
{	O
right	O
:	O
,.	O
0f}	O
"	O
.format	B-API
(	O
left=yr	O
[	O
0	O
]	O
,	O
right=yr	O
[	O
0	O
]	O
+yr	O
[	O
1	O
]	O
-1	O
)	O
for	O
yr	O
in	O
joint	O
]`	O
.	O

I've	O
also	O
tried	O
this	O
using	O
this	O
with	O
a	O
`	O
dtype	B-API
`	O
of	O
`	O
numpy.int32	O
`	O
or	O
`	O
numpy.int64	O
`	O
.	O

the	O
new	O
`	O
interpolate()	B-API
`	O
is	O
on	O
0.13.0	O
.	O

To	O
make	O
this	O
a	O
little	O
more	O
concrete	O
,	O
this	O
is	O
what	O
it	O
looks	O
like	O
for	O
the	O
8th	O
iteration	O
(	O
and	O
the	O
`	O
rolling_corr	B-API
`	O
uses	O
a	O
window	O
of	O
3	O
since	O
this	O
dataset	O
has	O
only	O
4	O
rows	O
):	O
#CODE	O

Try	O
this	O
:	O
`	O
dataframe.replace	B-API
(	O
{	O
"	O
rea	O
"	O
:	O
""	O
}	O
,	O
regex=True	O
)`	O

with	O
column	O
dtypes	B-API
:	O
#CODE	O

It	O
is	O
a	O
perfect	O
usecase	O
for	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

call	O
`	O
drop_duplicates()	B-API
`	O
after	O
`	O
concat()	B-API
`	O
:	O
#CODE	O

Even	O
if	O
it	O
doesn't	O
default	O
to	O
inplace	O
,	O
shouldn't	O
it	O
provide	O
an	O
inplace	O
parameter	O
the	O
way	O
replace()	B-API
does	O
?	O

Note	O
:	O
you	O
can	O
do	O
this	O
without	O
the	O
lambda	O
:	O
just	O
do	O
`	O
.apply	B-API
(	O
ast.literal_eval	O
)`	O

pattern	O
(	O
such	O
as	O
the	O
index-by-column-then-index-by	O
-	O
`	O
iloc	B-API
`	O
pattern	O
used	O
here	O
)	O
for	O
assignments	O
,	O
since	O
it	O
does	O
not	O

As	O
written	O
,	O
rolling_mean()	B-API
will	O
work	O
.	O

No	O
,	O
it	O
just	O
can't	O
handle	O
the	O
string	O
dtypes	B-API
.	O

The	O
trick	O
here	O
lies	O
in	O
the	O
`	O
.apply()	B-API
`	O
method	O
and	O
the	O
`	O
.groupby()	B-API
`	O
method	O
.	O

`	O
s	O
=	O
df	O
[	O
'	O
m	O
']	O
.replace	B-API
(	O
{	O
'	O
March	O
'	O
:	O
0	O
,	O
'	O
April	O
'	O
:	O
1	O
,	O
'	O
Dec	O
'	O
:	O
3}	O
)`	O
works	O
for	O
line	O
2	O
as	O
well	O
--	O
just	O
for	O
the	O
sake	O
of	O
anyone	O
learning	O
pandas	O
like	O
me	O

Don't	O
focus	O
on	O
having	O
the	O
'	O
right	O
dtype	B-API
'	O
,	O
dtypes	B-API
are	O
strange	O
.	O

I	O
am	O
particularly	O
talking	O
about	O
Pandas	O
version	O
0.11	O
as	O
I	O
am	O
busy	O
replacing	O
my	O
uses	O
of	O
.ix	B-API
with	O
either	O
.loc	B-API
or	O
.iloc	B-API
.	O

Doing	O
tz_localize	B-API
raises	O
an	O
exception	O
if	O
it's	O
already	O
there	O
,	O
and	O
tz_convert	B-API
raises	O
an	O
exception	O
if	O
it's	O
not	O
.	O

For	O
some	O
reason	O
it	O
is	O
related	O
to	O
the	O
line	O
you	O
just	O
removed	O
`	O
labels	O
=	O
[	O
"	O
{	O
left	O
:	O
,.	O
0f	O
}	O
to	O
{	O
right	O
:	O
,.	O
0f}	O
"	O
.format	B-API
(	O
left=yr	O
[	O
0	O
]	O
,	O
right=yr	O
[	O
0	O
]	O
+yr	O
[	O
1	O
]	O
-1	O
)	O
for	O
yr	O
in	O
joint	O
]`	O
.	O

Its	O
already	O
marked	O
as	O
an	O
issue	O
:	O
#URL	O
the	O
numerical	O
instability	O
is	O
due	O
to	O
the	O
naive	O
implementation	O
of	O
the	O
algorithm	O
.	O
for	O
example	O
,	O
rolling_var	B-API
has	O
already	O
been	O
fixed	O
for	O
this	O
.	O
pull	O
requests	O
are	O
welcome	O
!	O

Am	O
I	O
using	O
replace()	B-API
incorrectly	O
?	O

The	O
rolling_mean	B-API
and	O
ewma	B-API
functions	O
in	O
pandas	O
are	O
not	O
meant	O
for	O
randomly	O
spaced	O
x-values	O
,	O
so	O
they	O
are	O
not	O
really	O
appropriate	O
.	O

Minor	O
:	O
`	O
notnull	B-API
`	O
is	O
also	O
a	O
method	O
of	O
DataFrames	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
f	O
(	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
which	O
calculates	O
the	O
distance	O
between	O
two	O
points	O
(	O
defined	O
using	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
.	O

For	O
all	O
110k+	O
records	O
in	O
`	O
df1	O
`	O
do	O
you	O
want	O
to	O
apply	O
your	O
distance	O
function	O
for	O
every	O
record	O
in	O
`	O
df2	O
`	O
?	O

I	O
chose	O
to	O
use	O
map	B-API
and	O
list	O
comprehensions	O
because	O
they	O
will	O
be	O
faster	O
than	O
a	O
standard	O
`	O
for	O
each	O
`	O

However	O
I	O
took	O
this	O
into	O
account	O
and	O
used	O
map	B-API
,	O
and	O
nested	O
comprehensions	O
which	O
are	O
going	O
to	O
be	O
faster	O
than	O
a	O
for	O
loop	O
.	O

Keep	O
getting	O
:	O
KeyError	O
:	O
'	O
cannot	O
use	O
a	O
single	O
bool	O
to	O
index	O
into	O
setitem	O
'	O
on	O
this	O
line	O
of	O
code	O
in	O
the	O
second	O
chunk	O
I	O
posted	O
.	O

i	O
have	O
to	O
merge	O
them	O
in	O
to	O
the	O
same	O
cell	O
before	O
applying	O
this	O
method	O
.	O

Or	O
is	O
there	O
are	O
way	O
to	O
marge	O
the	O
columns	O
in	O
pandas	O
?	O

I	O
have	O
two	O
TimeSeries	O
with	O
some	O
overlapping	O
dates	O
/	O
indices	O
and	O
I'd	O
like	O
to	O
merge	O
them	O
.	O

I	O
have	O
an	O
excel	O
file	O
(	O
.xls	O
format	O
)	O
with	O
5	O
sheets	O
,	O
I	O
want	O
to	O
replace	O
the	O
contents	O
of	O
sheet	O
5	O
with	O
contents	O
of	O
my	O
pandas	O
data	O
frame	O
.	O

So	O
,	O
I	O
decided	O
to	O
do	O
this	O
task	O
in	O
VBA	O
and	O
drop	O
python	O
completely	O
.	O

It	O
could	O
be	O
I'm	O
not	O
using	O
the	O
right	O
keywords	O
,	O
so	O
if	O
you	O
have	O
suggestions	O
,	O
that	O
could	O
also	O
help	O
.	O

plus	O
the	O
selected	O
rows	O
usage	O
x	O
2	O
,	O
which	O
will	O
happen	O
when	O
you	O
concat	O
the	O
rows	O

after	O
the	O
concat	B-API
the	O
usage	O
will	O
go	O
down	O
to	O
selected	O
rows	O
usage	O

See	O
example	O
here	O
:	O
#URL	O
Not	O
sure	O
this	O
will	O
solve	O
it	O
,	O
but	O
that	O
will	O
do	O
the	O
query	O
in	O
chunks	O
,	O
and	O
you	O
can	O
aggregate	O
or	O
merge	O
them	O
in	O
pandas	O

Try	O
a	O
`	O
dropna	B-API
`	O
or	O
use	O
`	O
missing=	O
'	O
drop	O
'`	O
to	O
Logit	O
.	O

You	O
might	O
also	O
check	O
that	O
the	O
right	O
hand	O
side	O
is	O
full	O
rank	O
`	O
np.linalg.matrix_rank	B-API
(	O
data	O
[	O
train_cols	O
]	O
.values	B-API
)`	O

append	O
pandas.DataFrame.GroupBy	B-API
results	O
into	O
another	O
dataframe	O

You	O
need	O
to	O
append	O
the	O
intermediate	O
DataFrames	O
to	O
a	O
list	O
and	O
then	O
concatenate	O
the	O
results	O
.	O

I	O
am	O
taking	O
the	O
second	O
dataframe	O
and	O
doing	O
some	O
calculations	O
with	O
it	O
to	O
append	O
to	O
the	O
first	O
dataframe	O
.	O

However	O
it	O
does	O
not	O
appear	O
that	O
what	O
I	O
am	O
appending	O
to	O
the	O
first	O
data	O
frame	O
is	O
actually	O
happening	O
.	O

Could	O
you	O
use	O
concat	B-API
instead	O
?	O

`	O
m=	O
m.concat	O
([	O
a0	O
,	O
a1	O
,	O
a2	O
,	O
a3	O
,	O
a4	O
,	O
a5	O
,	O
a6	O
,	O
a7	O
,	O
a8	O
,	O
a9	O
]	O
,	O
ignore_index=True	O
)`	O

I	O
get	O
an	O
error	O
trying	O
to	O
use	O
this	O
...	O

AttributeError	O
:	O
'	O
DataFrame	O
'	O
object	O
has	O
no	O
attribute	O
'	O
concat	B-API
'	O

[	O
`	O
append	B-API
`]	O
(	O
#URL	O
)	O
does	O
*	O
not	O
*	O
operate	O
in	O
place	O
.	O

But	O
for	O
a	O
start	O
I	O
would	O
just	O
be	O
happy	O
to	O
get	O
the	O
first	O
result	O
.	O

I	O
suspect	O
that	O
I	O
need	O
to	O
use	O
searchsort	O
and	O
asof	B-API
,	O
but	O
I	O
am	O
not	O
quite	O
sure	O
how	O
to	O
do	O
that	O
with	O
.	O

You're	O
looking	O
for	O
a	O
near	O
timestamp	O
,	O
where	O
`	O
asof	B-API
`	O
searches	O
for	O
the	O
latest	O
timestamp	O
.	O

It	O
is	O
only	O
applied	O
to	O
a	O
time	O
series	O
,	O
so	O
you	O
would	O
have	O
to	O
apply	O
`	O
reset_index	B-API
`	O
to	O
your	O
`	O
DataFrame	O
`	O

You're	O
going	O
to	O
have	O
to	O
iterate	O
over	O
your	O
list	O
,	O
get	O
copies	O
of	O
them	O
filtered	O
and	O
then	O
concat	O
them	O
all	O
together	O
#CODE	O

A	O
solution	O
without	O
loop	O
but	O
`	O
merge	B-API
`	O
:	O
#CODE	O

If	O
there	O
are	O
no	O
blanks	O
some	O
columns	O
convert	O
to	O
`	O
TRUE	O
/	O
FALSE	O
`	O
,	O
others	O
leave	O
as	O
`	O
Yes	O
/	O
No	O
`	O
but	O
dtype	B-API
is	O
bool	B-API
.	O

`	O
fhs	O
=	O
fhs.drop	O
([	O
1002	O
])`	O
to	O
drop	O
that	O
row	O
and	O
data	O
types	O
are	O
still	O
good	O
.	O

first	O
column	O
comes	O
into	O
df	O
as	O
Yes	O
,	O
No	O
,	O
Yes	O
,	O
Yes	O
type	O
bool	O
xxxx	O
below	O

3rd	O
column	O
comes	O
into	O
df	O
as	O
FALSE	O
,	O
FALSE	O
,	O
TRUE	O
,	O
TRUE	O
type	O
bool	O

print	O
(	O
len	B-API
(	O
upregulated	O
)	O
,	O
end=	O
'	O
\n	O
')	O

remove	O
overlay	O
text	O
from	O
pandas	O
boxplot	O

I	O
am	O
trying	O
to	O
remove	O
the	O
overlay	O
text	O
on	O
my	O
boxplot	O
I	O
created	O
using	O
pandas	O
.	O

The	O
code	O
to	O
generate	O
it	O
is	O
as	O
follows	O
(	O
minus	O
a	O
few	O
other	O
modifications	O
):	O

I	O
just	O
want	O
to	O
remove	O
the	O
"	O
boxplot	O
grouped	O
by	O
0	O
...	O

I	O
know	O
how	O
to	O
create	O
a	O
new	O
column	O
with	O
`	O
apply	B-API
`	O
or	O
`	O
np.where	B-API
`	O
based	O
on	O
the	O
values	O
of	O
another	O
column	O
,	O
but	O
a	O
way	O
of	O
selectively	O
changing	O
the	O
values	O
of	O
an	O
existing	O
column	O
is	O
escaping	O
me	O
;	O
I	O
suspect	O
`	O
df.ix	B-API
`	O
is	O
involved	O
?	O

@USER	O
For	O
indexing	O
with	O
boolean	O
vectors	O
this	O
is	O
perfectly	O
fine	O
,	O
if	O
you	O
want	O
to	O
add	O
in	O
other	O
forms	O
of	O
indexing	O
you	O
would	O
want	O
`	O
loc	B-API
`	O
.	O

For	O
instance	O
:	O
`	O
df.loc	B-API
[	O
df.name.str.contains	O
(	O
'	O
e$	O
')	O
,	O
'	O
flag	O
']	O
=	O
'	O
Blue	O
'`	O
.	O

use	O
``	O
apply	B-API
``	O
ONLY	O
as	O
a	O
last	O
resort	O
(	O
e.g.	O
you	O
can't	O
do	O
vectorized	O
things	O
)	O
.	O
even	O
if	O
you	O
have	O
a	O
very	O
complicated	O
function	O
to	O
do	O
,	O
you	O
can	O
often	O
do	O
vectorized	O
calculations	O
on	O
most	O
of	O
it	O
,	O
saving	O
the	O
last	O
for	O
``	O
apply	B-API
``	O
,	O
which	O
is	O
essentially	O
a	O
loop	O
.	O

Using	O
apply	B-API
took	O
172ms	O
versus	O
39ms	O
using	O
Jeff's	O
method	O
,	O
I	O
can	O
also	O
confirm	O
that	O
it	O
made	O
negligle	O
difference	O
whether	O
the	O
apply	B-API
was	O
called	O
inside	O
or	O
outside	O
the	O
function	O
but	O
it	O
does	O
modify	O
the	O
df	O
so	O
you	O
didn't	O
need	O
to	O
return	O
the	O
df	O
as	O
it	O
was	O
being	O
modified	O
inside	O
the	O
function	O

And	O
then	O
sometimes	O
different	O
solutions	O
(	O
in	O
this	O
case	O
using	O
`	O
apply	B-API
`)	O
come	O
up	O
on	O
google	O
/	O
stackoverflow	O
and	O
yet	O
again	O
I	O
can	O
NOT	O
verify	O
that	O
there	O
is	O
no	O
better	O
solution	O
as	O
I	O
dont	O
have	O
the	O
insight	O
into	O
the	O
library	O
.	O

I	O
kindof	O
disagree	O
with	O
using	O
df	O
as	O
the	O
variable	O
name	O
here	O
,	O
I	O
also	O
think	O
I'd	O
just	O
use	O
len	B-API
:	O
`	O
df.groupby	B-API
(	O
"	O
Name	O
")	O
.filter	B-API
(	O
lambda	O
x	O
:	O
len	B-API
(	O
x	O
)	O
>	O
2	O
)`	O

Merge	O
existing	O
dataframe	O
into	O
fixed	O
size	O
new	O
dataframe	O

Then	O
I	O
want	O
merge	B-API
these	O
kinds	O
of	O
table	O
into	O
new	O
dataframe	O

How	O
could	O
I	O
merge	O
them	O
in	O
that	O
way	O
?	O

Inconsistent	O
behavior	O
of	O
apply	B-API
with	O
operator.itemgetter	O
v.s.	O
applymap	B-API
operator.itemgetter	O

`	O
apply	B-API
`	O
gives	O
wrong	O
result	O
#CODE	O

apply	B-API
is	O
being	O
passed	O
an	O
entire	O
row	O
which	O
is	O
a	O
series	O
of	O
2	O
elements	O
which	O
are	O
lists	O
;	O
the	O
last	O
list	O
is	O
returned	O
and	O
coerced	O
to	O
a	O
series	O
.	O
embedded	O
lists	O
as	O
elements	O
are	O
not	O
a	O
good	O
idea	O
in	O
general	O
.	O

The	O
reason	O
I	O
am	O
asking	O
,	O
is	O
because	O
I	O
suspect	O
(	O
?	O
)	O
it	O
is	O
faster	O
to	O
create	O
a	O
zero	O
filled	O
dataframe	O
,	O
and	O
then	O
replace	O
each	O
element	O
as	O
needed	O
.	O

So	O
it	O
might	O
be	O
faster	O
to	O
create	O
an	O
empty	O
dataframe	O
with	O
nxm	O
dimensions	O
and	O
then	O
replace	O
elements	O
as	O
needed	O
(	O
by	O
copying	O
a	O
list	O
to	O
each	O
column	O
)	O
.	O

in	O
general	O
creating	O
an	O
empty	O
frame	O
,	O
then	O
filling	O
it	O
column	O
by	O
column	O
is	O
not	O
very	O
efficient	O
;	O
use	O
a	O
dict	O
/	O
list	O
instead	O
,	O
or	O
create	O
sub-frames	O
and	O
concat	O
them	O

Are	O
you	O
trying	O
to	O
shift	O
ends	O
by	O
one	O
(	O
month	O
)	O
?	O

My	O
initial	O
suggestion	O
was	O
to	O
do	O
the	O
shift	B-API
after	O
you've	O
reindexed	O
(	O
since	O
you're	O
about	O
to	O
do	O
that	O
anyway	O
):	O
#CODE	O

the	O
shift	B-API
index	O
looks	O
like	O
a	O
better	O
fix	O
,	O
still	O
would	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
date	O
add	O
function	O
,	O
which	O
is	O
how	O
I'd	O
do	O
it	O
in	O
sql	O
,	O
that	O
could	O
apply	O
?	O

I'd	O
still	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
DateAdd	O
type	O
function	O
that	O
I	O
could	O
use	O
that	O
might	O
also	O
apply	O
for	O
use	O
elsewhere	O
if	O
needed	O
?	O

Alternatively	O
you	O
could	O
use	O
`	O
apply	B-API
`	O
(	O
but	O
this	O
will	O
usually	O
be	O
slower	O
):	O
#CODE	O

Since	O
you	O
are	O
using	O
the	O
"	O
trailing	O
row	O
"	O
you	O
are	O
going	O
to	O
need	O
to	O
use	O
`	O
shift	B-API
`	O
:	O
#CODE	O

thanks	O
shift	B-API
is	O
what	O
i	O
was	O
looking	O
for	O
.	O
now	O
i	O
can	O
find	O
examples	O
in	O
the	O
Pandas	O
book	O

I	O
have	O
been	O
searching	O
for	O
hours	O
,	O
literally	O
the	O
entire	O
day	O
on	O
how	O
to	O
generate	O
a	O
pivot	O
table	O
in	O
Python	O
.	O

What	O
I	O
want	O
is	O
to	O
take	O
a	O
csv	O
file	O
,	O
extract	O
the	O
first	O
column	O
and	O
generate	O
a	O
pivot	O
table	O
using	O
the	O
count	O
or	O
frequency	O
of	O
the	O
numbers	O
in	O
that	O
column	O
,	O
and	O
sort	O
descending	O
#CODE	O

These	O
columns	O
all	O
contain	O
an	O
identical	O
kind	O
of	O
data	O
,	O
and	O
I'd	O
like	O
to	O
stack	O
them	O
into	O
a	O
single	O
series	O
,	O
ergo	O
:	O
#CODE	O

From	O
here	O
,	O
I	O
can't	O
quite	O
figure	O
out	O
how	O
to	O
reindex	O
my	O
series	O
such	O
that	O
the	O
indexes	O
go	O
from	O
0	O
to	O
`	O
len	B-API
(	O
s	O
)`	O
.	O

But	O
it	O
could	O
be	O
an	O
unexpected	O
system	O
difference	O
--	O
I	O
am	O
using	O
Python	O
2.7.3	O
on	O
an	O
Ubuntu	O
machine	O
.	O

An	O
alternative	O
you	O
might	O
try	O
is	O
to	O
replace	O
exit()	O
with	O
os._exit	O
(	O
os.EX_OK	O
)	O
.	O

I	O
think	O
it	O
uses	O
`	O
patsy	O
`	O
in	O
the	O
backend	O
to	O
translate	O
the	O
formula	O
expression	O
,	O
and	O
intercept	O
is	O
added	O
automatically	O
.	O

Trying	O
to	O
append	O
this	O
to	O
a	O
new	O
datastore	O
.	O

The	O
datastore	O
does	O
not	O
exist	O
so	O
I	O
use	O
the	O
following	O
to	O
create	O
and	O
append	O
the	O
data	O
;	O
#CODE	O

I'm	O
not	O
looking	O
to	O
concatenate	O
strings	O
,	O
just	O
shift	O
everything	O
over	O
.	O

I	O
saw	O
a	O
method	O
using	O
"	O
R	O
"	O
and	O
melt	B-API
,	O
however	O
I	O
would	O
like	O
to	O
stick	O
with	O
python	O
/	O
pandas	O
if	O
possible	O
.	O

I	O
cannot	O
post	O
real	O
request	O
for	O
security	O
reason	O
.	O

By	O
the	O
way	O
the	O
code	O
works	O
without	O
"	O
append	B-API
"	O
within	O
for	O
loop	O
.	O

At	O
first	O
I	O
tried	O
using	O
pivot	B-API
(	O
with	O
timestamp	O
as	O
an	O
index	O
)	O
,	O
but	O
that	O
didn't	O
work	O
because	O
of	O
those	O
duplicates	O
.	O

I	O
don't	O
want	O
to	O
drop	O
them	O
,	O
since	O
the	O
other	O
data	O
is	O
different	O
and	O
should	O
not	O
be	O
lost	O
.	O

Since	O
index	O
contains	O
no	O
duplicates	O
,	O
I	O
thought	O
maybe	O
I	O
can	O
pivot	O
over	O
it	O
and	O
after	O
that	O
merge	O
the	O
result	O
into	O
the	O
original	O
DataFrame	O
,	O
but	O
I	O
was	O
wondering	O
if	O
there	O
is	O
an	O
easier	O
more	O
intuitive	O
solution	O
.	O

As	O
your	O
`	O
get_dummies	B-API
`	O
returns	O
a	O
df	O
this	O
will	O
be	O
aligned	O
already	O
with	O
your	O
existing	O
df	O
so	O
just	O
`	O
concat	B-API
`	O
column-wise	O
:	O
#CODE	O

You	O
can	O
drop	O
the	O
'	O
cat	O
'	O
column	O
by	O
doing	O
`	O
df.drop	B-API
(	O
'	O
cat	O
'	O
,	O
axis=1	O
)`	O

You	O
can	O
see	O
that	O
the	O
array	O
is	O
masked	O
and	O
that	O
some	O
of	O
the	O
first	O
few	O
rows	O
show	O
examples	O
of	O
`	O
--	O
`	O
in	O
there	O
.	O

So	O
I	O
drop	O
the	O
last	O
field	O
(	O
`	O
refGage	O
`)	O
and	O
it	O
works	O
,	O
so	O
I	O
think	O
it's	O
masked	O
values	O
which	O
only	O
appear	O
in	O
that	O
field	O
.	O

I	O
used	O
df.ix()	B-API
to	O
replace	O
the	O
filled-in	O
tokens	O
for	O
what	O
was	O
masked	O
out	O
.	O

Next	O
,	O
you	O
can	O
use	O
a	O
dictionary	O
comprehension	O
together	O
with	O
`	O
loc	B-API
`	O
to	O
select	O
the	O
relevant	O
`	O
group_no	O
`	O
dataframe	O
.	O

To	O
get	O
the	O
last	O
group	O
number	O
,	O
I	O
get	O
the	O
last	O
value	O
using	O
`	O
iat	B-API
`	O
for	O
location	O
based	O
indexing	O
.	O

Then	O
apply	O
your	O
method	O
:	O
#CODE	O

Notice	O
that	O
if	O
you	O
unstack	B-API
the	O
`	O
id	O
`	O
index	O
level	O
of	O
`	O
df	O
`	O
then	O
you	O
get	O
:	O
#CODE	O

I'm	O
not	O
used	O
to	O
working	O
with	O
`	O
lists	O
`	O
in	O
columns	O
of	O
Pandas	O
and	O
don't	O
know	O
how	O
to	O
get	O
the	O
intersection	O
of	O
`	O
lists	O
`	O
from	O
two	O
columns	O
in	O
a	O
`	O
dataframe	O
`	O
,	O
then	O
get	O
the	O
index	O
of	O
where	O
the	O
words	O
appear	O
,	O
then	O
apply	O
plus	O
signs	O
to	O
the	O
front	O
of	O
each	O
found	O
index	O
.	O

Or	O
maybe	O
easier	O
would	O
be	O
a	O
string	O
replacement	O
on	O
`	O
df	O
[	O
'	O
Keyword	O
']`	O
using	O
the	O
words	O
from	O
`	O
StemmedAG	O
`	O
?	O

You	O
can	O
use	O
`	O
pivot	B-API
`	O
#CODE	O

Cool	O
I	O
didn't	O
know	O
about	O
pivot	B-API
either	O
...	O

Instead	O
of	O
creating	O
it	O
,	O
we	O
can	O
append	O
it	O
to	O
initial	O
StartDate	O
.	O

However	O
,	O
the	O
DptCityDptCountry	O
might	O
be	O
different	O
but	O
if	O
another	O
ID	O
matches	O
with	O
the	O
StartDate	O
and	O
DptCityDptCountry	O
,	O
it	O
will	O
be	O
added	O
up	O
i.e.	O
#CODE	O

Then	O
use	O
apply	B-API
and	O
return	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
set	O
of	O
dates	O
for	O
each	O
row	O
(	O
Series	O
of	O
Series	O
=	O
DataFrame	O
)	O
.	O

So	O
for	O
each	O
of	O
the	O
7	O
rows	O
in	O
the	O
DataFrame	O
,	O
I	O
get	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
date	O
range	O
.	O

Then	O
its	O
just	O
clever	O
stacking	O
,	O
naming	O
,	O
and	O
reset_index	B-API
.	O

Also	O
,	O
if	O
you	O
want	O
to	O
have	O
the	O
ticklabels	O
/	O
tickmarks	O
of	O
the	O
x-axis	O
connected	O
to	O
the	O
"	O
middle	O
axis	O
"	O
(	O
also	O
while	O
panning	O
/	O
zooming	O
)	O
,	O
then	O
it's	O
easiest	O
to	O
insert	O
an	O
extra	O
spine	O
;	O
take	O
a	O
look	O
at	O
[	O
`	O
mpl_toolkits.axisartist	B-API
`]	O
(	O
#URL	O
)	O
for	O
some	O
examples	O
of	O
this	O
.	O

print	O
(	O
'	O
Stock	O
:	O
'	O
,	O
col	O
,	O
'	O
max	O
diff	B-API
:	O
'	O
,	O
sl.max()	O
-	O
sl.min()	O
)`	O

Then	O
merge	O
back	O
to	O
the	O
original	O
dataframe	O
to	O
have	O
your	O
aggregates	O
displayed	O
against	O
each	O
row	O
:	O
#CODE	O

Unfortunately	O
im	O
getting	O
an	O
issue	O
when	O
trying	O
to	O
do	O
the	O
rename	O
.	O

The	O
true	O
/	O
false	O
column	O
does	O
not	O
have	O
a	O
column	O
name	O
,	O
so	O
how	O
would	O
I	O
rename	O
it	O
and	O
then	O
merge	O
it	O
back	O
into	O
the	O
original	O
dataframe	O
?	O

I	O
am	O
using	O
the	O
below	O
code	O
which	O
gives	O
me	O
the	O
summary	O
of	O
count	O
in	O
the	O
pivot	O
table	O
,	O
#CODE	O

but	O
what	O
i	O
want	O
is	O
the	O
%	O
of	O
row	O
calculation	O
as	O
in	O
excel	O
pivot	O
when	O
you	O
right	O
click	O
the	O
pivot	O
and	O
select	O
"	O
show	O
value	O
as	O
->	O
%	O
of	O
Row	O
Total	O
"	O
.	O

Since	O
my	O
Document	O
is	O
a	O
non-numeric	O
value	O
i	O
was	O
not	O
able	O
to	O
get	O
it	O
.	O

i	O
am	O
trying	O
to	O
manipulate	O
the	O
pivot	O
data	O
which	O
will	O
give	O
me	O
the	O
row	O
total	O
,	O
not	O
the	O
data	O
from	O
the	O
dataframe	O
and	O
what	O
i	O
wanted	O
is	O
"	O
%	O
of	O
row	O
total	O
"	O
.	O

you	O
can	O
actually	O
just	O
pass	O
`	O
aggfunc=len	O
`	O
,	O
since	O
`	O
len	B-API
`	O
is	O
already	O
a	O
function	O
:)	O

Hi	O
maxymoo	O
in	O
the	O
link	O
you	O
have	O
given	O
they	O
are	O
manipulating	O
one	O
of	O
the	O
column	O
from	O
the	O
dataframe	O
,	O
but	O
my	O
question	O
is	O
different	O
i	O
am	O
trying	O
to	O
manipulate	O
the	O
pivot	O
data	O
which	O
will	O
give	O
me	O
the	O
row	O
total	O
and	O
what	O
i	O
wanted	O
is	O
"	O
%	O
of	O
row	O
total	O
"	O
.	O

Then	O
you	O
can	O
basically	O
use	O
the	O
solution	O
@USER	O
linked	O
to	O
,	O
but	O
you	O
need	O
to	O
use	O
`	O
iloc	B-API
`	O
or	O
similar	O
b	O
/	O
c	O
the	O
table	O
columns	O
are	O
a	O
little	O
complicated	O
now	O
(	O
being	O
a	O
multi-indexed	O
result	O
of	O
the	O
pivot	O
table	O
)	O
.	O

Unfortunately	O
,	O
if	O
I	O
try	O
to	O
resample	O
,	O
I	O
get	O
an	O
error	O
#CODE	O

Are	O
you	O
ask	O
for	O
a	O
process	O
to	O
interpolate	O
,	O
or	O
a	O
process	O
to	O
aggregate	O
,	O
or	O
both	O
?	O

Firstly	O
,	O
prepare	O
a	O
function	O
to	O
map	O
the	O
day	O
to	O
week	O
#CODE	O

Assume	O
now	O
your	O
initialized	O
new	O
dataframe	O
is	O
`	O
result	O
`	O
,	O
you	O
can	O
now	O
do	O
a	O
join	B-API
#CODE	O

The	O
`	O
Nan	O
`	O
is	O
what	O
you	O
need	O
to	O
interpolate	O
.	O

Turns	O
out	O
the	O
key	O
is	O
to	O
resample	O
a	O
groupby	B-API
object	O
like	O
so	O
:	O
#CODE	O

Then	O
,	O
I	O
append	O
a	O
row	O
of	O
missing	O
values	O
.	O

Finally	O
,	O
I	O
can	O
insert	O
values	O
into	O
this	O
DataFrame	O
one	O
cell	O
at	O
a	O
time	O
.	O

This	O
approach	O
works	O
perfectly	O
fine	O
,	O
with	O
the	O
exception	O
that	O
the	O
append	B-API
statement	O
inserts	O
an	O
additional	O
column	O
to	O
my	O
DataFrame	O
.	O

The	O
append	B-API
is	O
trying	O
to	O
append	O
a	O
column	O
to	O
your	O
dataframe	O
.	O

The	O
column	O
it	O
is	O
trying	O
to	O
append	B-API
is	O
not	O
named	O
and	O
has	O
two	O
None	O
/	O
Nan	O
elements	O
in	O
it	O
which	O
pandas	O
will	O
name	O
(	O
by	O
default	O
)	O
as	O
column	O
named	O
0	O
.	O

In	O
order	O
to	O
do	O
this	O
successfully	O
,	O
the	O
column	O
names	O
coming	O
into	O
the	O
append	B-API
for	O
the	O
data	O
frame	O
must	O
be	O
consistent	O
with	O
the	O
current	O
data	O
frame	O
column	O
names	O
or	O
else	O
new	O
columns	O
will	O
be	O
created	O
(	O
by	O
default	O
)	O
#CODE	O

have	O
merged	O
2	O
dataframes	O
with	O
left	O
join	B-API
.	O
works	O
as	O
I	O
expected	O
until	O
I	O
attempt	O
to	O
use	O
the	O
generated	O
value	O
in	O
a	O
simple	O
string	O
concatenation	O
.	O

I	O
am	O
ultimately	O
trying	O
to	O
merge	O
two	O
dataframes	O
together	O
,	O
but	O
I	O
am	O
running	O
into	O
an	O
issue	O
when	O
I	O
try	O
to	O
specify	O
the	O
column	O
on	O
which	O
they	O
should	O
be	O
merged	O
.	O

Conform	O
the	O
index	O
to	O
another	O
frequency	O
.	O

Then	O
its	O
straightforward	O
to	O
resample	O
to	O
another	O
frequency	O
.	O

In	O
the	O
second	O
chunk	O
you	O
are	O
resampling	O
and	O
the	O
result	O
is	O
a	O
Series	O
of	O
monthly	O
frequency	O
so	O
it	O
would	O
appear	O
that	O
the	O
daily	O
information	O
is	O
lost	O
.	O

Then	O
you	O
resample	O
and	O
somehow	O
the	O
days	O
are	O
there	O
?	O

I	O
want	O
to	O
use	O
a	O
combination	O
of	O
map	B-API
&	O
lambda	O
functions	O
to	O
do	O
this	O

the	O
map	B-API
function	O
does	O
not	O
append	O
to	O
NN	O
.	O

Have	O
you	O
tried	O
using	O
`	O
concat	B-API
`	O
and	O
a	O
generator	O
expression	O
instead	O
:	O
#CODE	O

Can	O
Pandas	O
find	O
all	O
the	O
lines	O
that	O
join	O
any	O
pair	O
of	O
dots	O
and	O
don't	O
intersect	O
any	O
of	O
the	O
given	O
lines	O
without	O
iteration	O
?	O

I'm	O
a	O
Stata	O
user	O
and	O
in	O
Stata	O
,	O
I'd	O
be	O
using	O
replace	B-API
command	O
conditional	O
on	O
regexm	O
.	O

I'm	O
trying	O
to	O
learn	O
Python	O
and	O
it's	O
been	O
a	O
difficult	O
journey	O
!	O

We	O
then	O
apply	O
another	O
function	O
to	O
this	O
that	O
converts	O
the	O
str	O
numbers	O
to	O
ints	O
,	O
puts	O
these	O
in	O
a	O
list	O
and	O
returns	O
the	O
smallest	O
value	O
:	O
#CODE	O

this	O
is	O
an	O
approach	O
that	O
I	O
hadn't	O
thought	O
about	O
and	O
one	O
that	O
I'm	O
likely	O
to	O
employ	O
down	O
the	O
road	O
.	O
for	O
age	O
,	O
I	O
wanted	O
the	O
series	O
[	O
62	O
,	O
55	O
,	O
67	O
]	O
at	O
the	O
end	O
,	O
and	O
the	O
problem	O
I'm	O
having	O
now	O
is	O
that	O
I	O
can't	O
target	O
just	O
row2	O
when	O
I	O
apply	O
split	B-API
(	O
'	O
')	O
.	O

return	O
min	B-API
(	O
list	O
(	O
map	B-API
(	O
int	O
,	O
x	O
)))`	O
to	O
`	O
def	O
highest	O
(	O
x	O
):	O

return	O
max	B-API
(	O
list	O
(	O
map	B-API
(	O
int	O
,	O
x	O
)))`	O

I	O
want	O
to	O
apply	O
df	O
[	O
'	O
age	O
']	O
=d	O
f	O
[	O
'	O
e0	O
']	O
[(	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
str	O
(	O
x	O
)	O
.split	B-API
(	O
'	O
')	O
[	O
1	O
])	O
to	O
only	O
rows	O
for	O
which	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)	O
so	O
as	O
to	O
not	O
overwrite	O
what	O
was	O
already	O
in	O
the	O
age	O
column	O
...	O

Suppose	O
I	O
have	O
two	O
DataFrames	O
a	O
b	O
where	O
a	O
is	O
larger	O
than	O
b	O
and	O
has	O
all	O
NaNs	O
.	O

I	O
wish	O
to	O
merge	O
the	O
values	O
from	O
b	O
into	O
a	O
.	O

the	O
w	O
variable	O
will	O
not	O
surpass	O
len	B-API
(	O
seq	O
)	O
.	O

For	O
example	O
instead	O
of	O
looping	O
trough	O
every	O
element	O
in	O
a	O
numpy	O
array	O
to	O
do	O
some	O
processing	O
you	O
can	O
apply	O
a	O
numpy	O
function	O
directly	O
on	O
the	O
array	O
and	O
get	O
the	O
results	O
in	O
seconds	O
rather	O
than	O
hours	O
.	O
as	O
an	O
example	O
:	O
#CODE	O

Computing	O
`	O
len	B-API
(	O
seq	O
)`	O
inside	O
the	O
loop	O
is	O
not	O
necessary	O
,	O
since	O
its	O
value	O
is	O
not	O
changing	O
.	O

You	O
don't	O
really	O
need	O
the	O
`	O
if	O
`	O
statement	O
,	O
since	O
in	O
your	O
code	O
it	O
always	O
evaluate	O
to	O
true	O
(	O
`	O
w	O
in	O
range	O
(	O
len	B-API
(	O
seq	O
))`	O
means	O
`	O
w	O
`	O
maximium	O
value	O
will	O
be	O
`	O
len	B-API
(	O
seq	O
)	O
-1	O
`)	O
.	O

I	O
tried	O
pivot	B-API
but	O
it	O
returns	O
an	O
error	O

Hmm	O
My	O
dataframe	O
had	O
12	O
rows	O
but	O
when	O
i	O
tried	O
the	O
unstack	B-API
operation	O
the	O
resulting	O
dataframe	O
has	O
only	O
6	O
rows	O
not	O
exactly	O
what	O
i	O
want.My	O
resulting	O
dataframe	O
should	O
also	O
have	O
12	O
rows	O

For	O
example	O
,	O
say	O
`	O
Jul-03	O
`	O
data	O
,	O
row	O
`	O
0	O
,	O
6	O
,	O
9	O
`	O
are	O
all	O
records	O
about	O
the	O
same	O
`	O
snapDate	O
`	O
with	O
instance	O
`	O
XX	O
`	O
.	O

So	O
doing	O
a	O
pivot	B-API
would	O
reshape	O
these	O
3	O
rows	O
to	O
only	O
one	O
row	O
because	O
those	O
data	O
have	O
been	O
moved	O
to	O
columns	O
.	O

Hi	O
I	O
went	O
ahead	O
and	O
changed	O
the	O
datatype	O
of	O
AvgWaitInMs	O
to	O
int	O
and	O
the	O
pivot	B-API
worked	O

What	O
I	O
would	O
like	O
to	O
do	O
is	O
slice	O
each	O
group	O
down	O
to	O
3	O
hours	O
max	O
and	O
append	O
something	O
to	O
the	O
6	O
and	O
9	O
length	O
groups	O
to	O
denote	O
that	O
it	O
is	O
the	O
same	O
page	O
like	O
the	O
following	O
:	O
#CODE	O

So	O
,	O
I	O
truncated	O
my	O
data	O
set	O
in	O
the	O
question	O
to	O
make	O
it	O
easier	O
to	O
read	O
and	O
thinking	O
that	O
whatever	O
solution	O
came	O
would	O
also	O
apply	O
..	O

If	O
'	O
data	O
'	O
is	O
a	O
pd.DataFrame	B-API
and	O
you	O
iterate	O
over	O
range	O
(	O
0	O
,	O
len	B-API
(	O
data	O
))	O
and	O
then	O
add	O
data	O
to	O
your	O
list	O
'	O
all_info	O
'	O
,	O
you	O
simply	O
add	O
the	O
whole	O
DataFrame	O
'	O
data	O
'	O
i	O
times	O
to	O
the	O
list	O
.	O

Python	O
pandas	O
:	O
retrieve	O
the	O
field	O
associated	O
to	O
the	O
min	O
of	O
another	O
(	O
cross	O
apply	O
equivalent	O
)	O

In	O
SQL	O
I	O
was	O
used	O
to	O
doing	O
this	O
with	O
a	O
cross	O
apply	O
.	O

PS	O
other	O
than	O
calculating	O
the	O
min	O
first	O
,	O
then	O
doing	O
a	O
join	B-API
on	O
primary	O
key	O
and	O
date	O

I	O
can	O
do	O
this	O
in	O
two	O
steps	O
:	O
1	O
)	O
group	O
by	O
primary	O
key	O
and	O
calculate	O
min	O
(	O
date	O
)	O
2	O
)	O
do	O
an	O
inner	O
join	B-API
between	O
the	O
starting	O
table	O
and	O
the	O
table	O
calculated	O
in	O
the	O
previous	O
step	O
,	O
on	O
primary	O
key	O
and	O
date	O
,	O
to	O
retrieve	O
the	O
amount	O

Call	O
`	O
resample	B-API
`	O
and	O
pass	O
the	O
rule	O
as	O
'	O
10Min	O
'	O
:	O
#CODE	O

The	O
quickest	O
way	O
I	O
know	O
how	O
to	O
wrangle	O
this	O
thing	O
into	O
a	O
long	O
form	O
dataframe	O
is	O
using	O
`	O
stack	B-API
`	O
and	O
then	O
`	O
reset_index	B-API
`	O
:	O
#CODE	O

Maybe	O
my	O
real	O
question	O
is	O
"	O
why	O
isn't	O
`	O
melt	B-API
`	O
a	O
DataFrame	O
method	O
?	O

This	O
works	O
pretty	O
well	O
:	O
`	O
pd.melt	B-API
(	O
wide_df.reset_index()	O
,	O
"	O
subject	O
")`	O
,	O
but	O
it	O
feels	O
like	O
it	O
would	O
be	O
easier	O
to	O
read	O
as	O
chained	O
method	O
calls	O
that	O
can	O
be	O
read	O
in	O
linear	O
order	O
.	O

not	O
sure	O
why	O
their	O
isn't	O
a	O
``	O
melt	B-API
``	O
on	O
DataFrame	O
,	O
could	O
/	O
should	O
be	O
.	O

bool	O
operator	O
in	O
for	O
Timestamp	O
in	O
Series	O
does	O
not	O
work	O

Is	O
there	O
a	O
way	O
to	O
drop	O
columns	O
in	O
a	O
Dataframe	O
with	O
column	O
names	O
having	O
a	O
particular	O
letter	O
as	O
I	O
wasn't	O
able	O
to	O
find	O
any	O
information	O
on	O
this	O
?	O

I	O
want	O
to	O
drop	O
all	O
column	O
headers	O
having	O
the	O
letter	O
`	O
F	O
`	O
in	O
them	O
.	O

I	O
was	O
planning	O
on	O
doing	O
it	O
using	O
`	O
df.drop	B-API
([	O
df.columns	B-API
[[	O
column_names	O
]]]	O
,	O
axis=1	O
)`	O
,	O
but	O
there	O
are	O
so	O
many	O
that	O
I	O
was	O
wondering	O
if	O
there	O
is	O
an	O
easier	O
way	O
to	O
do	O
this	O
.	O

Rolling	B-API
argmax	B-API
in	O
pandas	O

I	O
have	O
a	O
pandas	O
TimeSeries	O
and	O
would	O
like	O
to	O
apply	O
the	O
argmax	B-API
function	O
to	O
a	O
rolling	B-API
window	O
.	O

However	O
,	O
due	O
to	O
casting	O
to	O
float	O
from	O
rolling_apply	B-API
,	O
if	O
I	O
apply	O
`	O
numpy.argmax()	B-API
`	O
,	O
I	O
only	O
obtain	O
the	O
index	O
of	O
the	O
slice	O
of	O
the	O
ndarray	O
.	O

Is	O
there	O
a	O
way	O
to	O
apply	O
a	O
rolling	B-API
argmax	B-API
to	O
a	O
Series	O
/	O
DataFrame	O
?	O

Here	O
is	O
a	O
work-around	O
,	O
essentially	O
doing	O
the	O
apply	B-API
'	O
manually	O
'	O
,	O
should	O
be	O
pretty	O
efficient	O
actually	O
.	O

You	O
could	O
do	O
a	O
`	O
shift	B-API
`	O
first	O
:	O
#CODE	O

Merge	O
csv's	O
with	O
some	O
common	O
columns	O
and	O
fill	O
in	O
Nans	O

pandas	O
-	O
resample	B-API
-	O
upsampling	O
before	O
downsampling	O

My	O
objective	O
is	O
to	O
resample	O
this	O
data	O
frame	O
with	O
a	O
fixed	O
time	O
window	O
(	O
e.g.	O
:	O
1	O
second	O
)	O
using	O
last	O
for	O
regularization	O
when	O
upsampling	O
and	O
the	O
mean	O
for	O
downsampling	O
.	O

Is	O
this	O
possible	O
at	O
all	O
using	O
pandas	O
resample	B-API
function	O
?	O

You	O
can't	O
mix	O
upsample	O
/	O
downsample	O
in	O
a	O
single	O
`	O
resample	B-API
`	O
operation	O
.	O

I'm	O
not	O
sure	O
why	O
the	O
order	O
of	O
operations	O
would	O
matter	O
to	O
you	O
as	O
long	O
as	O
you	O
get	O
the	O
desired	O
results	O
.	O

Thanks	O
for	O
your	O
answer	O
,	O
it	O
was	O
not	O
clear	O
to	O
me	O
that	O
you	O
had	O
to	O
make	O
multiple	O
calls	O
to	O
resample	B-API
.	O

You	O
can	O
then	O
concat	O
this	O
back	O
to	O
get	O
the	O
'	O
I	O
'	O
column	O
back	O
:	O
#CODE	O

Actually	O
setting	O
index_col=	O
'	O
I	O
'	O
when	O
reading	O
allows	O
to	O
avoid	O
the	O
concat	B-API
!	O

As	O
a	O
follow	O
up	O
to	O
this	O
post	O
,	O
I	O
would	O
like	O
to	O
concatenate	O
a	O
number	O
of	O
columns	O
based	O
on	O
their	O
index	O
but	O
I	O
am	O
encountering	O
some	O
problems	O
.	O

In	O
this	O
example	O
I	O
get	O
an	O
Attribute	O
error	O
related	O
to	O
the	O
map	B-API
function	O
.	O

Help	O
around	O
this	O
error	O
would	O
be	O
appreciated	O
as	O
would	O
code	O
that	O
does	O
the	O
equivalent	O
concatenation	O
of	O
columns	O
.	O

note	O
that	O
support	O
for	O
`	O
filter	B-API
(	O
None	O
,	O
iterable	O
)`	O
ceased	O
in	O
Python	O
3	O
,	O
need	O
to	O
do	O
`	O
filter	B-API
(	O
bool	O
,	O
iterable	O
)`	O
there	O

I	O
have	O
found	O
workaround	O
which	O
is	O
extremely	O
slow	O
due	O
to	O
the	O
"	O
in	O
python	O
"	O
apply	B-API
:	O
#CODE	O

How	O
to	O
drop	O
extra	O
copy	O
of	O
duplicate	O
index	O
of	O
Pandas	O
Series	O
?	O

So	O
how	O
to	O
drop	O
extra	O
duplicate	O
rows	O
of	O
series	O
,	O
keep	O
the	O
unique	O
rows	O
and	O
only	O
one	O
copy	O
of	O
the	O
duplicate	O
rows	O
in	O
an	O
efficient	O
way	O
?	O

One	O
way	O
would	O
be	O
using	O
`	O
drop	B-API
`	O
and	O
`	O
index.get_duplicates	B-API
`	O
:	O
#CODE	O

Not	O
totally	O
drop	O
the	O
duplicated	O
ones	O
.	O

You	O
can	O
groupby	B-API
the	O
index	O
and	O
apply	O
a	O
function	O
that	O
returns	O
one	O
value	O
per	O
index	O
group	O
.	O

@USER	O
sorry	O
,	O
"	O
arbitrary	O
"	O
of	O
length	O
len	B-API
(	O
s	O
)	O
:)	O
.	O

Below	O
is	O
my	O
snippet	O
:	O
import	O
pandas	O
as	O
pd	O
;	O
idx_tp	O
=	O
[(	O
'	O
600809	O
'	O
,	O
'	O
20061231	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070331	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070630	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070331	O
')]	O
;	O
dt	B-API
=	O
[	O
'	O
demo	O
'	O
,	O
'	O
demo	O
'	O
,	O
'	O
demo	O
'	O
,	O
'	O
demo	O
']	O
;	O
idx	O
=	O
pd.MultiIndex.from_tuples	B-API
(	O
idx_tp	O
,	O
names	O
=	O
[	O
'	O
STK_ID	O
'	O
,	O
'	O
RPT_Date	O
'])	O
;	O
s	O
=	O
pd.Series	B-API
(	O
dt	B-API
,	O
index=idx	O
);	O
#	O
s.groupby	O
(	O
s.index	O
)	O
.first()	B-API
will	O
crash	O
on	O
my	O
machine	O

Edit	O
:	O
another	O
solution	O
which	O
is	O
faster	O
is	O
to	O
use	O
`	O
value_counts	B-API
`	O
(	O
and	O
normalize	B-API
):	O
#CODE	O

I	O
had	O
thought	O
this	O
was	O
more	O
concisely	O
written	O
as	O
a	O
`	O
resample	B-API
`	O
,	O
if	O
you	O
use	O
a	O
DatetimeIndex	B-API
:	O

len	B-API
(	O
Series.unique()	B-API
)	O
might	O
be	O
even	O
faster	O
.	O

Interestingly	O
,	O
len	B-API
(	O
Series.unique()	B-API
)	O
is	O
usually	O
much	O
faster	O
than	O
Series.nunique()	B-API
.	O

Next	O
,	O
these	O
3	O
columns	O
should	O
be	O
combined	O
into	O
one	O
column	O
-	O
the	O
mean	O
of	O
the	O
order	O
numbers	O
-	O
but	O
I	O
do	O
know	O
how	O
to	O
do	O
that	O
part	O
(	O
with	O
apply	B-API
and	O
axis=1	O
)	O
.	O

I	O
would	O
like	O
to	O
normalize	O
my	O
data	O
by	O
dividing	O
every	O
row	O
by	O
the	O
first	O
value	O
of	O
that	O
very	O
row	O
.	O

I	O
am	O
just	O
getting	O
stuck	O
on	O
"	O
setting	O
with	O
chained	O
indexing	O
"	O
and	O
setting	O
with	O
iloc	B-API
/	O
loc	B-API
/	O
ix	B-API
.	O

I	O
can't	O
figure	O
out	O
how	O
to	O
represent	O
this	O
using	O
iloc	B-API
,	O
loc	B-API
and	O
ix	B-API
.	O

Python	O
2.7	O
&	O
Pandas	O
:	O
How	O
to	O
replace	O
values	O
at	O
12:00	O
with	O
values	O
from	O
11:55	O
?	O

How	O
do	O
I	O
explicitly	O
say	O
'	O
replace	O
the	O
values	O
at	O
19:40	O
:	O
00	O
with	O
the	O
values	O
at	O
19:35	O
:	O
00	O
?	O

Python	O
merge	O
excel	O
documents	O
with	O
dynamic	O
columns	O

However	O
,	O
since	O
they	O
are	O
not	O
100%	O
identical	O
,	O
I	O
cannot	O
simply	O
merge	O
them	O
together	O
and	O
upload	O
it	O
into	O
a	O
database	O
without	O
messing	O
up	O
the	O
data	O
.	O

If	O
a	O
large	O
proportion	O
of	O
them	O
are	O
similar	O
,	O
and	O
this	O
is	O
a	O
one-off	O
operation	O
it	O
may	O
be	O
worth	O
your	O
while	O
coding	O
the	O
solution	O
for	O
the	O
majority	O
and	O
handling	O
the	O
other	O
documents	O
(	O
or	O
groups	O
of	O
them	O
if	O
they	O
are	O
similar	O
)	O
separately	O
.	O

Any	O
recommendations	O
to	O
a	O
db	O
that	O
would	O
allow	O
me	O
to	O
dump	O
a	O
few	O
thousand	O
excel	O
documents	O
and	O
then	O
create	O
join	O
queries	O
to	O
the	O
VIN	O
column	O
?	O

I	O
am	O
doing	O
a	O
transformation	O
on	O
a	O
variable	O
from	O
a	O
pandas	O
dataframe	O
and	O
then	O
I	O
would	O
like	O
to	O
replace	O
the	O
column	O
with	O
my	O
new	O
values	O
.	O

The	O
problem	O
seems	O
to	O
be	O
that	O
after	O
the	O
transformation	O
,	O
the	O
length	O
of	O
the	O
array	O
is	O
not	O
the	O
same	O
as	O
the	O
length	O
of	O
my	O
dataframe's	O
index	O
.	O

When	O
I	O
check	O
the	O
length	O
,	O
these	O
lengths	O
seem	O
to	O
disagree	O
.	O

The	O
len	B-API
(	O
array	O
)	O
says	O
it	O
is	O
2	O
but	O
when	O
I	O
call	O
the	O
stats.boxcox	O
it	O
says	O
it	O
is	O
50000	O
.	O

Print	O
out	O
`	O
len	B-API
(	O
df	O
)`	O
and	O
`	O
len	B-API
(	O
stats.boxcox	O
(	O
df.variable	O
))`	O
.	O

How	O
to	O
calculate	O
the	O
count	O
of	O
column	O
values	O
less	O
than	O
95	O
on	O
each	O
row	O
on	O
pandas	O
pivot	O
table	O

I	O
am	O
new	O
to	O
pandas	O
pivot	O
tables	O
,	O
how	O
to	O
get	O
the	O
count	O
of	O
column	O
values	O
less	O
than	O
95	O
for	O
a	O
row	O
on	O
pandas	O
pivot	O
table	O
#CODE	O

My	O
decorated	O
DataFrames	O
return	O
new	O
and	O
similarly	O
decorated	O
DataFrames	O
when	O
I	O
use	O
methods	O
such	O
as	O
copy	B-API
and	O
groupby.agg	B-API
.	O

I.e.	O
,	O
how	O
can	O
I	O
have	O
my	O
decorated	O
DataFrames	O
replace	O
the	O
stock	O
DataFrames	O
?	O

Still	O
not	O
getting	O
the	O
hang	O
of	O
pandas	O
,	O
I	O
am	O
attempting	O
to	O
join	O
two	O
data	O
frames	O
in	O
Pandas	O
using	O
merge	B-API
.	O

I	O
have	O
read	O
in	O
the	O
CSVs	O
into	O
two	O
data	O
frames	O
(	O
named	O
dropData	O
and	O
deosData	O
in	O
the	O
code	O
below	O
)	O
.	O

The	O
deosData	O
file	O
is	O
an	O
entire	O
year	O
s	O
worth	O
of	O
observations	O
that	O
I	O
am	O
trying	O
to	O
match	O
up	O
with	O
corresponding	O
entries	O
in	O
dropData	O
.	O

I	O
have	O
gone	O
through	O
the	O
documentation	O
for	O
the	O
merge	B-API
function	O
and	O
have	O
tried	O
the	O
following	O
code	O
in	O
various	O
iterations	O
,	O
so	O
far	O
I	O
have	O
only	O
been	O
able	O
to	O
have	O
a	O
blank	O
data	O
frame	O
with	O
correct	O
header	O
row	O
,	O
or	O
have	O
the	O
two	O
data	O
frames	O
merged	O
on	O
the	O
0	O
--	O
(	O
N-1	O
)	O
indexing	O
that	O
is	O
assigned	O
by	O
default	O
:	O

After	O
searching	O
on	O
SE	O
and	O
the	O
Doc	O
s	O
I	O
have	O
tried	O
resetting	O
the	O
index	O
,	O
ignoring	O
the	O
index	O
columns	O
,	O
copying	O
the	O
Date_Time	O
column	O
as	O
a	O
separate	O
index	O
and	O
trying	O
to	O
merge	O
on	O
the	O
new	O
column	O
,	O
I	O
have	O
tried	O
using	O
on=None	O
,	O
left_on	O
and	O
right_on	O
as	O
permutations	O
of	O
Date_Time	O
to	O
no	O
avail	O
.	O

I	O
have	O
checked	O
the	O
column	O
data	O
types	O
,	O
Date_Time	O
in	O
both	O
are	O
dtype	B-API
Objects	O
,	O
I	O
do	O
not	O
know	O
if	O
this	O
is	O
the	O
source	O
of	O
the	O
error	O
,	O
since	O
the	O
only	O
issues	O
I	O
could	O
find	O
searching	O
revolved	O
around	O
matching	O
different	O
dtypes	B-API
to	O
each	O
other	O
.	O

What	O
I	O
am	O
looking	O
to	O
do	O
is	O
have	O
the	O
two	O
data	O
frames	O
merge	O
where	O
the	O
two	O
'	O
Date_Time	O
'	O
columns	O
intersect	O
.	O

You	O
can	O
use	O
`	O
join	B-API
`	O
,	O
but	O
you	O
first	O
need	O
to	O
set	O
the	O
index	O
:	O
#CODE	O

You	O
can	O
also	O
do	O
`	O
groupby	B-API
(	O
...,	O
as_index=False	O
)`	O
,	O
though	O
buggy	O
with	O
apply	B-API
in	O
0.12	O
,	O
fixed	O
in	O
0.13	O
.	O

I've	O
converted	O
the	O
last	O
step	O
to	O
no	O
longer	O
be	O
a	O
loop	O
and	O
instead	O
save	O
directly	O
to	O
a	O
list	O
.	O

AFAIK	O
,	O
you	O
would	O
have	O
to	O
separate	O
the	O
two	O
parts	O
and	O
append	O
as	O
lists	O
since	O
the	O
columns	O
of	O
interest	O
are	O
different	O
and	O
converting	O
to	O
a	O
dictionary	O
would	O
include	O
the	O
`	O
NaN	O
`	O
s	O
otherwise	O
.	O

When	O
using	O
the	O
pure	O
XlsxWriter	O
I	O
can	O
apply	O
formats	O
to	O
cells	O
what	O
also	O
works	O
nice	O
.	O

Basically	O
how	O
would	O
I	O
apply	O
`	O
df	O
[	O
'	O
col1	O
']	O
.str	B-API
.contains	B-API
(	O
'	O
^	O
')`	O
to	O
an	O
entire	O
dataframe	O
at	O
once	O
and	O
filter	O
down	O
to	O
any	O
rows	O
that	O
have	O
records	O
containing	O
the	O
match	O
?	O

Pandas	O
:	O
apply	O
different	O
functions	O
to	O
different	O
columns	O

i	O
am	O
looking	O
to	O
apply	O
multiply	O
masks	O
on	O
each	O
column	O
of	O
a	O
pandas	O
dataset	O
(	O
respectively	O
to	O
it's	O
properties	O
)	O
in	O
python	O
.	O

how	O
can	O
i	O
apply	O
the	O
concat_mask	O
on	O
df	O
,	O
so	O
that	O
i	O
select	O
rows	O
,	O
in	O
which	O
all	O
Boolean	O
criteria	O
are	O
matched	O
(	O
are	O
True	O
)	O
?	O

.	O
Can	O
You	O
insert	O
that	O
into	O
your	O
answer	O
?	O

In	O
the	O
proper	O
code	O
i	O
actually	O
iterate	O
throw	O
all	O
columns	O
and	O
apply	O
various	O
of	O
diffenrent	O
conditions	O
to	O
mask	O
each	O
column	O
.	O

If	O
you	O
return	O
a	O
Series	O
of	O
the	O
(	O
split	O
)	O
location	O
,	O
you	O
can	O
merge	O
(	O
`	O
join	B-API
`	O
to	O
merge	O
on	O
index	O
)	O
the	O
resulting	O
DF	O
directly	O
with	O
your	O
value	O
column	O
.	O

If	O
I'm	O
not	O
mistaken	O
,	O
it	O
only	O
works	O
if	O
`	O
df	O
`	O
has	O
index	O
that	O
is	O
`	O
range	O
(	O
len	B-API
(	O
df	O
))`	O
,	O
right	O
?	O

`	O
join	B-API
`	O
is	O
shorthand	O
for	O
merging	O
on	O
index	O
with	O
both	O
frames	O
,	O
so	O
the	O
indices	O
need	O
only	O
be	O
consistent	O
(	O
which	O
it	O
will	O
be	O
here	O
as	O
the	O
apply	B-API
and	O
col	O
selection	O
don't	O
affect	O
it	O
)	O
.	O

How	O
to	O
resample	O
a	O
dataframe	O
with	O
different	O
functions	O
applied	O
to	O
each	O
column	O
?	O

@	O
Wes	O
McKinney	O
this	O
should	O
be	O
`	O
resample	B-API
`	O
in	O
0.8	O
,	O
isn't	O
it	O
?	O

Therefore	O
,	O
I	O
join	B-API
the	O
index	O
of	O
`	O
count_df	O
`	O
(	O
`	O
left_index=True	O
`)	O
with	O
the	O
`	O
CompanyName	O
`	O
column	O
of	O
`	O
df	O
`	O
(	O
`	O
right_on=	O
"	O
CompanyName	O
"`)	O
.	O

You	O
can	O
drop	O
the	O
extraneous	O
column	O
using	O
`	O
df.drop	B-API
`	O
:	O
#CODE	O

(	O
3	O
)	O
save	O
the	O
header	O
columns	O
for	O
concat	B-API
later	O
#CODE	O

(	O
5	O
)	O
output	O
:	O
concat	B-API
[	O
header	O
data	O
]	O
.	O
write	O
output	O
#CODE	O

groupby	B-API
after	O
concat	B-API
,	O
column	O
missing	O
in	O
the	O
group	O
mean	O

concat	B-API
two	O
dataframe	O
,	O
then	O
groupby	B-API
'	O
type	O
'	O
and	O
calculate	O
the	O
mean	O
,	O
columns	O
of	O
second	O
df	O
,	O
i.e.	O
d1~d10	O
,	O
showing	O
in	O
the	O
concat'ed	O
dataframe	O
but	O
not	O
in	O
the	O
grouped	O
mean	O
.	O

I	O
want	O
to	O
create	O
a	O
new	O
DataFrame	O
such	O
that	O
each	O
row	O
is	O
created	O
from	O
the	O
original	O
df	O
but	O
rows	O
with	O
loc	O
counts	O
greater	O
than	O
2	O
are	O
excluded	O
.	O

That	O
is	O
,	O
the	O
new	O
df	O
is	O
created	O
by	O
looping	O
through	O
the	O
old	O
df	O
,	O
counting	O
the	O
number	O
of	O
loc	O
rows	O
that	O
have	O
come	O
before	O
,	O
and	O
including	O
/	O
excluding	O
the	O
row	O
based	O
on	O
this	O
count	O
.	O

The	O
output	O
excludes	O
the	O
4th	O
row	O
in	O
the	O
original	O
df	O
because	O
its	O
loc	O
count	O
is	O
greater	O
than	O
2	O
(	O
i.e.	O
3	O
)	O
.	O

Also	O
,	O
be	O
careful	O
with	O
your	O
column	O
names	O
,	O
since	O
`	O
loc	O
`	O
clashes	O
with	O
the	O
`	O
.loc	B-API
`	O
method	O
.	O

So	O
you	O
get	O
a	O
string	O
back	O
:)	O
.	O

You	O
can	O
use	O
eval	B-API
(	O
""	O
[	O
1.5	O
,	O
2.5	O
,	O
3.5	O
]"")	O
,	O
but	O
I	O
hear	O
it's	O
bad	O
practice	O
.	O

You	O
can	O
map	O
your	O
lists	O
to	O
strings	O
by	O
using	O
`"	O
,	O
"	O
.join	B-API
(	O
your_list	O
)`	O
given	O
that	O
you	O
only	O
use	O
floats	O
.	O

merge	B-API
the	O
dataframe	O
on	O
ID	O
#CODE	O

The	O
`	O
merge	B-API
`	O
did	O
the	O
trick	O
,	O
but	O
I	O
thought	O
it	O
was	O
more	O
usefull	O
to	O
just	O
do	O
a	O
`	O
dfMerged.dropna()	O
`	O
after	O
the	O
merge	B-API
and	O
that	O
will	O
be	O
the	O
set	O
with	O
the	O
difference	O
.	O

yes	O
,	O
essentially	O
,	O
the	O
answer	O
was	O
really	O
about	O
the	O
`	O
merge	B-API
`	O
method	O
,	O
which	O
allows	O
you	O
to	O
sql-like	O
joins	O
.	O

Instead	O
,	O
I	O
get	O
an	O
error	O
telling	O
me	O
that	O
equiv	O
is	O
not	O
a	O
callable	O
function	O
.	O

Fair	O
enough	O
,	O
it's	O
a	O
dictionary	O
,	O
but	O
even	O
if	O
I	O
wrap	O
it	O
in	O
a	O
function	O
I	O
still	O
get	O
frustration	O
.	O

So	O
I	O
tried	O
to	O
use	O
a	O
map	B-API
function	O
that	O
seems	O
to	O
work	O
with	O
other	O
operations	O
,	O
but	O
it	O
also	O
is	O
defeated	O
by	O
use	O
of	O
a	O
dictionary	O
:	O
#CODE	O

ok	O
,	O
revised	O
the	O
answer	O
;	O
you	O
can	O
do	O
almost	O
anything	O
inside	O
the	O
apply	B-API
FYI	O

In	O
order	O
to	O
normalize	O
data	O
in	O
a	O
pandas	O
DataFrame	O
I	O
wrote	O
the	O
following	O
functions	O
:	O
#CODE	O

If	O
you	O
want	O
the	O
values	O
themselves	O
,	O
you	O
can	O
`	O
groupby	B-API
`	O
'	O
Column1	O
'	O
and	O
then	O
call	O
`	O
apply	B-API
`	O
and	O
pass	O
the	O
`	O
list	B-API
`	O
method	O
to	O
apply	O
to	O
each	O
group	O
.	O

You	O
could	O
`	O
groupby	B-API
`	O
on	O
`	O
Column1	O
`	O
and	O
then	O
take	O
`	O
Column3	O
`	O
to	O
`	O
apply	B-API
(	O
list	O
)`	O
and	O
call	O
`	O
to_dict	B-API
`	O
?	O

Pandas	O
-	O
How	O
can	O
I	O
set	O
rules	O
for	O
selecting	O
which	O
duplicates	O
to	O
drop	O

What	O
I	O
want	O
to	O
do	O
is	O
drop	O
the	O
values	O
that	O
have	O
the	O
same	O
index	O
(	O
date	O
time	O
)	O
,	O
but	O
I	O
want	O
to	O
make	O
a	O
rule	O
like	O
:	O

I	O
have	O
tried	O
using	O
groupby	B-API
and	O
apply	B-API
in	O
several	O
different	O
ways	O
but	O
I	O
cant	O
get	O
it	O
to	O
work	O
.	O

You	O
could	O
use	O
`	O
del	O
df	O
[	O
'	O
dist	O
']`	O
to	O
drop	O
the	O
dist	O
column	O
when	O
you	O
no	O
longer	O
need	O
it	O
.	O

Though	O
I	O
was	O
wondering	O
if	O
you	O
could	O
do	O
it	O
immediately	O
using	O
lambda	O
,	O
apply	B-API
and	O
groupby	B-API
.	O

I	O
am	O
sorry	O
I	O
am	O
trying	O
to	O
insert	O
code	O
into	O
comments	O
I	O
cant	O
do	O
it	O

All	O
I	O
am	O
doing	O
at	O
the	O
moment	O
is	O
loading	O
the	O
.csv	O
as	O
a	O
dataframe	O
and	O
then	O
writing	O
it	O
to	O
the	O
db	O
using	O
`	O
df.to_sql	B-API
(	O
table_name	O
,	O
engine	O
,	O
index=False	O
,	O
if_exists=	O
'	O
append	B-API
'	O
,	O
chunksize=1000	O
)`	O

I	O
want	O
to	O
transform	O
it	O
into	O
a	O
single	O
column	O
data	O
with	O
index	O
being	O
year-month	O
.	O

I	O
try	O
to	O
stack	O
my	O
original	O
data	O
but	O
it	O
becomes	O
a	O
time	O
series	O
,	O
which	O
has	O
the	O
year	O
mix	O
with	O
my	O
values	O
.	O

`	O
set_index	B-API
`	O
to	O
`	O
Year	O
`	O
first	O
,	O
and	O
then	O
`	O
stack	B-API
`	O
.	O
