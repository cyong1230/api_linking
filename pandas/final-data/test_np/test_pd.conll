`	O
fromiter	B-API
`	O
wants	O
a	O
1d	O
input	O
,	O
e.g.	O
`	O
[	O
1	O
,	O
2	O
,	O
3	O
]`	O
(	O
or	O
the	O
generator	O
equivalent	O
)	O
.	O

read	O
more	O
:	O
take()	B-API

For	O
this	O
I'm	O
using	O
an	O
instance	O
of	O
the	O
`	O
numpy	O
`	O
class	O
`	O
RandomState	B-API
`	O
.	O

You	O
can	O
write	O
a	O
thinly	O
wrapped	O
subclass	O
to	O
`	O
np.ndarray	B-API
`	O
.	O

Using	O
`	O
ndarray.reshape	B-API
`	O
#CODE	O

E.g.	O
this	O
works	O
in	O
the	O
interpreter	O
:	O
`	O
>>>	O
a	O
=	O
np.arange	B-API
(	O
10	O
,	O
dtype=float	O
)	O
.resize	B-API
(	O
1	O
,	O
5	O
)`	O
,	O
because	O
the	O
interpreter	O
doesn't	O
"	O
see	O
"	O
the	O
intermediate	O
value	O
.	O

I	O
attempted	O
your	O
suggestion	O
but	O
got	O
stuck	O
trying	O
to	O
iterate	O
through	O
the	O
existing	O
dtype	B-API
.	O

`	O
numpy.setdiff1d	B-API
(	O
a	O
,	O
a	O
[	O
sel_id	O
])`	O
should	O
do	O
the	O
trick	O
.	O

Instead	O
of	O
disabling	O
the	O
behavior	O
you	O
could	O
try	O
using	O
np.select	B-API
:	O

+1	O
I	O
liked	O
you	O
approach	O
,	O
but	O
how	O
to	O
make	O
`	O
np.copyto()	B-API
`	O
work	O
with	O
a	O
memoryvew	O
?	O

Just	O
import	O
Decimal	O
and	O
for	O
the	O
printing	O
just	O
write	O
print	O
Decimal	O
(	O
ndarray	B-API
[	O
i	O
])	O
.	O

Or	O
,	O
for	O
that	O
matter	O
,	O
numpy.genfromtxt	B-API
.	O

glad	O
to	O
hear	O
it	O
-	O
I	O
only	O
recently	O
found	O
out	O
about	O
`	O
np.einsum	B-API
`	O
myself	O
,	O
and	O
it	O
has	O
rocked	O
my	O
world	O
ever	O
since	O

The	O
`	O
dtype	B-API
`	O
could	O
be	O
deduced	O
from	O
one	O
(	O
or	O
more	O
)	O
of	O
the	O
dictionary	O
items	O
:	O
#CODE	O

I	O
didn't	O
realize	O
`	O
array_split	B-API
`	O
existed	O
!	O

However	O
,	O
in	O
that	O
case	O
,	O
you	O
could	O
just	O
do	O
:	O
(	O
`	O
searchsorted	B-API
`	O
uses	O
bisection	O
)	O
#CODE	O

Btw	O
.	O
you	O
can	O
also	O
implicitly	O
force	O
the	O
`	O
dtype	B-API
`	O
to	O
be	O
`	O
float	O
`	O
when	O
using	O
dots	O
:	O
#CODE	O

dtypes	B-API
.	O

I	O
would	O
prefer	O
using	O
the	O
xor	O
ufunc	O
I	O
think	O
,	O
which	O
is	O
`	O
bitwise_xor	B-API
`	O
(	O
or	O
`	O
logical_xor	B-API
`)	O
:	O
#CODE	O

This	O
is	O
the	O
root	O
of	O
why	O
your	O
`	O
fromarrays	B-API
`	O
works	O
,	O
but	O
not	O
the	O
`	O
append_fields	O
`	O
.	O

The	O
dtype	B-API
should	O
be	O
big	O
endian	O
.	O

parameterArray	O
+=	O
line.split()	O
\nline	O
=	O
self.inputBuffer.next()	O
\	O
nnp.parameterArray	O
=	O
np.array	B-API
(	O
parameterArray	O
)	O

As	O
JoshAdel	O
points	O
out	O
,	O
`	O
vectorize	B-API
`	O
wraps	O
`	O
frompyfunc	B-API
`	O
.	O

Sorry	O
,	O
the	O
line	O
was	O
output	O
[	O
i	O
,	O
j	O
]	O
=	O
np.sum	B-API
(	O
ssd_difference	O
[	O
#URL	O
(	O
)	O
)	O

(	O
or	O
`	O
np.array	B-API
([[	O
1	O
]	O
,	O
[	O
2	O
]	O
,	O
[	O
3	O
]	O
,	O
[	O
4	O
]])	O
.shape	B-API
`)	O

Thank	O
you	O
for	O
the	O
great	O
tipp	O
with	O
`	O
plt.hist	B-API
(	O
img.ravel()	O
)`	O
!	O

The	O
`	O
recarray	B-API
`	O
class	O
accepts	O
an	O
aligned	O
parameter	O
,	O
but	O
looks	O
to	O
lose	O
it	O
in	O
`	O
format_parser	B-API
`	O
.	O

In	O
case	O
someone	O
comes	O
past	O
this	O
,	O
numpy	O
(	O
as	O
of	O
1.8	O
I	O
think	O
)	O
support	O
higher	O
that	O
2D	O
generation	O
of	O
position	O
grids	O
with	O
meshgrid	B-API
.	O

`	O
numpy.random.choice	B-API
`	O
is	O
not	O
implemented	O
in	O
Python	O
but	O
in	O
a	O
`	O
.pyx	O
`	O
file	O
which	O
needs	O
to	O
be	O
compiled	O
to	O
C	O
using	O
Cython	O
.	O

A	O
plain	O
`	O
.copy	B-API
`	O
did	O
work	O
for	O
me	O
.	O

`	O
A	O
[	O
np.ix_	B-API
(	O
x	O
,	O
y	O
)]`	O

einsum	B-API
:	O
5.2	O
s	O

10**423	O
exceeds	O
the	O
largest	O
int	O
representable	O
as	O
an	O
integer	O
(	O
or	O
float	O
)	O
NumPy	O
dtype	B-API
,	O
so	O
there	O
is	O
no	O
point	O
in	O
using	O
NumPy	O
here	O
:	O
`	O
np.iinfo	B-API
(	O
'	O
int64	O
')	O
.max	B-API
<	O
10**423	O
`	O
.	O

Probably	O
,	O
better	O
performance	O
is	O
by	O
using	O
`	O
numpy.fromiter	B-API
`	O
:	O
#CODE	O

Why	O
are	O
the	O
polyfit	B-API
constants	O
from	O
the	O
third	O
case	O
listed	O
as	O
NAN	O
?	O

Try	O
`	O
numpy.array_split	B-API
`	O
.	O

Using	O
np.repeat	B-API
on	O
sub-arrays	O

shows	O
that	O
'	O
region	O
'	O
has	O
an	O
`	O
object	O
`	O
dtype	B-API
:	O
#CODE	O

What	O
I	O
am	O
looking	O
for	O
is	O
something	O
along	O
the	O
original	O
functionality	O
of	O
`	O
np.unique	B-API
`	O
#CODE	O

In	O
my	O
opinion	O
,	O
np.matrix	B-API
should	O
override	O
for	O
addition	O
and	O
subtraction	O
as	O
well	O
.	O

or	O
`	O
np.vstack	B-API
`	O
,	O
`	O
np.dstack	B-API
`	O
`	O
np.r_	B-API
`	O
,	O
`	O
np.c_	B-API
`	O
,	O
`	O
np.concatenate	B-API
`	O
depending	O
on	O
the	O
desired	O
shapes	O
.	O

TypeError	O
when	O
using	O
SymPy	O
matrices	O
for	O
numpy.linalg.eig	B-API

Doing	O
`	O
a.astype	O
(	O
float	O
)`	O
actually	O
creates	O
a	O
*	O
new	O
*	O
ndarray	B-API
which	O
is	O
of	O
type	O
`	O
float	O
`	O
.	O

Trying	O
to	O
vectorize	B-API
the	O
code	O
also	O
resulted	O
in	O
very	O
poor	O
performance	O
,	O

Also	O
look	O
into	O
the	O
genfromtxt	B-API
and	O
loadtxt	B-API
family	O
of	O
Numpy	O
functions	O
.	O

`	O
coll	O
[	O
1	O
]	O
.set_color	B-API
(	O
"	O
r	O
")	O
#	O
this	O
does	O
not	O
work	O
,	O
coll	O
not	O
indexable	O
this	O
way	O
`	O

The	O
`	O
testing.assert_equal	B-API
`	O
approach	O
is	O
almost	O
good	O
,	O
except	O
that	O
it	O
presumably	O
fails	O
if	O
`	O
__debug__	O
`	O
is	O
False	O
!	O

I've	O
just	O
checked	O
and	O
found	O
out	O
that	O
my	O
implementation	O
is	O
about	O
2.x	O
times	O
*	O
faster	O
*	O
than	O
using	O
`	O
numpy.convolve	B-API
`	O
.	O

Not	O
as	O
concise	O
as	O
I	O
wanted	O
(	O
I	O
was	O
experimenting	O
with	O
`	O
mask_indices	B-API
`	O
)	O
,	O
but	O
this	O
will	O
also	O
do	O
the	O
work	O
:	O
#CODE	O

The	O
documentation	O
of	O
`	O
numpy.nonzero()	B-API
`	O
describes	O
how	O
its	O
result	O
must	O
be	O
interpreted	O
.	O

scikits-learn	O
pca	B-API
dimension	O
reduction	O
issue	O

`	O
np.mean	B-API
`	O
can	O
also	O
preserve	O
dimensions	O
if	O
needed	O
.	O

Are	O
there	O
alternatives	O
to	O
do	O
the	O
sorts	O
of	O
things	O
`	O
einsum	B-API
`	O
can	O
do	O
with	O
sparse	O
matrices	O
?	O

Your	O
immediate	O
problem	O
is	O
`	O
numpy.putmask	B-API
`	O
.	O

why	O
not	O
`	O
np.array	B-API
([	O
o.value1	O
for	O
o	O
in	O
objects	O
])`	O
?	O

In	O
a	O
comment	O
to	O
`	O
@USER	O
`	O
s	O
answer	O
I	O
suggested	O
`	O
np.delete	B-API
`	O
.	O

I	O
have	O
a	O
`	O
numpy.ndarray	B-API
`	O
.	O

I	O
believe	O
it	O
comes	O
down	O
to	O
the	O
fact	O
that	O
Python	O
calls	O
a	O
`	O
__getitem__	B-API
`	O
on	O
your	O
objects	O
and	O
treats	O
the	O
entire	O
block	O
of	O
code	O
of	O
`	O
for	O
`	O
loop	O
as	O
an	O
inline	O
statement	O
.	O

In	O
the	O
Notes	O
section	O
to	O
column_stack	B-API
,	O
it	O
points	O
out	O
this	O
:	O

`	O
logical_or	B-API
(	O
a	O
,	O
logical_or	B-API
(	O
b	O
,	O
c	O
))`	O

How	O
about	O
reading	O
them	O
in	O
correctly	O
as	O
numpy.datetime64	O
objects	O
using	O
numpy.loadtxt	B-API
(	O
they	O
are	O
coming	O
from	O
a	O
csv	O
file	O
)	O
?	O

Also	O
-	O
I	O
see	O
that	O
np.getfromtxt()	O
has	O
a	O
'	O
dtype	B-API
'	O
option	O
which	O
allows	O
the	O
user	O
to	O
specify	O
the	O
datatype	O
of	O
each	O
column	O
.	O

No	O
worries	O
,	O
the	O
dtype	B-API
is	O
inferred	O
as	O
`	O
int64	O
`	O
unless	O
you	O
pass	O
it	O
explicitly	O

whats	O
the	O
result	O
of	O
`	O
print	O
a	O
`	O
after	O
`	O
a	O
=	O
np.loadtxt	B-API
`	O

Keep	O
in	O
mind	O
that	O
`	O
np.cov	B-API
`	O
is	O
basically	O
doing	O
`	O
data.dot	O
(	O
data.T	O
)`	O
.	O

If	O
you	O
want	O
to	O
vectorize	B-API
operations	O
,	O
you	O
need	O
to	O
think	O
in	O
terms	O
of	O
these	O
higher	O
dimensional	O
arrays	O
.	O

Does	O
`	O
s2	O
=	O
pd.Series	B-API
(	O
s	O
,	O
dtype	B-API
=o	O
bject	O
)`	O
work	O
?	O

`	O
PyArray_DATA	B-API
`	O
is	O
defined	O
in	O

`	O
a	O
[:	O
,	O
:	O
,	O
5	O
]	O
.shape	B-API
=	O
(	O
10	O
,	O
10	O
,	O
1	O
)`	O

Can	O
you	O
print	O
`	O
datas	O
[	O
0	O
]	O
.shape	B-API
`	O
?	O

actually	O
used	O
is	O
this	O
line	O
within	O
the	O
definition	O
for	O
`	O
np.array_repr	B-API
`	O

That's	O
why	O
`	O
dstack	B-API
`	O
behaves	O
the	O
way	O
it	O
does	O
.	O

>>>	O
x	O
=	O
np.asanyarray	B-API
(	O
[	O
]	O
,	O
dtype=	O
'	O
float64	O
')	O

This	O
doesn't	O
work	O
for	O
floating	O
point	O
types	O
(	O
it	O
will	O
not	O
consider	O
+	O
0.0	O
and	O
-	O
0.0	O
the	O
same	O
value	O
)	O
,	O
and	O
`	O
np.intersect1d	B-API
`	O
uses	O
sorting	O
,	O
so	O
it	O
is	O
has	O
linearithmic	O
,	O
not	O
linear	O
,	O
performance	O
.	O

But	O
off	O
course	O
,	O
isreal	B-API
would	O
be	O
more	O
readable	O
:-)	O

mshgrd	O
=	O
ax.pcolormesh	B-API
(	O
X	O
,	O
Y	O
,	O
Z	O
)	O

Otherwise	O
,	O
the	O
performance	O
advantages	O
of	O
using	O
numpy	O
are	O
quickly	O
nullified	O
,	O
regardless	O
of	O
how	O
you	O
implement	O
your	O
ringbuffer	B-API
.	O

The	O
answer	O
is	O
numpy.clip	B-API
#CODE	O

Can	O
you	O
please	O
go	O
into	O
more	O
depth	O
about	O
nesting	O
a	O
recarray	B-API
in	O
another	O
by	O
using	O
the	O
np.object	O
method	O
?	O

Why	O
do	O
you	O
need	O
`	O
vectorize	B-API
`	O
for	O
that	O
?	O

I	O
did	O
try	O
gc.colletc()	O
without	O
success	O
but	O
adding	O
a	O
clf()	B-API
inside	O
the	O
loop	O
does	O
the	O
trick	O
!	O

not	O
a	O
bad	O
solution	O
;	O
though	O
I	O
am	O
somewhat	O
wary	O
of	O
the	O
performance	O
of	O
random.shuffle	B-API
.	O

date2num	B-API
,	O
ValueError	O
:	O
ordinal	O
must	O
be	O
>	O
=	O
1	O

And	O
you	O
could	O
override	O
`	O
__mul__	B-API
`	O
,	O
`	O
__add__	B-API
`	O
,	O
`	O
__sub__	B-API
`	O
accordingly	O
,	O
but	O
I	O
don't	O
know	O
exactly	O
how	O
numpy-like	O
you	O
actually	O
*	O
need	O
*	O
this	O
to	O
be	O
,	O
so	O
I	O
can't	O
say	O
for	O
sure	O
.	O

`	O
np.array	B-API
=	O
partial	O
(	O
np.array	B-API
,	O
dtype=	O
np.float32	O
)`	O
with	O
`	O
partial	O
`	O
from	O
the	O
`	O
functools	O
`	O
module	O
.	O

A	O
solution	O
that	O
worked	O
uses	O
griddata	B-API
.	O

Numpy	O
1.7.0	O
assert_array_almost_equal	B-API
documentation	O

You	O
can	O
read	O
matlab	O
(	O
.mat	B-API
)	O
files	O
in	O
Python	O
,	O
try	O
this	O
:	O
#CODE	O

Thanks	O
for	O
the	O
idea	O
of	O
genfromtxt()	B-API
.	O

If	O
you	O
are	O
using	O
numpy	O
,	O
for	O
multidimensional	O
lists	O
`	O
numpy.repeat	B-API
`	O
is	O
your	O
best	O
bet	O
.	O

If	O
the	O
following	O
equation	O
is	O
element-wise	O
True	O
,	O
then	O
allclose	B-API
returns	O
`	O
True	O
`	O
:	O
#CODE	O

`	O
np.vstack	B-API
`	O
just	O
vertically	O
stacks	O
the	O
arrays	O
you	O
pass	O
to	O
it	O
,	O
and	O
so	O
something	O
else	O
in	O
your	O
code	O
may	O
be	O
cutting	O
off	O
the	O
rest	O
of	O
the	O
results	O
inadvertently	O
.	O

If	O
you	O
move	O
the	O
line	O
`	O
np_verticies=	O
np.array	B-API
(	O
verticies	O
)`	O
outside	O
of	O
`	O
Fnumpy	O
`	O
and	O
the	O
timed	O
section	O
your	O
results	O
will	O
be	O
very	O
different	O
:	O
#CODE	O

`	O
fromiter	B-API
`'	O
s	O
example	O
is	O
essentially	O
this	O
:	O
`	O
np.fromiter	B-API
((	O
x*x	O
for	O
x	O
in	O
range	O
(	O
5	O
))	O
,	O
int	O
)`	O
.	O

In	O
Python	O
,	O
I	O
have	O
a	O
numpy.array	B-API
of	O
integers	O
`	O
[	O
2	O
,	O
4	O
,	O
7	O
,	O
8	O
,	O
9	O
,	O
10	O
,	O
15	O
,	O
10	O
8]	O
`	O
.	O

I	O
will	O
go	O
with	O
newaxis	B-API
then	O
.	O

pcolormesh	B-API
returns	O
a	O
QuadMesh	B-API
.	O

And	O
when	O
I	O
call	O
each	O
of	O
the	O
instructions	O
inside	O
f()	B-API
individually	O
it	O
gives	O
me	O
an	O
other	O
result	O
(	O
which	O
is	O
correct	O
):	O
#CODE	O

Here's	O
one	O
vectorized	O
approach	O
based	O
on	O
`	O
np.einsum	B-API
`	O
-	O
#CODE	O

What's	O
the	O
`	O
dtype	B-API
`	O
of	O
these	O
arrays	O
?	O

try	O
adding	O
a	O
`	O
show()	B-API
`	O
in	O
the	O
end	O

`	O
pandas.DataFrame	B-API
`	O

You	O
can	O
define	O
your	O
own	O
types	O
by	O
creating	O
a	O
class	O
and	O
writing	O
a	O
`	O
__add__	B-API
`	O
or	O
`	O
__sub__	B-API
`	O
method	O
.	O

On	O
the	O
other	O
hand	O
,	O
if	O
I	O
did	O
with	O
`	O
genfromtxt	B-API
`	O
,	O
the	O
third	O
column	O
is	O
problem	O
because	O
it	O
includes	O
comma	O
inside	O
double-quota	O
.	O

Apparently	O
,	O
if	O
there	O
is	O
no	O
'	O
missing_value	O
'	O
attribute	O
Netcdf4	O
defaults	O
to	O
a	O
missing	O
value	O
appropriate	O
for	O
the	O
dtype	B-API
.	O

do	O
be	O
aware	O
that	O
if	O
you	O
have	O
NaNs	O
,	O
there	O
is	O
an	O
equivalent	O
np.nanstd	B-API
with	O
the	O
similar	O
ddof	O
options	O

[	O
True	O
,	O
True	O
]]	O
,	O
dtype	B-API
=b	O
ool	O
)`	O

@USER	O
true	O
,	O
although	O
`	O
np.array	B-API
([	O
x	O
for	O
bb	O
in	O
b	O
for	O
x	O
in	O
bb	O
])`	O
will	O
do	O
the	O
job	O
.	O

return	O
matrix_power	B-API
(	O
self	O
,	O
other	O
)	O

vector	O
=	O
numpy.array	B-API
(	O
vector	O
);	O

If	O
so	O
then	O
you	O
should	O
have	O
no	O
problem	O
fitting	O
the	O
`	O
numpy.fft.rfftfreq	B-API
`	O
method	O
into	O
your	O
own	O
code	O
.	O

This	O
fails	O
:	O
`	O
einsum	B-API
(	O
'	O
i	O
...,	O
i	O
...	O

Python	O
&	O
Numpy	O
-	O
create	O
dynamic	O
,	O
arbitrary	O
subsets	O
of	O
ndarray	B-API

For	O
example	O
,	O
I	O
have	O
a	O
`	O
ndarray	B-API
`	O
that	O
is	O
:	O
#CODE	O

I	O
went	O
with	O
the	O
np.memmap	B-API
because	O
the	O
performance	O
is	O
similar	O
to	O
hdf5	O
and	O
I	O
already	O
have	O
numpy	O
in	O
production	O
.	O

its	O
np.log	B-API
not	O
m.log	O

what	O
happens	O
if	O
you	O
[	O
`	O
Py_INCREF	O
(	O
self	O
)`]	O
(	O
#URL	O
)	O
after	O
`	O
.base	B-API
`	O
assignment	O
?	O

File	O
"	O
/	O
usr	O
/	O
lib64	O
/	O
python2.6	O
/	O
site-packages	O
/	O
numpy	O
/	O
core	O
/	O
fromnumeric.py	O
"	O
,	O
line	O
806	O
,	O
in	O
searchsorted	B-API

why	O
isn't	O
the	O
`	O
ndarray	B-API
`	O
constructor	O
mentioned	O
here	O
?	O

>>>	O
z	O
=	O
numpy.array	B-API
([	O
1	O
,	O
2	O
]	O

Is	O
there	O
an	O
equivelent	O
to	O
`	O
fseek	O
`	O
when	O
using	O
`	O
fromfile	B-API
`	O
to	O
skip	O
the	O
beginning	O
of	O
the	O
file	O
?	O

The	O
linear	O
algebra	O
functions	O
are	O
generally	O
grouped	O
in	O
`	O
numpy.linalg	B-API
`	O
.	O

np.mean	B-API
:	O
#CODE	O

As	O
others	O
have	O
said	O
,	O
32-bit	O
versions	O
of	O
numpy	O
still	O
support	O
64-bit	O
dtypes	B-API
.	O

`	O
vstack	B-API
`	O
is	O
coercing	O
the	O
type	O
of	O
`	O
d	O
`	O
to	O
the	O
type	O
of	O
`	O
e	O
`	O
.	O

`	O
df.plot	B-API
`	O
returns	O
an	O
AxesSubplot	O
,	O
which	O
has	O
a	O
`	O
axvspan	B-API
`	O
method	O
.	O

With	O
the	O
variables	O
defined	O
above	O
,	O
`	O
np.searchsorted	B-API
(	O
lat	O
,	O
x	O
)`	O
is	O
16x	O
faster	O
than	O
the	O
equivalent	O
call	O
`	O
np.nanargmin	B-API
((	O
lat-x	O
)	O
**2	O
)`	O
on	O
my	O
computer	O
.	O

Pypy	O
with	O
iterators	O
is	O
still	O
solving	O
this	O
about	O
3x	O
faster	O
than	O
CPython	O
+	O
Numpy	O
,	O
even	O
when	O
using	O
`	O
np.searchsorted	B-API
`	O
(	O
see	O
my	O
solution	O
)	O
.	O

and	O
`	O
hstack	B-API
((	O
a	O
,	O
z	O
))`	O
?	O

Have	O
you	O
tried	O
passing	O
`	O
interpolation=	O
'	O
nearest	O
'`	O
to	O
`	O
imshow	B-API
`	O
?	O

`	O
cumsum	B-API
`	O
might	O
not	O
be	O
the	O
best	O
example	O
.	O

I	O
think	O
you're	O
after	O
`	O
plt.axis	B-API
([	O
xmin	O
,	O
xmax	O
,	O
ymin	O
,	O
ymax	O
])`	O
:	O
#CODE	O

Is	O
`	O
(	O
dry	O
,	O
unrch	O
)	O
=	O
((	O
G	O
==	O
3	O
)	O
.sum()	B-API
,	O
(	O
G	O
==	O
1	O
)	O
.sum()	B-API
)`	O
more	O
vectorized	O
?	O

Then	O
,	O
`	O
np.array	B-API
(	O
np.matrix	B-API
(	O
s.strip	O
(	O
'	O
[	O
]')))`	O
will	O
do	O
the	O
same	O
magic	O
.	O

I'm	O
trying	O
to	O
vectorize	B-API
Z	O
,	O
but	O
I'm	O
finding	O
it	O
rather	O
difficult	O
for	O
a	O
triple	O
for	O
loop	O
.	O

How	O
would	O
that	O
be	O
done	O
using	O
np.dot	B-API
?	O

I	O
was	O
surprised	O
how	O
descending	O
sorting	O
of	O
np.array	B-API
seem	O
so	O
un-pythonic	O
.	O

`	O
numpy.genfromtxt	B-API
`	O
accepts	O
generators	O
,	O
so	O
you	O
can	O
chain	O
`	O
genfromtext	O
`	O
and	O
`	O
ifilter	O
`	O
:	O
#CODE	O

I	O
also	O
tried	O
`	O
df.query()	B-API
`	O
,	O
but	O
no	O
much	O
improvement	O
.	O

According	O
to	O
the	O
documentation	O
(	O
e.g.	O
,	O
here	O
)	O
,	O
`	O
PyArray_SimpleNew	B-API
`	O
has	O
a	O
return	O
of	O
type	O
`	O
PyObject	O
*	O
`	O
and	O
thus	O
the	O
above	O
should	O
be	O
perfectly	O
fine	O
.	O

Edit	O
:	O
`	O
np.where	B-API
`	O
is	O
optional	O
,	O
thanks	O
@USER	O
.	O

or	O
with	O
`	O
numpy.concatenate	B-API
`	O
?	O

@USER	O
you	O
can	O
do	O
it	O
,	O
it's	O
easy	O
with	O
`	O
np.histogram	B-API
`	O
.	O

`	O
numpy.base_repr	B-API
`	O
uses	O
this	O
,	O
but	O
only	O
operates	O
on	O
scalars	O
.	O

Python	O
apply_along_axis	B-API
of	O
multiple	O
arrays	O

`	O
numpy.average()	B-API
`	O
has	O
a	O
weights	O
option	O
,	O
but	O
`	O
numpy.std()	B-API
`	O
does	O
not	O
.	O

I	O
wanted	O
to	O
write	O
`	O
M.det()	O
`	O
instead	O
of	O
`	O
numpy.linalg.det	B-API
(	O
M	O
)`	O
,	O

I	O
was	O
working	O
with	O
something	O
like	O
```	O
s	O
=	O
pd.DataFrame	B-API
([	O
'	O
1	O
'	O
,	O
'	O
na	O
'	O
,	O
'	O
3	O
'	O
,	O
'	O
4	O
'])	O
.	O

tested	O
it	O
a	O
bit	O
myself	O
:	O
sympy.sin	O
is	O
much	O
slower	O
than	O
numpy.sin	B-API

I	O
was	O
thinking	O
of	O
something	O
like	O
`	O
frombuffer	B-API
`	O
.	O

OLS	O
solution	O
using	O
pinv	B-API
/	O
svd	B-API
#CODE	O

The	O
bad	O
days	O
are	O
eliminated	O
,	O
and	O
the	O
good	O
ones	O
are	O
kept	O
.	O

@USER	O
Well	O
in	O
this	O
case	O
,	O
`	O
searchsorted	B-API
`	O
is	O
basically	O
looking	O
for	O
places	O
or	O
indices	O
where	O
elements	O
from	O
`	O
message	O
`	O
exists	O
in	O
the	O
keys	O
of	O
`	O
codes	O
`	O
.	O

@USER	O
--	O
I	O
had	O
a	O
hard	O
time	O
remembering	O
how	O
`	O
translate	O
`	O
and	O
`	O
maketrans	O
`	O
work	O
for	O
quite	O
a	O
while	O
too	O
,	O
but	O
I've	O
gotten	O
used	O
to	O
it	O
.	O

Edit	O
:	O
if	O
you're	O
using	O
a	O
version	O
of	O
numpy	O
>	O
=	O
1.8.0	O
,	O
then	O
`	O
np.linalg.eigvals	B-API
`	O
operates	O
over	O
the	O
last	O
two	O
dimensions	O
of	O
whatever	O
array	O
you	O
hand	O
it	O
,	O
so	O
if	O
you	O
reshape	O
your	O
input	O
to	O
an	O
`	O
(	O
n_subarrays	O
,	O
nrows	O
,	O
ncols	O
)`	O
array	O
you'll	O
only	O
have	O
to	O
call	O
`	O
eigvals	B-API
`	O
once	O
:	O
#CODE	O

`	O
reshape	B-API
`	O
returns	O
a	O
view	O
of	O
the	O
original	O
array	O
,	O
not	O
a	O
copy	O
,	O
so	O
the	O
conversion	O
to	O
3D	O
only	O
requires	O
altering	O
the	O
`	O
shape	O
`	O
and	O
`	O
strides	O
`	O
attributes	O
of	O
the	O
array	O
,	O
without	O
having	O
to	O
copy	O
any	O
of	O
the	O
actual	O
data	O
.	O

sum	O
this	O
new	O
array	O
along	O
particular	O
axes	O
;	O
and	O
then	O
maybe	O

Calling	O
`	O
reshape	B-API
`	O
returns	O
a	O
view	O
,	O
so	O
it	O
doesn't	O
incur	O
any	O
big	O
copying	O
costs	O
or	O
anything	O
like	O
that	O
.	O

so	O
at	O
some	O
point	O
in	O
the	O
execution	O
it	O
will	O
max	O
my	O
memory	O
.	O

Note	O
that	O
extension	O
to	O
even	O
higher	O
combinatorics	O
should	O
be	O
trivial	O
,	O
along	O
the	O
lines	O
presented	O
;	O
but	O
keep	O
an	O
eye	O
on	O
the	O
n	O
used	O
in	O
that	O
case	O
.	O

These	O
functions	O
return	O
a	O
list	O
,	O
which	O
I	O
convert	O
to	O
a	O
numpy	O
array	O
and	O
then	O
sum	O
over	O
.	O

Can	O
it	O
be	O
because	O
of	O
the	O
many	O
zeros	O
in	O
the	O
initial	O
table	O
?	O

I	O
also	O
understand	O
that	O
sum	B-API
(	O
A	O
,	O
axis=1	O
)	O
will	O
sum	O
each	O
row	O
.	O

But	O
what	O
I	O
really	O
want	O
to	O
do	O
,	O
is	O
to	O
bin	O
`	O
array	O
[:	O
,	O
1	O
]`	O
by	O
day	O
(	O
as	O
derived	O
by	O
the	O
unix	O
timestamps	O
in	O
array	O
[:	O
,	O
0	O
])	O
,	O
and	O
plot	O
these	O
as	O
a	O
stacked	O
histogram	O
,	O
with	O
each	O
(	O
colored	O
)	O
stack	O
representing	O
a	O
day	O
.	O

It's	O
interesting	O
to	O
see	O
that	O
when	O
I	O
go	O
back	O
to	O
`	O
nloop=1000	O
`	O
,	O
`	O
nreps=3	O
`	O
I	O
actually	O
see	O
a	O
slightly	O
*	O
greater	O
*	O
rate	O
of	O
cache	O
misses	O
for	O
the	O
row	O
sum	O
(	O
17%	O
vs	O
13%	O
)	O
,	O
even	O
though	O
it's	O
faster	O
than	O
the	O
column	O
sum	O
.	O

You	O
can	O
concatenate	O
arrays	O
in	O
`	O
numpy	O
`	O
.	O

If	O
you	O
are	O
100%	O
sure	O
that	O
l2	O
would	O
only	O
be	O
one	O
column	O
then	O
you	O
can	O
reshape	O
that	O
array	O
to	O
make	O
it	O
one	O
dimensional	O
before	O
doing	O
the	O
subtraction	O
.	O

You	O
won't	O
be	O
able	O
to	O
create	O
a	O
2D	O
array	O
that	O
way	O
,	O
and	O
@USER	O
method	O
of	O
returning	O
a	O
1D	O
array	O
that	O
you	O
reshape	O
afterwards	O
is	O
a	O
sure	O
go	O
.	O

I	O
have	O
a	O
square	O
matrix	O
A	O
(	O
could	O
be	O
any	O
size	O
)	O
and	O
I	O
want	O
to	O
take	O
the	O
upper	O
triangular	O
part	O
and	O
place	O
those	O
values	O
in	O
an	O
array	O
without	O
the	O
values	O
below	O
the	O
center	O
diagonal	O
(	O
k=0	O
)	O
.	O

You	O
can	O
mimic	O
this	O
behavior	O
with	O
a	O
simple	O
function	O
to	O
flatten	O
a	O
list	O
:	O
#CODE	O

So	O
`	O
popt	O
`	O
,	O
according	O
to	O
the	O
documentation	O
,	O
returns	O
*	O
"	O
Optimal	O
values	O
for	O
the	O
parameters	O
so	O
that	O
the	O
sum	O
of	O
the	O
squared	O
error	O
of	O
f	O
(	O
xdata	O
,	O
popt	O
)	O
-	O
ydata	O
is	O
minimized	O
"	O
.	O

And	O
I'd	O
like	O
indices	O
`	O
i	O
`	O
such	O
that	O
,	O
#CODE	O

But	O
,	O
`	O
resize	B-API
`	O
looks	O
like	O
it	O
just	O
might	O
be	O
the	O
thing	O
I'm	O
looking	O
for	O
...	O

`	O
rfft	B-API
`	O
,	O
apart	O
from	O
repeated	O
terms	O
excluded	O
,	O
and	O
an	O
almost	O
2x	O
speed-up	O
,	O
returns	O
the	O
exact	O
same	O
you	O
would	O
get	O
from	O
`	O
fft	B-API
`	O
.	O

Plus	O
,	O
if	O
I	O
have	O
4	O
dimensions	O
,	O
I	O
thought	O
I	O
should	O
have	O
4	O
eigenvalues	O
and	O
not	O
150	O
like	O
the	O
eig	B-API
gives	O
me	O
.	O

If	O
I	O
run	O
your	O
code	O
to	O
generate	O
`	O
d	O
`	O
and	O
`	O
dx	O
`	O
with	O
`	O
eig	B-API
`	O
I	O
get	O
the	O
following	O
:	O
#CODE	O

In	O
other	O
words-	O
it	O
is	O
not	O
just	O
taking	O
a	O
min	O
or	O
max	O
.	O

D	O
[	O
I+1	O
,	O
J+1	O
]	O
=	O
map	B-API
(	O
norm	O
,	O
x	O
[	O
I	O
]	O
-y	O
[	O
J	O
])	O
+	O
np.minimum	B-API
(	O
np.minimum	B-API
(	O
D	O
[	O
I	O
,	O
J	O
]	O
,	O
D	O
[	O
I	O
,	O
J+1	O
])	O
,	O
D	O
[	O
I+1	O
,	O
J	O
])	O
?	O

`	O
dot	B-API
`	O
just	O
has	O
tighter	O
code	O
for	O
a	O
specific	O
combination	O
of	O
dimensions	O
.	O

numpy	O
sum	B-API
does	O
not	O
agree	O

Since	O
you	O
are	O
only	O
adding	O
many	O
`	O
1	O
`	O
s	O
you	O
can	O
convert	O
`	O
diff	O
`	O
to	O
`	O
bool	O
`	O
:	O
#CODE	O

It	O
isn't	O
mathematically	O
possible	O
to	O
represent	O
0	O
on	O
a	O
log	O
scale	O
,	O
so	O
the	O
first	O
value	O
will	O
have	O
to	O
either	O
be	O
masked	O
or	O
clipped	O
to	O
a	O
very	O
small	O
positive	O
number	O
.	O

possible	O
duplicate	O
of	O
[	O
Efficiently	O
count	O
the	O
number	O
of	O
occurrences	O
of	O
unique	O
subarrays	O
in	O
NumPy	O
?	O
]	O
(	O
#URL	O
)	O

Or	O
you	O
could	O
mask	O
the	O
x	O
value	O
as	O
well	O
,	O
so	O
the	O
indices	O
were	O
consistent	O
between	O
x	O
and	O
y	O
#CODE	O

Here	O
the	O
`	O
outer	B-API
`	O
method	O
of	O
the	O
`	O
multiply	B-API
`	O
ufunc	O
is	O
used	O
to	O
create	O
the	O
new	O
20x20	O
array	O
.	O

I	O
have	O
a	O
3D	O
numpy	O
array	O
consisting	O
of	O
1's	O
and	O
zeros	O
defining	O
open	O
versus	O
filled	O
space	O
in	O
a	O
porous	O
solid	O
(	O
it's	O
currently	O
a	O
numpy	O
Int64	O
array	O
)	O
.	O

You	O
are	O
attempting	O
to	O
broadcast	O
a	O
4-D	O
array	O
together	O
with	O
a	O
3-D	O
array	O
.	O

Scipy	O
NDimage	O
correlate	O
:	O
unbearably	O
slow	O

I	O
know	O
that	O
I	O
can	O
reshape	O
the	O
array	O
to	O
a	O
100	O
x	O
2	O
array	O
of	O
grid	O
points	O
:	O
#CODE	O

You	O
probably	O
could	O
get	O
`	O
append	B-API
`	O
to	O
work	O
,	O
but	O
it	O
just	O
does	O
a	O
step	O
by	O
step	O
concatenate	O
,	O
which	O
is	O
slower	O
.	O

This	O
produces	O
a	O
random	O
permutation	O
of	O
each	O
column's	O
indices	O
.	O

As	O
it	O
happens	O
,	O
the	O
histogram	O
is	O
enough	O
for	O
the	O
former	O
.	O

I	O
see	O
how	O
the	O
symmetry	O
of	O
the	O
trace	O
lets	O
you	O
replace	O
the	O
final	O
`	O
dot	B-API
`	O
.	O

In	O
that	O
question	O
,	O
I	O
sought	O
to	O
sum	O
values	O
in	O
a	O
numpy	O
structured	O
array	O
based	O
on	O
multiple	O
criteria	O
,	O
including	O
matches	O
in	O
a	O
list	O
.	O

to	O
delete	O
the	O
lines	O
that	O
had	O
zeros	O
in	O
them	O
!	O

Fill	O
scipy	O
/	O
numpy	O
matrix	O
based	O
on	O
indices	O
and	O
values	O

It	O
looks	O
like	O
a	O
vector	O
product	O
followed	O
by	O
a	O
sum	O
along	O
the	O
resulting	O
array	O
.	O

The	O
trick	O
is	O
that	O
this	O
convolve	B-API
function	O
can	O
be	O
used	O
in-place	O
so	O
the	O
double	O
for	O
loop	O
:	O
#CODE	O

But	O
this	O
reshape	B-API
should	O
produce	O
a	O
`	O
(	O
n	O
,	O
1	O
,	O
1	O
)`	O
array	O
,	O
not	O
your	O
`	O
(	O
1	O
,	O
1	O
,	O
1	O
,...	O
)`	O
array	O
.	O

For	O
an	O
extreme	O
example	O
,	O
consider	O
a	O
sequence	O
that	O
consists	O
of	O
9	O
zeros	O
followed	O
by	O
the	O
result	O
of	O
a	O
coin	O
toss	O
,	O
9	O
zeros	O
and	O
another	O
coin	O
toss	O
,	O
etc	O
.	O

If	O
so	O
then	O
`	O
np.array	B-API
(	O
a	O
)`	O
is	O
a	O
2d	O
array	O
,	O
and	O
you	O
can	O
sum	O
over	O
`	O
axis=1	O
`	O
.	O

I	O
am	O
trying	O
to	O
create	O
a	O
lat	O
/	O
lon	O
grid	O
that	O
contains	O
an	O
array	O
of	O
found	O
indices	O
where	O
two	O
conditions	O
are	O
met	O
for	O
a	O
lat	O
/	O
lon	O
combination	O
.	O

This	O
NAMBE	O
is	O
the	O
absolute	O
difference	O
between	O
a	O
base	O
vector	O
and	O
another	O
vector	O
,	O
divided	O
by	O
the	O
base	O
vector	O
and	O
multiplied	O
by	O
a	O
hundred	O
,	O
in	O
pseudo-code	O
notation	O
:	O
#CODE	O

this	O
my	O
code	O
to	O
and	O
i	O
want	O
to	O
use	O
histogram	O
data	O
to	O
plot	O
scatter	O
where	O
y	O
axis	O
is	O
counts	O
center	O
from	O
the	O
histogram	O
,	O
is	O
there	O
any	O
direct	O
command	O
or	O
way	O
to	O
do	O
this	O
?	O

Please	O
compile	O
with	O
`	O
cython	O
-a	O
`	O
,	O
then	O
show	O
us	O
the	O
C	O
code	O
that	O
the	O
`	O
a	O
[	O
0	O
]	O
+=	O
sum	O
`	O
line	O
turns	O
into	O
.	O

The	O
revised	O
question	O
is	O
still	O
a	O
duplicate	O
,	O
see	O
[	O
this	O
question	O
]	O
(	O
#URL	O
)	O
,	O
and	O
[	O
this	O
question	O
]	O
(	O
#URL	O
)	O
for	O
finding	O
the	O
indices	O
.	O

ValueError	O
:	O
operands	O
could	O
not	O
be	O
broadcast	O
together	O
with	O
different	O
shapes	O
in	O
numpy	O
?	O

There	O
are	O
thousands	O
of	O
numbers	O
below	O
the	O
ones	O
shown	O
here	O
.	O

Assuming	O
you	O
want	O
to	O
align	O
all	O
the	O
arrays	O
to	O
the	O
left	O
,	O
and	O
pad	O
to	O
the	O
right	O
with	O
zeros	O
,	O
then	O
you	O
could	O
first	O
find	O
the	O
maximum	O
length	O
with	O
#CODE	O

How	O
to	O
do	O
the	O
same	O
If	O
I	O
want	O
to	O
apply	O
norm	O
column-wise	O
to	O
a	O
matrix	O
?	O

The	O
easiest	O
approach	O
is	O
to	O
reshape	O
to	O
data	O
to	O
a	O
long	O
format	O
using	O
`	O
.stack	B-API
`	O
,	O
which	O
can	O
be	O
be	O
passed	O
straight	O
into	O
rolling	O
mean	O
.	O

It's	O
pretty	O
low-level	O
,	O
and	O
mostly	O
focused	O
on	O
how	O
to	O
address	O
the	O
more	O
difficult	O
problem	O
of	O
how	O
to	O
pass	O
C++	O
data	O
to	O
and	O
from	O
NumPy	O
without	O
copying	O
,	O
but	O
here's	O
how	O
you'd	O
do	O
a	O
copied	O
std	O
::	O
vector	O
return	O
with	O
that	O
:	O
#CODE	O

`	O
std	O
=	O
RMS	O
(	O
data	O
-	O
mean	O
)`	O
.	O

This	O
generalized	O
diagonal	O
would	O
be	O
defined	O
as	O
those	O
elements	O
of	O
the	O
array	O
whose	O
0th	O
and	O
2nd	O
index	O
coincide	O
,	O
and	O
would	O
have	O
shape	O
(	O
3	O
,	O
3	O
,	O
7	O
)	O
.	O

I	O
have	O
a	O
given	O
array	O
`	O
[	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
1	O
,	O
1	O
,	O
2	O
,	O
1	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
1	O
,	O
0	O
,	O
1	O
,	O
2	O
,	O
1	O
,	O
0	O
,	O
2	O
,	O
3	O
`]	O
(	O
arbitrary	O
elements	O
from	O
0-5	O
)	O
and	O
I	O
want	O
to	O
have	O
a	O
counter	O
for	O
the	O
occurence	O
of	O
zeros	O
in	O
a	O
row	O
.	O

To	O
see	O
the	O
benefits	O
of	O
this	O
,	O
you	O
need	O
to	O
use	O
`	O
z	O
,	O
p	O
,	O
k	O
=	O
butter	O
(	O
output=	O
'	O
zpk	O
')`	O
and	O
then	O
work	O
with	O
poles	O
and	O
zeros	O
instead	O
of	O
numerator	O
and	O
denominator	O
.	O

In	O
that	O
case	O
you	O
would	O
"	O
extrapolate	O
"	O
zeros	O
to	O
the	O
left	O
and	O
the	O
right	O
.	O

can	O
numpy	O
interpret	O
column	O
of	O
indices	O
like	O
matlab	O
does	O

To	O
get	O
the	O
diagonal	O
elements	O
you	O
can	O
get	O
their	O
indices	O
with	O
`	O
np.triu_indices	B-API
`	O
(	O
or	O
,	O
for	O
the	O
lower	O
triangle	O
,	O
`	O
np.tril_indices	B-API
`)	O
and	O
then	O
index	O
by	O
them	O
.	O

The	O
question	O
states	O
that	O
the	O
input	O
array	O
is	O
of	O
shape	O
`	O
(	O
128	O
,	O
36	O
,	O
8)	O
`	O
and	O
we	O
are	O
interested	O
in	O
finding	O
unique	O
subarrays	O
of	O
length	O
`	O
8	O
`	O
in	O
the	O
last	O
dimension	O
.	O

What	O
does	O
work	O
,	O
however	O
is	O
nesting	O
append	B-API
and	O
concatenate	B-API
#CODE	O

(	O
`	O
b	O
`	O
will	O
be	O
broadcast	O
along	O
(	O
?	O
)	O
the	O
first	O
axis	O
)	O
#CODE	O

As	O
he	O
points	O
out	O
,	O
the	O
`	O
[	O
0	O
]	O
[	O
1	O
]`	O
element	O
is	O
what	O
you'd	O
want	O
for	O
`	O
cov	B-API
(	O
a	O
,	O
b	O
)`	O
.	O

returns	O
`	O
1	O
`	O
,	O
making	O
the	O
sum	O
not	O
commutative	O
!	O

But	O
as	O
I	O
have	O
a	O
log	O
of	O
values	O
(	O
10000+	O
)	O
,	O
this	O
will	O
be	O
quite	O
slow	O
.	O

@USER	O
-	O
good	O
point	O
.	O
anyway	O
,	O
`	O
diff	B-API
`	O
works	O
on	O
python	O
lists	O
too	O
.	O

It	O
will	O
also	O
work	O
if	O
they	O
are	O
both	O
arrays	O
that	O
can	O
be	O
broadcast	O
.	O

It's	O
column	O
stack	O
that	O
requires	O
equal	O
length	O
strings	O
.	O

In	O
the	O
end	O
it	O
is	O
usually	O
not	O
too	O
complicated	O
,	O
especially	O
if	O
you	O
use	O
[	O
`	O
mgrid	B-API
`]	O
(	O
#URL	O
)	O
or	O
similar	O
to	O
get	O
the	O
indices	O
.	O

The	O
absolute	O
error	O
will	O
be	O
at	O
most	O
1	O
/	O
2	O
ULP	O
,	O
2	O
-150	O
.	O

AttributeError	O
:	O
'	O
Add	O
'	O
object	O
has	O
no	O
attribute	O
'	O
log	O
'	O
Python	O

Or	O
,	O
you	O
could	O
initialize	O
an	O
array	O
of	O
all	O
zeros	O
if	O
you	O
know	O
the	O
size	O
of	O
the	O
array	O
ahead	O
of	O
time	O
.	O

Are	O
you	O
checking	O
shape	O
or	O
number	O
of	O
nonzero	O
values	O
?	O

Something	O
like	O
`	O
eigvals	O
,	O
eigvecs	O
=	O
la.eigh	O
(	O
mat	B-API
)`	O
`	O
principal	O
=	O
eigvecs	O
[:	O
,	O
eigvals.argmax()	O
]`	O
`	O
if	O
(	O
principal	O
>	O
=	O
0	O
)	O
.all()	O
or	O
(	O
pricipal	O
<=	O
0	O
)	O
.all()	O
:	O
print	O
'	O
all	O
the	O
same	O
'`	O
?	O

I	O
also	O
want	O
bins	O
to	O
have	O
a	O
width	O
of	O
.5	O
so	O
that	O
I	O
can	O
have	O
a	O
bin	O
from	O
10.5	O
to	O
11	O
or	O
24	O
to	O
24.5	O
etc	O
...	O
because	O
otherwise	O
,	O
python	O
outputs	O
the	O
histogram	O
with	O
the	O
bins	O
random	O
and	O
undetermined	O
.	O

Maximum	O
is	O
always	O
bigger	O
than	O
the	O
minimum	O
(	O
more	O
to	O
the	O
right	O
on	O
a	O
1d	O
axis	O
,	O
not	O
by	O
absolute	O
value	O
)	O
.	O

should	O
give	O
the	O
sum	O
of	O
the	O
columns	O
.	O

Suppose	O
,	O
You	O
wanna	O
check	O
how	O
many	O
times	O
you	O
will	O
get	O
six	O
if	O
you	O
roll	O
dice	O
10	O
times	O
.	O

With	O
this	O
option	O
,	O
the	O
result	O
will	O
broadcast	O
correctly	O

Do	O
you	O
mean	O
`	O
indices	O
=	O
np.where	B-API
(	O
a	O
==	O
a.max()	O
)`	O
in	O
line	O
3	O
?	O

The	O
problem	O
I	O
have	O
much	O
later	O
on	O
in	O
the	O
code	O
is	O
that	O
if	O
one	O
of	O
these	O
parameters	O
isn't	O
in	O
the	O
ASCII	O
file	O
it	O
throws	O
errors	O
up	O
so	O
I	O
have	O
to	O
keep	O
adding	O
in	O
ones	O
I	O
don't	O
need	O
.	O

`	O
append	B-API
`	O
adds	O
them	O
to	O
the	O
end	O
of	O
the	O
list	O
,	O
which	O
is	O
exactly	O
what	O
you	O
want	O
.	O

I	O
have	O
two	O
3dim	O
numpy	O
matrices	O
and	O
I	O
want	O
to	O
do	O
a	O
dot	O
product	O
according	O
to	O
one	O
axis	O
without	O
using	O
a	O
loop	O
in	O
theano	O
.	O

you	O
have	O
at	O
most	O
4	O
in	O
that	O
dimension	O
(	O
see	O
your	O
reshape	O
line	O
)	O
,	O
so	O
the	O
index	O
it	O
will	O
count	O
are	O
0	O
and	O
2	O
(	O
1	O
and	O
3	O
are	O
skipped	O
,	O
and	O
3	O
is	O
the	O
last	O
element	O
)	O
.	O

Once	O
we	O
have	O
the	O
indices	O
to	O
sort	O
`	O
data	O
`	O
,	O
to	O
get	O
a	O
sorted	O
copy	O
of	O
the	O
array	O
it	O
is	O
faster	O
to	O
use	O
the	O
indices	O
than	O
to	O
re-sort	O
the	O
array	O
:	O
#CODE	O

I	O
hope	O
this	O
will	O
help	O
you	O
perform	O
your	O
transpose	O
and	O
column-wise	O
operations	O

It	O
is	O
better	O
to	O
specify	O
that	O
I'm	O
looking	O
for	O
something	O
that	O
performs	O
the	O
log-sum-exp	O
trick	O
,	O
doing	O
a	O
simply	O
succession	O
of	O
exp	O
elem-wise	O
,	O
summing	O
the	O
rows	O
and	O
doing	O
a	O
log	O
elem-wise	O
is	O
trivial	O
in	O
`	O
scipy.sparse	O
`	O
.	O

Scipy	O
uses	O
`	O
int32	O
`	O
to	O
store	O
`	O
indptr	O
`	O
and	O
`	O
indices	O
`	O
for	O
the	O
sparse	O
formats	O
.	O

But	O
not	O
able	O
to	O
plot	O
it	O
as	O
a	O
graph	O
(	O
something	O
like	O
a	O
histogram	O
)	O
...	O
that	O
is	O
the	O
problem	O
.	O

It	O
gave	O
error	O
testing	O
doesnot	O
have	O
attribute	O
append	O
as	O
its	O
of	O
None	O
Type	O
.	O

In	O
both	O
cases	O
,	O
you	O
can	O
access	O
individual	O
elements	O
by	O
indices	O
,	O
like	O
`	O
R	O
[	O
0	O
]`	O
(	O
which	O
would	O
give	O
you	O
a	O
specific	O
object	O
,	O
a	O
`	O
np.void	O
`	O
,	O
that	O
still	O
gives	O
you	O
the	O
possibility	O
to	O
access	O
the	O
fields	O
separately	O
)	O
,	O
or	O
by	O
slices	O
`	O
R	O
[	O
1	O
:	O
-1	O
]`	O
...	O

I	O
think	O
you	O
can	O
have	O
a	O
sum	O
over	O
a	O
sliding	O
window	O
(	O
or	O
a	O
rolling	O
window	O
)	O
or	O
a	O
mean	O
over	O
a	O
sliding	O
window	O
.	O

I	O
got	O
your	O
point	O
and	O
I	O
find	O
it	O
more	O
logical	O
,	O
but	O
when	O
trying	O
the	O
code	O
you've	O
suggested	O
to	O
get	O
rid	O
of	O
the	O
second	O
error	O
I	O
got	O
another	O
error	O
:	O
`	O
AttributeError	O
:	O
flatten	B-API
`	O

`	O
dot	B-API
`	O
does	O
many	O
things	O
under	O
the	O
hood	O
,	O
it	O
is	O
apparent	O
that	O
`	O
np.dot	B-API
(	O
A	O
,	O
x	O
)`	O
is	O
not	O
calling	O
BLAS	O
and	O
is	O
somehow	O
defaulting	O
over	O
to	O
numpy's	O
internal	O
GEMM	O
routine	O
.	O

Below	O
is	O
some	O
code	O
which	O
uses	O
a	O
callback	O
to	O
print	O
out	O
the	O
current	O
azimuthal	O
and	O
elevation	O
angles	O
,	O
as	O
well	O
as	O
append	O
them	O
to	O
a	O
list	O
for	O
further	O
use	O
later	O
.	O

It's	O
super	O
alex	O
,	O
here	O
to	O
answer	O
NumPy	O
questions	O
in	O
the	O
blink	O
of	O
an	O
eye	O
:)	O

Your	O
solution	O
of	O
searching	O
the	O
eigenvalues	O
for	O
the	O
ones	O
you	O
want	O
seems	O
plausible	O
enough	O
.	O

If	O
d	O
is	O
larger	O
than	O
8	O
or	O
9	O
,	O
then	O
bases	O
will	O
be	O
sufficiently	O
long	O
that	O
you	O
probably	O
would	O
be	O
better	O
off	O
going	O
with	O
the	O
other	O
version	O
using	O
the	O
dot	O
product	O
.	O

I'm	O
not	O
sure	O
which	O
indices	O
i	O
need	O
to	O
change	O
to	O
achieve	O
the	O
minimum	O
and	O
not	O
the	O
maximum	O
values	O
.	O

The	O
dimension	O
of	O
`	O
result	O
`	O
has	O
been	O
set	O
earlier	O
to	O
the	O
correct	O
dimension	O
,	O
so	O
can	O
check	O
it	O
,	O
but	O
it	O
would	O
be	O
nice	O
to	O
only	O
use	O
the	O
length	O
of	O
`	O
indices	O
`	O
to	O
determine	O
it	O
.	O

Alternatively	O
,	O
what	O
about	O
applying	O
the	O
same	O
function	O
without	O
indices	O
along	O
the	O
depth	O
axes	O
?	O

Here's	O
an	O
O	O
(	O
n	O
log	O
n	O
)	O
algorithm	O
for	O
your	O
problem	O
.	O

You	O
need	O
to	O
add	O
axes	O
to	O
`	O
coeffs	O
`	O
so	O
it	O
will	O
broadcast	O
in	O
the	O
dimension	O
(	O
s	O
)	O
you	O
want	O
.	O

If	O
you	O
want	O
to	O
search	O
for	O
a	O
certain	O
rank	O
on	O
B	O
randomly	O
,	O
you	O
need	O
to	O
start	O
off	O
with	O
a	O
valid	O
B	O
with	O
max	O
rank	O
,	O
and	O
rotate	O
a	O
random	O
column	O
j	O
of	O
a	O
random	O
B	O
i	O
by	O
a	O
random	O
amount	O
.	O

I	O
want	O
to	O
save	O
some	O
histogram	O
data	O
in	O
a	O
csv	O
file	O
.	O

I	O
want	O
to	O
read	O
a	O
mat	O
file	O
back	O
in	O
python	O
but	O
I	O
have	O
trouble	O
going	O
back	O
to	O
a	O
graph	O
,	O
because	O
the	O
mat	O
file	O
gives	O
a	O
numpy.ndarray	B-API
type	O
file	O
and	O
I	O
need	O
a	O
sparse	O
matrix	O
to	O
reconstruct	O
my	O
graph	O
.	O

numpy	O
makes	O
it	O
easy	O
to	O
translate	O
python	O
objects	O
into	O
numpy	O
ndarrays	O
,	O
and	O
will	O
even	O
pick	O
an	O
appropriate	O
resulting	O
data	O
type	O
if	O
one	O
is	O
not	O
specified	O
:	O
#CODE	O

This	O
`	O
T	O
`	O
and	O
`	O
X	O
`	O
broadcast	O
together	O
just	O
fine	O
,	O
for	O
example	O
`	O
T*X	O
`	O
works	O
.	O

I	O
have	O
a	O
numpy	O
matrix	O
A	O
and	O
I	O
need	O
a	O
function	O
that	O
will	O
count	O
(	O
A	O
[	O
i	O
,	O
j	O
]	O
/	O
sum	O
of	O
all	O
elements	O
in	O
i-th	O
column	O
)	O
-	O
A	O
[	O
i	O
,	O
j	O
]	O
/	O
sum	O
of	O
all	O
elements	O
in	O
j-th	O
row	O

This	O
also	O
works	O
if	O
,	O
instead	O
of	O
a	O
single	O
index	O
,	O
you	O
provide	O
an	O
array	O
of	O
indices	O
:	O
#CODE	O

How	O
to	O
solve	O
nonlinear	O
equation	O
without	O
sympy	O
(	O
max	O
and	O
min	O
)	O
?	O

Bivariate	O
Legendre	O
Polynomial	O
Fitting	O
to	O
find	O
orthogonal	O
coefficents	O

I	O
have	O
a	O
big	O
n-square	O
diagonal	O
matrix	O
,	O
in	O
the	O
scipy's	O
sparse	O
DIA	O
format	O

To	O
find	O
the	O
most	O
frequent	O
value	O
of	O
a	O
flat	O
array	O
,	O
use	O
`	O
unique	B-API
`	O
,	O
`	O
bincount	B-API
`	O
and	O
`	O
argmax	B-API
`	O
:	O
#CODE	O

The	O
funny	O
thing	O
is	O
in	O
the	O
above	O
function	O
If	O
i	O
pass	O
an	O
extra	O
argument	O
and	O
just	O
divide	O
sum	O
by	O
it	O
,	O
then	O
the	O
times	O
are	O
the	O
same	O
again	O
.	O

are	O
the	O
same	O
as	O
the	O
ones	O
posted	O
in	O
the	O
examples	O
of	O
this	O
web	O
page	O
.	O

How	O
to	O
remove	O
rings	O
from	O
convolve	O
healpix	O
map	O
?	O

With	O
the	O
information	O
of	O
the	O
full	O
stack	O
trace	O
report	O
the	O
bug	O
to	O
the	O
ubuntu	O
team	O
.	O

fastest	O
way	O
to	O
get	O
lookup	O
table	O
indices	O
with	O
numpy	O

Well	O
,	O
a	O
few	O
more	O
,	O
anyway	O
:	O
`	O
cos	B-API
`	O
,	O
`	O
pi	B-API
`	O
,	O
`	O
diag	B-API
`	O

I	O
implemented	O
a	O
LOWESS	O
smoother	O
(	O
which	O
is	O
the	O
curve	O
you	O
see	O
)	O
with	O
a	O
tight	O
fit	O
to	O
eliminate	O
noise	O
,	O
since	O
the	O
real	O
waveforms	O
have	O
a	O
non-trivial	O
noise	O
component	O
,	O
and	O
then	O
tried	O
doing	O
a	O
rolling	O
max	O
with	O
a	O
window	O
over	O
the	O
data	O
,	O
but	O
I	O
can't	O
get	O
anything	O
solid	O
.	O

But	O
sum	B-API
function	O
from	O
numpy	O
doesn't	O
suport	O
"	O
1:3	O
"	O

(	O
the	O
`	O
np.nonzero	B-API
`	O
should	O
return	O
a	O
tuple	O
with	O
one	O
element	O
,	O
an	O
array	O
of	O
indices	O
)	O
.	O

Can	O
the	O
"	O
small	O
values	O
of	O
derivative	O
"	O
be	O
small	O
with	O
respect	O
to	O
the	O
sin	O
curve	O
?	O

6	O
columns	O
,	O
92370574	O
rows	O
,	O
2496502	O
locations	O
,	O
37	O
months	O
each	O
,	O
unique	O
amounts	O
for	O
each	O
value	O
.	O

Note	O
that	O
where	O
possible	O
,	O
`	O
reshape	B-API
`	O
will	O
give	O
you	O
a	O
view	O
of	O
the	O
array	O
.	O

Here	O
you	O
append	O
only	O
a	O
REFERENCE	O
to	O
your	O
only	O
one	O
existing	O
`	O
energy	O
`	O
array	O
.	O

And	O
you	O
can	O
combine	O
the	O
summation	O
and	O
multiplication	O
into	O
a	O
dot	O
product	O
:	O
#CODE	O

For	O
example	O
,	O
`	O
a	O
`	O
is	O
generated	O
from	O
`	O
a	O
=	O
z	O
[	O
z	O
!	O
=0	O
]`	O
;	O
`	O
a	O
`	O
then	O
changes	O
through	O
some	O
processing	O
,	O
and	O
now	O
I	O
need	O
to	O
insert	O
`	O
nan	O
`	O
s	O
where	O
there	O
were	O
originally	O
zeros	O
.	O

I	O
frequently	O
use	O
the	O
numpy.where	B-API
function	O
to	O
gather	O
a	O
tuple	O
of	O
indices	O
of	O
a	O
matrix	O
having	O
some	O
property	O
.	O

I	O
suspect	O
the	O
original	O
formula	O
was	O
right	O
but	O
you	O
didn't	O
encode	O
it	O
right	O
in	O
Python	O
.	O

This	O
gets	O
me	O
the	O
sum	O
of	O
all	O
red	O
combined	O
in	O
original	O
-	O
all	O
red	O
combined	O
in	O
mutated	O
.	O

`	O
p2	O
=	O
einsum	B-API
(	O
'	O
nk	O
,	O
nk	O
->	O
n	O
'	O
,	O
p1	O
,	O
delta	O
)`	O
is	O
the	O
pairwise	O
dot	O
product	O
of	O
the	O
rows	O
of	O
`	O
p1	O
`	O
and	O
`	O
delta	O
`	O
.	O

I	O
did	O
the	O
reshape	B-API
,	O
just	O
so	O
that	O
both	O
arrays	O
are	O
same	O
shape	O
,	O
but	O
I	O
do	O
not	O
think	O
you	O
really	O
need	O
the	O
reshaping	O
,	O
with	O
the	O
list	O
comprehension	O
the	O
shape	O
of	O
array	O
you	O
get	O
is	O
`	O
(	O
length	O
of	O
string	O
,	O
)`	O

Also	O
,	O
I	O
expect	O
the	O
positions	O
of	O
the	O
zeros	O
to	O
be	O
relatively	O
sparse	O
(	O
~1%	O
of	O
all	O
bit	O
positions	O
)	O
.	O

Slicing	O
arrays	O
with	O
meshgrid	B-API
/	O
array	O
indices	O
in	O
Numpy	O

(	O
An	O
nonzero	O
exit	O
status	O
usually	O
indicates	O
an	O
error	O
on	O
Unix	O
style	O
systems	O
.	O
A	O
couple	O
programs	O
are	O
different	O
,	O
e.g.	O
,	O
`	O
diff	B-API
`	O
.	O
)	O
Try	O
examining	O
the	O
`	O
stderr	O
`	O
produced	O
by	O
the	O
subprocess	O
to	O
see	O
what	O
error	O
messages	O
are	O
printed	O
there	O
.	O

To	O
achieve	O
exactly	O
what	O
you	O
are	O
asking	O
for	O
I	O
would	O
apply	O
a	O
`	O
[	O
3x3	O
]`	O
box-filter	O
on	O
the	O
image	O
and	O
than	O
I	O
would	O
resize	O
the	O
matrix	O
using	O
nearest	O
neighbor	O
interpolation	O
.	O

Is	O
there	O
a	O
quick	O
way	O
to	O
reshape	O
my	O
`	O
csr_matrix	O
`	O
without	O
copying	O
everything	O
in	O
it	O
?	O

The	O
catch	O
is	O
that	O
I	O
need	O
to	O
keep	O
the	O
colors	O
exactly	O
the	O
way	O
they	O
are	O
(	O
background	O
:	O
I'm	O
resizing	O
a	O
map	O
where	O
provinces	O
are	O
color-coded	O
)	O
,	O
and	O
so	O
I	O
cannot	O
just	O
perform	O
a	O
resize	O
with	O
bicubic	O
interpolation	O
,	O
because	O
that	O
will	O
also	O
interpolate	O
the	O
pixel	O
colors	O
while	O
smoothing	O
.	O

You	O
should	O
"	O
flatten	O
"	O
the	O
array	O
of	O
arrays	O
first	O
.	O
unfortunately	O
,	O
there's	O
no	O
builtin	O
method	O
,	O
see	O
#URL	O

then	O
concatenate	O
the	O
saved	O
objects	O
whit	O
this	O
code	O
:	O
#CODE	O

For	O
something	O
like	O
a	O
dot	O
product	O
,	O
pandas	O
`	O
DataFrames	O
`	O
are	O
generally	O
going	O
to	O
be	O
slower	O
than	O
a	O
numpy	O
array	O
since	O
pandas	O
is	O
doing	O
**	O
a	O
lot	O
more	O
stuff	O
**	O
aligning	O
labels	O
,	O
potentially	O
dealing	O
with	O
heterogenous	O
types	O
,	O
and	O
so	O
on	O
.	O

I	O
want	O
to	O
pass	O
an	O
array	O
of	O
indices	O
and	O
column	O
names	O
and	O
get	O
a	O
list	O
of	O
objects	O
that	O
are	O
found	O
in	O
the	O
corresponding	O
index	O
and	O
column	O
name	O
.	O

From	O
this	O
you	O
would	O
expect	O
the	O
total	O
sum	O
to	O
be	O
`	O
100,679,697	O
=	O
200*	O
(	O
1,000,000	O
-	O
499,097	O
)	O
+	O
499,097	O
`	O

The	O
histogram	O
way	O
is	O
not	O
the	O
fastest	O
,	O
and	O
can't	O
tell	O
the	O
difference	O
between	O
an	O
arbitrarily	O
small	O
separation	O
of	O
points	O
and	O
`	O
2	O
*	O
sqrt	B-API
(	O
2	O
)	O
*	O
b	O
`	O
(	O
where	O
`	O
b	O
`	O
is	O
bin	O
width	O
)	O
.	O

}	O
for	O
n=1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
,	O
6	O
(	O
using	O
Sum	B-API
(	O
c_n	O
exp	B-API
(	O
i	O
2	O
pi	O
n	O
x	O
)	O
)	O
as	O
Fourier	O
series	O
)	O
.	O

I	O
think	O
I	O
can	O
t	O
just	O
simple	O
sum	O
the	O
"	O
seq	O
*	O
"	O
array	O
,	O
because	O
instead	O
of	O
a	O
chord	O
I	O
will	O
get	O
noise	O
.	O

I	O
presume	O
you	O
want	O
to	O
transpose	O
first	O
:	O
#CODE	O

Oh	O
,	O
that's	O
interesting	O
you	O
can	O
do	O
it	O
with	O
stack	B-API
.	O

In	O
this	O
case	O
,	O
using	O
numpy	O
outer	B-API
operations	O
allow	O
you	O
to	O
compute	O
the	O
multiplications	O
and	O
sums	O
at	O
the	O
`	O
C	O
`	O
loop	O
speed	O
.	O

The	O
most	O
efficient	O
way	O
is	O
likely	O
to	O
use	O
'	O
np.empty()	B-API
'	O
to	O
allocate	O
the	O
space	O
/	O
memory	O
for	O
your	O
end	O
dataset	O
and	O
then	O
load	O
data	O
&	O
broadcast	O
within	O
that	O
using	O
slice	O
indexing	O
.	O

Ok	O
,	O
with	O
your	O
histogram	O
I	O
get	O
at	O
least	O
the	O
total	O
number	O
of	O
each	O
pair	O
.	O

This	O
is	O
because	O
python's	O
sum	O
is	O
basically	O
summing	O
a	O
for	O
loop	O
over	O
the	O
object	O
.	O

Then	O
the	O
entire	O
shape	O
changes	O
from	O
(	O
x	O
,	O
y	O
)	O
to	O
merely	O
(	O
x	O
,	O
)	O
and	O
I	O
get	O
'	O
too	O
many	O
indices	O
'	O
errors	O
when	O
I	O
try	O
to	O
use	O
masks	O
.	O

If	O
reps	O
has	O
length	O
d	O
,	O
the	O
result	O
will	O
have	O
dimension	O
of	O
max	B-API
(	O
d	O
,	O
A.ndim	O
)	O
.	O

I	O
want	O
to	O
do	O
this	O
by	O
dividing	O
each	O
histogram	O
by	O
its	O
maximum	O
value	O
so	O
all	O
the	O
distributions	O
have	O
the	O
same	O
scale	O
.	O

An	O
obvious	O
path	O
would	O
be	O
to	O
transpose	O
the	O
array	O
so	O
that	O
the	O
indices	O
that	O
I	O
am	O
selecting	O
would	O
come	O
up	O
first	O
.	O

Now	O
,	O
for	O
mean	O
calculations	O
,	O
those	O
numeric	O
IDs	O
could	O
be	O
used	O
as	O
`"	O
weights	O
"`	O
for	O
binning	O
with	O
`	O
np.bincount	B-API
`	O
,	O
giving	O
us	O
the	O
sum	O
of	O
data	O
elements	O
corresponding	O
to	O
each	O
`	O
ID	O
`	O
.	O

However	O
,	O
what	O
I	O
need	O
is	O
a	O
string	O
containing	O
all	O
the	O
elements	O
in	O
the	O
list	O
linked	O
by	O
'	O
;	O
'	O
,	O
not	O
the	O
list	O
itself	O
,	O
so	O
it	O
seems	O
like	O
I	O
have	O
to	O
sum	O
all	O
the	O
elements	O
in	O
asString	O
with	O
another	O
iteration	O
?	O

the	O
output	O
I	O
need	O
:	O
`	O
S	O
=	O
[	O
2	O
,	O
5	O
,	O
8	O
,	O
11	O
,	O
14	O
]`	O
I	O
thought	O
something	O
like	O
:	O
`	O
S1	O
=	O
np.array	B-API
(	O
L	O
[:	O
]	O
[	O
1	O
,	O
0	O
])`	O
should	O
work	O
but	O
whatever	O
I	O
try	O
I	O
have	O
the	O
error	O
like	O
:	O
`	O
TypeError	O
:	O
list	O
indices	O
must	O
be	O
integers	O
,	O
not	O
tuple	O
`	O
.	O

I	O
need	O
it	O
because	O
in	O
the	O
next	O
part	O
I	O
will	O
sum	O
up	O
this	O
large	O
np.array	B-API
with	O
some	O
delta_array	O
that	O
has	O
the	O
same	O
shape	O
.	O

Used	O
reshape	B-API
to	O
make	O
rows	O
into	O
columns	O
.	O

I	O
understand	O
that	O
you	O
could	O
create	O
an	O
array	O
of	O
zeros	O
and	O
iteratively	O
change	O
the	O
values	O
in	O
each	O
column	O
,	O
but	O
I	O
also	O
understand	O
this	O
is	O
not	O
an	O
efficient	O
method	O
.	O

I'm	O
trying	O
to	O
implement	O
the	O
univariate	O
gradient	O
descent	O
algorithm	O
in	O
python	O
.	O

numpy	O
glossary	O
says	O
the	O
sum	O
along	O
axis	O
argument	O
`	O
axis=1	O
`	O
sums	O
over	O
rows	O
:	O
"	O
we	O
can	O
sum	O
each	O
row	O
of	O
an	O
array	O
,	O
in	O
which	O
case	O
we	O
operate	O
along	O
columns	O
,	O
or	O
axis	O
1	O
"	O
.	O

It	O
also	O
prints	O
out	O
the	O
new	O
indices	O
signature	O
.	O

At	O
first	O
,	O
your	O
`	O
result	O
`	O
does	O
not	O
look	O
like	O
a	O
complex	O
FFT	O
output	O

debug	O
performance	O
diff	O
of	O
Same	O
code	O
on	O
nearly	O
same	O
cpu	O
/	O
ram	O

The	O
HTML	O
file	O
generated	O
by	O
Cython	O
indicates	O
that	O
the	O
bottleneck	O
is	O
the	O
dot	O
products	O
(	O
which	O
is	O
expected	O
of	O
course	O
)	O
.	O

`	O
numpy.unique	B-API
`	O
with	O
`	O
return_index=True	O
`	O
will	O
give	O
you	O
a	O
list	O
of	O
indices	O
to	O
take	O
from	O
.	O

I	O
forgot	O
exactly	O
why	O
,	O
but	O
there	O
is	O
a	O
good	O
reason	O
why	O
you	O
calculate	O
it	O
as	O
the	O
ratio	O
between	O
these	O
two	O
averages	O
,	O
instead	O
of	O
directly	O
averaging	O
`	O
fft	B-API
(	O
y	O
)	O
/	O
fft	B-API
(	O
x	O
)`	O
.	O

Do	O
you	O
really	O
want	O
this	O
'	O
roll	B-API
'	O
?	O

By	O
adding	O
a	O
nonzero	O
number	O
at	O
the	O
end	O
of	O
the	O
array	O
,	O
you	O
can	O
still	O
use	O
np.nonzero	B-API
to	O
get	O
your	O
desired	O
outcome	O
.	O

which	O
simply	O
sorts	O
the	O
terms	O
and	O
then	O
takes	O
the	O
ones	O
which	O
aren't	O
equal	O
to	O
the	O
previous	O
one	O
.	O

4	O
:	O
I	O
am	O
not	O
sure	O
about	O
the	O
indices	O
,	O
by	O
writing	O
couple	O
of	O
code	O
lines	O
I	O
just	O
able	O
to	O
get	O
cluster	O
indices	O
based	O
on	O
fclusterdata	O
.	O

Matlab	O
gives	O
me	O
a	O
norm	O
=	O
2	O
for	O
your	O
matrix	O
.	O

I	O
first	O
generated	O
a	O
labelled	O
array	O
of	O
unique	O
IDs	O
for	O
each	O
discrete	O
region	O
,	O
calculated	O
sizes	O
for	O
each	O
ID	O
,	O
masked	O
the	O
size	O
array	O
to	O
focus	O
only	O
on	O
size	O
==	O
1	O
blobs	O
,	O
then	O
index	O
the	O
original	O
array	O
and	O
set	O
IDs	O
with	O
a	O
size	O
==	O
1	O
to	O
0	O
:	O
#CODE	O

absolute	B-API
(	O
a	O
-	O
b	O
)	O
=	O
(	O
atol	O
+	O
rtol	O
*	O
absolute	B-API
(	O
b	O
))	O

Then	O
I	O
reshape	O
this	O
to	O
form	O
a	O
2D	O
numpy	O
array	O
.	O

n=5	O
(	O
min	O
length	O
of	O
sequence	O
)	O

I	O
have	O
written	O
a	O
function	O
which	O
contains	O
nested	O
loops	O
and	O
a	O
conditional	O
statement	O
;	O
the	O
purpose	O
of	O
the	O
loop	O
is	O
to	O
return	O
a	O
list	O
of	O
indices	O
for	O
the	O
nearest	O
elements	O
in	O
array	O
x	O
when	O
compared	O
to	O
array	O
y	O
.	O

I	O
also	O
want	O
to	O
color	O
the	O
1D	O
histogram	O
bars	O
according	O
to	O
the	O
same	O
normalization	O
.	O

If	O
you	O
are	O
calling	O
it	O
with	O
an	O
empty	O
matrix	O
for	O
[	O
low	O
,	O
high	O
]	O
it	O
will	O
just	O
use	O
whatever	O
the	O
max	O
and	O
min	O
values	O
in	O
the	O
array	O
are	O
.	O

Creating	O
a	O
class	O
deriving	O
from	O
`	O
ndarray	B-API
`	O
and	O
overriding	O
indexing	O
such	O
that	O
the	O
absolute	O
indices	O
are	O
used	O
.	O

One	O
solution	O
is	O
to	O
sort	O
both	O
arrays	O
(	O
adding	O
an	O
index	O
column	O
so	O
that	O
the	O
sorted	O
arrays	O
still	O
contains	O
the	O
original	O
indices	O
)	O
.	O

Use	O
`	O
reshape	B-API
`	O
:	O
#CODE	O

What's	O
wrong	O
with	O
the	O
normal	O
div	O
/	O
mod	O
operations	O
?	O

You	O
can	O
use	O
`	O
argmin	B-API
`	O
to	O
find	O
the	O
False	O
values	O
,	O
and	O
this	O
will	O
be	O
faster	O
and	O
take	O
less	O
memory	O
than	O
using	O
nonzero	B-API
,	O
but	O
this	O
is	O
linear	O
in	O
the	O
length	O
of	O
`	O
a	O
`	O
.	O

I'd	O
like	O
it	O
to	O
be	O
like	O
8x10^8	O
or	O
.8x10	O
^9	O
to	O
save	O
space	O
instead	O
of	O
putting	O
all	O
those	O
zeros	O
.	O

The	O
one	O
I	O
pointed	O
out	O
in	O
a	O
comment	O
to	O
other	O
answer	O
as	O
to	O
encode	O
the	O
binary	O
representation	O
of	O
the	O
array	O
as	O
a	O
Base64	O
text	O
block	O
.	O

due	O
to	O
broadcasting	O
,	O
you	O
don't	O
need	O
to	O
repeat	O
duplicate	O
indices	O
,	O
thus	O
:	O
#CODE	O

Maybe	O
`	O
flatten()	B-API
`	O
the	O
original	O
array	O
,	O
then	O
use	O
your	O
1D	O
solution	O
,	O
finally	O
calculate	O
the	O
real	O
nD	O
indices	O
using	O
the	O
original	O
shape	O
?	O

Note	O
that	O
the	O
diagonal	O
is	O
always	O
zero	O
since	O
`	O
mahalanobis	O
(	O
x	O
,	O
x	O
)`	O
equals	O
zero	O
for	O

possible	O
duplicate	O
of	O
[	O
NumPy	O
min	B-API
/	O
max	B-API
in-place	O
assignment	O
]	O
(	O
#URL	O
)	O

Once	O
the	O
tree	O
structure	O
has	O
been	O
built	O
,	O
go	O
back	O
and	O
collect	O
all	O
the	O
branches	O
and	O
leaves	O
into	O
the	O
array	O
structure	O
and	O
by	O
definition	O
,	O
they	O
will	O
be	O
unique	O
.	O

I	O
wrote	O
the	O
following	O
code	O
but	O
the	O
output	O
only	O
contains	O
the	O
ids	O
(	O
single	O
column	O
)	O
.	O

Maximum	O
is	O
always	O
bigger	O
than	O
the	O
minimum	O
(	O
more	O
to	O
the	O
right	O
on	O
a	O
1d	O
axis	O
,	O
not	O
by	O
absolute	O
value	O
)	O
.	O

Note	O
that	O
`	O
unq_count	O
`	O
doesn't	O
count	O
the	O
occurrences	O
of	O
the	O
last	O
unique	O
item	O
,	O
because	O
that	O
is	O
not	O
needed	O
to	O
split	O
the	O
index	O
array	O
.	O

If	O
yes	O
,	O
you	O
can	O
use	O
the	O
Linux	O
terminal	O
to	O
strip	O
quotes	O
from	O
the	O
ends	O
of	O
the	O
rows	O
quickly	O
.	O

The	O
append	B-API
method	O
for	O
a	O
numpy	O
array	O
returns	O
a	O
copy	O
of	O
the	O
array	O
with	O
new	O
items	O
added	O
to	O
the	O
end	O
.	O

I	O
want	O
to	O
get	O
the	O
norm	B-API
of	O
this	O
array	O
using	O
numpy	O
.	O

The	O
only	O
problem	O
here	O
is	O
that	O
I	O
think	O
it	O
will	O
append	O
directly	O
to	O
the	O
column	O
,	O
when	O
I	O
would	O
prefer	O
it	O
to	O
append	O
to	O
a	O
new	O
column	O
.	O

You	O
don't	O
need	O
to	O
import	O
string	O
,	O
and	O
you	O
don't	O
need	O
to	O
loop	O
through	O
all	O
the	O
lines	O
and	O
append	O
text	O
or	O
count	O
the	O
characters	O
.	O

The	O
transpose	O
of	O
the	O
transpose	O
of	O
a	O
matrix	O
==	O
that	O
matrix	O
,	O
or	O
,	O
[	O
A^T	O
]	O
^T	O
==	O
A	O
.	O

Currently	O
I	O
am	O
looping	O
through	O
the	O
arrays	O
and	O
using	O
numpy.dstack	B-API
to	O
stack	O
the	O
1000	O
arrays	O
into	O
a	O
rather	O
large	O
3d	O
array	O
...	O
and	O
then	O
will	O
calculate	O
the	O
mean	O
across	O
the	O
3rd	O
(	O
?	O
)	O
dimension	O
.	O

If	O
you	O
strip	O
all	O
these	O
out	O
and	O
just	O
call	O
lapack	O
in	O
your	O
for	O
loop	O
(	O
since	O
you	O
already	O
know	O
the	O
dimensions	O
of	O
your	O
matrix	O
and	O
maybe	O
know	O
that	O
it's	O
real	O
,	O
not	O
complex	O
)	O
,	O
things	O
run	O
MUCH	O
faster	O
(	O
Note	O
that	O
I've	O
made	O
my	O
array	O
larger	O
)	O
:	O
#CODE	O

First	O
,	O
you	O
have	O
a	O
binomial	O
response	O
:	O
having	O
or	O
not	O
having	O
a	O
particular	O
behavior	O
.	O

The	O
call	O
to	O
`	O
np.sqrt	B-API
`	O
,	O
which	O
is	O
a	O
Python	O
function	O
call	O
,	O
is	O
killing	O
your	O
performance	O
You	O
are	O
computing	O
the	O
square	O
root	O
of	O
scalar	O
floating	O
point	O
value	O
,	O
so	O
you	O
should	O
use	O
the	O
`	O
sqrt	B-API
`	O
function	O
from	O
the	O
C	O
math	O
library	O
.	O

This	O
would	O
call	O
the	O
function	O
`	O
np.loadtxt	B-API
`	O
which	O
would	O
load	O
the	O
file	O
`	O
GPBUSD1d.txt	O
'`	O
and	O
transpose	O
(	O
"	O
unpack	O
")	O
it	O
.	O

You	O
can't	O
change	O
the	O
typing	O
of	O
the	O
array	O
in-place	O
(	O
unless	O
I'm	O
grossly	O
mistaken	O
)	O
,	O
but	O
you	O
can	O
floor	B-API
.	O

Finally	O
I	O
just	O
transpose	O
the	O
dataframe	O
to	O
get	O
ids	O
as	O
rows	O
and	O
categories	O
as	O
columns	O
.	O

The	O
following	O
way	O
of	O
obtaining	O
the	O
unique	O
elements	O
in	O
all	O
sub-arrays	O
is	O
very	O
fast	O
:	O
#CODE	O

You	O
can't	O
use	O
the	O
numpy	O
reshape	B-API
for	O
a	O
simple	O
reason	O
:	O
you	O
have	O
data	O
duplicity	O
in	O
your	O
original	O
array	O
(	O
time	O
and	O
positions	O
)	O
and	O
not	O
in	O
the	O
result	O
you	O
want	O
.	O

So	O
it	O
does	O
not	O
make	O
much	O
sense	O
to	O
me	O
to	O
reshape	O
it	O
to	O
a	O
"	O
1d-matrix	O
"	O
.	O

Now	O
create	O
5-bit	O
bitstrings	O
from	O
each	O
integer	O
and	O
join	O
them	O
together	O
:	O
#CODE	O

It	O
would	O
probably	O
be	O
just	O
as	O
much	O
work	O
to	O
translate	O
the	O
top	O
Matlab	O
routine	O
from	O
Maurits	O
.	O

In	O
the	O
particular	O
case	O
of	O
your	O
example	O
,	O
where	O
your	O
unique	O
values	O
are	O
sequential	O
integers	O
,	O
you	O
can	O
use	O
`	O
find_objects	O
`	O
directly	O
.	O

axis=1	O
refers	O
to	O
working	O
on	O
rows	O
in	O
this	O
2d	O
case	O
(	O
axis=0	O
,	O
in	O
contrast	O
,	O
would	O
be	O
getting	O
you	O
the	O
max	B-API
in	O
each	O
column	O
)	O

There	O
are	O
many	O
other	O
`	O
ufunc	O
`	O
,	O
and	O
other	O
iteration	O
modes	O
-	O
`	O
accumulate	B-API
`	O
,	O
`	O
reduceat	B-API
`	O
.	O

All	O
diagonal	O
elements	O
will	O
be	O
of	O
the	O
form	O
`	O
s_i	O
**	O
2	O
/	O
s_i	O
**	O
2	O
==	O
1	O
`	O
.	O

@USER	O
In	O
the	O
example	O
above	O
,	O
I	O
get	O
the	O
following	O
error	O
:	O
Non-broadcastable	O
operand	O
with	O
shape	O
(	O
100	O
)	O
doesn't	O
match	O
the	O
broadcast	B-API
shape	O
(	O
100,100	O
)	O

is	O
calculated	O
such	O
that	O
all	O
but	O
the	O
diagonal	O
#CODE	O

To	O
compute	O
the	O
number	O
of	O
unique	O
elements	O
in	O
a	O
numpy	O
array	O
,	O
you	O
can	O
use	O
`	O
unique	B-API
(	O
x	O
)	O
.size	O
`	O
or	O
`	O
len	B-API
(	O
unique	B-API
(	O
x	O
))`	O
(	O
see	O
`	O
numpy.unique	B-API
`	O
)	O
.	O

Or	O
would	O
that	O
basically	O
require	O
implementing	O
the	O
outer	O
loop	O
in	O
Cython	O
?	O

For	O
a	O
tensor	O
it	O
is	O
not	O
clear	O
how	O
to	O
define	O
an	O
inverse	O
or	O
a	O
transpose	O
.	O

Second	O
,	O
you	O
are	O
doing	O
transpose	B-API
the	O
hard	O
way	O
.	O

Where	O
does	O
log	B-API
(	O
b	O
,	O
2	O
)	O
come	O
from	O
?	O

(	O
The	O
values	O
in	O
the	O
corners	O
correspond	O
to	O
the	O
diagonal	O
elements	O
.	O
)	O

I	O
tried	O
using	O
the	O
scipy.stat	O
module	O
by	O
creating	O
my	O
numbers	O
with	O
`	O
np.random.normal	B-API
`	O
,	O
since	O
it	O
only	O
takes	O
data	O
and	O
not	O
stat	O
values	O
like	O
mean	O
and	O
std	O
dev	O
(	O
is	O
there	O
any	O
way	O
to	O
use	O
these	O
values	O
directly	O
)	O
.	O

The	O
asymptotic	O
complexity	O
of	O
both	O
of	O
the	O
`	O
matrix_rank	B-API
`	O
and	O
`	O
det	B-API
`	O
calls	O
are	O
therefore	O
O	O
(	O
n^3	O
)	O
,	O
the	O
complexity	O
of	O
LU	O
decomposition	O
.	O

I	O
think	O
the	O
np.std()	B-API
is	O
just	O
universal	O
std	B-API
.	O

Golub	O
and	O
Van	O
Loan	O
also	O
provide	O
a	O
way	O
of	O
storing	O
a	O
matrix	O
in	O
diagonal	O
dominant	O
form	O
.	O

I	O
see	O
no	O
reason	O
why	O
`	O
numpy	O
`	O
would	O
need	O
to	O
make	O
a	O
copy	O
for	O
an	O
operation	O
like	O
this	O
,	O
as	O
long	O
as	O
it	O
does	O
the	O
necessary	O
checks	O
for	O
overlaps	O
(	O
though	O
of	O
course	O
as	O
others	O
have	O
noted	O
,	O
`	O
resize	B-API
`	O
may	O
itself	O
have	O
to	O
allocate	O
a	O
new	O
block	O
of	O
memory	O
)	O
.	O

I	O
found	O
another	O
stack	O
question	O
about	O
this	O
here	O
,	O
but	O
I	O
am	O
not	O
entirely	O
sure	O
how	O
it	O
was	O
resolved	O
,	O
I'm	O
still	O
a	O
little	O
confused	O
.	O

Maybe	O
`	O
floor	B-API
(	O
arange	B-API
(	O
0	O
,	O
10	O
,	O
0.1	O
))`	O
?	O

In	O
python	O
,	O
I	O
would	O
like	O
to	O
convolve	O
the	O
two	O
matrices	O
along	O
the	O
second	O
axis	O
only	O
.	O

`	O
view	B-API
`	O
is	O
basically	O
taking	O
your	O
two	O
coordinates	O
as	O
a	O
single	O
variable	O
that	O
can	O
be	O
used	O
to	O
find	O
the	O
unique	O
coordinates	O
.	O

Keep	O
in	O
mind	O
that	O
machine	O
precision	O
for	O
a	O
32-bit	O
double	O
is	O
~	O
10^-16	O
,	O
which	O
will	O
be	O
an	O
absolute	O
limiting	O
factor	O
.	O

Also	O
,	O
if	O
there	O
is	O
then	O
I	O
could	O
just	O
append	O
to	O
the	O
b	O
and	O
c	O
arrays	O
each	O
time	O
instead	O
of	O
overwriting	O
and	O
starting	O
from	O
scratch	O
each	O
loop	O
.	O

Use	O
`	O
multiprocessing.Process	O
(	O
target	O
=	O
somefunc	O
,	O
args	O
=	O
(	O
sa	O
,	O
)`	O
(	O
and	O
`	O
start	O
`	O
,	O
maybe	O
`	O
join	B-API
`)	O
to	O
call	O
`	O
somefunc	O
`	O
in	O
a	O
separate	O
process	O
,	O
passing	O
the	O
shared	O
array	O
.	O

Take	O
a	O
look	O
a	O
the	O
concatenate	B-API
function	O
.	O

Unlike	O
Joe	O
Kington's	O
answer	O
,	O
the	O
benefit	O
of	O
this	O
is	O
that	O
you	O
don't	O
need	O
to	O
know	O
the	O
original	O
shape	O
of	O
the	O
data	O
in	O
the	O
`	O
.mat	O
`	O
file	O
,	O
i.e.	O
no	O
need	O
to	O
reshape	O
upon	O
reading	O
in	O
.	O

but	O
I	O
think	O
,	O
finding	O
the	O
local	O
max	O
can	O
be	O
simplified	O
to	O
:	O
#CODE	O

@USER	O
`	O
swapaxes	B-API
`	O
seemed	O
to	O
be	O
indistinguishable	O
from	O
`	O
transpose	B-API
(	O
0	O
,	O
2	O
,	O
1	O
)`	O
.	O

Do	O
gradient	B-API
actually	O
compute	O
really	O
a	O
gradient	O
?	O

I	O
would	O
suggest	O
to	O
first	O
program	O
it	O
with	O
`	O
np.nditer	B-API
`	O
and	O
then	O
translate	O
it	O
into	O
C	O
.	O

As	O
you	O
can	O
see	O
,	O
using	O
the	O
join	B-API
function	O
on	O
the	O
list	O
(	O
`	O
binary_list	O
`)	O
works	O
properly	O
,	O
but	O
on	O
the	O
equivalent	O
numpy	O
array	O
(	O
`	O
binary_split_array	O
`)	O
it	O
doesn't	O
:	O
we	O
can	O
see	O
the	O
string	O
returned	O
is	O
only	O
72	O
characters	O
long	O
instead	O
of	O
80	O
.	O

@USER	O
.B	O
.	O
the	O
above	O
question	O
is	O
significantly	O
different	O
from	O
mine	O
;	O
it	O
asks	O
for	O
both	O
min	B-API
and	O
max	B-API
,	O
and	O
it	O
is	O
for	O
2D	O
matrix	O

This	O
will	O
join	O
the	O
rows	O
and	O
write	O
them	O
to	O
a	O
new	O
csv	O
:	O
#CODE	O

The	O
reason	O
I	O
have	O
`	O
-det	O
(	O
mat	O
)`	O
in	O
the	O
energy	O
function	O
is	O
because	O
the	O
simulated	O
annealing	O
algorithm	O
does	O
minimization	O
.	O

Also	O
is	O
`	O
x	O
`	O
unique	O
?	O

Pandas	O
append	B-API
filtered	O
row	O
to	O
another	O
DataFrame	O

Again	O
,	O
the	O
code	O
notes	O
that	O
set	O
of	O
combinations	O
is	O
not	O
unique	O
;	O
but	O
it	O
does	O
have	O
a	O
unique	O
subset	O
,	O
namely	O
[[	O
2	O
3	O
]	O
,	O
[	O
0	O
1	O
]]	O
,	O
which	O
as	O
you	O
just	O
revealed	O
,	O
you	O
do	O
consider	O
a	O
valid	O
combination	O
.	O

That	O
concatenate	B-API
action	O
should	O
be	O
pretty	O
fast	O
.	O

If	O
you	O
want	O
to	O
pass	O
in	O
the	O
transpose	O
,	O
you'll	O
need	O
to	O
set	O
`	O
rowvar	O
`	O
to	O
zero	O
.	O

You	O
can	O
override	O
this	O
behavior	O
by	O
using	O
the	O
arguments	O
`	O
vmin	O
`	O
and	O
`	O
vmax	O
`	O
(	O
or	O
`	O
norm	O
`)	O
of	O
`	O
imshow	B-API
`	O
.	O

@USER	O
,	O
`	O
cs	O
`	O
is	O
sorted	O
and	O
`	O
searchsorted()	B-API
`	O
exploits	O
that	O
to	O
do	O
a	O
binary	O
search	O
-	O
only	O
`	O
O	O
(	O
log	B-API
(	O
len	B-API
(	O
weights	O
)))`	O
comparisons	O
are	O
needed	O
.	O

Think	O
`	O
flatten	B-API
`	O
without	O
the	O
copy	O
.	O

In	O
your	O
case	O
it	O
looks	O
like	O
the	O
weight	O
arrays	O
will	O
have	O
the	O
same	O
dimension	O
as	O
'	O
A	O
'	O
,	O
so	O
you	O
reshape	O
them	O
accordingly	O
and	O
multiply	O
dx	O
and	O
dy	O
by	O
their	O
individual	O
weight	O
vectors	O
.	O

Does	O
this	O
mean	O
the	O
standard	O
error	O
of	O
the	O
gradient	O
or	O
intercept	O
?	O

Also	O
,	O
the	O
algo	O
has	O
a	O
lot	O
of	O
matrices	O
manipulation	O
(	O
fft	B-API
,	O
filters	O
,	O
etc	O
.	O
)	O
,	O
so	O
using	O
numpy	O
/	O
scipy	O
should	O
result	O
in	O
faster	O
run	O
time	O
.	O

You	O
can	O
broadcast	O
that	O
into	O
an	O
array	O
using	O
expressions	O
,	O
for	O
example	O
#CODE	O

If	O
I	O
use	O
the	O
above	O
test	O
on	O
the	O
absolute	O
values	O
of	O
the	O
angles	O
to	O
be	O
tested	O
,	O
everything	O

The	O
returned	O
gradient	O
hence	O
has	O

"	O
In	O
the	O
first	O
case	O
the	O
gradient	O
is	O
1	O
mV	O
/	O
ms	O
,	O
in	O
the	O
second	O
case	O
it	O
is	O
50	O
mV	O
/	O
ms	O
.	O

If	O
True	O
,	O
uses	O
the	O
old	O
behavior	O
from	O
Numeric	O
,	O
(	O
correlate	B-API
(	O
a	O
,	O
v	O
)	O
==	O
correlate	B-API
(	O
v	O
,	O
a	O
)	O
,	O
and	O
the	O
conjugate	O
is	O
not	O
taken	O
for	O
complex	O
arrays	O
)	O
.	O

Why	O
don't	O
you	O
just	O
compress	O
the	O
files	O
with	O
the	O
built-in	O
`	O
gzip	O
`	O
module	O
?	O

So	O
you	O
need	O
to	O
write	O
some	O
function	O
that	O
convert	O
a	O
poly	O
parameters	O
array	O
to	O
a	O
latex	O
string	O
,	O
here	O
is	O
an	O
example	O
:	O
#CODE	O

In	O
your	O
example	O
,	O
the	O
square	O
root	O
is	O
calculated	O
by	O
evaluating	O
the	O
the	O
module	O
and	O
the	O
argument	O
of	O
your	O
complex	O
number	O
(	O
essentially	O
via	O
the	O
log	B-API
function	O
,	O
which	O
returns	O
log	B-API
(	O
module	O
)	O
+	O
i	O
phase	O
)	O
.	O

I	O
am	O
trying	O
to	O
run	O
hstack	B-API
to	O
join	O
a	O
column	O
of	O
integer	O
values	O
to	O
a	O
list	O
of	O
columns	O
created	O
by	O
a	O
TF-IDF	O
(	O
so	O
I	O
can	O
eventually	O
use	O
all	O
of	O
these	O
columns	O
/	O
features	O
in	O
a	O
classifier	O
)	O
.	O

How	O
to	O
pass	O
these	O
`	O
norm	O
`	O
and	O
`	O
cmap	O
`	O
parameters	O
in	O
matplotlib	O
to	O
`	O
plt.show	B-API
`	O
or	O
`	O
imshow()	B-API
`	O
?	O

Forget	O
about	O
the	O
C	O
stack	O
,	O
numpy	O
objects	O
can't	O
use	O
it	O
.	O

You	O
can	O
use	O
the	O
append	B-API
function	O
as	O
he	O
has	O
defined	O
.	O

This	O
can	O
be	O
particularly	O
tricky	O
when	O
trying	O
to	O
append	O
to	O
a	O
numpy	O
array	O
quickly	O
.	O

I	O
have	O
a	O
question	O
regarding	O
to	O
the	O
`	O
fft	B-API
`	O
and	O
`	O
ifft	B-API
`	O
functions	O
.	O

So	O
for	O
now	O
,	O
I	O
just	O
changed	O
the	O
max	B-API
(	O
z	O
)	O
to	O
a	O
number	O
that	O
I	O
know	O
is	O
the	O
max	B-API
(	O
1567	O
)	O
.	O

The	O
`	O
add	B-API
`	O
operation	O
does	O
not	O
do	O
the	O
same	O
thing	O
as	O
`	O
join	B-API
`	O
.	O

You	O
don't	O
specify	O
`	O
x	O
`	O
or	O
`	O
y	O
`	O
,	O
and	O
your	O
`	O
mat	O
[:	O
,	O
i+1	O
]`	O
indexing	O
will	O
not	O
work	O
with	O
a	O
structured	O
array	O
.	O

This	O
is	O
because	O
in	O
some	O
cases	O
it's	O
not	O
just	O
NaNs	O
and	O
1s	O
,	O
but	O
other	O
integers	O
,	O
which	O
gives	O
a	O
std	O
>	O
0	O
.	O

You	O
could	O
check	O
whether	O
this	O
is	O
the	O
case	O
,	O
and	O
append	O
to	O
your	O
sample	O
in	O
a	O
loop	O
if	O
necessary	O
.	O

The	O
above	O
code	O
works	O
,	O
but	O
would	O
be	O
better	O
to	O
append	O
the	O
data_array	O
retrieved	O
from	O
for	O
loop	O
directly	O
into	O
the	O
numpy	O
array	O
rather	O
than	O
using	O
python	O
list	O
.	O

If	O
you	O
want	O
an	O
intersection	O
between	O
the	O
two	O
arrays	O
you	O
can	O
loop	O
;	O
for	O
i	O
data	O
:	O
and	O
get	O
i	O
from	O
first	O
array	O
,	O
and	O
i	O
from	O
second	O
array.But	O
I'm	O
not	O
sure	O
if	O
I	O
follow	O
it	O
correctly	O
,	O
you	O
have	O
some	O
data	O
which	O
has	O
0	O
occurences	O
in	O
some	O
columns	O
of	O
your	O
array	O
,	O
if	O
you	O
append	O
the	O
other	O
values	O
to	O
a	O
new	O
array	O
the	O
memory	O
of	O
where	O
in	O
the	O
data	O
those	O
values	O
came	O
from	O
is	O
already	O
automatically	O
stored	O
.	O

(	O
2	O
)	O
Collect	O
the	O
parts	O
of	O
the	O
SQL	O
command	O
in	O
a	O
list	O
and	O
do	O
a	O
`	O
str.join	B-API
`	O
in	O
the	O
end	O
,	O
to	O
avoid	O
allocating	O
an	O
increasingly	O
long	O
string	O
each	O
time	O
(	O
you	O
can't	O
really	O
append	O
to	O
a	O
string	O
in	O
Python	O
as	O
they	O
are	O
immutable	O
)	O
.	O

append	O
C	O
:\	O
libav\usr\bin\	O
to	O
the	O
'	O
Path	O
'	O
environment	O
variable	O

How	O
to	O
efficiently	O
join	O
a	O
list	O
of	O
values	O
to	O
a	O
list	O
of	O
intervals	O
?	O

The	O
alignment	O
angles	O
may	O
be	O
unique	O
,	O
a	O
discrete	O
set	O
,	O
or	O
a	O
continuum	O
as	O
below	O
.	O

Alternatively	O
,	O
you	O
could	O
assign	O
the	O
flip	O
cards	O
their	O
own	O
unique	O
IDs	O
and	O
store	O
them	O
in	O
the	O
same	O
record	O
array	O
as	O
the	O
regular	O
cards	O
,	O
as	O
the	O
properties	O
seem	O
to	O
have	O
the	O
same	O
names	O
,	O
and	O
then	O
have	O
a	O
`	O
flip_id	O
`	O
field	O
that	O
would	O
be	O
some	O
set	O
value	O
such	O
as	O
`	O
0	O
`	O
or	O
`	O
None	O
`	O
for	O
cards	O
without	O
flip	O
aspects	O
and	O
then	O
the	O
ID	O
of	O
the	O
flip	O
card	O
for	O
those	O
cards	O
that	O
do	O
have	O
a	O
flip	O
.	O

You	O
can	O
notice	O
that	O
there	O
is	O
gray	O
strip	O
on	O
top	O
and	O
on	O
the	O
left	O
...	O

Furthermore	O
you	O
then	O
go	O
and	O
compute	O
the	O
norm	O
of	O
those	O
three	O
values	O
.	O

Tables	O
have	O
an	O
append	B-API
method	O
that	O
can	O
easily	O
add	O
additional	O
rows	O
.	O

@USER	O
,	O
I	O
tested	O
the	O
append	B-API
method	O
of	O
array	O
by	O
measure	O
the	O
time	O
it	O
cost	O
,	O
since	O
resize	B-API
the	O
array	O
will	O
use	O
more	O
time	O
.	O

I	O
think	O
you	O
need	O
to	O
use	O
append	B-API
function	O
to	O
append	B-API
new	O
array	O
with	O
previous	O
array	O
,	O
asarray	B-API
function	O
converts	O
input	O
to	O
array	O
.	O

I	O
would	O
store	O
all	O
your	O
data	O
in	O
a	O
python	O
list	O
and	O
use	O
the	O
append	B-API
function	O
to	O
add	O
new	O
measurement	O
.	O

The	O
Series	O
must	O
also	O
have	O
a	O
`	O
name	O
`	O
to	O
be	O
used	O
with	O
`	O
join	B-API
`	O
,	O
which	O
gets	O
pulled	O
in	O
as	O
a	O
new	O
field	O
called	O
`	O
name	O
`	O
.	O

NumPy	O
by	O
itself	O
is	O
a	O
fairly	O
low-level	O
tool	O
,	O
and	O
will	O
be	O
very	O
much	O
similar	O
to	O
using	O
MATLAB	O
.	O
pandas	O
on	O
the	O
other	O
hand	O
provides	O
rich	O
time	O
series	O
functionality	O
,	O
data	O
alignment	O
,	O
NA-friendly	O
statistics	O
,	O
groupby	B-API
,	O
merge	O
and	O
join	B-API
methods	O
,	O
and	O
lots	O
of	O
other	O
conveniences	O
.	O

already	O
have	O
all	O
header	O
names	O
listed	O
then	O
you	O
can	O
use	O
"	O
join	B-API
"	O
and	O

Because	O
these	O
are	O
irregular	O
operations	O
,	O
I	O
can't	O
use	O
merge	B-API
/	O
join	B-API
.	O

It	O
should	O
be	O
a	O
bit	O
quicker	O
just	O
by	O
not	O
using	O
so	O
many	O
intermediary	O
bitstrings	O
-	O
it's	O
all	O
done	O
in	O
the	O
join	B-API
method	O
.	O

How	O
can	O
i	O
use	O
the	O
unique	B-API
(	O
a	O
,	O
rows	O
)	O
from	O
MATLab	O
at	O
python	O
?	O

If	O
you	O
convert	O
your	O
2D	O
coordinates	O
into	O
`	O
target_map	O
`	O
into	O
flat	O
indices	O
into	O
it	O
using	O
`	O
np.ravel_multi_index	B-API
`	O
,	O
you	O
can	O
use	O
`	O
np.unique	B-API
`	O
and	O
`	O
np.bincount	B-API
`	O
to	O
speed	O
things	O
up	O
quite	O
a	O
bit	O
:	O
#CODE	O

To	O
get	O
the	O
unobserved	O
values	O
filled	O
,	O
we'll	O
use	O
the	O
`	O
unstack	B-API
`	O
and	O
`	O
stack	B-API
`	O
methods	O
.	O

The	O
actual	O
RMS	O
would	O
be	O
`	O
norm	B-API
(	O
x	O
)	O
/	O
sqrt	B-API
(	O
x.size	O
)`	O
,	O
but	O
for	O
minimization	O
the	O
constant	O
multiplier	O
doesn't	O
make	O
any	O
difference	O
.	O

The	O
above	O
entire	O
expression	O
is	O
therefore	O
evaluating	O
to	O
an	O
array	O
of	O
truth	O
values	O
,	O
rather	O
than	O
a	O
single	O
`	O
True	O
`	O
/	O
`	O
False	O
`	O
.	O

For	O
the	O
multiprocessing	O
:	O
You	O
can	O
distribute	O
the	O
data	O
sets	O
across	O
cores	O
,	O
do	O
`	O
partial_fit	O
`	O
,	O
get	O
the	O
weight	O
vectors	O
,	O
average	O
them	O
,	O
distribute	O
them	O
to	O
the	O
estimators	O
,	O
do	O
partial	O
fit	O
again	O
.	O

the	O
size	O
of	O
Y	O
is	O
100e6	O
x	O
1	O

Put	O
I	O
think	O
that	O
following	O
this	O
route	O
would	O
lead	O
to	O
an	O
inefficient	O
solution	O
.	O

Your	O
example	O
come	O
at	O
a	O
good	O
time	O
for	O
me	O
,	O
so	O
I	O
now	O
have	O
something	O
concrete	O
to	O
train	O
with	O
.	O

One	O
thing	O
I	O
find	O
very	O
confortable	O
with	O
Numpy	O
is	O
the	O
vectorization	O
of	O
operations	O
with	O
arrays	O
(	O
ie	O
.	O
the	O
absence	O
of	O
any	O
explicit	O
looping	O
)	O
,	O
and	O
the	O
implicit	O
element-by-element	O
behavior	O
of	O
operations	O
.	O

I	O
suggest	O
to	O
set	O
it	O
to	O
some	O
reasonable	O
upper	O
limit	O
,	O
though	O
.	O

Gonna	O
try	O
to	O
find	O
another	O
solution	O
.	O

Is	O
it	O
possible	O
to	O
construct	O
a	O
`	O
numpy	O
`	O
matrix	O
from	O
a	O
function	O
?	O

I	O
have	O
2D	O
numpy	O
array	O
,	O
with	O
example	O
shape	O
:	O
#CODE	O

`	O
grid	O
[	O
0	O
]`	O
can	O
be	O
used	O
as	O
a	O
proxy	O
for	O
the	O
index	O
`	O
i	O
`	O
,	O
and	O

Thank	O
you	O
Martijn	O
:)	O
-	O
your	O
are	O
BIG	O
help	O
,	O
and	O
just	O
one	O
thing	O
confuses	O
me	O
,	O
how	O
do	O
I	O
tell	O
python	O
to	O
read	O
all	O
CDR	O
records	O
if	O
record	O
is	O
907	O
bytes	O
long	O
.	O

I	O
want	O
to	O
get	O
the	O
elements	O
of	O
a	O
`	O
numpy	O
`	O
array	O
using	O
an	O
index	O
array	O
like	O
so	O
#CODE	O

I	O
can	O
weight	O
them	O
how	O
I	O
want	O
to	O
as	O
long	O
as	O
sum	O
of	O
their	O
weights	O
adds	O
to	O
1	O
.	O

I	O
wanted	O
to	O
try	O
to	O
duplicate	O
those	O
performance	O
gains	O
when	O
solving	O
the	O
distance	O
between	O
two	O
equal	O
sized	O
arrays	O
.	O

Even	O
if	O
it	O
worked	O
,	O
I	O
would	O
not	O
expect	O
any	O
speed-up	O
from	O
this	O
compared	O
to	O
an	O
ordinary	O
loop	O
,	O
since	O
it	O
needs	O
to	O
call	O
a	O
Python	O
function	O
for	O
every	O
entry	O
.	O

@USER	O
,	O
you're	O
right	O
,	O
if	O
you	O
have	O
to	O
convert	O
everything	O
to	O
ndarrays	O
it's	O
often	O
not	O
worth	O
it	O
.	O

An	O
example	O
implementation	O
without	O
recalculating	O
the	O
distance	O
array	O
would	O
be	O
this	O
:	O
#CODE	O

I	O
need	O
to	O
return	O
all	O
of	O
the	O
points	O
within	O
a	O
distance	O
of	O
X	O
units	O
from	O
every	O
point	O
.	O

EDIT	O
:	O
Actually	O
renaming	O
my	O
package	O
does	O
not	O
fix	O
it	O
.	O

2	O
)	O
look	O
at	O
the	O
lengths	O
distance	O
(	O
point	O
,	O
centre	O
,	O
metric=	O
...	O
)	O
of	O
all	O
the	O
rays	O
.	O

Sorry	O
,	O
all	O
are	O
positive	O
values	O
greater	O
than	O
0	O
.	O

After	O
that	O
I	O
convert	O
the	O
image	O
to	O
BGR	O
model	O
:	O
#CODE	O

How	O
do	O
I	O
standardize	O
a	O
matrix	O
?	O

Speed	O
can	O
probably	O
be	O
increased	O
by	O
ensuring	O
that	O
the	O
record	O
array	O
you	O
pass	O
to	O
Cython	O
is	O
contiguous	O
.	O

fid	O
is	O
the	O
file	O
currently	O
being	O
looked	O
at	O

I'm	O
guessing	O
it's	O
opening	O
TWO	O
filehandles	O
per	O
iteration	O
,	O
just	O
based	O
on	O
the	O
498	O
(	O
a	O
bit	O
less	O
than	O
half	O
1024	O
,	O
and	O
Python	O
would	O
have	O
some	O
files	O
open	O
itself	O
(	O
maybe	O
25-odd	O
?	O
)	O
.	O

The	O
idea	O
is	O
to	O
count	O
the	O
number	O
of	O
occurrences	O
of	O
each	O
transition	O
,	O
and	O
use	O
the	O
counts	O
in	O
a	O
vectorized	O
update	O
of	O
the	O
matrix	O
.	O

I	O
kept	O
them	O
in	O
to	O
distinguish	O
them	O
from	O
the	O
`	O
math	O
`	O
ones	O
,	O
which	O
won't	O
work	O
for	O
this	O
approach	O
.	O

Powers	O
of	O
two	O
are	O
simple	O
to	O
compute	O
,	O
but	O
mixed	O
radix	O
sizes	O
can	O
be	O
faster	O
and	O
use	O
less	O
memory	O
.	O

The	O
stars	O
/	O
dots	O
are	O
the	O
`	O
X	O
`	O
and	O
`	O
Y	O
`	O
plotted	O
with	O
two	O
modifications	O
,	O
I	O
removed	O
the	O
first	O
position	O
and	O
added	O
a	O
false	O
one	O
to	O
make	O
this	O
a	O
full	O
example	O
of	O
the	O
sought	O
algorithm	O
.	O

Please	O
look	O
at	O
my	O
EDIT	O
2	O
,	O
where	O
I	O
described	O
my	O
problem	O
with	O
input	O
data	O
...	O
and	O
why	O
I	O
can't	O
get	O
matrix	O
..	O

pyqt	O
:	O
Convert	O
numpy	O
array	O
to	O
QImage	O

To	O
find	O
the	O
difference	O
between	O
your	O
data	O
and	O
a	O
point	O
,	O
you'd	O
just	O
do	O
`	O
data	O
-	O
point	O
`	O
.	O

Unfortunately	O
when	O
numpy	O
reads	O
the	O
19-digit	O
number	O
as	O
a	O
floating	O
point	O
number	O
,	O
there	O
is	O
not	O
enough	O
precision	O
to	O
get	O
all	O
the	O
significant	O
digits	O
,	O
so	O
there	O
is	O
a	O
rounding	O
error	O
.	O

The	O
exceptions	O
are	O
very	O
rare	O
,	O
if	O
any	O
.	O

I	O
can't	O
reproduce	O
your	O
problem	O
on	O
Linux	O
using	O
the	O
same	O
versions	O
of	O
numpy	O
and	O
python	O
and	O
a	O
quickly	O
made	O
test	O
file	O
(	O
with	O
dos	O
line	O
endings	O
,	O
even	O
)	O
...	O

I	O
imagine	O
I	O
would	O
have	O
to	O
use	O
the	O
uncompiled	O
source	O
provided	O
from	O
each	O
of	O
these	O
three	O
projects	O
.	O

However	O
,	O
I	O
am	O
checking	O
optimization	O
routine	O
result	O
,	O
and	O
sometimes	O
power	O
is	O
negative	O
,	O
sometimes	O
it	O
is	O
positive	O
.	O

What	O
about	O
array	O
of	O
arrays	O
that	O
contains	O
some	O
structures	O
?	O

The	O
y	O
data	O
takes	O
the	O
shape	O
of	O
the	O
triangle	O
wave	O
below	O
.	O

There	O
are	O
some	O
algorithm	O
to	O
calculate	O
faster	O
the	O
results	O
for	O
low	O
valued	O
matrix	O
,	O
but	O
just	O
google	O
for	O
this	O
.	O

Those	O
are	O
not	O
random	O
replacements	O
by	O
any	O
means	O
.	O

I	O
would	O
suggest	O
to	O
make	O
the	O
library	O
use	O
an	O
(	O
NumPy-	O
)	O
array	O
you	O
allocate	O
in	O
Python	O
and	O
pass	O
on	O
to	O
the	O
library	O
.	O

For	O
the	O
simple	O
case	O
of	O
"	O
remove	O
column	O
3	O
"	O
,	O
`	O
delete	O
`	O
makes	O
more	O
sense	O
;	O
for	O
a	O
more	O
complicated	O
case	O
,	O
`	O
take	O
`	O
probably	O
makes	O
more	O
sense	O
.	O

I	O
have	O
an	O
array	O
of	O
points	O
in	O
numpy	O
:	O
#CODE	O

I	O
have	O
done	O
7	O
of	O
the	O
problems	O
on	O
Project	O
Euler	O
(	O
nothing	O
to	O
brag	O
about	O
,	O
but	O
it	O
might	O
give	O
you	O
a	O
better	O
idea	O
of	O
where	O
I	O
stand	O
in	O
skills	O
)	O
.	O

How	O
do	O
I	O
find	O
the	O
length	O
(	O
or	O
dimensions	O
,	O
size	O
)	O
of	O
a	O
numpy	O
matrix	O
in	O
python	O
?	O

It's	O
longer	O
than	O
the	O
other	O
answer	O
but	O
is	O
more	O
generic	O
(	O
can	O
be	O
used	O
with	O
values	O
that	O
are	O
not	O
strings	O
)	O
.	O

I	O
coded	O
my	O
own	O
routine	O
with	O
Python	O
/	O
Numpy	O
,	O
and	O
it	O
is	O
giving	O
me	O
a	O
little	O
bit	O
different	O
results	O
from	O
the	O
MATLAB	O
code	O
somebody	O
else	O
did	O
,	O
and	O
I	O
am	O
having	O
hard	O
time	O
finding	O
out	O
where	O
it	O
is	O
coming	O
from	O
because	O
of	O
different	O
random	O
draws	O
.	O

How	O
can	O
1,000,000	O
4-byte	O
ints	O
be	O
compressed	O
any	O
smaller	O
?	O

If	O
this	O
number	O
is	O
less	O
than	O
a	O
third	O
of	O
the	O
total	O
I'll	O
use	O
my	O
answer	O
above	O
.	O

I	O
have	O
done	O
7	O
of	O
the	O
problems	O
on	O
Project	O
Euler	O
(	O
nothing	O
to	O
brag	O
about	O
,	O
but	O
it	O
might	O
give	O
you	O
a	O
better	O
idea	O
of	O
where	O
I	O
stand	O
in	O
skills	O
)	O
.	O

Apologies	O
if	O
this	O
is	O
a	O
wrongly	O
framed	O
question	O
or	O
if	O
this	O
question	O
was	O
already	O
asked	O
earlier	O
(	O
I	O
couldn't	O
find	O
it	O
)	O

If	O
you	O
can	O
choose	O
,	O
I	O
strongly	O
recommend	O
pandas	O
:	O
it	O
has	O
"	O
column	O
indexing	O
"	O
built-in	O
plus	O
a	O
lot	O
of	O
other	O
features	O
.	O

But	O
this	O
will	O
iterate	O
through	O
the	O
entire	O
array	O
and	O
allocate	O
a	O
new	O
array	O
in	O
memory	O
containing	O
the	O
all	O
the	O
results	O
,	O
and	O
only	O
then	O
check	O
to	O
see	O
if	O
it	O
is	O
empty	O
.	O

Since	O
some	O
askers	O
and	O
some	O
answers	O
both	O
avoid	O
that	O
constraint	O
,	O
I	O
encourage	O
anyone	O
who's	O
here	O
and	O
doesn't	O
mind	O
having	O
PIL	O
to	O
look	O
below	O
,	O
and	O
any	O
non-PIL	O
answers	O
(	O
new	O
or	O
old	O
)	O
to	O
mention	O
that	O
they're	O
a	O
PIL-is-used	O
type	O
of	O
answer	O
,	O
to	O
distinguish	O
themselves	O
from	O
answers	O
meeting	O
the	O
original	O
constraint	O
.	O

As	O
I	O
understand	O
your	O
question	O
,	O
you	O
have	O
a	O
2D	O
array	O
of	O
"	O
z	O
"	O
values	O
that	O
ranges	O
from	O
some	O
xmin	O
to	O
xmax	O
,	O
and	O
ymin	O
to	O
ymax	O
in	O
each	O
direction	O
.	O

The	O
covariance	O
matrix	O
of	O
a	O
dataset	O
A	O
is	O
:	O
1	O
/(	O
N-1	O
)	O
*	O
AA^T	O

I	O
have	O
a	O
large	O
(	O
500k	O
by	O
500k	O
)	O
,	O
sparse	O
matrix	O
.	O

I	O
can't	O
comment	O
on	O
a	O
numpy	O
array	O
as	O
I	O
haven't	O
used	O
one	O
before	O
,	O
but	O
for	O
using	O
a	O
list	O
of	O
lists	O
Python	O
already	O
has	O
built	O
in	O
support	O
.	O

If	O
`	O
finer_fxy	O
`	O
is	O
stored	O
in	O
the	O
probably-default	O
`	O
float64	O
`	O
s	O
,	O
this	O
would	O
take	O
about	O
64	O
GiB	O
of	O
memory	O
;	O
not	O
surprising	O
that	O
you're	O
running	O
out	O
.	O

Sebastian's	O
solution	O
for	O
a	O
way	O
around	O
the	O
integer-values-only	O
restriction	O
and	O
big-values	O
problem	O
.	O

This	O
allows	O
the	O
column	O
to	O
hold	O
float	O
values	O
at	O
first	O
,	O
and	O
strings	O
later	O
.	O

Efficient	O
slicing	O
of	O
matrices	O
using	O
matrix	O
multiplication	O
,	O
with	O
Python	O
,	O
NumPy	O
,	O
SciPy	O

Is	O
there	O
a	O
more	O
compact	O
way	O
to	O
operate	O
on	O
array	O
elements	O
,	O
without	O
having	O
to	O
use	O
the	O
standard	O
for	O
loop	O
.?	O

Please	O
look	O
at	O
this	O
answer	O
:	O
#URL	O

When	O
I	O
tried	O
this	O
,	O
I	O
got	O
sort	O
of	O
similar	O
shaped	O
"	O
tiles	O
"	O
of	O
different	O
colors	O
rather	O
than	O
3	O
Gaussian	O
humps	O
.	O

I	O
created	O
the	O
first	O
array	O
like	O
this	O
:	O

(	O
Note	O
that	O
I	O
can't	O
imagine	O
any	O
reason	O
why	O
this	O
should	O
be	O
necessary	O
.	O
)	O

SOLUTION	O
:	O
i	O
have	O
some	O
scattered	O
points	O
(	O
i	O
don't	O
know	O
how	O
many	O
)	O
and	O
i	O
want	O
to	O
reduce	O
it	O
to	O
a	O
8	O
meaning	O
point	O
.	O
one	O
of	O
the	O
technique	O
i	O
can	O
use	O
is	O
to	O
clusterize	O
them	O
with	O
some	O
cluster	O
algorithms	O
.	O

that	O
blas	O
is	O
reference	O
blas	O
from	O
netlib	O
-	O
the	O
slowest	O
blas	O
around	O
.	O
install	O
atlas	O
or	O
mkl	O
instead	O
.	O

EDIT	O
:	O
Answer	O
updated	O
for	O
a	O
2D	O
array	O
.	O

But	O
you	O
lose	O
a	O
lot	O
of	O
NumPy	O
power	O
that	O
way	O
.	O

Because	O
I	O
view	O
doesn't	O
really	O
have	O
to	O
do	O
with	O
filtering	O
,	O
but	O
rather	O
with	O
different	O
representation	O
of	O
the	O
same	O
data	O
.	O

@USER	O
,	O
not	O
sure	O
what	O
you	O
mean	O
by	O
"	O
changing	O
original	O
values	O
"	O
.	O

this	O
could	O
also	O
be	O
achieved	O
elegantly	O
with	O
numpy's	O
`	O
where	O
`	O
function	O

I	O
need	O
to	O
specify	O
datatypes	O
for	O
all	O
numerical	O
types	O
since	O
I	O
care	O
about	O
int	O
8/	O
16	O
/	O
32	O
,	O
etc	O
,	O
but	O
I	O
would	O
like	O
to	O
benefit	O
from	O
the	O
auto	O
string	O
length	O
detection	O
that	O
works	O
if	O
I	O
don't	O
specify	O
datatypes	O
.	O

In	O
the	O
following	O
trivial	O
function	O
,	O
I	O
have	O
declared	O
the	O
numpy	O
array	O
argument	O
`	O
arr	O
`	O
using	O
the	O
buffer	O
syntax	O
.	O

I	O
remember	O
that	O
there	O
was	O
a	O
smart	O
trick	O
about	O
turning	O
on	O
and	O
off	O
the	O
right	O
intersections	O
of	O
rows	O
and	O
columns	O
to	O
turn	O
off	O
one-by-one	O
all	O
the	O
lightbulbs	O
,	O
but	O
it	O
wont	O
come	O
back	O
to	O
my	O
mind	O
...	O

However	O
this	O
code	O
is	O
to	O
slow	O
in	O
the	O
current	O
version	O
,	O
and	O
I	O
am	O
wondering	O
wheater	O
there	O
is	O
a	O
faster	O
solution	O
.	O
thanks	O
!	O

This	O
would	O
probably	O
be	O
the	O
most	O
efficient	O
way	O
to	O
access	O
a	O
numpy	O
array	O
stored	O
on	O
disk	O
.	O

hmmmmm	O
,	O
probably	O
it	O
will	O
help	O
some	O
others	O
to	O
sort	O
dictionarys	O
or	O
to	O
prevent	O
from	O
using	O
commands	O
like	O
sorted	O
=	O
sorted	O
(	O
...	O
)	O
.	O

The	O
ticket	O
simply	O
spoke	O
of	O
random	O
number	O
seeding	O
with	O
64-bit	O
,	O
perhaps	O
its	O
referring	O
to	O
a	O
different	O
random	O
number	O
generator	O
.	O

Not	O
really	O
elegant	O
at	O
all	O
but	O
you	O
can	O
get	O
close	O
to	O
what	O
you	O
want	O
using	O
a	O
tuple	O
to	O
store	O
pointers	O
to	O
the	O
arrays	O
.	O

For	O
example	O
I	O
am	O
looking	O
for	O
4.2	O
but	O
I	O
know	O
in	O
the	O
array	O
there	O
is	O
no	O
4.2	O
but	O
I	O
want	O
to	O
return	O
the	O
index	O
of	O
the	O
value	O
4.1	O
instead	O
of	O
4.4	O
.	O

Print	O
'	O
Length	O
of	O
together	O
'	O
goes	O
just	O
before	O
the	O
matrix	O
line	O
.	O

solve	O
a	O
nonlinear	O
equation	O
at	O
several	O
intermediate	O
points	O
of	O
a	O
calculation	O
,	O
not	O
just	O
as	O
the	O
final	O
result	O
.	O

Find	O
where	O
they're	O
located	O
at	O
(	O
assumes	O
the	O
data	O
is	O
sorted	O
!!	O
):	O
#CODE	O

You	O
need	O
Python	O
to	O
keep	O
track	O
of	O
your	O
vector	O
so	O
that	O
it	O
can	O
be	O
deleted	O
*	O
after	O
*	O
the	O
numpy	O
array	O
.	O

I	O
find	O
that	O
I	O
have	O
to	O
first	O
build	O
a	O
list	O
and	O
then	O
cast	O
it	O
(	O
using	O
"	O
array	O
")	O
to	O
an	O
array	O
.	O

I	O
have	O
an	O
numpy	O
one	O
dimensional	O
array	O
c	O
that	O
is	O
supposed	O
to	O
be	O
filled	O
with	O
the	O
contents	O
of	O

but	O
the	O
issue	O
now	O
,	O
when	O
I	O
am	O
trying	O
to	O
save	O
the	O
name	O
of	O
the	O
file	O
as	O
well	O
in	O
the	O
csv	O
file	O
like	O
this	O
:	O
#CODE	O

After	O
you	O
do	O
this	O
no	O
matter	O
where	O
the	O
template	O
object	O
is	O
in	O
a	O
calculation	O
.	O

So	O
the	O
easiest	O
thing	O
to	O
do	O
would	O
be	O
to	O
take	O
a	O
sample	O
of	O
say	O
,	O
1000	O
points	O
,	O
from	O
your	O
data	O
:	O
#CODE	O

Your	O
array	O
consists	O
of	O
:	O
#CODE	O

The	O
final	O
DF	O
should	O
have	O
as	O
many	O
columns	O
as	O
all	O
the	O
df	O
columns	O
added	O
together	O
,	O
so	O
it	O
grow	O
additively	O
and	O
not	O
be	O
combinatorial	O
.	O

I'm	O
sorting	O
the	O
cells	O
of	O
the	O
matrix	O
by	O
the	O
float	O
value	O
,	O
producing	O
a	O
list	O
of	O
`	O
(	O
row	O
,	O
col	O
,	O
value	O
)`	O
tuples	O
.	O

Is	O
it	O
essential	O
that	O
you	O
need	O
a	O
numpy	O
array	O
?	O

Mh	O
.	O
but	O
look	O
at	O
this	O
:	O

All	O
variables	O
are	O
dependent	O
on	O
each	O
other	O
and	O
I	O
am	O
only	O
looking	O
for	O
local	O
minima	O
from	O
the	O
initial	O
guess	O
.	O

The	O
basic	O
idea	O
is	O
to	O
simply	O
run	O
all	O
the	O
usual	O
steps	O
of	O
a	O
root	O
finder	O
in	O
parallel	O
on	O
a	O
vector	O
of	O
variables	O
,	O
using	O
a	O
function	O
that	O
can	O
be	O
evaluated	O
on	O
a	O
vector	O
of	O
variables	O
and	O
equivalent	O
vector	O
(	O
s	O
)	O
of	O
parameters	O
that	O
define	O
the	O
individual	O
component	O
functions	O
.	O

Hence	O
,	O
with	O
NetworkX	O
,	O
you	O
can	O
put	O
in	O
an	O
adjacency	O
matrix	O
and	O
find	O
out	O
which	O
authors	O
are	O
clustered	O
together	O
.	O

The	O
issue	O
your	O
having	O
more	O
likely	O
is	O
a	O
python	O
mmap	O
issue	O
,	O
since	O
python	O
mmaps	O
handle	O
all	O
the	O
memory	O
mapping	O
and	O
file	O
closing	O
for	O
numpy	O
memmaps	O
.	O

So	O
far	O
,	O
I'm	O
sticking	O
with	O
C++	O
-	O
on	O
my	O
tests	O
,	O
at	O
least	O
2	O
orders	O
of	O
magnitude	O
faster	O
!	O

Sorting	O
ends	O
up	O
being	O
the	O
slowest	O
step	O
but	O
it's	O
still	O
faster	O
if	O
m	O
is	O
large	O
because	O
the	O
n*log	O
(	O
n	O
)	O
sort	O
is	O
faster	O
than	O
(	O
n*m	O
)	O
.	O

Basically	O
,	O
I	O
am	O
getting	O
a	O
memory	O
error	O
in	O
python	O
when	O
trying	O
to	O
perform	O
an	O
algebraic	O
operation	O
on	O
a	O
numpy	O
matrix	O
.	O

Surely	O
there	O
must	O
be	O
a	O
way	O
to	O
populate	O
a	O
boost	O
::	O
python	O
::	O
numeric	O
::	O
array	O
with	O
data	O
from	O
a	O
simple	O
std	O
::	O
vector	O
without	O
having	O
to	O
get	O
some	O
3rd	O
party	O
library	O
.	O

Here	O
again	O
a	O
if	O
statement	O
could	O
do	O
,	O
but	O
I	O
am	O
wondering	O
if	O
there	O
is	O
a	O
workarouns	O
and	O
a	O
Python	O
library	O
where	O
negative	O
exposant	O
is	O
allowed	O
.	O

The	O
key	O
point	O
here	O
is	O
that	O
Tabular	O
and	O
NumPy	O
set	O
certain	O
standards	O
for	O
what	O
counts	O
as	O
"	O
fast	O
"	O
or	O
"	O
slow	O
"	O
--	O
and	O
then	O
,	O
force	O
you	O
to	O
be	O
explicit	O
about	O
operations	O
that	O
are	O
going	O
to	O
be	O
slow	O
.	O

Asume	O
that	O
your	O
numpy	O
module	O
is	O
located	O
at	O
/	O
Users	O
/	O
Me	O
/	O
python	O
/	O
modules	O
directory	O
.	O

I	O
am	O
not	O
responsible	O
from	O
any	O
brain	O
damage	O
resulting	O
from	O
attempting	O
to	O
understand	O
this	O
code	O
.	O

There	O
a	O
plenty	O
of	O
places	O
where	O
you're	O
inadvertently	O
creating	O
additional	O
temporary	O
arrays	O
,	O
but	O
they're	O
mostly	O
irrelevant	O
,	O
as	O
they're	O
overwhelmed	O
by	O
what	O
goes	O
on	O
during	O
the	O
call	O
to	O
`	O
select	O
`	O
.	O

The	O
fact	O
that	O
you	O
are	O
using	O
`	O
object	O
`	O
arrays	O
(	O
not	O
very	O
common	O
and	O
not	O
very	O
memory-efficient	O
)	O
presents	O
a	O
particular	O
problem	O
when	O
trying	O
to	O
determine	O
the	O
index	O
of	O
non-None	O
array	O
items	O
.	O

where	O
things	O
improve	O
as	O
the	O
number	O
of	O
bits	O
increases	O
.	O

Really	O
,	O
4D	O
arrays	O
are	O
just	O
1D	O
arrays	O
in	O
memory	O
anyway	O
(	O
Unless	O
you	O
really	O
have	O
view	O
objects	O
,	O
but	O
it	O
should	O
still	O
work	O
with	O
those	O
as	O
well	O
)	O

I'll	O
add	O
comments	O
to	O
explain	O
things	O
in	O
a	O
bit	O
.	O

I	O
was	O
assuming	O
that	O
the	O
rgb	O
and	O
ycc	O
matrices	O
were	O
just	O
a	O
matrix	O
that	O
had	O
as	O
many	O
rows	O
as	O
pixels	O
and	O
a	O
column	O
per	O
colour	O
component	O
.	O

For	O
example	O
,	O
suppose	O
`	O
a	O
=	O
ones	O
((	O
3	O
,	O
3	O
))`	O
.	O

Therefore	O
,	O
n	O
and	O
m	O
correspond	O
to	O
indices	O
in	O
the	O
array	O
,	O
but	O
I'm	O
not	O
sure	O
how	O
?	O

Update	O
:	O
As	O
mentioned	O
in	O
my	O
comment	O
below	O
,	O
I	O
should	O
have	O
stated	O
that	O
I'm	O
trying	O
to	O
do	O
this	O
on	O
2D	O
arrays	O
,	O
and	O
therefore	O
get	O
a	O
set	O
of	O
2D	O
indices	O
back	O
.	O

Need	O
to	O
add	O
a	O
check	O
for	O
that	O
,	O
but	O
otherwise	O
thanks	O
!	O

I	O
think	O
you	O
just	O
want	O
`	O
label	O
==	O
num	O
`	O
where	O
`	O
num	O
`	O
is	O
the	O
number	O
of	O
the	O
object	O
in	O
`	O
label	O
`	O
(	O
the	O
labeled	O
array	O
)	O
.	O

My	O
question	O
is	O
how	O
can	O
I	O
go	O
thru	O
the	O
array	O
to	O
access	O
the	O
object	O
in	O
the	O
array	O
?	O

The	O
matrix	O
in	O
the	O
example	O
above	O
is	O
singular	O
(	O
determinant	O
~	O
0	O
)	O
.	O

See	O
the	O
note	O
at	O
#URL	O

would	O
turn	O
into	O
either	O
this	O
array	O
:	O
#CODE	O

Note	O
that	O
this	O
is	O
a	O
bit	O
more	O
sophisticated	O
than	O
the	O
simple	O
do-it-yourself	O
convolve-method	O
,	O
since	O
it	O
tries	O
to	O
handle	O
the	O
problems	O
at	O
the	O
beginning	O
and	O
the	O
end	O
of	O
the	O
data	O
by	O
reflecting	O
it	O
(	O
which	O
may	O
or	O
may	O
not	O
work	O
in	O
your	O
case	O
...	O
)	O
.	O

Usually	O
,	O
in	O
numpy	O
,	O
you	O
keep	O
the	O
string	O
data	O
in	O
a	O
separate	O
array	O
.	O

Any	O
idea	O
what	O
might	O
be	O
happening	O
?	O

but	O
the	O
size	O
is	O
wrong	O
because	O
i've	O
assigned	O
1000	O
as	O
the	O
period	O
size	O
.	O

This	O
may	O
not	O
be	O
perfectly	O
pythonic	O
(	O
perhaps	O
someone	O
can	O
think	O
of	O
a	O
nicer	O
implementation	O
using	O
generators	O
or	O
itertools	O
?	O
)	O
but	O
it	O
is	O
hard	O
to	O
imagine	O
any	O
method	O
that	O
relies	O
on	O
searching	O
one	O
point	O
at	O
a	O
time	O
beating	O
this	O
in	O
speed	O
.	O

Thanks	O
,	O
your	O
post	O
helped	O
me	O
solve	O
this	O
problem	O
.	O

Now	O
imagine	O
that	O
the	O
next	O
time	O
step	O
some	O
values	O
change	O
,	O
so	O
should	O
this	O
picture	O
.	O

Since	O
get_probability	O
is	O
a	O
function	O
,	O
so	O
what	O
value	O
is	O
being	O
passed	O
to	O
count	O
parameter	O
here	O
???	O

taking	O
the	O
sum	O
for	O
each	O
column	O
.	O

You	O
should	O
be	O
able	O
to	O
just	O
load	O
the	O
entire	O
thing	O
into	O
memory	O
on	O
a	O
modern	O
machine	O
.	O

What	O
I	O
want	O
to	O
do	O
is	O
to	O
calculate	O
the	O
geographic	O
distances	O
between	O
rows	O
(	O
with	O
the	O
special	O
condition	O
that	O
the	O
first	O
element	O
is	O
always	O
zero	O
,	O
at	O
the	O
starting	O
point	O
)	O
.	O

We	O
can	O
simply	O
use	O
the	O
leastsq	O
function	O
to	O
find	O
the	O
best	O
coefficients	O
.	O

If	O
the	O
list	O
of	O
python	O
objects	O
doesn't	O
grow	O
at	O
all	O
from	O
frame	O
to	O
frame	O
,	O
the	O
leak	O
is	O
probably	O
in	O
the	O
C	O
code	O
or	O
the	O
python-to-C	O
link	O

Any	O
and	O
all	O
advice	O
is	O
greatly	O
appreciated	O
.	O

Numpy	O
:	O
Is	O
there	O
an	O
array	O
size	O
limit	O
?	O

Then	O
do	O
this	O
after	O
each	O
calculation	O
:	O
for	O
i	O
in	O
range	O
(	O
len	O
(	O
array	O
)):	O
array	O
[	O
i	O
]	O
[	O
i	O
]=	O
0	O

I	O
know	O
the	O
random	O
functions	O
and	O
numbers	O
seem	O
odd	O
,	O
but	O
conceptually	O
this	O
still	O
should	O
work	O
,	O
as	O
it	O
worked	O
when	O
both	O
were	O
set	O
to	O
variables	O
individually	O
.	O

@USER	O
are	O
your	O
numbers	O
in	O
the	O
range	O
of	O
-128	O
to	O
127	O
before	O
you	O
convert	O
them	O
to	O
8b	O
it	O
?	O

In	O
the	O
future	O
,	O
how	O
should	O
I	O
go	O
about	O
trying	O
to	O
find	O
routines	O
like	O
this	O
?	O

At	O
20,000	O
elements	O
,	O
your	O
method	O
is	O
about	O
25%	O
faster	O
.	O

I'll	O
fix	O
it	O
just	O
for	O
you	O
:P	O

Then	O
I	O
convert	O
it	O
to	O
a	O
numpy	O
array	O
:	O
#CODE	O

Just	O
throwing	O
in	O
my	O
two	O
cents	O
you	O
could	O
do	O
this	O
pretty	O
simply	O
using	O
list	O
comprehension	O
if	O
it's	O
always	O
a	O
2d	O
array	O
like	O
that	O
#CODE	O

While	O
its	O
expected	O
value	O
here	O
is	O
zero	O
,	O
the	O
particular	O
realizations	O
will	O
fluctuate	O
around	O
that	O
expected	O
value	O
.	O

Then	O
if	O
each	O
item	O
is	O
weighted	O
with	O
weight	O
w_i	O
,	O
the	O
"	O
summed	O
histogram	O
"	O
would	O
have	O
weight	O
sum	O
(	O
i	O
in	O
items	O
)	O
w_i	O
D_ij	O
.	O

This	O
approach	O
will	O
take	O
an	O
overhead	O
because	O
of	O
crating	O
a	O
new	O
array	O
in	O
memory	O
.	O

"	O
Eric's	O
suggestion	O
for	O
revising	O
this	O
question	O
is	O
a	O
good	O
start	O
,	O
but	O
I	O
think	O
the	O
question	O
"	O
Given	O
a	O
Cartesian	O
plane	O
,	O
how	O
to	O
discretize	O
it	O
in	O
a	O
matrix	O
form	O
?	O

it	O
is	O
the	O
same	O
as	O
long	O
as	O
you	O
ignore	O
precision	O
issue	O
-	O
which	O
matters	O
quite	O
often	O
when	O
you	O
start	O
taking	O
exponential	O
of	O
numbers	O
.	O

Google	O
Protocol	O
Buffers	O
support	O
self-describing	O
too	O
,	O
are	O
pretty	O
fast	O
(	O
but	O
Python	O
support	O
is	O
poor	O
at	O
present	O
time	O
,	O
slow	O
and	O
buggy	O
)	O
.	O

Not	O
all	O
people	O
can	O
install	O
NumPy	O
(	O
or	O
even	O
Python	O
:D	O
)	O
as	O
many	O
Blender	O
users	O
are	O
just	O
artists	O
.	O

All	O
possible	O
solutions	O
are	O
mentioned	O
in	O
the	O
comments	O
.	O

I've	O
also	O
refined	O
your	O
approach	O
to	O
allow	O
zooming	O
in	O
over	O
a	O
section	O
of	O
the	O
data	O
and	O
to	O
produce	O
better	O
results	O
at	O
the	O
borders	O
.	O

I	O
need	O
to	O
specify	O
datatypes	O
for	O
all	O
numerical	O
types	O
since	O
I	O
care	O
about	O
int	O
8/	O
16	O
/	O
32	O
,	O
etc	O
,	O
but	O
I	O
would	O
like	O
to	O
benefit	O
from	O
the	O
auto	O
string	O
length	O
detection	O
that	O
works	O
if	O
I	O
don't	O
specify	O
datatypes	O
.	O

I	O
would	O
appreciate	O
any	O
assistance	O
you	O
can	O
offer	O
.	O

Let's	O
say	O
for	O
example	O
I	O
have	O
a	O
matrix	O
X	O
which	O
is	O
my	O
input	O
.	O

@USER	O
-	O
By	O
the	O
way	O
,	O
indexing	O
returns	O
a	O
view	O
(	O
essentially	O
a	O
pointer	O
)	O
into	O
the	O
array	O
.	O

Note	O
that	O
`	O
view	O
`	O
holds	O
the	O
same	O
data	O
as	O
the	O
original	O
array	O
!	O

EDIT	O
:	O
What	O
sort	O
of	O
sequence	O
is	O
it	O
you're	O
making	O
?	O

The	O
relative	O
error	O
is	O
less	O
than	O
2	O
-24	O
,	O
which	O
is	O
1	O
/	O
2	O
ULP	O
divided	O
by	O
the	O
smallest	O
the	O
value	O
could	O
be	O
(	O
the	O
smallest	O
value	O
in	O
the	O
interval	O
for	O
a	O
particular	O
ULP	O
,	O
so	O
the	O
power	O
of	O
two	O
that	O
bounds	O
it	O
)	O
.	O

This	O
is	O
called	O
matrix	O
transposition	O
.	O

@USER	O
The	O
solutions	O
there	O
all	O
make	O
use	O
of	O
the	O
fact	O
that	O
only	O
a	O
3x3	O
sliding	O
window	O
is	O
needed	O
,	O
but	O
I	O
need	O
something	O
that	O
works	O
for	O
all	O
sizes	O
of	O
templates	O
.	O

(	O
0008	O
,	O
103e	O
)	O
Series	O
Description	O
LO	O
:	O
'	O
Screen	O
Save	O
'	O

@USER	O
khanSever	O
20k	O
wouldn't	O
be	O
a	O
problem	O
for	O
modern	O
computers	O
,	O
if	O
you	O
are	O
really	O
thresholded	O
by	O
speed	O
in	O
this	O
kind	O
of	O
computation	O
,	O
I	O
would	O
say	O
that	O
you	O
shouldn't	O
have	O
had	O
an	O
inhomogenous	O
data	O
array	O
to	O
begin	O
with	O
.	O

@USER	O
Eweiwi	O
:	O
Did	O
you	O
find	O
my	O
answer	O
anyway	O
useful	O
?	O

You	O
can	O
now	O
compute	O
the	O
function	O
`	O
f	O
(	O
x	O
)`	O
at	O
any	O
point	O
`	O
x	O
`	O
.	O

BTW	O
:	O
this	O
is	O
a	O
neat	O
workaround	O
,	O
but	O
if	O
it	O
were	O
possible	O
to	O
use	O
the	O
`	O
in	O
`	O
operator	O
would	O
have	O
preferred	O
,	O
as	O
in	O
my	O
"	O
real	O
case	O
"	O
I	O
have	O
a	O
pool	O
of	O
roughly	O
10	O
values	O
,	O
non	O
only	O
`	O
(	O
6	O
,	O
8)	O
`	O
.	O

In	O
this	O
example	O
I	O
want	O
to	O
return	O
an	O
array	O
of	O
[	O
202	O
203	O
206	O
210	O
]	O

So	O
f	O
(	O
x	O
,	O
y	O
)	O
=	O
0	O

I	O
present	O
below	O
a	O
sample	O
silhouette	O
implementation	O
in	O
both	O
MATLAB	O
and	O
Python	O
/	O
Numpy	O
(	O
keep	O
in	O
mind	O
that	O
I	O
am	O
more	O
fluent	O
in	O
MATLAB	O
):	O

Python	O
import	O
Column	O
Data	O
from	O
MySQL	O
as	O
Array	O

This	O
is	O
just	O
the	O
partial	O
count	O
due	O
to	O
the	O
34	O
1-chips	O
.	O

I	O
want	O
to	O
know	O
how	O
I	O
should	O
index	O
/	O
access	O
some	O
data	O
programmatically	O
in	O
python	O
.	O

There	O
is	O
a	O
short	O
comment	O
at	O
the	O
end	O
of	O
the	O
introduction	O
to	O
SciPy	O
documentation	O
:	O

What	O
about	O
the	O
maximum	O
value	O
in	O
the	O
array	O
?	O

If	O
you	O
use	O
a	O
list	O
of	O
`	O
True	O
/	O
False	O
`	O
,	O
NumPy	O
will	O
interpret	O
that	O
as	O
a	O
list	O
of	O
`	O
1	O
/	O
0	O
`	O
as	O
integers	O
,	O
that	O
is	O
,	O
indices	O
,	O
meaning	O
that	O
you	O
'	O
either	O
get	O
the	O
second	O
or	O
first	O
element	O
of	O
your	O
array	O
.	O

But	O
it's	O
still	O
an	O
array	O
and	O
there	O
is	O
no	O
difference	O
in	O
asymptotic	O
complexity	O
.	O

Here's	O
one	O
way	O
(	O
same	O
matrix	O
as	O
before	O
):	O
#CODE	O

assume	O
i	O
have	O
100	O
points	O
whose	O
coordinates	O
are	O
random	O
,	O

If	O
you	O
just	O
want	O
the	O
first	O
one	O
,	O
use	O
next	O
with	O
the	O
list	O
comprehension	O
as	O
a	O
generator	O
expression	O
.	O

So	O
I	O
am	O
able	O
to	O
plot	O
what	O
I	O
want	O
onto	O
my	O
matrix	O

By	O
X3D	O
,	O
are	O
you	O
referring	O
to	O
the	O
x3d	O
standard	O
for	O
3d	O
content	O
,	O
as	O
at	O
#URL	O
If	O
so	O
,	O
I	O
would	O
very	O
much	O
like	O
to	O
learn	O
more	O
of	O
what	O
you	O
are	O
doing	O
--	O
thanks	O

Would	O
it	O
be	O
prohibitvely	O
wasteful	O
to	O
save	O
them	O
with	O
a	O
fixed	O
width	O
?	O

BSD-licensed	O
Python	O
source	O
code	O
for	O
surface	O
fits	O
can	O
be	O
found	O
at	O

...	O
which	O
returned	O
`	O
True	O
`	O
on	O
each	O
value	O
of	O
the	O
array	O
.	O

I	O
have	O
two	O
ordered	O
numpy	O
arrays	O
and	O
I	O
want	O
to	O
interleave	O
them	O
so	O
that	O
I	O
take	O
one	O
item	O
from	O
the	O
first	O
array	O
,	O
then	O
another	O
from	O
the	O
second	O
,	O
then	O
back	O
to	O
the	O
first	O
-	O
taking	O
the	O
next	O
item	O
that	O
is	O
larger	O
than	O
the	O
one	O
I	O
just	O
took	O
from	O
the	O
second	O
and	O
so	O
on	O
.	O

Did	O
you	O
look	O
at	O
the	O
link	O
in	O
my	O
answer	O
to	O
the	O
SciPy	O
page	O
on	O
Performance	O
Python	O
.	O

If	O
you	O
want	O
the	O
column	O
indices	O
instead	O
of	O
the	O
resulting	O
square	O
matrix	O
,	O
just	O
replace	O
`	O
return	O
B	O
`	O
with	O
`	O
return	O
colset	O
`	O
.	O

At	O
the	O
end	O
of	O
it	O
all	O
:	O
#CODE	O

Is	O
there	O
no	O
equivalent	O
function	O
that	O
gets	O
the	O
index	O
of	O
the	O
last	O
occurrence	O
?	O

I	O
want	O
to	O
get	O
a	O
cartesian	O
product	O
of	O
a	O
[:	O
:	O
i	O
]	O
and	O
b	O
[:	O
:	O
j	O
]	O
from	O
c	O
.	O

python	O
/	O
numpy	O
:	O
how	O
to	O
get	O
2D	O
array	O
column	O
length	O
?	O

Your	O
example	O
works	O
for	O
me	O
if	O
I	O
sample	O
around	O
2**6	O
points	O
.	O

NumPy's	O
main	O
object	O
is	O
the	O
homogeneous	O
multidimensional	O
array	O
.	O

Pythonic	O
way	O
to	O
import	O
data	O
from	O
multiple	O
files	O
into	O
an	O
array	O

The	O
only	O
thing	O
I	O
was	O
going	O
to	O
add	O
was	O
this	O
:	O
#URL	O
Indicated	O
that	O
this	O
is	O
not	O
likely	O
to	O
change	O
.	O

i	O
have	O
a	O
numpy	O
array	O
like	O
the	O
following	O
#CODE	O

I	O
want	O
to	O
write	O
a	O
Boost-Python	O
program	O
to	O
take	O
a	O
symbolic	O
python	O
function	O
from	O
user	O
and	O
evaluate	O
its	O
derivative	O
in	O
my	O
program	O
.	O

Is	O
there	O
a	O
way	O
around	O
this	O
?	O

Not	O
sure	O
if	O
I	O
explained	O
this	O
all	O
really	O
well	O
,	O
but	O
just	O
print	O
out	O
a_strided	O
and	O
you'll	O
see	O
what	O
the	O
result	O
is	O
and	O
how	O
easy	O
this	O
makes	O
the	O
operation	O
.	O

But	O
when	O
I	O
start	O
calling	O
columns	O
by	O
their	O
field	O
names	O
,	O
screwy	O
things	O
happen	O
.	O

all	O
I	O
get	O
is	O
very	O
high	O
or	O
inf	O
numbers	O
.	O

If	O
you're	O
iterating	O
through	O
,	O
and	O
applying	O
the	O
function	O
to	O
_each_	O
item	O
,	O
then	O
,	O
yeah	O
,	O
the	O
numpy	O
functions	O
will	O
be	O
slower	O
.	O

Slicing	O
does	O
not	O
copy	O
the	O
array	O
into	O
new	O
memory	O
(	O
unlike	O
delete	O
)	O
.	O

And	O
here's	O
the	O
filled	O
version	O
:	O
#CODE	O

This	O
is	O
a	O
little	O
bit	O
annoying	O
to	O
do	O
,	O
but	O
at	O
least	O
you	O
can	O
remove	O
that	O
annoying	O
`	O
==	O
`	O
easily	O
,	O
using	O
sorting	O
(	O
and	O
thats	O
probably	O
your	O
speed	O
killer	O
)	O
.	O

I	O
still	O
haven't	O
found	O
an	O
entirely	O
satisfactory	O
solution	O
,	O
but	O
nevertheless	O
there	O
is	O
something	O
one	O
can	O
do	O
to	O
obtain	O
the	O
pointer	O
with	O
a	O
lot	O
less	O
overhead	O
in	O
CPython	O
.	O

I	O
also	O
tried	O
using	O
NumPy	O
masked	O
arrays	O
,	O
with	O
NaN	O
fill_value	O
,	O
which	O
also	O
did	O
not	O
work	O
.	O

cartesian	O
(	O
split	O
(	O
a	O
,	O
3	O
))`	O
.	O

I	O
did	O
a	O
little	O
further	O
experimenting	O
and	O
found	O
a	O
numpy	O
specific	O
way	O
to	O
solve	O
this	O
:	O
#CODE	O

When	O
you	O
need	O
to	O
deal	O
with	O
exponential	O
,	O
you	O
quickly	O
go	O
into	O
under	O
/	O
over	O
flow	O
since	O
the	O
function	O
grows	O
so	O
quickly	O
.	O

Long	O
story	O
short	O
,	O
not	O
only	O
does	O
tabular	O
not	O
act	O
like	O
a	O
spreadsheet	O
out	O
of	O
the	O
box	O
,	O
I	O
can't	O
find	O
a	O
way	O
to	O
make	O
it	O
work	O
.	O

What	O
do	O
you	O
mean	O
"	O
two	O
significant	O
figures	O
"	O
?	O

We	O
put	O
it	O
in	O
a	O
list	O
and	O
double	O
it	O
.	O

For	O
example	O
for	O
value	O
255	O
the	O
coordinates	O
of	O
the	O
box	O
around	O
the	O
value	O
255	O
will	O
be	O
upper	O
left	O
(	O
0	O
,	O
0	O
)	O
and	O
lower	O
right	O
(	O
4	O
,	O
6	O
)	O
.	O

Like	O
in	O
a	O
java	O
program	O
,	O
you	O
can	O
choose	O
to	O
start	O
it	O
up	O
with	O
,	O
say	O
,	O
5GB	O
of	O
memory	O
.	O

However	O
,	O
due	O
to	O
the	O
way	O
the	O
data	O
points	O
lie	O
it	O
does	O
not	O
give	O
me	O
a	O
y-axis	O
interception	O
at	O
0	O
.	O

I'd	O
like	O
to	O
sort	O
it	O
such	O
that	O
my	O
points	O
are	O
ordered	O
by	O
x-coordinate	O
,	O
and	O
then	O
by	O
y	O
in	O
cases	O
where	O
the	O
x	O
coordinate	O
is	O
the	O
same	O
.	O

Of	O
course	O
this	O
will	O
slow	O
the	O
program	O
down	O
,	O
but	O
at	O
least	O
it'll	O
finish	O
.	O

Im	O
writing	O
it	O
here	O
because	O
i	O
cant	O
put	O
image	O
in	O
comment	O
.	O

In	O
looking	O
at	O
`	O
fill	O
`	O
,	O
I	O
saw	O
that	O
`	O
repeat	O
`	O
suits	O
my	O
needs	O
even	O
better	O
.	O

Note	O
that	O
an	O
array's	O
base	O
will	O
be	O
another	O
array	O
,	O
even	O
if	O
it	O
is	O
a	O
subset	O
:	O
#CODE	O

If	O
you	O
have	O
float	O
data	O
,	O
or	O
data	O
spread	O
over	O
a	O
huge	O
range	O
you	O
can	O
convert	O
it	O
to	O
integers	O
by	O
doing	O
:	O
#CODE	O

@USER	O
,	O
plaes	O
recommend	O
using	O
a	O
generator	O
(	O
parenthesis	O
)	O
instead	O
of	O
a	O
list	O
(	O
brackets	O
)	O
in	O
order	O
to	O
save	O
memory	O
and	O
gain	O
speed	O
when	O
managing	O
high	O
amounts	O
of	O
data	O
.	O

I	O
want	O
to	O
divide	O
this	O
array	O
into	O
3	O
blocks	O
of	O
size	O
2x4	O
,	O
and	O
then	O
find	O
the	O
mean	O
of	O
all	O
three	O
blocks	O
(	O
so	O
that	O
the	O
shape	O
of	O
the	O
mean	O
is	O
2x4	O
.	O

(	O
Have	O
a	O
look	O
at	O
the	O
comments	O
above	O
the	O
code	O
for	O
that	O
portion	O
.	O
)	O

That	O
is	O
because	O
`	O
fsolve	O
`	O
thinks	O
it	O
is	O
looking	O
for	O
an	O
array	O
of	O
length	O
17	O
that	O
solves	O
`	O
p	O
`	O
.	O

When	O
there's	O
a	O
choice	O
between	O
working	O
with	O
NumPy	O
array	O
and	O
numeric	O
lists	O
,	O
the	O
former	O
are	O
typically	O
faster	O
.	O

Wait	O
...	O
why	O
do	O
you	O
need	O
the	O
negative	O
?	O

But	O
if	O
a	O
dense	O
3d	O
array	O
representation	O
isn't	O
that	O
much	O
bigger	O
,	O
storing	O
it	O
as	O
a	O
chuncked	O
and	O
compressed	O
hdf5	O
array	O
is	O
probably	O
the	O
way	O
to	O
go	O
.	O

Index	O
datetime	O
in	O
numpy	O
array	O

Is	O
there	O
an	O
"	O
expandable	O
"	O
matrix	O
data	O
structure	O
available	O
in	O
a	O
well	O
tested	O
module	O
?	O

You	O
can	O
make	O
this	O
one-liner	O
reusable	O
if	O
you	O
are	O
going	O
to	O
repeat	O
it	O
a	O
lot	O
:	O
#CODE	O

Here's	O
my	O
array	O
(	O
rather	O
,	O
a	O
method	O
of	O
generating	O
representative	O
test	O
arrays	O
):	O
#CODE	O

We	O
need	O
more	O
information	O
on	O
your	O
array	O
.	O

@USER	O
:	O
If	O
the	O
code	O
all	O
F77	O
,	O
why	O
is	O
the	O
question	O
tagged	O
Python	O
?	O

It	O
does	O
that	O
without	O
densifying	O
the	O
matrix	O
right	O
?	O

To	O
speed	O
up	O
the	O
program	O
,	O
I	O
want	O
to	O
pass	O
the	O
index	O
through	O
a	O
subroutine	O
,	O
but	O
I	O
cannot	O
pass	O
`	O
[	O
index	O
[	O
0	O
]	O
,	O
:	O
,	O
index	O
[	O
1	O
]	O
,	O
index	O
[	O
2	O
]]`	O
through	O
a	O
subroutine	O
because	O
I	O
cannot	O
pass	O
the	O
colon	O
'	O
:	O
'	O
.	O

Any	O
thoughts	O
on	O
what	O
I'm	O
doing	O
wrong	O
?	O

This	O
will	O
be	O
far	O
,	O
far	O
faster	O
than	O
constantly	O
reallocating	O
the	O
array	O
inside	O
the	O
loop	O
.	O

How	O
can	O
I	O
get	O
a	O
new	O
array	O
containing	O
the	O
values	O
of	O
specific	O
attributes	O
of	O
those	O
objects	O
?	O

Seriously	O
,	O
at	O
least	O
leave	O
a	O
note	O
,	O
but	O
given	O
the	O
"	O
complexity	O
"	O
of	O
your	O
actual	O
request	O
I'd	O
say	O
that	O
you'll	O
have	O
better	O
chances	O
with	O
a	O
new	O
question	O
.	O

and	O
find	O
the	O
roots	O
with	O
numpy	O
:	O
#CODE	O

I	O
need	O
to	O
create	O
a	O
numpy	O
array	O
of	O
N	O
elements	O
,	O
but	O
I	O
want	O
to	O
access	O
the	O

I	O
have	O
allocated	O
a	O
chunk	O
of	O
double	O
in	O
a	O
C	O
library	O
and	O
I	O
would	O
like	O
to	O
create	O
a	O
numpy	O
1D	O
array	O
based	O
on	O
that	O
data	O
;	O
ideally	O
I	O
would	O
like	O
two	O
versions	O
one	O
which	O
only	O
wraps	O
the	O
c_ptr	O
readonly	O
-	O
letting	O
the	O
C	O
layer	O
retain	O
ownership	O
of	O
the	O
data	O
,	O
and	O
one	O
which	O
copies	O
the	O
data	O
.	O

The	O
code	O
included	O
in	O
pypy	O
is	O
a	O
new	O
array	O
class	O
which	O
tries	O
to	O
be	O
compatible	O
with	O
numpy	O
,	O
IOW	O
,	O
it	O
is	O
a	O
reimplementation	O
from	O
scratch	O
,	O
without	O
many	O
features	O
from	O
numpy	O
.	O

Like	O
I	O
say	O
,	O
I'm	O
honestly	O
struggling	O
,	O
any	O
help	O
would	O
be	O
much	O
appreciated	O
.	O

with	O
array	O
.	O

I'm	O
not	O
sure	O
that	O
I	O
understand	O
the	O
difference	O
between	O
copying	O
the	O
matrix	O
(	O
example	O
1	O
)	O
and	O
copying	O
the	O
data	O
(	O
example	O
2	O
)	O
.	O

Does	O
anybody	O
know	O
of	O
a	O
(	O
common	O
case	O
)	O
faster-than-linear	O
way	O
to	O
find	O
the	O
endpoints	O
of	O
a	O
boolean	O
property	O
of	O
an	O
array	O
.	O

Any	O
unrecognized	O
type	O
will	O
work	O
this	O
way	O
,	O
so	O
you	O
might	O
want	O
to	O
use	O
`	O
myclass	O
`	O
instead	O
of	O
`	O
object	O
`	O
.	O

Iterate	O
over	O
vectors	O
in	O
a	O
multidimensional	O
numpy	O
array	O

This	O
way	O
you	O
can	O
load	O
a	O
large	O
dataset	O
from	O
a	O
textfile	O
memory-efficiently	O
while	O
retaining	O
all	O
the	O
convenient	O
parsing	O
features	O
of	O
the	O
two	O
functions	O
.	O

you	O
may	O
win	O
few	O
cycles	O
if	O
you	O
multiply	O
by	O
inverse	O
instead	O
of	O
dividing	O
in	O
floating-point	O
performance	O
.	O

Without	O
knowing	O
the	O
size	O
or	O
quantity	O
of	O
the	O
images	O
or	O
the	O
application	O
of	O
the	O
algorithm	O
(	O
computer	O
vision	O
?	O
)	O
,	O
I	O
can't	O
say	O
how	O
big	O
a	O
deal	O
that	O
kind	O
of	O
speedup	O
is	O
.	O

Is	O
there	O
an	O
easy	O
way	O
to	O
sort	O
these	O
eigenvalues	O
(	O
and	O
associated	O
vectors	O
)	O
in	O
order	O
?	O

You	O
can	O
pass	O
a	O
numpy	O
array	O
or	O
matrix	O
as	O
an	O
argument	O
when	O
initializing	O
a	O
sparse	O
matrix	O
.	O

(	O
For	O
most	O
common	O
applications	O
of	O
quadratic	O
forms	O
q	O
A	O
,	O
the	O
matrix	O
A	O
is	O
symmetric	O
,	O
or	O
even	O
symmetric	O
positive	O
definite	O
,	O
so	O
feel	O
free	O
to	O
assume	O
that	O
either	O
one	O
of	O
these	O
is	O
the	O
case	O
,	O
if	O
it	O
matters	O
for	O
your	O
answer	O
.	O
)	O

I	O
think	O
you	O
might	O
find	O
the	O
`	O
flat	O
`	O
method	O
useful	O
.	O

Now	O
that	O
we	O
have	O
both	O
the	O
starting	O
and	O
ending	O
values	O
,	O
we	O
can	O
use	O
the	O
indices	O
function	O
from	O
this	O
question	O
to	O
get	O
an	O
array	O
of	O
selector	O
indices	O
:	O
#CODE	O

10	O
(	O
i	O
?	O
1	O
)	O
K	O
,	O
where	O
K	O
=	O
k	O
/	O
(	O
n	O
?	O
1	O
)	O
.	O

This	O
identifies	O
which	O
rows	O
have	O
any	O
element	O
which	O
are	O
True	O
#CODE	O

Broadcasting	O
is	O
a	O
more	O
general	O
way	O
to	O
fill	O
an	O
array	O
and	O
I	O
would	O
guess	O
is	O
slower	O
or	O
equal	O
to	O
the	O
very	O
narrow	O
use	O
case	O
of	O
`	O
fill	O
`	O
.	O

By	O
"	O
not	O
replicating	O
data	O
"	O
I	O
am	O
assuming	O
you	O
mean	O
"	O
not	O
allocating	O
more	O
memory	O
"	O
.	O

Can	O
you	O
post	O
all	O
/	O
more	O
of	O
the	O
data	O
?	O

The	O
scoring	O
matrix	O
would	O
be	O
trivial	O
,	O
as	O
the	O
"	O
distance	O
"	O
between	O
two	O
numbers	O
is	O
just	O
their	O
difference	O
.	O

Contours	O
around	O
scipy	O
labeled	O
regions	O
in	O
a	O
2D	O
grid	O

Why	O
doesn't	O
the	O
shape	O
of	O
my	O
numpy	O
array	O
change	O
?	O

Mind	O
also	O
the	O
indexing	O
starts	O
at	O
`	O
0	O
`	O

I	O
have	O
a	O
vague	O
feeling	O
that	O
I	O
might	O
have	O
seen	O
a	O
question	O
addressing	O
this	O
problem	O
,	O
but	O
I	O
can't	O
find	O
it	O
now	O
.	O

If	O
you	O
know	O
which	O
rows	O
are	O
to	O
be	O
deleted	O
,	O
just	O
extract	O
the	O
other	O
rows	O
(	O
you	O
need	O
)	O
and	O
create	O
a	O
new	O
array	O
.	O

If	O
there	O
is	O
any	O
other	O
way	O
I	O
guess	O
I	O
have	O
to	O
do	O
that	O
.	O

I	O
have	O
a	O
matrix	O
,	O
say	O
#CODE	O

You	O
might	O
find	O
out	O
the	O
distribution	O
information	O
using	O
`	O
cat	O
/	O
etc	O
/	O
*-release	O
`	O
;)	O

I	O
was	O
wondering	O
if	O
anyone	O
found	O
a	O
good	O
workaround	O
,	O
as	O
my	O
real-world	O
problem	O
of	O
iterating	O
over	O
the	O
Cartesian-product	O
of	O
the	O
rows	O
in	O
very	O
large	O
arrays	O
is	O
so	O
slow	O
it's	O
impeding	O
progress	O
.	O

I	O
have	O
an	O
array	O
of	O
x	O
,	O
y	O
,	O
z	O
distances	O
and	O
I	O
need	O
to	O
find	O
the	O
differences	O
between	O
each	O
vector	O
from	O
one	O
another	O
.	O

The	O
code	O
above	O
finds	O
parts	O
where	O
there	O
are	O
at	O
least	O
MIN_SILENCE	O
consecutive	O
elements	O
smaller	O
than	O
SILENCE_THRESHOLD	O
.	O

The	O
list	O
of	O
indices	O
will	O
always	O
be	O
ascending	O
,	O
never	O
have	O
duplicates	O
,	O
but	O
may	O
have	O
gaps	O
like	O
the	O
example	O
.	O

Any	O
ideas	O
?	O

sum	O
function	O
in	O
python	O

All	O
globals	O
hold	O
either	O
values	O
referenced	O
by	O
those	O
tuples	O
or	O
are	O
lists	O
of	O
tuples	O
.	O

You	O
can	O
pass	O
a	O
list	O
or	O
an	O
array	O
as	O
indexes	O
to	O
any	O
np	O
array	O
.	O

The	O
array	O
I'm	O
using	O
is	O
quite	O
large	O
(	O
3500x3500	O
)	O
,	O
so	O
I'm	O
wondering	O
where	O
the	O
best	O
place	O
to	O
load	O
it	O
is	O
for	O
repeated	O
use	O
.	O

Basically	O
,	O
it	O
comes	O
down	O
to	O
checking	O
before	O
you	O
add	O
.	O

I	O
have	O
a	O
simple	O
function	O
called	O
get_gradient	O
which	O
takes	O
a	O
numpy	O
array	O
of	O
[[	O
x	O
,	O
y	O
,	O
Vx	O
,	O
Vy	O
]]	O
and	O
returns	O
(	O
should	O
return	O
)	O
an	O
array	O
of	O
[[	O
Vx	O
,	O
Vy	O
,	O
Ax	O
,	O
Ay	O
]]	O
.	O

I	O
found	O
this	O
post	O
:	O
Python	O
:	O
finding	O
an	O
element	O
in	O
an	O
array	O

So	O
,	O
are	O
VBOs	O
simply	O
not	O
meant	O
to	O
be	O
that	O
big	O
(	O
I	O
somehow	O
doubt	O
that	O
VBOs	O
could	O
only	O
have	O
around	O
17k	O
triangles	O
each	O
)	O
?	O

`	O
flags	O
`	O
parameter	O
leads	O
to	O
`	O
TypeError	O
`	O
if	O
input	O
array	O
is	O
not	O
contiguous	O
.	O

I	O
then	O
have	O
a	O
2nd	O
array	O
similar	O
to	O
#CODE	O

Convert	O
a	O
list	O
of	O
2D	O
numpy	O
arrays	O
to	O
one	O
3D	O
numpy	O
array	O
?	O

I'm	O
currently	O
a	O
grad	O
student	O
at	O
Harvard	O
and	O
a	O
good	O
friend	O
of	O
mine	O
went	O
there	O
(	O
he	O
would	O
have	O
graduated	O
two	O
or	O
three	O
years	O
ago	O
,	O
as	O
he	O
is	O
currently	O
a	O
second-year	O
grad	O
student	O
here	O
at	O
Harvard	O
with	O
me	O
)	O
.	O

I'm	O
not	O
clear	O
on	O
how	O
you	O
are	O
wanting	O
to	O
plot	O
it	O
,	O
but	O
it	O
sound	O
like	O
you'll	O
need	O
to	O
select	O
some	O
values	O
of	O
a	O
column	O
.	O

The	O
issue	O
I	O
am	O
running	O
in	O
to	O
is	O
that	O
the	O
array	O
can	O
be	O
larger	O
than	O
3gb	O
in	O
size	O
(	O
these	O
are	O
huge	O
images	O
)	O
and	O
I	O
need	O
to	O
segment	O
them	O
prior	O
to	O
ingesting	O
them	O
.	O

The	O
latter	O
might	O
be	O
faster	O
because	O
it	O
doesn't	O
produce	O
the	O
intermediate	O
`	O
x**2	O
`	O
array	O
.	O

Any	O
suggestions	O
?	O

"	O
A	O
copy	O
of	O
arr	O
with	O
the	O
elements	O
specified	O
by	O
obj	O
removed	O
.	O

is	O
not	O
it	O
another	O
copy	O
?	O

NOTE	O
:	O
the	O
row	O
has	O
"	O
:	O
"	O
,	O
but	O
the	O
"	O
:	O
"	O
does	O
mean	O
the	O
dict	O
'	O
:	O
'	O
.	O

If	O
,	O
for	O
some	O
reason	O
,	O
I	O
would	O
only	O
save	O
one	O
dictionary	O
then	O
every	O
script	O
loading	O
this	O
file	O
with	O
pickle	O
would	O
mess	O
up	O
the	O
order	O
of	O
the	O
stored	O
variables	O
.	O

You	O
might	O
also	O
want	O
to	O
take	O
a	O
look	O
at	O
Anvil	O
,	O
announcement	O
here	O
.	O

The	O
other	O
way	O
that	O
I	O
know	O
is	O
to	O
convert	O
Y	O
to	O
list	O
iteratively	O
.	O

This	O
is	O
especially	O
helpful	O
since	O
it	O
includes	O
the	O
import	O
commands	O
and	O
info	O
on	O
how	O
to	O
write	O
to	O
file	O
.	O

But	O
actually	O
I	O
am	O
not	O
so	O
sure	O
that	O
from	O
where	O
you	O
are	O
now	O
,	O
using	O
sparse	O
matrices	O
will	O
gain	O
you	O
any	O
speed-up	O
.	O

Upon	O
deeper	O
examination	O
of	O
the	O
relationship	O
between	O
the	O
python	O
printout	O
and	O
the	O
structure	O
of	O
my	O
underlying	O
data	O
,	O
I	O
see	O
that	O
the	O
python	O
print	O
command	O
is	O
saying	O
that	O
there	O
are	O
two	O
empty	O
columns	O
at	O
the	O
end	O
of	O
the	O
array	O
.	O

How	O
to	O
convert	O
a	O
simple	O
list	O
of	O
lists	O
into	O
a	O
numppy	O
array	O
?	O

Django	O
has	O
a	O
library	O
for	O
encapsulating	O
all	O
the	O
database	O
work	O
into	O
Python	O
classes	O
,	O
so	O
you	O
don't	O
have	O
to	O
mess	O
with	O
raw	O
SQL	O
until	O
you	O
have	O
to	O
do	O
something	O
really	O
clever	O
.	O

So	O
I	O
got	O
numpy	O
,	O
scipy	O
,	O
IPython	O
,	O
and	O
matplotlib	O
working	O
(	O
I	O
can	O
import	O
all	O
four	O
with	O
"	O
import	O
_	O
)"	O
.	O

@USER	O
`	O
new	O
type	O
not	O
compatible	O
with	O
array	O
.	O

Is	O
there	O
any	O
way	O
to	O
do	O
this	O
in	O
Python	O
?	O

Then	O
you	O
can	O
choose	O
many	O
methods	O
to	O
visualize	O
it	O
.	O

Numpy	O
Array	O
to	O
base64	O
and	O
back	O
to	O
Numpy	O
Array	O
-	O
Python	O

In	O
each	O
iteration	O
of	O
Gibbs	O
sampling	O
,	O
we	O
remove	O
one	O
(	O
current	O
)	O
word	O
,	O
sample	O
a	O
new	O
topic	O
for	O
that	O
word	O
according	O
to	O
a	O
posterior	O
conditional	O
probability	O
distribution	O
inferred	O
from	O
the	O
LDA	O
model	O
,	O
and	O
update	O
word-topic	O
counts	O
,	O
as	O
follows	O
:	O
#CODE	O

I	O
am	O
getting	O
weird	O
errors	O
when	O
I	O
try	O
to	O
convert	O
a	O
black	O
and	O
white	O
PIL	O
image	O
to	O
a	O
numpy	O
array	O
.	O

Numpy	O
arrays	O
have	O
a	O
`	O
copy	O
`	O
method	O
which	O
you	O
can	O
use	O
for	O
just	O
this	O
purpose	O
.	O

Actually	O
I	O
could	O
not	O
test	O
with	O
big	O
K	O
,	O
d	O
and	O
N	O
as	O
I	O
was	O
going	O
out	O
of	O
memory	O
.	O

With	O
all	O
of	O
these	O
options	O
you	O
have	O
to	O
pay	O
a	O
JNA	O
tax	O
...	O
all	O
of	O
your	O
data	O
has	O
to	O
be	O
copied	O
before	O
it	O
can	O
be	O
processed	O
.	O

Useless	O
because	O
it	O
ignores	O
the	O
"	O
cross	O
platform	O
issues	O
,	O
proprietary	O
tool	O
chains	O
,	O
certification	O
gates	O
,	O
licensed	O
technologies	O
,	O
and	O
stringent	O
performance	O
requirements	O
on	O
top	O
of	O
the	O
issues	O
with	O
legacy	O
codebases	O
and	O
workforce	O
availability	O
"	O
(	O
John	O
Carmack	O
)	O
that	O
op	O
is	O
probably	O
facing	O
.	O

And	O
that	O
the	O
values	O
of	O
all	O
(	O
x	O
,	O
y	O
)	O
pairs	O
are	O
given	O
.	O

Is	O
is	O
possible	O
to	O
have	O
a	O
3-D	O
record	O
array	O
in	O
numpy	O
?	O

However	O
,	O
the	O
evidence	O
suggests	O
that	O
you've	O
encountered	O
an	O
issue	O
of	O
this	O
sort	O
.	O

There's	O
_way_	O
less	O
overhead	O
this	O
way	O
.	O

I'm	O
having	O
trouble	O
figuring	O
out	O
what	O
kind	O
of	O
test	O
I	O
need	O
here	O
,	O
and	O
the	O
best	O
numpy	O
/	O
scipy	O
/	O
R	O
function	O
to	O
use	O
for	O
these	O
kinds	O
of	O
issues	O
.	O

I	O
have	O
see	O
people	O
using	O
dictionaries	O
,	O
but	O
the	O
arrays	O
are	O
large	O
and	O
filled	O
with	O
both	O
positive	O
and	O
negative	O
floats	O
.	O

How	O
can	O
I	O
speed	O
up	O
iteration	O
through	O
this	O
transformed	O
numpy	O
array	O
?	O

This	O
is	O
may	O
not	O
be	O
the	O
best	O
way	O
to	O
solve	O
this	O
but	O
have	O
a	O
look	O
at	O
the	O
following	O
...	O

All	O
in	O
all	O
,	O
I	O
would	O
go	O
with	O
the	O
#CODE	O

This	O
is	O
not	O
a	O
matter	O
of	O
style	O
.	O
without	O
the	O
list	O
(	O
_	O
)	O
it	O
does	O
not	O
even	O
work	O
at	O
last	O
for	O
the	O
case	O
i	O
have	O
that	O
y	O
is	O
an	O
array	O
itself	O

(	O
at	O
least	O
it	O
gives	O
me	O
an	O
error	O
stating	O
that	O
the	O
'	O
as	O
'	O
is	O
reserved	O
in	O
python	O
2.6	O
)	O
Am	O
I	O
correct	O
?	O

Did	O
you	O
try	O
looking	O
at	O
numpy	O
for	O
matlab	O
users	O
manuals	O
,	O
like	O
:	O
#URL	O

I	O
would	O
not	O
try	O
to	O
process	O
`	O
arr	O
`	O
in	O
place	O
-	O
it	O
seems	O
that	O
a	O
new	O
array	O
is	O
created	O
under	O
the	O
hood	O
in	O
most	O
cases	O
anyway	O
.	O

Now	O
you	O
must	O
initialize	O
each	O
element	O
of	O
the	O
numpy	O
array	O
to	O
be	O
an	O
1-d	O
numpy	O
array	O
:	O
#CODE	O

The	O
easiest	O
way	O
around	O
this	O
is	O
to	O
just	O
use	O
a	O
numpy	O
array	O
,	O
instead	O
of	O
a	O
numpy	O
matrix	O
:	O
#CODE	O

I	O
am	O
trying	O
to	O
create	O
an	O
affinity	O
matrix	O
for	O
an	O
image	O
.	O

to	O
handle	O
the	O
error	O
cases	O
and	O
the	O
return	O
value	O
,	O
they	O
are	O
not	O
related	O
to	O
the	O
array	O
assignment	O
.	O

Saving	O
a	O
Numpy	O
array	O
as	O
an	O
image	O
(	O
instructions	O
)	O

Using	O
this	O
,	O
I	O
know	O
I	O
am	O
calculating	O
r-squared	O
correctly	O
for	O
linear	O
best-fit	O
(	O
degree	O
equals	O
1	O
)	O
.	O

No	O
expert	O
on	O
the	O
topic	O
,	O
but	O
this	O
is	O
some	O
kind	O
of	O
adjency	O
matrix	O
(	O
#URL	O
)	O
.	O

about	O
15	O
times	O
faster	O
using	O
broadcast	O

Arrays	O
to	O
Matrix	O
numpy	O

but	O
it	O
appears	O
to	O
only	O
take	O
square	O
matrices	O
.	O

Any	O
idea	O
how	O
that	O
can	O
be	O
done	O
?	O

In	O
your	O
code	O
,	O
`	O
a	O
[	O
condition	O
]	O
[	O
index	O
]`	O
returns	O
the	O
value	O
in	O
a	O
,	O
but	O
I	O
want	O
the	O
INDEX	O
in	O
a	O
,	O
so	O
that	O
`	O
a	O
[	O
INDEX	O
]	O
=	O
a	O
[	O
condition	O
]	O
[	O
index	O
]`	O
.	O

Any	O
database	O
that	O
can	O
create	O
an	O
index	O
will	O
provide	O
relatively	O
fast	O
look-ups	O
(	O
depending	O
on	O
how	O
many	O
millions	O
of	O
records	O
you're	O
storing	O
)	O
.	O

Actually	O
,	O
the	O
best	O
way	O
to	O
manage	O
packages	O
on	O
OS	O
X	O
is	O
[	O
Homebrew	O
]	O
(	O
#URL	O
)	O
(	O
not	O
Fink	O
or	O
MacPorts	O
:))	O
-	O
which	O
unfortunately	O
lists	O
neither	O
NumPy	O
now	O
SciPy	O
at	O
the	O
current	O
time	O
.	O

I	O
would	O
like	O
to	O
keep	O
`	O
xcoords	O
`	O
a	O
numpy	O
array	O
if	O
possible	O
.	O
what	O
do	O
you	O
mean	O
'	O
adding	O
them	O
to	O
the	O
object	O
before	O
it	O
is	O
returned	O
'	O
?	O

But	O
I	O
just	O
need	O
to	O
sort	O
out	O
which	O
points	O
to	O
send	O
for	O
a	O
complete	O
graph	O
.	O

how	O
do	O
I	O
calculate	O
that	O
an	O
array	O
of	O
python	O
numpy	O
or	O
me	O
of	O
all	O
the	O
calculate	O
decimals	O
and	O
not	O
skip	O
like	O
.	O

It	O
will	O
support	O
it	O
on	O
the	O
next	O
release	O
.	O

Python	O
lists	O
are	O
defined	O
with	O
square	O
brackets	O
,	O
and	O
we	O
want	O
to	O
generate	O
a	O
list	O
of	O
lists	O
(	O
where	O
each	O
piece	O
contains	O
one	O
of	O
your	O
defined	O
segments	O
)	O
.	O

The	O
biggest	O
gotcha	O
for	O
me	O
was	O
that	O
almost	O
every	O
standard	O
operator	O
is	O
overloaded	O
to	O
distribute	O
across	O
the	O
array	O
.	O

I	O
want	O
to	O
combine	O
the	O
two	O
into	O
a	O
mutli-dimensional	O
numpy	O
array	O
.	O

where	O
`	O
nlooks	O
`	O
and	O
`	O
dfactor	O
`	O
are	O
scalars	O
and	O
`	O
Ic	O
`	O
is	O
the	O
unfiltered	O
array	O
.	O

In	O
a	O
10x5x5	O
matrix	O
with	O
`	O
x	O
[	O
0	O
,	O
:	O
,	O
:]	O
=	O
0	O
`	O
I	O
would	O
expect	O
a	O
result	O
of	O
:	O
#CODE	O

For	O
example	O
:	O
I	O
have	O
a	O
=	O
array	O
([	O
123	O
,	O
412	O
,	O
444	O
])	O

While	O
it	O
often	O
results	O
in	O
a	O
massive	O
speedup	O
to	O
eliminate	O
for	O
loops	O
and	O
take	O
advantage	O
of	O
numpy	O
built-ins	O
/	O
vectorization	O
.	O

If	O
I	O
understand	O
correctly	O
you	O
have	O
a	O
three	O
dimensional	O
array	O
,	O
something	O
like	O
:	O
#CODE	O

@USER	O
:	O
where	O
is	O
a	O
new	O
array	O
created	O
?	O

array	O
([	O
41	O
,	O
32	O
,	O
41	O
,	O
33	O
,	O
42	O
,	O
32	O
,	O
42	O
,	O
33	O
])	O

Any	O
idea	O
when	O
it	O
will	O
be	O
ready	O
?	O

I	O
see	O
you've	O
taken	O
care	O
of	O
my	O
edge	O
issues	O
,	O
although	O
your	O
filter	O
size	O
is	O
hardcoded	O
;)	O
.	O

If	O
you	O
open	O
idle	O
and	O
type	O
`	O
import	O
matplotlib	O
`	O
it	O
shouldn't	O
return	O
an	O
error	O

No	O
expert	O
on	O
the	O
topic	O
,	O
but	O
this	O
is	O
some	O
kind	O
of	O
adjency	O
matrix	O
(	O
#URL	O
)	O
.	O

Edit	O
:	O
If	O
it's	O
a	O
floating	O
point	O
issue	O
,	O
what	O
sort	O
of	O
floating	O
point	O
error	O
mistakes	O
a	O
number	O
much	O
less	O
than	O
1	O
as	O
one	O
around	O
8	O
?	O

The	O
question	O
was	O
about	O
how	O
to	O
slice	O
if	O
the	O
rank	O
is	O
not	O
known	O
at	O
the	O
time	O
I	O
write	O
the	O
code	O
.	O

I	O
think	O
a	O
typical	O
method	O
is	O
to	O
always	O
double	O
the	O
size	O
,	O
when	O
you	O
really	O
don't	O
know	O
how	O
large	O
things	O
will	O
be	O
.	O

This	O
script	O
is	O
mainly	O
intended	O
to	O
demonstrate	O
building	O
an	O
independent	O
python	O
in	O
your	O
home	O
directory	O
,	O
and	O
assumes	O
the	O
system	O
you're	O
building	O
on	O
has	O
the	O
proper	O
dependencies	O
already	O
installed	O
,	O
but	O
it	O
at	O
least	O
points	O
you	O
in	O
the	O
right	O
direction	O
.	O

and	O
use	O
the	O
information	O
on	O
the	O
size	O
inclued	O
in	O
the	O
filename	O
to	O
restore	O
the	O
initial	O
shape	O

Hmm	O
I	O
added	O
for	O
first	O
example	O
,	O
did	O
you	O
know	O
how	O
to	O
copy	O
from	O
IDE	O
exactly	O
with	O
commas	O
and	O
everything	O
..?	O

@USER	O
:	O
Your	O
answer	O
will	O
give	O
false	O
positives	O
in	O
the	O
event	O
that	O
one	O
or	O
more	O
(	O
but	O
not	O
all	O
)	O
of	O
the	O
elements	O
in	O
B	O
matches	O
with	O
one	O
of	O
the	O
rows	O
in	O
A	O
.	O

I	O
would	O
like	O
to	O
average	O
the	O
2	O
different	O
arrays	O
contained	O
within	O
`	O
record	O
`	O
.	O

I	O
need	O
to	O
constrained	O
minimization	O
of	O
some	O
data	O
(	O
ie	O
so	O
that	O
I	O
get	O
the	O
minimum	O
value	O
within	O
a	O
certain	O
range	O
)	O
.	O

In	O
this	O
case	O
,	O
I	O
would	O
like	O
to	O
return	O
the	O
index	O
2	O
(	O
2nd	O
row	O
)	O
.	O

a	O
32	O
bits	O
process	O
can	O
only	O
access	O
around	O
4	O
GB	O
of	O
memory	O
.	O

How	O
do	O
I	O
find	O
out	O
,	O
if	O
the	O
numpy	O
BLAS	O
libraries	O
are	O
availalbe	O
as	O
dynamically-loadable	O
?	O

(	O
they	O
are	O
at	O
same	O
scale	O
)	O

Now	O
simply	O
create	O
a	O
new	O
array	O
and	O
multiply	O
:	O
#CODE	O

Take	O
a	O
look	O
at	O
this	O
Project	O
Euler	O
problem	O
:	O
#URL	O

Python	O
:	O
how	O
to	O
store	O
a	O
numpy	O
multidimensional	O
array	O
in	O
PyTables	O
?	O

How	O
can	O
i	O
load	O
all	O
24	O
joblib	O
files	O
in	O
one	O
program	O
without	O
any	O
errors	O
?	O

Where	O
I'm	O
stuck	O
is	O
what	O
the	O
wrapper	O
code	O
should	O
then	O
look	O
like	O
to	O
pass	O
a	O
MxN	O
numpy	O
array	O
to	O
the	O
**	O
coords1	O
and	O
**	O
coords2	O
arguments	O
.	O

I	O
have	O
created	O
a	O
numpy	O
2d	O
array	O
of	O
type	O
string	O
called	O
'	O
minutes_array	O
'	O
with	O
the	O
first	O
column	O
as	O
unix	O
timestamps	O
rounded	O
to	O
the	O
nearest	O
minute	O
covering	O
every	O
minute	O
from	O
the	O
start	O
of	O
the	O
sensor	O
timeseries	O
to	O
the	O
end	O
with	O
three	O
empty	O
columns	O
to	O
be	O
filled	O
with	O
data	O
from	O
each	O
of	O
the	O
3	O
sensors	O
where	O
available	O
.	O

Which	O
can	O
be	O
done	O
in	O
O	O
(	O
n	O
)	O
,	O
but	O
your	O
answer	O
requires	O
O	O
(	O
mn	O
)	O
,	O
where	O
m	O
is	O
size	O
of	O
window	O
.	O

Somehow	O
I	O
always	O
thought	O
you	O
can	O
load	O
the	O
shared	O
library	O
compiled	O
with	O
any	O
compiler	O
.	O

`	O
array	O
=[	O
'	O
NaN	O
'	O
,	O
'	O
20	O
'	O
,	O
'	O
383.333	O
'	O
,	O
'	O
NaN	O
'	O
,	O
'	O
NaN	O
'	O
,	O
'	O
NaN	O
'	O
,	O
'	O
5	O
'	O
,	O
'	O
100	O
'	O
,	O
'	O
129	O
'	O
,	O
'	O
122.5	O
'	O
,	O
'	O
NaN	O
'	O
,	O
'	O
NaN	O
']`	O

array	O
,	O
and	O
then	O
use	O
`	O
view	O
`	O
to	O
turn	O
it	O
into	O
a	O
structured	O
array	O
,	O
and	O
then	O
use	O

and	O
so	O
all	O
we	O
need	O
to	O
do	O
is	O
:	O
#CODE	O

Any	O
clue	O
to	O
why	O
this	O
is	O
happening	O
?	O

I	O
think	O
the	O
definition	O
used	O
in	O
the	O
field	O
of	O
statistics	O
is	O
the	O
value	O
in	O
the	O
middle	O
of	O
your	O
data	O
array	O
after	O
it	O
has	O
been	O
sorted	O
.	O

Dense	O
covariance	O
matrices	O
of	O
that	O
size	O
suggest	O
operations	O
that	O
run	O
forever	O
!	O

In	O
this	O
case	O
,	O
I'd	O
like	O
it	O
to	O
return	O
a	O
density	O
that's	O
essentially	O
peaked	O
completely	O
at	O
a	O
difference	O
of	O
0	O
,	O
with	O
no	O
mass	O
everywhere	O
else	O
.	O

If	O
the	O
array	O
is	O
doubles	O
(	O
remember	O
python	O
floats	O
are	O
C	O
doubles	O
by	O
default	O
)	O
then	O
you	O
have	O
to	O
think	O
a	O
bit	O
harder	O
as	O
==	O
is	O
not	O
really	O
safe	O
or	O
what	O
you	O
want	O
for	O
floating	O
point	O
values	O
.	O

They	O
all	O
have	O
their	O
strengths	O
and	O
weaknesses	O
.	O

numpy	O
array	O
of	O
chars	O
to	O
string	O

matrix	O
rank	O
:	O
#CODE	O

This	O
slows	O
down	O
for	O
large	O
sigma	O
,	O
at	O
which	O
point	O
using	O
FFT-based	O
smoothing	O
might	O
be	O
faster	O
.	O

What	O
is	O
the	O
fastest	O
way	O
to	O
iterate	O
through	O
all	O
one	O
dimensional	O
sub-arrays	O
of	O
an	O
n	O
dimensional	O
array	O
in	O
python	O
.	O

This	O
works	O
,	O
but	O
it's	O
really	O
slow	O
.	O

If	O
I	O
create	O
a	O
simple	O
array	O
like	O
this	O
in	O
Python	O
I'm	O
able	O
to	O
read	O
the	O
values	O
in	O
the	O
C	O
code	O
:	O

In	O
an	O
ideal	O
world	O
,	O
the	O
function	O
or	O
class	O
would	O
support	O
overlap	O
between	O
the	O
divisions	O
in	O
the	O
input	O
matrix	O
too	O
.	O

My	O
problem	O
is	O
different	O
because	O
I	O
need	O
to	O
find	O
**	O
all	O
**	O
the	O
roots	O
of	O
my	O
function	O
,	O
on	O
a	O
given	O
interval	O
.	O

How	O
can	O
I	O
create	O
a	O
PyArrayObject	O
from	O
this	O
structure	O
,	O
specially	O
how	O
I	O
can	O
create	O
a	O
numpy	O
array	O
that	O
hold	O
3	O
object	O
(	O
off	O
course	O
3	O
is	O
an	O
example	O
here	O
)	O
(	O
each	O
of	O
them	O
is	O
an	O
array	O
)	O

x	O
:	O
a	O
numpy	O
2d	O
array	O

Thanks	O
for	O
the	O
info	O
.	O

How	O
would	O
you	O
avoid	O
the	O
loop	O
in	O
the	O
case	O
that	O
all	O
entries	O
in	O
`	O
repl	O
`	O
are	O
the	O
same	O
?	O

Pulling	O
data	O
from	O
a	O
numpy	O
array	O

There's	O
no	O
effective	O
difference	O
(	O
they	O
both	O
return	O
views	O
into	O
the	O
original	O
array	O
)	O
.	O

Thanks	O
for	O
all	O
the	O
tips	O
!	O

remove	O
zero	O
lines	O
2-D	O
numpy	O
array	O

Instead	O
of	O
using	O
`	O
PyInt_AsLong	O
`	O
,	O
use	O
the	O
`	O
PyArray_*	O
`	O
functions	O
provided	O
by	O
Numpy's	O
C	O
API	O
to	O
access	O
the	O
data	O
;	O
in	O
particular	O
,	O
see	O
section	O
Array	O
API	O
.	O

Well	O
,	O
I	O
tried	O
dividing	O
by	O
the	O
largest	O
place	O
value	O
.	O

All	O
of	O
those	O
numpys	O
are	O
linked	O
to	O
the	O
system	O
Accelerate	O
framework	O
:	O
#CODE	O

and	O
I	O
wish	O
to	O
create	O
a	O
third	O
array	O
with	O
each	O
element	O
from	O
`	O
b	O
`	O
appearing	O
`	O
a	O
`	O
times	O
in	O
the	O
new	O
array	O
,	O
as	O
:	O
#CODE	O

I	O
can	O
imagine	O
a	O
number	O
of	O
approaches	O
to	O
storing	O
both	O
of	O
these	O
data	O
formats	O
,	O
ranging	O
from	O
storing	O
the	O
metadata	O
with	O
the	O
`	O
AttributeSet	O
`	O
class	O
for	O
each	O
`	O
Array	O
`	O
/	O
`	O
CArray	O
`	O
to	O
using	O
a	O
`	O
Table	O
`	O
for	O
all	O
of	O
the	O
metadata	O
.	O

I	O
want	O
to	O
calculate	O
the	O
average	O
of	O
four	O
neighbors	O
in	O
a	O
huge	O
array	O
.	O

Suppress	O
Scientific	O
Notation	O
in	O
Numpy	O
When	O
Creating	O
Array	O
From	O
Nested	O
List	O

I	O
want	O
to	O
find	O
the	O
vector	O
x	O
'	O
such	O
that	O
Ax	O
'	O
is	O
as	O
close	O
as	O
possible	O
to	O

And	O
the	O
dataset	O
in	O
question	O
is	O
beyond	O
doubt	O
particular	O
:	O
There	O
certainly	O
is	O
an	O
upper	O
bound	O
and	O
a	O
precision	O
.	O

Only	O
integers	O
can	O
be	O
used	O
as	O
array	O
or	O
matrix	O
indices	O
.	O

I	O
can't	O
find	O
it	O
online	O
anywhere	O
.	O

I	O
will	O
try	O
your	O
code	O
,	O
but	O
I	O
am	O
also	O
going	O
to	O
try	O
writing	O
a	O
simple	O
C	O
extension	O
to	O
simply	O
do	O
the	O
reading	O
,	O
math	O
,	O
and	O
drawing	O
all	O
in	O
one	O
place	O
.	O

Are	O
there	O
any	O
good	O
greedy	O
implementations	O
to	O
solve	O
this	O
or	O
am	O
I	O
on	O
my	O
own	O
to	O
implement	O
this	O
?	O

The	O
problem	O
is	O
that	O
for	O
the	O
array	O
input	O
,	O
SWIG	O
complains	O
that	O
there	O
is	O
no	O
typemap	O
.	O

Is	O
`	O
column_array_to_add	O
`	O
another	O
2D	O
array	O
,	O
or	O
is	O
it	O
a	O
1D	O
column	O
array	O
,	O
as	O
the	O
name	O
implies	O
?	O

the	O
sum	O
of	O
a	O
triple-product	O
(	O
element-wise	O
)	O
.	O

I	O
ran	O
a	O
simple	O
speed	O
test	O
comparing	O
numpy	O
and	O
python	O
list	O
comprehension	O
,	O
and	O
apparently	O
list	O
comprehension	O
was	O
faster	O
.	O

That	O
is	O
why	O
your	O
sample	O
loop	O
has	O
been	O
collapsed	O
to	O
read	O
in	O
the	O
full	O
sample	O
for	O
the	O
receiver	O
and	O
channel	O
in	O
one	O
large	O
read	O
.	O

Something	O
like	O
the	O
following	O
iterator	O
should	O
get	O
around	O
both	O
of	O
these	O
problems	O
:	O
#CODE	O

I	O
appreciate	O
any	O
input	O
on	O
this	O
...	O

Do	O
you	O
really	O
need	O
to	O
find	O
such	O
a	O
weird	O
thing	O
?	O

Any	O
particular	O
reason	O
you	O
don't	O
want	O
to	O
use	O
a	O
straightforward	O
approach	O
?	O

The	O
advantage	O
of	O
numpy	O
is	O
the	O
support	O
of	O
slicing	O
at	O
different	O
levels	O
.	O

An	O
implementation	O
,	O
however	O
,	O
is	O
not	O
really	O
open	O
to	O
interpretation	O
.	O

Python	O
numpy	O
masked	O
array	O
initialization	O

You	O
can	O
further	O
optimize	O
by	O
exploiting	O
array-order	O
alignment	O
to	O
reduce	O
excess	O
memory	O
consumption	O
caused	O
by	O
copying	O
the	O
original	O
arrays	O
.	O

For	O
example	O
,	O
any	O
vector	O
(	O
of	O
the	O
appropriate	O
dimension	O
)	O
can	O
be	O
an	O
eigenvector	O
of	O
the	O
identity	O
matrix	O
.	O

The	O
normal	O
64-bit	O
double-precision	O
floating	O
point	O
has	O
least	O
positive	O
normal	O
value	O
2.2E-308	O
;	O
storing	O
logs	O
gives	O
you	O
an	O
effective	O
least	O
positive	O
normal	O
1E-	O
(	O
1.7E308	O
)	O
.	O

index	O
set	O
for	O
each	O
position	O
in	O
the	O
index	O
arrays	O
.	O

I	O
am	O
wondering	O
if	O
reassigning	O
temp	O
[	O
]	O
to	O
a	O
1-element	O
shorter	O
vector	O
each	O
time	O
is	O
slow	O
,	O
would	O
it	O
be	O
faster	O
to	O
pre-allocate	O
a	O
96-3	O
length	O
list	O
of	O
vectors	O
of	O
length	O
96	O
,	O
95	O
,	O
94	O
...	O
to	O
3	O
?	O

What	O
would	O
we	O
do	O
,	O
if	O
we	O
wanted	O
to	O
change	O
values	O
at	O
indexes	O
which	O
are	O
multiple	O
of	O
given	O
n	O
,	O
like	O
a	O
[	O
2	O
]	O
,	O
a	O
[	O
4	O
]	O
,	O
a	O
[	O
6	O
]	O
,	O
a	O
[8	O
]	O
.....	O
for	O
n=2	O
?	O

Thanks	O
for	O
all	O
the	O
python	O
guidance	O
!	O

I'm	O
not	O
really	O
pro	O
Matlab	O
,	O
but	O
surely	O
Stata	O
can't	O
be	O
so	O
bad	O
as	O
to	O
require	O
`	O
adoedit	O
`	O
just	O
to	O
know	O
what	O
algorithm	O
it	O
is	O
using	O
?	O

This	O
can	O
be	O
found	O
relatively	O
easily	O
by	O
just	O
looking	O
at	O
points	O
where	O
the	O
potential	O
exceeds	O
a	O
certain	O
threshold	O
.	O

Negative	O
indices	O
are	O
interpreted	O
as	O
counting	O
from	O
the	O
end	O
of	O
the	O
array	O

I	O
was	O
using	O
unsigned	O
int	O
indices	O
to	O
speed	O
up	O
access	O
according	O
to	O
:	O
#URL	O

I've	O
tried	O
to	O
vectorise	O
it	O
using	O
numpy	O
but	O
I'm	O
not	O
really	O
sure	O
how	O
to	O
do	O
it	O
given	O
that	O
the	O
matrix	O
/	O
2D	O
array	O
gets	O
changed	O
on	O
each	O
iteration	O
.	O

Numpy	O
slicing	O
x	O
,	O
y	O
,	O
z	O
array	O
for	O
variable	O
z	O

I	O
would	O
like	O
to	O
convert	O
(	O
a	O
more	O
complicated	O
form	O
of	O
)	O
the	O
follwing	O
Matlab	O
code	O
#CODE	O

I	O
have	O
a	O
NumPy	O
array	O
'	O
boolarr	O
'	O
of	O
boolean	O
type	O
.	O

If	O
you	O
have	O
only	O
integers	O
that	O
are	O
between	O
0	O
and	O
n	O
(	O
if	O
not	O
its	O
no	O
problem	O
to	O
generalize	O
to	O
any	O
integer	O
range	O
unless	O
its	O
very	O
sparse	O
)	O
,	O
the	O
most	O
efficient	O
way	O
is	O
the	O
use	O
of	O
take	O
/	O
fancy	O
indexing	O
:	O
#CODE	O

Instead	O
of	O
2D	O
coordinates	O
,	O
I	O
use	O
index	O
for	O
every	O
elements	O
in	O
the	O
matrix	O
.	O

I	O
already	O
tried	O
converting	O
the	O
cols	O
to	O
int	O
but	O
that	O
didn't	O
solve	O
it	O
.	O

Although	O
I'm	O
sure	O
there	O
are	O
methods	O
for	O
applying	O
RK	O
to	O
an	O
equation	O
such	O
as	O
this	O
,	O
I	O
didn't	O
find	O
any	O
evidence	O
of	O
them	O
in	O
_Numerical	O
Recipes_	O
,	O
which	O
I	O
think	O
qualifies	O
that	O
topic	O
as	O
relatively	O
obscure	O
;-)	O

When	O
facing	O
a	O
big	O
computation	O
,	O
it	O
will	O
run	O
tests	O
using	O
several	O
implementations	O
to	O
find	O
out	O
which	O
is	O
the	O
fastest	O
one	O
on	O
our	O
computer	O
at	O
this	O
moment	O
.	O

Use	O
an	O
array	O
of	O
floating	O
point	O
numbers	O
instead	O
.	O

`	O
numpy	O
`	O
slicing	O
operations	O
probably	O
involve	O
`	O
for	O
`	O
loops	O
at	O
some	O
level	O
,	O
but	O
they're	O
implemented	O
in	O
c	O
,	O
and	O
provide	O
a	O
linear	O
time	O
solution	O
for	O
this	O
.	O

I	O
have	O
one	O
question	O
:	O
Is	O
there	O
only	O
one	O
way	O
to	O
do	O
addition	O
of	O
two	O
matrix	O
?	O

@USER	O
It	O
is	O
now	O
supported	O
,	O
at	O
least	O
in	O
my	O
version	O
(	O
1.7.1	O
)	O
.	O

I	O
know	O
I	O
could	O
start	O
a	O
number	O
of	O
times	O
at	O
random	O
locations	O
but	O
I'm	O
not	O
able	O
to	O
do	O
that	O
with	O
what	O
I	O
am	O
currently	O
working	O
on	O
and	O
have	O
to	O
use	O
on	O
of	O
these	O
minimisers	O
out	O
of	O
the	O
box	O
.	O

For	O
small	O
displacements	O
of	O
around	O
4-5	O
pixels	O
,	O
the	O
direction	O
of	O
vector	O
calculated	O
seems	O
to	O
be	O
fine	O
,	O
but	O
the	O
magnitude	O
of	O
the	O
vector	O
is	O
too	O
small	O
(	O
that's	O
why	O
I	O
had	O
to	O
multiply	O
u	O
,	O
v	O
by	O
3	O
before	O
plotting	O
them	O
)	O
.	O

However	O
,	O
I	O
will	O
need	O
to	O
access	O
all	O
waveforms	O
at	O
some	O
point	O
.	O

I've	O
find	O
this	O
:	O
#URL	O
but	O
when	O
I	O
try	O
to	O
install	O
this	O
I	O
get	O
an	O
error	O
:	O
#CODE	O

yes	O
,	O
I	O
can	O
assume	O
either	O
that	O
I	O
have	O
g	O
explicitly	O
or	O
that	O
I	O
can	O
sample	O
x	O
according	O
to	O
g	O
.	O

`	O
example	O
`	O
is	O
a	O
structured	O
array	O
consisting	O
of	O
two	O
elements	O
(	O
`	O
(	O
1	O
,	O
2	O
,	O
3	O
)`	O
and	O
`	O
(	O
4	O
,	O
5	O
,	O
6	O
)`)	O
,	O
each	O
element	O
(	O
or	O
'	O
record	O
')	O
having	O
3	O
fields	O
.	O

If	O
i	O
have	O
two	O
variables	O
-	O
where	O
they	O
either	O
are	O
a	O
1d	O
array	O
of	O
values	O
length	O
n	O
,	O
or	O
are	O
a	O
single	O
value	O
,	O
how	O
do	O
i	O
loop	O
through	O
them	O
so	O
that	O
I	O
get	O
n	O
values	O
returned	O
.	O

For	O
each	O
point	O
in	O
array	O
A	O
,	O
I	O
need	O
to	O
find	O
how	O
many	O
points	O
in	O
array	O
B	O
are	O
within	O
a	O
certain	O
distance	O
of	O
it	O
.	O

It	O
does	O
,	O
but	O
somehow	O
it	O
is	O
8	O
times	O
slower	O
than	O
copying	O
to	O
numpy	O
array	O
:(	O
I	O
suppose	O
the	O
regular	O
python	O
overhead	O
slows	O
things	O
down	O
much	O
more	O
than	O
a	O
copy	O
...	O

It	O
all	O
depends	O
on	O
its	O
dependencies	O
.	O

Is	O
there	O
a	O
way	O
to	O
make	O
an	O
array	O
of	O
such	O
strings	O
?	O

`	O
grid	O
[	O
1	O
]`	O
can	O
be	O
used	O
as	O
a	O
proxy	O
for	O
the	O
index	O
`	O
j	O
`	O
.	O

After	O
doing	O
so	O
,	O
I	O
discovered	O
that	O
if	O
I	O
tried	O
to	O
open	O
the	O
IPython	O
HTML	O
Notebook	O
I	O
got	O
the	O
error	O
message	O
:	O
#CODE	O

(	O
the	O
new	O
matrix	O
would	O
have	O
n-2	O
rows	O
m-2	O
columns	O
)	O
.	O

and	O
duplicate	O
index	O
values	O
at	O
the	O
correpsonding	O
sites	O
within	O

I	O
found	O
that	O
the	O
best	O
way	O
to	O
produce	O
small	O
pdf	O
files	O
is	O
to	O
save	O
as	O
eps	O
in	O
matplotlib	O
and	O
then	O
use	O
epstopdf	O
.	O

You	O
could	O
rearrange	O
the	O
image	O
to	O
put	O
the	O
(	O
0	O
,	O
0	O
)	O
in	O
the	O
middle	O
with	O
some	O
matrix	O
manipulation	O
.	O

Please	O
,	O
see	O
the	O
next	O
example	O
:	O

A	O
function	O
that	O
broadcasts	O
a	O
scalar	O
operation	O
over	O
an	O
array	O
is	O
called	O
a	O
universal	O
function	O
,	O
or	O
ufunc	O
.	O

may	O
not	O
exist	O
until	O
the	O
datasets	O
get	O
quite	O
big	O
(	O
maybe	O
you'll	O
need	O
at	O
least	O
10,000	O
rows	O
per	O
data	O
set	O
)	O
.	O

Magic	O
answers	O
like	O
this	O
are	O
not	O
really	O
helpful	O
because	O
they	O
don't	O
solve	O
the	O
problem	O
.	O

I	O
think	O
what	O
I	O
was	O
missing	O
is	O
that	O
I	O
really	O
have	O
a	O
3	O
dimensional	O
array	O
,	O
48x365x3	O
.	O

I	O
load	O
a	O
some	O
machine	O
learning	O
data	O
from	O
a	O
csv	O
file	O
.	O

So	O
I	O
have	O
it	O
running	O
(	O
or	O
at	O
least	O
that	O
assignment	O
isn't	O
throwing	O
an	O
error	O
and	O
it's	O
compiling	O
)	O
!	O

@USER	O
The	O
first	O
function	O
is	O
taking	O
chunks	O
of	O
200	O
items	O
from	O
your	O
huge	O
array	O
,	O
and	O
copying	O
those	O
chunks	O
to	O
a	O
new	O
,	O
even	O
more	O
ginormous	O
array	O
.	O

@USER	O
:	O
With	O
`	O
where	O
`	O
it	O
looks	O
definitely	O
nice	O
,	O
but	O
have	O
you	O
consider	O
also	O
the	O
implications	O
to	O
performance	O
when	O
implementing	O
with	O
`	O
where	O
`	O
?	O

Anyone	O
any	O
idea	O
what	O
this	O
means	O
?!	O

Assuming	O
you	O
are	O
using	O
g++	O
to	O
compile	O
...	O
have	O
you	O
had	O
different	O
results	O
in	O
any	O
way	O
when	O
experimenting	O
with	O
compiler	O
optimization	O
flags	O
?	O

With	O
the	O
overhead	O
of	O
the	O
data	O
structure	O
you	O
could	O
be	O
looking	O
at	O
usage	O
much	O
higher	O
than	O
that	O
--	O
I	O
can't	O
say	O
how	O
much	O
because	O
I	O
don't	O
know	O
the	O
memory	O
model	O
behind	O
SciPy	O
/	O
numpy	O
.	O

I	O
have	O
serious	O
doubt	O
that	O
adding	O
two	O
numpy	O
arrays	O
is	O
a	O
bottleneck	O
that	O
you	O
can	O
solve	O
rewriting	O
things	O
in	O
C	O
.	O

Where	O
exactly	O
is	O
the	O
error	O
occurring	O
?	O

I	O
frequently	O
convert	O
16-bit	O
grayscale	O
image	O
data	O
to	O
8-b	O
it	O
image	O
data	O
for	O
display	O
.	O

Reduce	O
it	O
to	O
a	O
1	O
/	O
10	O
resolution	O
,	O
find	O
the	O
one	O
white	O
pixel	O
,	O
and	O
then	O
you	O
have	O
a	O
precise	O
idea	O
of	O
where	O
to	O
search	O
for	O
the	O
centroid	O
.	O

I	O
ran	O
a	O
test	O
to	O
compare	O
the	O
times	O
,	O
and	O
found	O
that	O
my	O
method	O
is	O
faster	O
by	O
quite	O
a	O
bit	O
,	O
but	O
Freddie	O
Witherdon	O
'	O
s	O
suggestion	O
is	O
even	O
faster	O
.	O

I	O
couldn't	O
find	O
it	O
in	O
the	O
OLS	O
recipe	O
(	O
#URL	O
)	O
.	O

convert	O
binary	O
string	O
to	O
numpy	O
array	O

How	O
to	O
know	O
where	O
warning	O
come	O
from	O
in	O
Python	O

