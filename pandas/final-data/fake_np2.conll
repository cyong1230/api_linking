I	O
haven't	O
checked	O
any	O
of	O
the	O
details	O
and	O
you	O
should	O
therefore	O
not	O
rely	O
on	O
it	O
to	O
be	O
correct	O
.	O

You	O
can	O
access	O
members	O
and	O
slices	O
of	O
the	O
array	O
as	O
you	O
would	O
with	O
normal	O
numpy	O
arrays	O
.	O

Running	O
1000	O
simulations	O
at	O
the	O
same	O
time	O
might	O
be	O
a	O
bit	O
expensive	O
though	O
.	O

I	O
need	O
to	O
look	O
at	O
other	O
formats	O
that	O
allow	O
create	O
.	O

finding	O
element	O
of	O
numpy	O
array	O
that	O
satisfies	O
condition	O

All	O
the	O
results	O
(	O
percentage	O
)	O
are	O
the	O
comparison	O
between	O
the	O
described	O
condition	O
and	O
the	O
reference	O
which	O
here	O
is	O
the	O
packaged	O
ATLAS	O
library	O
.	O

how	O
do	O
you	O
use	O
`	O
slicing	O
`	O
to	O
extract	O
something	O
from	O
`	O
x	O
`	O
?	O

Mapping	O
a	O
numpy	O
array	O
pairwise	O

If	O
that	O
is	O
all	O
you	O
want	O
to	O
do	O
,	O
it	O
should	O
just	O
work	O
otherwise	O
look	O
at	O
#URL	O
since	O
subclassing	O
an	O
array	O
is	O
not	O
that	O
simple	O
.	O

If	O
you	O
want	O
to	O
access	O
an	O
individual	O
element	O
using	O
2D	O
notation	O
,	O
you	O
can	O
create	O
a	O
view	O
and	O
work	O
with	O
that	O
.	O

Regarding	O
3	O
,	O
I	O
don't	O
think	O
this	O
would	O
be	O
necessary	O
since	O
the	O
above	O
trick	O
can	O
also	O
be	O
applied	O
to	O
an	O
array	O
allocated	O
by	O
`	O
shmarray	O
`	O
.	O

And	O
here	O
a	O
list	O
with	O
the	O
names	O
of	O
all	O
distribution	O
functions	O
available	O
in	O
Scipy	O
0.12.0	O
(	O
VI	O
):	O
#CODE	O

I	O
get	O
this	O
error	O
whenever	O
i	O
try	O
to	O
use	O
any	O
functions	O
of	O
matplotlib	O
such	O
as	O
graph	O
etc	O
...	O

Numpy	O
is	O
designed	O
for	O
repeated	O
application	O
of	O
the	O
exact	O
same	O
operation	O
in	O
parallel	O
across	O
an	O
array	O
.	O

Each	O
B	O
i	O
is	O
a	O
`	O
k	O
`	O
-by-	O
`	O
n	O
`	O
matrix	O
.	O

I	O
created	O
a	O
copy	O
of	O
the	O
initial	O
array	O
in	O
the	O
hope	O
that	O
it	O
would	O
sort	O
it	O
out	O
but	O
it	O
still	O
doesn't	O
work	O
!	O

So	O
far	O
,	O
all	O
the	O
solutions	O
I	O
found	O
required	O
converting	O
to	O
IPLImage	O
.	O

However	O
,	O
I	O
haven't	O
tested	O
this	O
very	O
systematically	O
,	O
and	O
it's	O
likely	O
that	O
for	O
smaller	O
matrices	O
the	O
additional	O
overhead	O
would	O
outweigh	O
the	O
performance	O
benefit	O
from	O
a	O
higher	O
thread	O
count	O
.	O

but	O
why	O
dimA+dimB	O
to	O
begin	O
with	O
,	O
that	O
just	O
leaves	O
you	O
0s	O
at	O
the	O
end	O
.	O

If	O
you	O
select	O
a	O
list	O
of	O
actual	O
fitness	O
entries	O
,	O
`	O
indices	O
`	O
,	O
the	O
corresponding	O
points	O
are	O
given	O
by	O
`	O
A	O
[	O
'	O
point	O
']	O
[	O
indices	O
]`	O
,	O
which	O
is	O
a	O
simple	O
`	O
(	O
n	O
,	O
3	O
)`	O
array	O
.	O

It's	O
also	O
possible	O
to	O
generate	O
an	O
array	O
of	O
indices	O
without	O
using	O
`	O
enumerate	O
`	O
.	O

If	O
you	O
want	O
to	O
keep	O
the	O
array	O
allocated	O
,	O
and	O
with	O
the	O
same	O
size	O
,	O
you	O
don't	O
need	O
to	O
clear	O
the	O
elements	O
.	O

It'll	O
print	O
out	O
all	O
methods	O
and	O
properties	O
of	O
the	O
object	O
.	O

Search	O
numpy	O
array	O
inside	O
numpy	O
array	O

Assigning	O
a	O
view	O
to	O
a	O
structured	O
array	O
also	O
copies	O
the	O
data	O
,	O
soyour	O
suggestion	O
doesnt	O
work	O
.	O

If	O
you	O
know	O
there	O
are	O
not	O
many	O
different	O
values	O
(	O
relative	O
to	O
the	O
size	O
of	O
the	O
input	O
"	O
itemArray	O
")	O
,	O
something	O
like	O
this	O
could	O
be	O
efficient	O
:	O
#CODE	O

When	O
I	O
import	O
numpy	O
in	O
a	O
script	O
,	O
I	O
don't	O
have	O
all	O
the	O
functions	O
of	O
numpy	O
available	O
,	O
only	O
few	O
of	O
them	O
(	O
not	O
a	O
lot	O
,	O
and	O
not	O
array	O
)	O
?	O

It	O
allows	O
to	O
have	O
your	O
custom	O
system	O
inside	O
the	O
home	O
directory	O
accessible	O
via	O
proot	O
and	O
,	O
therefore	O
,	O
you	O
can	O
install	O
any	O
packages	O
without	O
root	O
privileges	O
.	O

Hey	O
,	O
is	O
there	O
an	O
optimal	O
size	O
for	O
a	O
block	O
?	O

Numpy	O
array	O
,	O
how	O
to	O
select	O
indices	O
satisfying	O
multiple	O
conditions	O
?	O

I'm	O
still	O
learning	O
git	O
and	O
this	O
whole	O
open	O
source	O
thing	O
.	O

A	O
further	O
problem	O
is	O
that	O
a	O
list	O
index	O
can't	O
contain	O
duplicates	O
-	O
I	O
couldn't	O
simultaneously	O
read	O
pixels	O
`	O
[	O
1	O
,	O
2	O
]`	O
and	O
`	O
[	O
1	O
,	O
3	O
]`	O
,	O
since	O
my	O
list	O
of	O
pixel	O
x-coordinates	O
would	O
contain	O
`	O
[	O
1	O
,	O
1	O
]`	O
.	O

Your	O
interpretation	O
is	O
,	O
of	O
course	O
,	O
quite	O
correct	O
:	O
`	O
count	O
`	O
refers	O
to	O
the	O
number	O
of	O
elements	O
in	O
the	O
`	O
float*	O
`	O
"	O
array	O
"	O
.	O

This	O
all	O
works	O
.	O

Of	O
course	O
it	O
may	O
_not_	O
be	O
acceptable	O
,	O
but	O
it	O
seemed	O
like	O
it	O
was	O
at	O
least	O
trying	O
.	O

I	O
think	O
what	O
should	O
happen	O
is	O
for	O
R	O
to	O
be	O
overwritten	O
with	O
an	O
upper	O
triangular	O
matrix	O
.	O

@USER	O
Is	O
there	O
a	O
way	O
to	O
get	O
it	O
to	O
return	O
all	O
possible	O
solutions	O
?	O

Thank	O
you	O
all	O
for	O
some	O
great	O
insight	O
!	O

as	O
numpy	O
array	O
of	O
0	O
and	O
1	O
values	O
.	O

By	O
construction	O
of	O
the	O
problem	O
,	O
there	O
can	O
not	O
be	O
any	O
non-unique	O
values	O
lying	O
within	O
one	O
another	O
.	O

Both	O
functions	O
are	O
kind	O
of	O
equal	O
,	O
but	O
are	O
different	O
.	O

For	O
a	O
sparse	O
csr	O
matrix	O
(	O
X	O
)	O
and	O
a	O
list	O
of	O
indices	O
to	O
drop	O
(	O
index_to_drop	O
):	O
#CODE	O

This	O
will	O
be	O
relatively	O
slow	O
,	O
and	O
requires	O
you	O
to	O
have	O
twice	O
the	O
free	O
memory	O
space	O
required	O
to	O
store	O
the	O
array	O
.	O

I	O
need	O
numpy	O
for	O
this	O
because	O
I	O
don't	O
want	O
to	O
loop	O
through	O
the	O
array	O
n-times	O
for	O
n	O
groups	O
,	O
since	O
my	O
array	O
sizes	O
can	O
be	O
arbitrarily	O
large	O
.	O

I	O
wonder	O
what	O
the	O
speed	O
delta	O
between	O
native	O
Numpy	O
arrays	O
and	O
an	O
`	O
mpfr	O
`	O
array	O
,	O
seeing	O
as	O
`	O
mpfr	O
`	O
is	O
a	O
relatively	O
low-level	O
C	O
wrapper	O
class	O
.	O

In	O
this	O
particular	O
case	O
,	O
each	O
1D	O
column	O
(	O
`	O
column	O
=	O
myarray	O
[	O
i	O
,	O
j	O
,	O
:]	O
`)	O
of	O
the	O
3D	O
array	O
can	O
be	O
treated	O
independently	O
.	O

Any	O
ideas	O
?	O

Then	O
take	O
element	O
3	O
and	O
1	O
from	O
second	O
row	O
,	O
etc	O
.	O

print	O
len	O
(	O
index	O
)	O

I	O
don't	O
know	O
how	O
to	O
label	O
rows	O
and	O
columns	O
in	O
numpy	O
,	O
so	O
I	O
just	O
made	O
a	O
dict	O
mapping	O
the	O
row	O
label	O
to	O
the	O
row	O
index	O
and	O
another	O
doing	O
the	O
same	O
for	O
the	O
columns	O
.	O

It's	O
the	O
same	O
as	O
a	O
normal	O
solve	O
except	O
I	O
know	O
some	O
of	O
the	O
solution	O
to	O
begin	O
with	O
.	O

yeah	O
,	O
this	O
is	O
the	O
best	O
answer	O
anywhere	O
where	O
edge	O
cases	O
are	O
important	O
.	O

With	O
this	O
,	O
I	O
solve	O
the	O
problem	O
(	O
may	O
help	O
you	O
):	O
#CODE	O

Teach	O
a	O
man	O
to	O
fish	O
and	O
all	O
that	O
.	O

Looks	O
like	O
this	O
would	O
be	O
a	O
good	O
place	O
to	O
use	O
a	O
context	O
manager	O
,	O
so	O
you	O
can	O
say	O
"	O
with	O
fullprint	O
"	O
.	O

What	O
do	O
you	O
mean	O
by	O
'	O
random	O
sort	O
'	O
?	O

However	O
,	O
it	O
indeed	O
does	O
not	O
allow	O
you	O
to	O
exponentiate	O
any	O
matrix	O
directly	O
:	O
#CODE	O

The	O
first	O
one	O
would	O
probably	O
be	O
slow	O
for	O
large	O
data	O
,	O
and	O
the	O
second	O
one	O
does	O
not	O
seem	O
to	O
offer	O
any	O
other	O
interpolation	O
method	O
except	O
splines	O
.	O

EDIT	O
:	O
For	O
the	O
record	O
,	O
here	O
is	O
example	O
code	O
that	O
demonstrates	O
the	O
issue	O
:	O
#CODE	O

In	O
terms	O
of	O
functionality	O
,	O
it's	O
not	O
a	O
metaclass	O
at	O
all	O
,	O
it's	O
a	O
function	O
which	O
takes	O
a	O
class	O
(	O
along	O
with	O
some	O
others	O
stuff	O
)	O
and	O
returns	O
a	O
new	O
class	O
.	O

or	O
from	O
source	O
#CODE	O

Didn't	O
do	O
any	O
timings	O
here	O
,	O
but	O
it's	O
possible	O
this	O
version	O
has	O
reasonable	O
performance	O
.	O

I'll	O
just	O
test	O
whether	O
or	O
not	O
there's	O
a	O
significan	O
space	O
gain	O
on	O
my	O
data	O
with	O
protocol	O
2	O
.	O

Just	O
wanted	O
to	O
add	O
that	O
the	O
moving	O
average	O
function	O
has	O
been	O
extracted	O
into	O
the	O
[	O
Bottleneck	O
]	O
(	O
#URL	O
)	O
library	O
if	O
pandas	O
seems	O
too	O
heavyweight	O
as	O
a	O
dependency	O
.	O

`	O
numpy	O
`	O
can	O
use	O
`	O
malloc	O
`	O
/	O
`	O
realloc	O
`	O
for	O
creating	O
an	O
array	O
of	O
objects	O
of	O
`	O
sizeof	O
(	O
int	O
)`	O
.	O

If	O
you	O
read	O
through	O
the	O
documentation	O
of	O
those	O
engines	O
you	O
will	O
often	O
find	O
statements	O
saying	O
that	O
they	O
are	O
optimized	O
for	O
speed	O
(	O
30fps	O
-	O
60fps	O
)	O
.	O

I	O
know	O
I	O
have	O
to	O
look	O
at	O
each	O
row	O
,	O
but	O
I	O
don't	O
want	O
to	O
do	O
it	O
with	O
loops	O
.	O

I'm	O
hoping	O
this	O
can	O
at	O
least	O
save	O
someone	O
a	O
few	O
hours	O
of	O
hopeless	O
research	O
for	O
this	O
topic	O
.	O

What	O
does	O
"	O
doesn't	O
work	O
"	O
mean	O
?	O

You	O
might	O
look	O
at	O
your	O
code	O
that	O
generates	O
the	O
`	O
y	O
`	O
values	O
,	O
and	O
see	O
if	O
that	O
would	O
benefit	O
from	O
the	O
use	O
of	O
additional	O
numpy	O
or	O
scipy	O
functions	O
.	O

For	O
example	O
,	O
give	O
the	O
list	O
[	O
(	O
.3	O
,	O
'	O
a	O
')	O
,	O
(	O
.4	O
,	O
'	O
b	O
')	O
,	O
(	O
.3	O
,	O
'	O
c	O
')]	O
I'd	O
like	O
to	O
sample	O
'	O
b	O
'	O
40%	O
of	O
the	O
time	O
.	O

The	O
square	O
bracket	O
idea	O
you	O
mentioned	O
works	O
for	O
my	O
current	O
problem	O
.	O

However	O
,	O
when	O
I	O
try	O
to	O
use	O
a	O
weighted	O
average	O
#CODE	O

If	O
I	O
scale	O
that	O
to	O
a	O
2000	O
X	O
2000	O
np	O
array	O
,	O
here	O
is	O
what	O
I	O
get	O
:	O
#CODE	O

Unfortunately	O
,	O
I'm	O
not	O
aware	O
of	O
a	O
numpy	O
implementation	O
,	O
but	O
I	O
did	O
find	O
this	O
:	O
#URL	O

We	O
can	O
do	O
this	O
quite	O
neatly	O
using	O
numpy	O
,	O
without	O
having	O
to	O
worry	O
about	O
the	O
channels	O
at	O
all	O
!	O

It's	O
not	O
exactly	O
the	O
most	O
efficient	O
way	O
,	O
but	O
it	O
will	O
work	O
,	O
and	O
not	O
require	O
keeping	O
a	O
copy	O
of	O
the	O
file	O
in	O
memory	O
(	O
or	O
two	O
)	O
.	O

I'm	O
trying	O
to	O
find	O
the	O
fastest	O
way	O
to	O
find	O
the	O
first	O
non-zero	O
value	O
for	O
each	O
row	O
of	O
a	O
two	O
dimensional	O
sorted	O
array	O
.	O

Convert	O
the	O
numpy	O
array	O
into	O
a	O
list	O
first	O
.	O

@USER	O
do	O
you	O
mean	O
that	O
grid	O
dictonary	O
holds	O
the	O
results	O
in	O
memory	O
or	O
something	O
else	O
?	O

@USER	O
:	O
This	O
solution	O
is	O
indeed	O
designed	O
to	O
give	O
the	O
set	O
of	O
all	O
the	O
numbers	O
found	O
in	O
the	O
array	O
.	O

This	O
way	O
at	O
most	O
one	O
line	O
is	O
in	O
memory	O
at	O
any	O
one	O
time	O
.	O

It's	O
low	O
efficiency	O
,	O
I	O
want	O
to	O
know	O
are	O
there	O
any	O
builtin	O
functions	O
that	O
can	O
do	O
this	O
in	O
NumPy	O
.	O

The	O
raw	O
hardware	O
data	O
is	O
32-bit	O
signed	O
integer	O
,	O
which	O
becomes	O
float	O
when	O
I	O
convert	O
it	O
to	O
normal	O
physics	O
units	O
(	O
m	O
/	O
s	O
)	O

Calculate	O
subset	O
of	O
matrix	O
multiplication	O

EDIT	O
:	O
as	O
to	O
what	O
DSM	O
pointed	O
out	O
,	O
OP	O
is	O
infact	O
using	O
a	O
numpy	O
array	O
.	O

As	O
for	O
the	O
second	O
question	O
,	O
`	O
delete	O
`	O
has	O
been	O
suggested	O
before	O
:	O
#CODE	O

The	O
remaining	O
rows	O
of	O
the	O
matrices	O
are	O
all	O
linear	O
combinations	O
(	O
in	O
fact	O
exact	O
copies	O
for	O
almost	O
all	O
submatrices	O
)	O
of	O
these	O
rows	O
.	O

I'm	O
printing	O
the	O
contents	O
of	O
an	O
array	O
with	O
a	O
header	O
.	O

Edit	O
:	O
If	O
you	O
need	O
to	O
save	O
memory	O
try	O
radix	O
sort	O
,	O
which	O
is	O
much	O
faster	O
on	O
integers	O
than	O
quicksort	O
(	O
which	O
I	O
believe	O
is	O
what	O
numpy	O
uses	O
)	O
.	O

The	O
data	O
was	O
in	O
following	O
order	O
(	O
with	O
sample	O
data	O
)	O
#CODE	O

definitely	O
a	O
good	O
solution	O
,	O
nevertheless	O
I'd	O
like	O
to	O
solve	O
this	O
without	O
a	O
range	O
,	O
but	O
the	O
nearest	O
neighbour	O
.	O

For	O
my	O
recent	O
project	O
that	O
works	O
on	O
the	O
order	O
of	O
20000x20000	O
matrix	O
entries	O
,	O
I	O
will	O
quickly	O
and	O
disastrously	O
use	O
up	O
all	O
of	O
my	O
workstation's	O
8GB	O
of	O
RAM	O
and	O
more	O
.	O

Well	O
,	O
this	O
might	O
give	O
a	O
small	O
speed-up	O
just	O
because	O
it	O
uses	O
less	O
memory	O
.	O

Try	O
using	O
`	O
all	O
`	O
(	O
edited	O
to	O
return	O
`	O
int	O
`)	O
:	O
#CODE	O

:	O
I	O
don't	O
care	O
if	O
the	O
statement	O
modifies	O
array	O
or	O
not	O
.	O

Rather	O
than	O
doing	O
nans	O
I	O
put	O
in	O
-1	O
and	O
then	O
filtered	O
on	O
match	O
=	O
b	O
>	O
=	O
0	O
.	O

Removing	O
duplicate	O
columns	O
and	O
rows	O
from	O
a	O
NumPy	O
2D	O
array	O

arrays	O
to	O
extract	O
arrays	O
of	O
the	O
same	O

as	O
i	O
have	O
to	O
test	O
if	O
it	O
works	O
or	O
not	O
so	O
minimum	O
i	O
have	O
to	O
try	O
with	O
10-15	O
different	O
types	O
of	O
images	O
.	O
its	O
not	O
specific	O
images	O
it	O
can	O
be	O
any	O
image	O
of	O
people	O
.	O

So	O
having	O
a	O
python	O
loop	O
,	O
and	O
having	O
to	O
sum	O
all	O
the	O
results	O
together	O
,	O
is	O
taking	O
390	O
ms	O
more	O
than	O
200	O
times	O
what	O
it	O
takes	O
to	O
solve	O
each	O
of	O
the	O
200	O
systems	O
that	O
have	O
to	O
be	O
solved	O
.	O

You	O
could	O
then	O
sample	O
pixels	O
at	O
the	O
locations	O
of	O
the	O
new	O
points	O
.	O

I	O
could	O
use	O
an	O
idea	O
about	O
either	O
how	O
to	O
fix	O
the	O
compilation	O
errors	O
or	O
another	O
way	O
to	O
convert	O
my	O
python	O
objects	O
.	O

I	O
tried	O
every	O
possible	O
combination	O
resulting	O
with	O
a	O
0	O
bytes	O
file	O
if	O
the	O
extension	O
was	O
mpg	O
,	O
and	O
5.5kb	O
if	O
it	O
was	O
avi	O
.	O

Fortran	O
90	O
DOES	O
support	O
arbitrary	O
lower	O
bounds	O
on	O
arrays	O
,	O
and	O
borrowing	O
from	O
that	O
paradigm	O
sounds	O
quite	O
plausible	O
.	O

I	O
want	O
to	O
perform	O
an	O
operation	O
on	O
a	O
that	O
increments	O
all	O
the	O
values	O
inside	O
it	O
that	O
are	O
less	O
than	O
0	O
and	O
leaves	O
the	O
rest	O
alone	O
.	O
for	O
example	O
,	O
if	O
I	O
had	O
:	O
#CODE	O

I	O
like	O
how	O
this	O
one	O
uses	O
straight	O
python	O
slicing	O
and	O
doesn't	O
require	O
numpy	O

I	O
select	O
the	O
first	O
value	O
using	O
`	O
ys	O
[	O
0	O
]`	O
.	O

While	O
waiting	O
for	O
the	O
next	O
buffer	O
to	O
fill	O
,	O
I'd	O
like	O
to	O
process	O
the	O
most	O
recent	O
buffer	O
with	O
numpy	O
and	O
save	O
the	O
result	O
.	O

(	O
They	O
all	O
do	O
the	O
same	O
thing	O
,	O
in	O
this	O
case	O
.	O
)	O

As	O
of	O
PIL	O
1.1.6	O
,	O
the	O
"	O
proper	O
"	O
way	O
to	O
convert	O
between	O
images	O
and	O
numpy	O
arrays	O
is	O
simply	O
#CODE	O

So	O
first	O
you	O
need	O
to	O
construct	O
an	O
array	O
that	O
represents	O
the	O
rows	O
you	O
wish	O
to	O
select	O
.	O

Any	O
ideas	O
how	O
to	O
improve	O
this	O
?	O

If	O
this	O
is	O
the	O
case	O
,	O
you	O
can	O
easily	O
plot	O
a	O
known	O
asymmetric	O
shape	O
and	O
the	O
plot	O
will	O
tell	O
you	O
everything	O
.	O

Apart	O
from	O
the	O
compression	O
part	O
,	O
this	O
shouldn't	O
be	O
any	O
slower	O
than	O
normal	O
.	O

Acquiring	O
the	O
Minimum	O
array	O
out	O
of	O
Multiple	O
Arrays	O
by	O
order	O
in	O
Python	O

first	O
copy	O
#CODE	O

Getting	O
all	O
points	O
where	O
y=2	O
.	O

moving	O
average	O
function	O
on	O
numpy	O
/	O
scipy	O
?	O

for	O
a	O
N	O
dimensional	O
array	O
:	O
#CODE	O

From	O
looking	O
at	O
#URL	O
it	O
seems	O
that	O
it	O
was	O
originally	O
required	O
because	O
indexing	O
with	O
`	O
...	O

In	O
other	O
words	O
...	O
yes	O
you	O
can	O
trust	O
it	O
to	O
be	O
faster	O
...	O
but	O
don't	O
think	O
python	O
is	O
that	O
slow	O
that	O
you	O
cannot	O
do	O
a	O
for	O
loop	O
over	O
3	O
items	O
without	O
waiting	O
for	O
ages	O
...	O

And	O
all	O
that	O
while	O
you're	O
getting	O
lunch	O
.	O

If	O
you	O
do	O
want	O
to	O
raise	O
some	O
sort	O
of	O
exception	O
for	O
invalid	O
data	O
(	O
not	O
type	O
checking	O
)	O
,	O
either	O
let	O
an	O
existing	O
exception	O
propagate	O
,	O
or	O
wrap	O
it	O
in	O
your	O
own	O
exception	O
type	O
.	O

casting	O
are	O
used	O
in	O
Numexpr	O
,	O
in	O
contrast	O
with	O
NumPy	O
,	O
where	O
array	O
types	O

I	O
check	O
mathexchange	O
and	O
while	O
making	O
the	O
tags	O
for	O
the	O
post	O
,	O
it	O
didn't	O
have	O
any	O
the	O
ones	O
that	O
would	O
seem	O
relevant	O
like	O
scipy	O
and	O
numpy	O
or	O
even	O
sparse	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
.	O

Say	O
not	O
that	O
efficiency	O
is	O
a	O
secondary	O
priority	O
;	O
say	O
instead	O
that	O
I	O
want	O
to	O
perform	O
bivariate	O
optimization	O
:	O
pythonicity	O
+	O
efficiency	O
(	O
hence	O
the	O
post	O
title	O
)	O
.	O

Does	O
numpy	O
have	O
any	O
constructs	O
to	O
make	O
this	O
easier	O
?	O

If	O
you	O
view	O
`	O
P	O
`	O
as	O
a	O
rank-2	O
tensor	O
then	O
only	O
three	O
options	O
exist	O
for	O
the	O
product	O
of	O
`	O
P	O
`	O
with	O
itself	O
,	O
1	O
)	O
either	O
all	O
the	O
indexes	O
cancel	O
leaving	O
you	O
with	O
a	O
rank-0	O
tensor	O
(	O
a	O
scalar	O
)	O
,	O
2	O
)	O
1	O
set	O
of	O
indexes	O
cancels	O
and	O
you	O
are	O
left	O
with	O
a	O
rank-2	O
tensor	O
(	O
a	O
matrix	O
)	O
,	O
or	O
3	O
)	O
none	O
of	O
them	O
cancel	O
and	O
you're	O
left	O
with	O
a	O
rank-4	O
tensor	O
.	O

At	O
the	O
moment	O
I	O
made	O
a	O
custom	O
iterator	O
class	O
that	O
builds	O
a	O
list	O
of	O
lists	O
.	O

This	O
basically	O
sees	O
whether	O
two	O
circles	O
(	O
with	O
coordinates	O
that	O
correspond	O
to	O
the	O
indices	O
n	O
and	O
m	O
)	O
connect	O
.	O

It	O
would	O
mean	O
Gaussian	O
quadrature	O
using	O
points	O
along	O
the	O
line	O
that	O
are	O
easily	O
evaluated	O
.	O

I	O
see	O
one	O
potential	O
problem	O
-	O
beta	O
is	O
defined	O
as	O
1-dimensional	O
,	O
but	O
its	O
value	O
is	O
given	O
as	O
2-dimensional	O
(	O
dimensions	O
of	O
size	O
1	O
still	O
count	O
as	O
dimensions	O
)	O

Can	O
you	O
provide	O
an	O
algorithm	O
for	O
computing	O
them	O
based	O
on	O
block	O
size	O
?	O

If	O
`	O
X	O
`	O
is	O
your	O
array	O
,	O
#CODE	O

You	O
could	O
cast	O
the	O
array	O
to	O
a	O
list	O
:	O
#CODE	O

But	O
if	O
you	O
for	O
example	O
self	O
compiled	O
from	O
the	O
development	O
version	O
an	O
update	O
may	O
fix	O
most	O
of	O
it	O
.	O

In	O
VTK	O
I	O
am	O
able	O
to	O
use	O
the	O
following	O
snippet	O
to	O
save	O
the	O
render	O
window	O
as	O
an	O
image	O
.	O

In	O
other	O
words	O
,	O
the	O
4th	O
row	O
in	O
A_sorted	O
was	O
the	O
1st	O
row	O
in	O
the	O
original	O
array	O
,	O
A	O
,	O
etc	O
.	O

Add	O
a	O
`	O
return	O
`	O
statement	O
at	O
the	O
end	O
of	O
the	O
method	O
.	O

However	O
,	O
with	O
different	O
input	O
sizes	O
,	O
using	O
fft's	O
to	O
do	O
a	O
convolution	O
can	O
be	O
considerably	O
faster	O
(	O
Though	O
I	O
can't	O
seem	O
to	O
come	O
up	O
with	O
a	O
good	O
example	O
,	O
at	O
the	O
moment	O
...	O
)	O
.	O

That	O
is	O
a	O
shallow	O
copy	O
...	O

@USER	O
The	O
solutions	O
there	O
all	O
make	O
use	O
of	O
the	O
fact	O
that	O
only	O
a	O
3x3	O
sliding	O
window	O
is	O
needed	O
,	O
but	O
I	O
need	O
something	O
that	O
works	O
for	O
all	O
sizes	O
of	O
templates	O
.	O

A	O
masked	O
array	O
is	O
useful	O
here	O
:	O
#CODE	O

Second	O
I	O
would	O
like	O
it	O
to	O
be	O
easily	O
expandable	O
,	O
that	O
I	O
can	O
add	O
new	O
functions	O
easily	O
.	O

If	O
i	O
have	O
two	O
variables	O
-	O
where	O
they	O
either	O
are	O
a	O
1d	O
array	O
of	O
values	O
length	O
n	O
,	O
or	O
are	O
a	O
single	O
value	O
,	O
how	O
do	O
i	O
loop	O
through	O
them	O
so	O
that	O
I	O
get	O
n	O
values	O
returned	O
.	O

I	O
think	O
masked	O
arrays	O
have	O
been	O
in	O
numpy	O
for	O
a	O
few	O
years	O
now	O
.	O

I	O
have	O
an	O
array	O
defined	O
in	O
this	O
way	O
(	O
extracting	O
the	O
third	O
column	O
of	O
a	O
dataset	O
):	O
#CODE	O

I	O
wasn't	O
aware	O
of	O
the	O
option	O
of	O
using	O
`	O
data	O
[	O
list	O
]`	O
to	O
select	O
multiple	O
columns	O
.	O

Beware	O
that	O
if	O
the	O
type	O
of	O
the	O
output	O
array	O
is	O

Any	O
ideas	O
how	O
I	O
would	O
do	O
this	O
calculation	O
in	O
a	O
simpler	O
way	O
?	O

Those	O
take	O
up	O
about	O
15MB	O
of	O
space	O
which	O
,	O
considering	O
that	O
I	O
get	O
about	O
1000	O
result	O
files	O
in	O
a	O
series	O
,	O
is	O
unacceptable	O
to	O
save	O
.	O

I'm	O
trying	O
to	O
implement	O
a	O
logic	O
where	O
I'm	O
trying	O
to	O
subtract	O
each	O
element	O
of	O
an	O
array	O
from	O
every	O
other	O
element	O
of	O
the	O
array	O
and	O
then	O
find	O
the	O
minimum	O
difference	O
of	O
the	O
result	O
.	O

My	O
final	O
matrix	O
should	O
have	O
5416	O
rows	O
with	O
500	O
000	O
column	O
each	O
.	O

I	O
am	O
attempting	O
to	O
process	O
data	O
saved	O
to	O
CSV	O
that	O
may	O
have	O
missing	O
values	O
in	O
an	O
unknown	O
number	O
of	O
columns	O
(	O
up	O
to	O
around	O
30	O
)	O
.	O

Actually	O
the	O
surprise	O
is	O
still	O
hidden	O
in	O
a	O
way	O
,	O
because	O
in	O
your	O
examples	O
`	O
a	O
[	O
indices	O
]`	O
is	O
the	O
same	O
as	O
`	O
a	O
[	O
indices	O
[	O
0	O
]	O
,	O
indicies	O
[	O
1	O
]]`	O
but	O
`	O
a	O
[	O
indicies	O
,	O
:]	O
`	O
is	O
`	O
a	O
[(	O
indicies	O
[	O
0	O
]	O
,	O
indicies	O
[	O
1	O
])	O
,	O
:]	O
`	O
which	O
is	O
not	O
a	O
big	O
surprise	O
that	O
it	O
is	O
different	O
.	O

Slice	O
numpy	O
array	O
wth	O
list	O
of	O
wanted	O
rows	O

Here	O
is	O
a	O
slightly	O
more	O
complex	O
version	O
that	O
always	O
returns	O
a	O
view	O
into	O
the	O
original	O
array	O
(	O
of	O
course	O
provided	O
that	O
you	O
don't	O
do	O
any	O
advanced	O
indexing	O
;	O
this	O
should	O
be	O
guaranteed	O
by	O
your	O
specification	O
of	O
valid	O
indices	O
):	O
#CODE	O

If	O
the	O
array	O
is	O
one-dimensional	O
,	O
this	O
means	O
it	O
has	O
no	O
effect	O
.	O

The	O
problem	O
with	O
using	O
`	O
view	O
`	O
,	O
however	O
,	O
is	O
that	O
a	O
32-bit	O
integer	O
becomes	O
viewed	O
as	O
4	O
8-b	O
it	O
integers	O
,	O
and	O
we	O
only	O
care	O
about	O
the	O
value	O
in	O
the	O
last	O
8-b	O
its	O
.	O

So	O
this	O
won't	O
solve	O
OP's	O
question	O
(	O
unless	O
his	O
nD	O
is	O
2	O
or	O
3	O
)	O
.	O

Note	O
:	O
this	O
was	O
meant	O
as	O
a	O
comment	O
,	O
not	O
an	O
answer	O
...	O
just	O
needed	O
more	O
room	O
to	O
put	O
in	O
the	O
example	O
above	O
.	O

If	O
I	O
wanted	O
to	O
change	O
the	O
data	O
type	O
of	O
a	O
numpy	O
array	O
permanently	O
,	O
is	O
reassignment	O
the	O
best	O
way	O
?	O

The	O
shifted	O
shm-allocated	O
array	O
is	O
indeed	O
accessible	O
from	O
other	O
processes	O
.	O

The	O
second	O
solution	O
you	O
propose	O
is	O
better	O
from	O
that	O
point	O
of	O
view	O
.	O

It	O
checks	O
for	O
nans	O
and	O
empty	O
input	O
strings	O
.	O

The	O
ability	O
to	O
extract	O
columns	O
and	O
rows	O
by	O
header	O
name	O
(	O
as	O
in	O
the	O
above	O
example	O
)	O

With	O
Python	O
2.6.5	O
or	O
Python	O
2.7	O
,	O
and	O
Numpy	O
1.5.0	O
,	O
I	O
don't	O
get	O
any	O
error	O
.	O

Returns	O
a	O
boolean	O
array	O
the	O
same	O
length	O
as	O
`	O
ar1	O
`	O
that	O
is	O
True	O

If	O
the	O
objects	O
in	O
the	O
array	O
are	O
not	O
fixed	O
size	O
(	O
such	O
as	O
your	O
MultiEvent	O
)	O
the	O
operations	O
can	O
become	O
much	O
slower	O
.	O

@USER	O
:	O
True	O
the	O
code	O
I	O
gave	O
would	O
not	O
be	O
all	O
the	O
efficient	O

You	O
print	O
`	O
Length	O
of	O
together	O
2708000000	O
`	O
-	O
where	O
is	O
that	O
`	O
print	O
`	O
statement	O
in	O
your	O
code	O
?	O

Is	O
there	O
a	O
way	O
to	O
copy	O
just	O
the	O
reference	O
to	O
b	O
,	O
so	O
that	O
when	O
I	O
change	O
b	O
,	O
the	O
change	O
is	O
reflected	O
in	O
`	O
a	O
[	O
'	O
B	O
']	O
[	O
i	O
]`	O
?	O

If	O
the	O
matrix	O
is	O
not	O
symmetric	O
be	O
careful	O
about	O
the	O
order	O
in	O
dot	O
.	O

So	O
I	O
changed	O
the	O
"	O
array	O
"	O
to	O
matrix	O
.	O

config	O
paths	O
,	O
cflags	O
.	O

gnibbler	O
:	O
That	O
completely	O
misses	O
the	O
point	O
of	O
the	O
algorithm	O
,	O
this	O
is	O
a	O
simple	O
example	O
,	O
what	O
I	O
am	O
doing	O
is	O
Gauss-Seidel	O
iteration	O
,	O
which	O
infers	O
information	O
about	O
a	O
location	O
in	O
a	O
matrix	O
by	O
using	O
data	O
that	O
has	O
already	O
been	O
inferred	O
in	O
previous	O
entries	O
.	O

how	O
do	O
i	O
find	O
the	O
smallest	O
then	O
if	O
this	O
gives	O
me	O
the	O
n	O
greatest	O
values	O
?	O

@USER	O
:	O
you	O
can	O
wrap	O
the	O
insides	O
the	O
prange	O
loop	O
in	O
`	O
with	O
nogil	O
:	O
`	O
to	O
use	O
any	O
Python	O
constructs	O
.	O

For	O
each	O
`	O
Xi	O
`	O
greater	O
than	O
`	O
lower_limit_X	O
`	O
and	O
less	O
than	O
`	O
upper_limit_X	O
`	O
,	O
I	O
would	O
like	O
to	O
get	O
the	O
number	O
of	O
`	O
Yi	O
`'	O
s	O
that	O
are	O
greater	O
than	O
`	O
lower_limit_Y	O
`	O
and	O
less	O
than	O
`	O
upper_limit_Y	O
`	O
.	O

and	O
find	O
the	O
roots	O
?	O

I'd	O
like	O
to	O
generalize	O
this	O
to	O
an	O
ellipsoid	O
,	O
that	O
could	O
ideally	O
have	O
any	O
rotation	O
.	O

Is	O
there	O
any	O
way	O
to	O
integrate	O
the	O
entire	O
array	O
at	O
once	O
,	O
or	O
do	O
I	O
need	O
to	O
integrate	O
element-by-element	O
?	O

I	O
need	O
to	O
sum	O

with	O
'	O
f	O
'	O
and	O
'	O
F	O
'	O
,	O
or	O
before	O
and	O
after	O
the	O
decimal	O
point	O
for	O
a	O
floating	O

You	O
can	O
write	O
that	O
as	O
a	O
matrix	O
:	O
#CODE	O

In	O
fact	O
,	O
if	O
you	O
use	O
tuples	O
as	O
Justin	O
suggested	O
and	O
iterate	O
directly	O
over	O
the	O
rows	O
of	O
the	O
array	O
(	O
`	O
for	O
row	O
in	O
data	O
:	O
`)	O
,	O
it's	O
actually	O
faster	O
than	O
my	O
method	O
below	O
.	O

Using	O
the	O
`	O
ctypedef	O
`	O
keyword	O
in	O
Cython	O
will	O
make	O
it	O
add	O
the	O
C	O
/	O
C++	O
`	O
typedef	O
`	O
statement	O
with	O
the	O
given	O
types	O
in	O
the	O
compiled	O
Cython-code	O
.	O

Here	O
is	O
how	O
I	O
would	O
compute	O
a	O
subset	O
of	O
the	O
elements	O
of	O
C	O
given	O
a	O
list	O
of	O
tuples	O
of	O
C	O
index	O
values	O
.	O

In	O
my	O
specific	O
problem	O
`	O
A	O
,	O
B	O
`	O
are	O
slices	O
out	O
of	O
a	O
bigger	O
3-dimensional	O
array	O
`	O
Z	O
`	O
,	O

The	O
solution	O
to	O
get	O
all	O
the	O
data	O
you	O
need	O
as	O
you	O
build	O
the	O
list	O
,	O
by	O
using	O
the	O
accessor	O
on	O
each	O
iteration	O
.	O

Edit	O
:	O
Actually	O
you	O
could	O
also	O
sort	O
both	O
arrays	O
into	O
one	O
(	O
and	O
remember	O
which	O
one	O
belongs	O
to	O
which	O
class	O
)	O
,	O
then	O
go	O
from	O
there	O
by	O
checking	O
where	O
two	O
of	O
the	O
different	O
class	O
are	O
next	O
to	O
each	O
other	O
.	O

How	O
can	O
I	O
integrate	O
it	O
from	O
a	O
given	O
value	O
`	O
a	O
`	O
to	O
another	O
value	O
`	O
b	O
`	O
so	O
that	O
the	O
output	O
is	O
a	O
corresponding	O
array	O
?	O

I	O
want	O
to	O
multiply	O
a	O
sparse	O
matrix	O
A	O
,	O
with	O
a	O
matrix	O
B	O
which	O
has	O
0	O
,	O
-1	O
,	O
or	O
1	O
as	O
elements	O
.	O

If	O
you	O
turn	O
a	O
`	O
dict	O
`	O
into	O
an	O
array	O
,	O
you'll	O
get	O
an	O
object	O
array	O
.	O

`	O
Holy	O
CPU	O
cycles	O
batman	O
!	O

Note	O
:	O
Xarray	O
and	O
Yarray	O
are	O
each	O
single-column	O
vectors	O
with	O
data	O
at	O
each	O
index	O
that	O
links	O
the	O
two	O
arrays	O
as	O
sets	O
of	O
x	O
,	O
y	O
coordinates	O
.	O

Yeah	O
,	O
my	O
rule-of-thumb	O
is	O
**	O
numpy	O
**	O
for	O
anything	O
that	O
can	O
handle	O
small	O
amounts	O
of	O
latency	O
but	O
has	O
the	O
potential	O
to	O
be	O
very	O
large	O
,	O
**	O
lists	O
**	O
for	O
smaller	O
data	O
sets	O
where	O
latency	O
critical	O
,	O
and	O
of	O
course	O
**	O
real	O
benchmarking	O
**	O
FTW	O
:)	O

You	O
need	O
to	O
know	O
what	O
kind	O
of	O
information	O
is	O
stored	O
in	O
each	O
field	O
for	O
the	O
`	O
struct	O
`	O
module	O
to	O
make	O
sense	O
of	O
each	O
field	O
.	O

Once	O
you	O
have	O
this	O
array	O
,	O
you	O
can	O
get	O
your	O
sums	O
for	O
each	O
vertex	O
as	O
#CODE	O

Where	O
are	O
`	O
plot	O
`	O
and	O
`	O
show	O
`	O
coming	O
from	O
?	O

But	O
it	O
might	O
be	O
easier	O
(	O
and	O
more	O
understandable	O
when	O
you	O
look	O
at	O
the	O
code	O
in	O
the	O
future	O
)	O
to	O
just	O
drop	O
into	O
Cython	O
to	O
get	O
this	O
done	O
.	O

I	O
can't	O
comment	O
on	O
the	O
Perl	O
code	O
,	O
I	O
simply	O
don't	O
know	O
it	O
at	O
all	O
.	O

I	O
updated	O
the	O
answer	O
with	O
a	O
full	O
example	O
.	O

There	O
you	O
will	O
find	O
C	O
code	O
which	O
provides	O
the	O
same	O
functionality	O
as	O
`	O
fmincon	O
`	O
.	O

so	O
for	O
instance	O
,	O
for	O
an	O
array	O
the	O
code	O
looked	O
like	O
#CODE	O

I've	O
been	O
trying	O
to	O
find	O
a	O
solution	O
for	O
hours	O
.	O

Note	O
that	O
as	O
implemented	O
here	O
,	O
the	O
first	O
method	O
gives	O
incorrect	O
results	O
according	O
to	O
my	O
test	O
.	O

This	O
is	O
my	O
test	O
code	O
:	O
#CODE	O

This	O
will	O
short-circuit	O
if	O
you	O
just	O
want	O
to	O
determine	O
if	O
any	O
match	O
exists	O
.	O

It	O
also	O
helps	O
to	O
know	O
that	O
a	O
resource	O
like	O
Wolfram	O
Alpha	O
is	O
available	O
to	O
you	O
at	O
all	O
times	O
.	O

What	O
I	O
meant	O
was	O
if	O
we	O
had	O
three	O
arrays	O
`	O
X	O
=[	O
0	O
1	O
2	O
]	O
,	O
Y	O
=[	O
0	O
1	O
1	O
]	O
,	O
and	O
Z	O
=[	O
0	O
2	O
2	O
]`	O
there	O
would	O
be	O
six	O
values	O
in	O
the	O
range	O
of	O
greater	O
than	O
or	O
equal	O
1	O
and	O
and	O
less	O
than	O
or	O
equal	O
to	O
2	O
.	O

You	O
should	O
really	O
split	O
this	O
into	O
two	O
separate	O
questions	O
since	O
each	O
part	O
is	O
distinct	O
.	O

This	O
doesn't	O
answer	O
your	O
problem	O
exactly	O
,	O
but	O
I	O
think	O
especially	O
with	O
the	O
sum	O
issue	O
that	O
you	O
should	O
see	O
significant	O
speedups	O
with	O
these	O
changes	O
.	O

Basically	O
you're	O
iterating	O
through	O
each	O
item	O
in	O
`	O
Xa	O
`	O
and	O
omitting	O
the	O
ones	O
that	O
don't	O
fall	O
with	O
the	O
range	O
.	O

This	O
code	O
has	O
been	O
written	O
following	O
the	O
tips	O
(	O
and	O
copy	O
/	O
pasting	O
):	O
#URL	O

I	O
would	O
look	O
at	O
this	O
question	O
:	O
#URL	O

As	O
@USER	O
-Anderson	O
asked	O
,	O
why	O
not	O
avoid	O
making	O
an	O
array	O
?	O

to	O
create	O
such	O
an	O
array	O
.	O

In	O
short	O
,	O
I	O
find	O
class	O
C	O
to	O
provide	O
an	O
implementation	O
that	O
is	O
over	O
60x	O
faster	O
than	O
the	O
method	O
in	O
the	O
original	O
post	O
.	O

I	O
suggest	O
allocating	O
an	O
array	O
of	O
the	O
correct	O
size	O
up-front	O
,	O
then	O
populating	O
it	O
with	O
data	O
in	O
each	O
iteration	O
.	O

edited	O
my	O
solution	O
to	O
include	O
what	O
I	O
would	O
do	O
.	O
let	O
me	O
know	O
if	O
this	O
work	O
,	O
as	O
i	O
cannot	O
fully	O
test	O
because	O
i	O
dont	O
have	O
test	O
data	O
.	O

The	O
problem	O
is	O
if	O
i	O
don't	O
want	O
0:10	O
,	O
but	O
an	O
arbitrary	O
set	O
of	O
indices	O
.	O

and	O
it	O
occurs	O
at	O
the	O
line	O
:	O
`	O
del	O
innerAry	O
[	O
j	O
]`	O

Do	O
you	O
have	O
any	O
references	O
to	O
back	O
up	O
that	O
`	O
NaN	O
handling	O
is	O
much	O
slower	O
than	O
"	O
normal	O
"	O
float	O
at	O
the	O
CPU	O
level	O
`	O
?	O

What	O
do	O
you	O
mean	O
by	O
the	O
line	O
?	O

For	O
example	O
if	O
we	O
stick	O
with	O
a	O
linear	O
search	O
we	O
can	O
at	O
least	O
start	O
at	O
the	O
appropriate	O
end	O
(	O
search	O
backwards	O
to	O
find	O
last	O
value	O
matching	O
a	O
condition	O
)	O
.	O

Yes	O
,	O
but	O
you	O
don't	O
get	O
a	O
numpy	O
array	O
out	O
,	O
do	O
you	O
?	O

This	O
seems	O
like	O
a	O
simple	O
question	O
,	O
but	O
I	O
haven't	O
been	O
able	O
to	O
find	O
a	O
good	O
answer	O
.	O

@USER	O
:	O
it	O
could	O
also	O
mean	O
they	O
are	O
both	O
strictly	O
periodic	O
and	O
sinusoidal	O
,	O
but	O
their	O
frequencies	O
are	O
integer-independent	O
(	O
ie	O
.	O
the	O
interference	O
wave	O
is	O
not	O
periodic	O
)	O

Python	O
:	O
How	O
to	O
rotate	O
an	O
array	O
?	O

@USER	O
Your	O
edited	O
sample	O
input	O
is	O
still	O
not	O
consistent	O
with	O
your	O
expected	O
output	O
.	O

You	O
can	O
calculate	O
the	O
variance	O
yourself	O
using	O
the	O
mean	O
,	O
with	O
the	O
following	O
formula	O
:	O
#CODE	O

Populate	O
numpy	O
matrix	O
from	O
the	O
difference	O
of	O
two	O
vectors	O

where	O
#CODE	O

Interleaving	O
two	O
numpy	O
index	O
arrays	O
,	O
one	O
item	O
from	O
each	O
array	O

I	O
was	O
worried	O
about	O
the	O
performance	O
,	O
but	O
the	O
difference	O
in	O
load	O
time	O
is	O
tiny	O
for	O
me	O
.	O

I	O
looked	O
for	O
an	O
online	O
reference	O
but	O
couldn't	O
find	O
one	O
.	O

Numpy	O
/	O
Python	O
:	O
Array	O
iteration	O
without	O
for-loop	O

If	O
you	O
want	O
it	O
printed	O
with	O
commas	O
,	O
you	O
could	O
convert	O
it	O
to	O
a	O
Python	O
list	O
:	O
#CODE	O

I	O
have	O
included	O
my	O
code	O
to	O
see	O
if	O
you	O
can	O
help	O
me	O
implement	O
some	O
kind	O
of	O
'	O
fminsearch	O
'	O
to	O
find	O
the	O
optimal	O
parameter	O
values	O
k0	O
and	O
k1	O
that	O
will	O
fit	O
my	O
data	O
.	O

Any	O
ideas	O
what	O
this	O
could	O
be	O
all	O
about	O
?	O

What	O
does	O
"	O
IIUC	O
"	O
mean	O
?	O

I	O
can't	O
seem	O
to	O
find	O
examples	O
that	O
don't	O
rely	O
on	O
the	O
former	O
syntax	O
.	O

Any	O
help	O
would	O
be	O
greatly	O
appreciated	O
.	O

Where	O
blocks	O
is	O
a	O
3	O
dimensional	O
numpy	O
array	O
.	O

The	O
science	O
/	O
engineering	O
application	O
I'm	O
working	O
on	O
has	O
lots	O
of	O
linear	O
algebra	O
matrix	O
multiplications	O
,	O
therefore	O
I	O
use	O
Numpy	O
matrices	O
.	O

when	O
I	O
print	O
Chao	O
,	O
the	O
product	O
of	O
this	O
loop	O
I	O
currently	O
have	O
this	O
:	O

pyopengl	O
buffer	O
dynamic	O
read	O
from	O
numpy	O
array	O

I	O
also	O
have	O
an	O
array	O
which	O
is	O
my	O
desired	O
subset	O
of	O
ages	O
.	O

It	O
does	O
automatically	O
expand	O
the	O
array	O
,	O
but	O
now	O
every	O
item	O
in	O
the	O
array	O
is	O
`	O
None	O
`	O
and	O
cannot	O
be	O
changed	O
.	O

I'm	O
liking	O
fortran	O
more	O
at	O
the	O
moment	O
because	O
by	O
the	O
time	O
you	O
add	O
all	O
the	O
required	O
type	O
annotations	O
in	O
cython	O
I	O
think	O
it	O
ends	O
up	O
looking	O
less	O
clear	O
than	O
the	O
fortran	O
.	O

(	O
There	O
are	O
also	O
chances	O
that	O
Python	O
stores	O
the	O
number	O
on	O
the	O
heap	O
and	O
all	O
you	O
get	O
is	O
a	O
pointer	O
to	O
it	O
,	O
approximately	O
doubling	O
the	O
footprint	O
,	O
without	O
even	O
taking	O
in	O
account	O
metadata	O
but	O
that's	O
slippery	O
grounds	O
,	O
I'm	O
always	O
wrong	O
when	O
I	O
talk	O
about	O
Python	O
internals	O
,	O
so	O
let's	O
not	O
dig	O
it	O
too	O
much	O
.	O
)	O

Do	O
you	O
have	O
any	O
clue	O
?	O

your	O
method	O
works	O
,	O
@USER	O
.	O
put	O
it	O
into	O
an	O
answer	O
to	O
get	O
some	O
acceptance	O
points	O
.	O

that	O
blas	O
is	O
reference	O
blas	O
from	O
netlib	O
-	O
the	O
slowest	O
blas	O
around	O
.	O
install	O
atlas	O
or	O
mkl	O
instead	O
.	O

The	O
`	O
not	O
`	O
operator	O
implicitly	O
tries	O
to	O
convert	O
its	O
operand	O
to	O
`	O
bool	O
`	O
,	O
and	O
then	O
returns	O
the	O
opposite	O
truth	O
value	O
.	O

The	O
recommended	O
way	O
to	O
do	O
this	O
is	O
to	O
preallocate	O
before	O
the	O
loop	O
and	O
use	O
slicing	O
and	O
indexing	O
to	O
insert	O
#CODE	O

If	O
the	O
simple	O
sort	O
solution	O
is	O
good	O
enough	O
,	O
clearly	O
go	O
for	O
that	O
.	O

Basic	O
idea	O
being	O
,	O
I	O
know	O
the	O
actual	O
value	O
of	O
that	O
should	O
be	O
predicted	O
for	O
each	O
sample	O
in	O
a	O
row	O
of	O
N	O
,	O
and	O
I'd	O
like	O
to	O
determine	O
which	O
set	O
of	O
predicted	O
values	O
in	O
a	O
column	O
of	O
M	O
is	O
most	O
accurate	O
using	O
the	O
residuals	O
.	O

Fill	O
in	O
missing	O
values	O
with	O
nearest	O
neighbour	O
in	O
Python	O
numpy	O
masked	O
arrays	O
?	O

Any	O
tips	O
on	O
what	O
I'm	O
doing	O
wrong	O
?	O

SO	O
I	O
have	O
a	O
file	O
having	O
three	O
columns	O
;	O
Frequency	O
,	O
Power	O
spec	O
.	O

In	O
numpy	O
,	O
your	O
array	O
is	O
2	O
x	O
5	O
,	O
isn't	O
it	O
?	O

For	O
small-ish	O
problems	O
,	O
I	O
would	O
certainly	O
just	O
create	O
the	O
new	O
array	O
.	O

If	O
each	O
element	O
takes	O
up	O
4	O
bytes	O
,	O
it	O
would	O
require	O
4,000,000,000,000	O
bytes	O
of	O
memory	O
.	O

TypeError	O
:	O
must	O
be	O
str	O
,	O
not	O
bytes	O

Error	O
while	O
computing	O
probabilities	O
of	O
an	O
array	O
list	O

This	O
produces	O
the	O
array	O
,	O
but	O
I	O
don't	O
know	O
which	O
row	O
corresponds	O
to	O
which	O
year-disease	O
.	O

I'm	O
not	O
sure	O
what	O
you	O
mean	O
by	O
"	O
all	O
from	O
numpy	O
"	O
,	O
but	O
you	O
should	O
never	O
need	O
to	O
use	O
more	O
than	O
one	O
form	O
of	O
`	O
import	O
`	O
at	O
a	O
time	O
.	O

The	O
problem	O
is	O
that	O
you	O
have	O
an	O
array	O
of	O
strings	O
,	O
not	O
an	O
array	O
of	O
numbers	O
.	O

how	O
can	O
i	O
effectively	O
check	O
items	O
of	O
a	O
list	O
of	O
tuples	O
against	O
all	O
the	O
items	O
of	O
another	O
using	O
numpy	O
or	O
tabular	O
?	O

Replace	O
part	O
of	O
numpy	O
1D	O
array	O
with	O
shorter	O
array	O

Python	O
2.6	O
numpy	O
interaction	O
array	O
objects	O
error	O

So	O
for	O
square	O
matrices	O
it	O
is	O
basically	O
syntactic	O
sugar	O
for	O
the	O
exact	O
same	O
operation	O
.	O

If	O
we	O
evaulate	O
the	O
ij	O
th	O
element	O
of	O
the	O
matrix	O
U*A*V	O
,	O
then	O
it	O
must	O
equal	O
both	O
#CODE	O

How	O
can	O
I	O
get	O
new	O
array	O
`	O
B	O
`	O
such	O
as	O
if	O
`	O
row_set	O
=	O
[	O
0	O
,	O
2	O
,	O
5	O
]`	O
,	O
then	O
`	O
B	O
=	O
[	O
A_row	O
[	O
0	O
]	O
,	O
A_row	O
[	O
2	O
]	O
,	O
A_row	O
[	O
5	O
]]`	O
?	O

I	O
have	O
tried	O
the	O
following	O
to	O
fix	O
it	O
:	O

The	O
weighted	O
sum	O
result	O
is	O
approximated	O
by	O
the	O
multiple	O
passes	O
and	O
actually	O
after	O
very	O
few	O
of	O
them	O
the	O
output	O
is	O
already	O
smooth	O
.	O

Basically	O
,	O
it	O
comes	O
down	O
to	O
checking	O
before	O
you	O
add	O
.	O

Any	O
ideas	O
?	O

Do	O
you	O
really	O
have	O
matrix	O
type	O
or	O
just	O
list	O
of	O
lists	O
from	O
python	O
?	O

zI	O
[	O
N-1	O
]	O
=	O
f	O
(	O
xI	O
[	O
N-1	O
]	O
,	O
yI	O
[	O
N-1	O
])	O
.	O

The	O
actual	O
size	O
of	O
the	O
numpy	O
array	O
is	O
514	O
by	O
504	O
and	O
of	O
the	O
list	O
is	O
8	O
.	O

`	O
array	O
([[	O
a	O
,	O
a	O
,	O
a	O
,	O
a	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
0	O
,	O
b	O
,	O
b	O
,	O
b	O
,...	O
]	O
,	O

What's	O
wrong	O
with	O
just	O
separating	O
it	O
out	O
into	O
real	O
and	O
imaginary	O
parts	O
?	O

I	O
have	O
an	O
N-dimensional	O
array	O
and	O
a	O
set	O
N	O
index	O
arrays	O
,	O
who's	O
values	O
I	O
want	O
to	O
increment	O
.	O

As	O
@USER	O
suggests	O
in	O
a	O
comment	O
,	O
if	O
you	O
really	O
want	O
a	O
3D	O
array	O
--	O
which	O
is	O
not	O
entirely	O
clear	O
to	O
me	O
from	O
your	O
code	O
sample	O
--	O
you	O
can	O
use	O
:	O
#CODE	O

In	O
another	O
question	O
,	O
other	O
users	O
offered	O
some	O
help	O
if	O
I	O
could	O
supply	O
the	O
array	O
I	O
was	O
having	O
trouble	O
with	O
.	O

The	O
other	O
thing	O
is	O
changing	O
the	O
size	O
of	O
the	O
ticklabels	O
in	O
the	O
colorbar	O
which	O
I	O
haven't	O
figured	O
out	O
.	O

Unfortunately	O
,	O
these	O
lines	O
are	O
fast	O
already	O
,	O
but	O
I	O
will	O
take	O
any	O
speedup	O
to	O
offset	O
the	O
IO	O
issues	O
I	O
have	O
using	O
GDAL	O
.	O

First	O
you	O
need	O
to	O
write	O
a	O
function	O
that	O
when	O
given	O
an	O
array	O
of	O
values	O
,	O
with	O
the	O
middle	O
one	O
being	O
the	O
element	O
currently	O
examined	O
,	O
will	O
return	O
some	O
computation	O
of	O
those	O
values	O
.	O

Thanks	O
in	O
advance	O
for	O
any	O
help	O
.	O

so	O
what	O
you	O
want	O
is	O
some	O
sort	O
of	O
recursive	O
assignment	O
--	O
but	O
i	O
don't	O
believe	O
there	O
is	O
any	O
guarantee	O
that	O
this	O
will	O
settle	O
down	O
into	O
a	O
constant	O
value	O
.	O
sure	O
it	O
does	O
in	O
your	O
case	O
,	O
but	O
not	O
in	O
general	O
--	O
for	O
example	O
:	O
`	O
a	O
[:	O
]	O
=	O
2*a	O
[:	O
]`	O
would	O
loop	O
forever	O
.	O

Just	O
initialize	O
the	O
array	O
of	O
`	O
float*	O
`	O
to	O
point	O
to	O
each	O
of	O
the	O
rows	O
in	O
the	O
2-D	O
array	O
.	O

Do	O
things	O
go	O
wrong	O
gradually	O
and	O
more	O
and	O
more	O
,	O
or	O
all	O
at	O
once	O
?	O

If	O
you	O
don't	O
find	O
anything	O
useful	O
then	O
try	O
"	O
R	O
"	O
.	O

Unfortunately	O
,	O
when	O
I	O
tried	O
it	O
I	O
got	O
the	O
error	O
:	O
"	O
ValueError	O
:	O
array	O
is	O
too	O
big	O
.	O

EDIT	O
2	O
:	O
This	O
raises	O
another	O
question	O
-	O
What	O
is	O
`	O
env	O
`	O
and	O
why	O
does	O
`	O
make	O
`	O
add	O
it	O
?	O

However	O
it	O
doesn't	O
give	O
you	O
negative	O
overflows	O
,	O
probably	O
because	O
`	O
uint32	O
`	O
fits	O
inside	O
the	O
positive	O
values	O
of	O
the	O
`	O
int64	O
`	O
.	O

Consider	O
for	O
example	O
the	O
array	O
:	O
#CODE	O

One	O
difference	O
could	O
be	O
the	O
result	O
of	O
python	O
having	O
to	O
take	O
extra	O
steps	O
to	O
resolve	O
the	O
float64	O
types	O
.	O

How	O
do	O
I	O
turn	O
this	O
into	O
a	O
numpy	O
matrix	O
?	O

I	O
want	O
to	O
rotate	O
an	O
array	O
but	O
not	O
as	O
a	O
whole	O
,	O
only	O
small	O
portion	O
of	O
it	O
.	O

is	O
so	O
much	O
more	O
readable	O
than	O
any	O
dot	O
(	O
a	O
,	O
b	O
)	O
equivalent	O
.	O

The	O
array	O
looks	O
like	O
:	O
#CODE	O

Constructing	O
an	O
n-by-n	O
matrix	O
in	O
Numpy	O
is	O
easy	O
and	O
fairly	O
efficient	O
.	O

Numpy	O
array	O
broadcasting	O
with	O
vector	O
parameters	O

It	O
only	O
works	O
like	O
this	O
for	O
numpy	O
`	O
array	O
`	O
s	O
.	O

@USER	O
:	O
Also	O
there's	O
a	O
mistake	O
in	O
your	O
code	O
I	O
think	O
:	O
because	O
when	O
you	O
set	O
elements	O
to	O
NaN	O
in	O
each	O
iteration	O
,	O
the	O
elements	O
are	O
not	O
restored	O
to	O
their	O
pre-NaN	O
values	O
for	O
the	O
next	O
iteration	O
!	O

Quick	O
question	O
:	O
is	O
there	O
any	O
reason	O
why	O
you	O
use	O

Now	O
the	O
question	O
is	O
,	O
which	O
equal	O
area	O
projection	O
shall	O
I	O
choose	O
in	O
order	O
to	O
have	O
comparable	O
area	O
sizes	O
for	O
the	O
polygons	O
.	O

numpy	O
array	O
multiplication	O
issue	O

(	O
2	O
)	O
When	O
I	O
change	O
the	O
connection	O
keywords	O
to	O
check_same_thread=False	O
,	O
then	O
the	O
full	O
pool	O
of	O
workers	O
is	O
used	O
,	O
but	O
then	O
only	O
some	O
queries	O
succeed	O
and	O
some	O
queries	O
fail	O
.	O

It	O
also	O
has	O
the	O
advantage	O
of	O
being	O
able	O
to	O
load	O
and	O
store	O
transparently	O
with	O
HDF5	O
.	O

Bah	O
:	O
"	O
operates	O
on	O
two	O
n-dimensional	O
arrays	O
"	O
should	O
be	O
"	O
operates	O
on	O
an	O
n-dimensional	O
array	O
"	O
above	O
.	O

Instead	O
,	O
they	O
expect	O
the	O
user	O
to	O
either	O
pass	O
an	O
array	O
of	O
shape	O
`	O
(	O
r	O
,	O
c	O
)`	O
exactly	O
,	O
or	O
for	O
the	O
user	O
to	O
pass	O
a	O
1-D	O
array	O
that	O
broadcasts	O
up	O
to	O
shape	O
`	O
(	O
r	O
,	O
c	O
)`	O
.	O

Though	O
,	O
it	O
isn't	O
so	O
straight	O
forward	O
because	O
I	O
don't	O
necessarily	O
know	O
how	O
many	O
duplicates	O
of	O
each	O
lon	O
or	O
lat	O
there	O
are	O
which	O
determines	O
the	O
shape	O
of	O
the	O
array	O
.	O

geom	O
function	O
takes	O
an	O
n+1	O
X	O
2	O
array	O
and	O
n	O
as	O
input	O
,	O
i	O
guess	O
i'm	O
doing	O
something	O
really	O
stupid	O
(	O
which	O
i	O
think	O
i	O
am	O
)	O
or	O
i	O
don't	O
understand	O
this	O
behavior	O
#CODE	O

When	O
I	O
tried	O
this	O
,	O
I	O
got	O
sort	O
of	O
similar	O
shaped	O
"	O
tiles	O
"	O
of	O
different	O
colors	O
rather	O
than	O
3	O
Gaussian	O
humps	O
.	O

There	O
was	O
a	O
comment	O
here	O
saying	O
that	O
the	O
Apple	O
version	O
of	O
python	O
2.7	O
comes	O
with	O
numpy	O
so	O
you	O
shouldn't	O
have	O
to	O
install	O
it	O
at	O
all	O
.	O

For	O
more	O
general	O
solution	O
,	O
you	O
could	O
use	O
somekind	O
of	O
edge	O
detection	O
method	O
to	O
find	O
only	O
the	O
edge	O
points	O
.	O

If	O
you	O
see	O
any	O
errors	O
;	O
provide	O
a	O
link	O
to	O
the	O
code	O
that	O
can	O
be	O
run	O
.	O

What	O
I	O
am	O
looking	O
for	O
is	O
a	O
quick	O
and	O
easy	O
way	O
to	O
find	O
the	O
closest	O
(	O
nearest	O
neighbor	O
)	O
of	O
some	O
multidimensional	O
query	O
point	O
in	O
an	O
2D	O
(	O
numpy	O
)	O
array	O
of	O
multidimensional	O
points	O
(	O
also	O
numpy	O
arrays	O
)	O
.	O

How	O
do	O
I	O
get	O
the	O
`	O
Image	O
`	O
part	O
only	O
and	O
how	O
do	O
I	O
convert	O
it	O
to	O
Numpy	O
Array	O
?	O

Maybe	O
it'll	O
save	O
you	O
some	O
frustration	O
=)	O

Is	O
there	O
any	O
way	O
to	O
rewrite	O
this	O
functions	O
with	O
Numpy	O
?	O

Is	O
there	O
any	O
easy	O
way	O
to	O
speed	O
my	O
calculation	O
up	O
?	O

A	O
variable	O
in	O
Python	O
is	O
just	O
a	O
label	O
for	O
an	O
object	O
;	O
giving	O
the	O
object	O
a	O
new	O
label	O
doesn't	O
change	O
the	O
object	O
itself	O
at	O
all	O
.	O

But	O
this	O
is	O
actually	O
where	O
the	O
doc	O
belongs	O
.	O

So	O
given	O
the	O
sorted	O
version	O
,	O
you	O
can	O
reconstruct	O
the	O
original	O
by	O
"	O
putting	O
items	O
back	O
where	O
they	O
came	O
from	O
"	O
:	O
#CODE	O

Note	O
that	O
this	O
all	O
assumes	O
that	O
your	O
values	O
are	O
normally	O
distributed	O
.	O

(	O
Bounding	O
box	O
intersections	O
are	O
actually	O
a	O
rather	O
poor	O
way	O
of	O
deciding	O
where	O
to	O
place	O
labels	O
.	O
What's	O
the	O
point	O
in	O
writing	O
a	O
ton	O
of	O
code	O
for	O
something	O
that	O
will	O
only	O
work	O
in	O
one	O
case	O
out	O
of	O
1000	O
?	O
)	O

The	O
python	O
code	O
outputs	O
eleven	O
0's	O
,	O
eleven	O
1's	O
all	O
the	O
way	O
to	O
eleven	O
39's	O
.	O

@USER	O
;	O
in	O
above	O
example	O
z	O
is	O
(	O
5	O
,	O
2	O
)	O
array	O
created	O
by	O
another	O
function	O
,	O
with	O
first	O
dimension	O
from	O
the	O
number	O
of	O
True	O
(	O
at	O
least	O
one	O
True	O
in	O
x	O
>	O
y	O
)	O
,	O
here	O
5	O
,	O
and	O
second	O
dimention	O
as	O
the	O
first	O
dimension	O
of	O
x	O
,	O
here	O
2	O
.	O

I	O
have	O
a	O
NumPy	O
array	O
of	O
values	O
.	O

I	O
just	O
need	O
the	O
total	O
of	O
all	O
the	O
values	O
instead	O
of	O
the	O
actual	O
values	O
themselves	O
.	O

Didn't	O
think	O
about	O
multiplying	O
my	O
array	O
of	O
number	O
by	O
an	O
array	O
of	O
booleans	O
to	O
extract	O
my	O
data	O
.	O

not	O
to	O
convert	O
floats	O
to	O
floats	O
would	O
be	O
the	O
first	O
step	O
.	O

make	O
a	O
list	O
of	O
all	O
the	O
days	O

This	O
way	O
,	O
you	O
could	O
access	O
all	O
the	O
`	O
A	O
`	O
through	O
`	O
result	O
[	O
'	O
label	O
']	O
[	O
'	O
A	O
']`	O
...	O

picking	O
out	O
elements	O
based	O
on	O
complement	O
of	O
indices	O
in	O
Python	O
pandas	O

Joran	O
,	O
could	O
you	O
please	O
explain	O
what	O
you	O
mean	O
more	O
?	O

Anyone	O
have	O
any	O
clues	O
for	O
what	O
I	O
can	O
do	O
,	O
or	O
approaches	O
I	O
should	O
research	O
?	O

Appending	O
data	O
to	O
an	O
existing	O
array	O
is	O
a	O
natural	O
thing	O
to	O
want	O
to	O
do	O
for	O
anyone	O
with	O
python	O
experience	O
.	O

Note	O
that	O
you	O
get	O
a	O
sorte	O
copy	O
of	O
the	O
array	O
.	O

I'm	O
not	O
sure	O
that	O
this	O
is	O
the	O
way	O
that	O
you	O
should	O
do	O
things	O
as	O
I'd	O
expect	O
numpy	O
to	O
have	O
a	O
much	O
more	O
efficient	O
method	O
of	O
going	O
about	O
it	O
,	O
but	O
do	O
you	O
just	O
mean	O
something	O
like	O
this	O
?	O

`	O
KMID	O
`	O
is	O
a	O
function	O
,	O
not	O
an	O
array	O
,	O
so	O
you	O
can't	O
index	O
it	O
with	O
`	O
:	O
`	O
.	O

Insert	O
to	O
original	O
code	O
in	O
question	O
:	O
#CODE	O

Multiple	O
conditions	O
using	O
'	O
or	O
'	O
in	O
numpy	O
array	O

Usually	O
,	O
it's	O
best	O
to	O
avoid	O
the	O
matrix	O
class	O
(	O
see	O
docs	O
)	O
.	O

I	O
have	O
tried	O
two	O
different	O
methods	O
but	O
both	O
of	O
them	O
are	O
slow	O
.	O

Not	O
really	O
,	O
you	O
can	O
construct	O
the	O
Counter	O
from	O
any	O
iterable	O
.	O

(	O
I	O
have	O
the	O
code	O
ready	O
,	O
but	O
as	O
i'm	O
new	O
to	O
stackoverflow	O
,	O
i	O
don't	O
know	O
where	O
to	O
put	O
it	O
.	O
Here	O
,	O
in	O
this	O
comment	O
field	O
?	O
Or	O
rather	O
making	O
a	O
new	O
answer	O
??	O
)	O

For	O
example	O
,	O
one	O
simple	O
method	O
to	O
generate	O
at	O
most	O
rank	O
`	O
k	O
`	O
(	O
when	O
`	O
m	O
`	O
is	O
`	O
k+1	O
`)	O
is	O
to	O
get	O
a	O
random	O
valid	O
B	O
0	O
,	O
keep	O
rotating	O
all	O
rows	O
of	O
this	O
matrix	O
up	O
to	O
get	O
B	O
1	O
to	O
B	O
m-2	O
,	O
set	O
first	O
row	O
of	O
B	O
m-1	O
to	O
all	O
1	O
,	O
and	O
the	O
remaining	O
rows	O
to	O
all	O
0	O
.	O

Glad	O
you	O
saw	O
around	O
it	O
!	O

@USER	O
:	O
basically	O
I	O
am	O
converting	O
some	O
matlab	O
code	O
into	O
python	O
,	O
I	O
can	O
not	O
write	O
actual	O
code	O
because	O
that	O
is	O
confidential	O
,	O
(	O
1+float	O
(	O
100	O
))	O
Here	O
100	O
is	O
coming	O
from	O
two	O
dimension	O
string	O
matrix	O
,	O
that	O
why	O
I	O
have	O
written	O
float	O
to	O
convert	O
string	O
variable	O
.	O

instead	O
of	O
call	O
plot	O
(	O
test	O
[	O
"	O
x	O
"]	O
[	O
5:10	O
])	O
,	O
you	O
can	O
call	O
the	O
plot	O
method	O
of	O
Series	O
object	O
:	O
#CODE	O

The	O
size	O
of	O
a	O
slice	O
with	O
`	O
0:5	O
`	O
is	O
not	O
6	O
as	O
you	O
say	O
:	O
it's	O
5	O
.	O

This	O
ensures	O
proper	O
display	O
and	O
syntax	O
highlighting	O
-	O
right	O
now	O
someone	O
who	O
would	O
usually	O
fix	O
your	O
formatting	O
is	O
likely	O
to	O
not	O
do	O
it	O
because	O
he'd	O
have	O
to	O
remove	O
all	O
the	O
HTML	O
linebreaks	O
on	O
his	O
own	O
.	O

I	O
believe	O
you've	O
reduced	O
the	O
problem	O
to	O
a	O
one	O
of	O
finding	O
roots	O
.	O

In	O
order	O
to	O
make	O
sure	O
it	O
is	O
still	O
multiprocessor	O
safe	O
,	O
I	O
believe	O
you	O
will	O
have	O
to	O
use	O
the	O
`	O
acquire	O
`	O
and	O
`	O
release	O
`	O
methods	O
that	O
exist	O
on	O
the	O
`	O
Array	O
`	O
object	O
,	O
`	O
a	O
`	O
,	O
and	O
its	O
built	O
in	O
lock	O
to	O
make	O
sure	O
its	O
all	O
safely	O
accessed	O
(	O
though	O
I'm	O
not	O
an	O
expert	O
on	O
the	O
multiprocessor	O
module	O
)	O
.	O

So	O
,	O
given	O
your	O
matrix	O
M	O
,	O
your	O
problem	O
asks	O
to	O
maximize	O
the	O
PB	O
function	O
#CODE	O

I	O
would	O
like	O
to	O
find	O
all	O
elements	O
within	O
a	O
specific	O
range	O
.	O

I	O
cannot	O
seem	O
to	O
find	O
how	O
to	O
do	O
that	O
.	O

Any	O
thoughts	O
?	O

If	O
you	O
want	O
the	O
PRNGs	O
to	O
be	O
independent	O
,	O
do	O
not	O
seed	O
them	O
with	O
anything	O
.	O

In	O
the	O
end	O
I'll	O
probably	O
take	O
n	O
randomly	O
selected	O
samples	O
.	O

This	O
is	O
a	O
mystery	O
to	O
me	O
,	O
though	O
I	O
would	O
guess	O
that	O
there	O
must	O
be	O
more	O
overhead	O
associated	O
with	O
accessing	O
an	O
array	O
element	O
than	O
with	O
appending	O
to	O
a	O
list	O
.	O

If	O
it's	O
not	O
reasonable	O
,	O
you	O
can	O
always	O
decompose	O
the	O
matrix	O
multiplication	O
yourself	O
.	O

If	O
the	O
vectors	O
do	O
not	O
have	O
equal	O
dimension	O
,	O
or	O
if	O
you	O
want	O
to	O
avoid	O
numpy	O
,	O
then	O
perhaps	O
,	O
#CODE	O

In	O
particular	O
,	O
you	O
can't	O
index	O
a	O
2D	O
matrix	O
with	O
a	O
single	O
integer	O
,	O
because	O
--	O
well	O
--	O
it's	O
two	O
dimensional	O
and	O
you	O
need	O
to	O
specify	O
two	O
integers	O
,	O
hence	O
the	O
need	O
for	O
the	O
extra	O
0	O
index	O
in	O
the	O
second	O
example	O
.	O

nearly	O
all	O
of	O
which	O
the	O
author	O
responded	O
to	O
and	O
in	O
some	O
cases	O
,	O

I	O
added	O
the	O
slow	O
Python	O
code	O
to	O
the	O
description	O
.	O

The	O
easy	O
way	O
-	O
pick	O
a	O
random	O
number	O
q	O
[	O
0	O
,	O
1	O
]	O
.	O

will	O
be	O
the	O
number	O
of	O
bytes	O
which	O
the	O
pattern	O
of	O
streams	O
will	O
repeat	O
after	O
.	O

Any	O
idea	O
how	O
I	O
can	O
later	O
make	O
1.6.2	O
in	O
/	O
usr	O
/	O
local	O
/	O
lib	O
work	O
with	O
python-dbg	O
?	O

Because	O
I'm	O
still	O
not	O
quite	O
grasping	O
the	O
method	O
and	O
there	O
seems	O
to	O
be	O
simpler	O
ways	O
to	O
solve	O
the	O
problem	O
,	O
I'm	O
just	O
going	O
to	O
put	O
this	O
here	O
:	O
#CODE	O

how	O
do	O
I	O
fix	O
that	O
?	O

The	O
usual	O
shape	O
is	O
(	O
xx	O
,	O
)	O
.	O

what	O
does	O
`	O
[	O
0	O
,	O
1:3	O
]`	O
mean	O
?	O

@USER	O
he	O
basically	O
considers	O
x	O
as	O
my	O
array	O
and	O
defines	O
a	O
function	O
that	O
gives	O
the	O
range	O
of	O
each	O
row	O
..	O
works	O
fine	O
.	O

I	O
was	O
just	O
curious	O
to	O
find	O
a	O
*	O
best	O
practice	O
*	O
in	O
this	O
instance	O
I	O
suppose	O
.	O

I'm	O
guessing	O
there's	O
an	O
easy	O
way	O
to	O
do	O
this	O
without	O
iterating	O
through	O
the	O
full	O
array	O
.	O

I	O
don't	O
know	O
how	O
efficient	O
`	O
Image	O
`	O
is	O
at	O
storing	O
images	O
,	O
but	O
a	O
list	O
of	O
bytes	O
uses	O
four	O
bytes	O
of	O
space	O
for	O
each	O
element	O
in	O
the	O
list	O
,	O
so	O
you'll	O
burn	O
more	O
than	O
8GB	O
of	O
(	O
virtual	O
)	O
memory	O
...	O
and	O
a	O
lot	O
of	O
patience	O
.	O

They	O
are	O
all	O
floats	O

I	O
want	O
to	O
efficiently	O
iterate	O
through	O
the	O
two	O
columns	O
,	O
a	O
[:	O
,	O
0	O
]	O
and	O
a	O
[:	O
,	O
1	O
]	O
and	O
remove	O
any	O
pairs	O
that	O
meet	O
a	O
certain	O
condition	O
,	O
in	O
this	O
case	O
if	O
they	O
are	O
NaN	O
.	O

I	O
turned	O
`	O
color_array	O
`	O
into	O
a	O
two-dimensional	O
array	O
,	O
since	O
this	O
seems	O
more	O
appropriate	O
.	O

An	O
important	O
caveat	O
is	O
that	O
the	O
array	O
must	O
be	O
*	O
contiguous	O
*	O
in	O
memory	O
--	O
otherwise	O
the	O
view	O
fails	O
.	O

You	O
might	O
want	O
to	O
also	O
make	O
sure	O
that	O
you	O
use	O
a	O
method	O
of	O
generating	O
your	O
random	O
numbers	O
that	O
causes	O
them	O
to	O
fall	O
into	O
the	O
range	O
of	O
16	O
bit	O
ints	O
.	O

I	O
have	O
a	O
100x200	O
2D	O
array	O
expressed	O
as	O
a	O
numpy	O
array	O
consisting	O
of	O
black	O
(	O
0	O
)	O
and	O
white	O
(	O
255	O
)	O
cells	O
.	O

If	O
you	O
know	O
the	O
shape	O
of	O
the	O
array	O
(	O
to	O
find	O
discover	O
the	O
edges	O
)	O
you	O
can	O
use	O
simple	O
math	O
...	O
annoying	O
,	O
time	O
consuming	O
(	O
to	O
write	O
and	O
process	O
)	O
,	O
but	O
pretty	O
straight	O
forward	O
.	O

And	O
yet	O
another	O
way	O
,	O
possibly	O
faster	O
(	O
thanks	O
for	O
all	O
the	O
comments	O
,	O
guys	O
!	O
):	O
#CODE	O

Now	O
,	O
you	O
can	O
construct	O
another	O
matrix	O
,	O
B	O
,	O
that	O
has	O
1s	O
at	O
certain	O
locations	O
to	O
pick	O
the	O
elements	O
from	O
the	O
set	O
E	O
.	O

But	O
overhead	O
of	O
all	O
the	O
object	O
creation	O
it's	O
true	O
,	O
plus	O
the	O
time	O
of	O
Numpy	O
array	O
creation	O
.	O

I	O
was	O
trying	O
to	O
calculate	O
the	O
curvature	O
of	O
a	O
surface	O
given	O
by	O
array	O
of	O
points	O
(	O
x	O
,	O
y	O
,	O
z	O
)	O
.	O

You	O
also	O
don't	O
have	O
any	O
speed	O
improvement	O
,	O
when	O
you	O
try	O
to	O
do	O
a	O
function	O
return	O
in	O
C	O
instead	O
of	O
doing	O
that	O
in	O
python	O
,	O
also	O
array	O
access	O
is	O
neglectable	O
compared	O
to	O
the	O
cost	O
of	O
the	O
function	O
call	O
.	O

I	O
want	O
to	O
view	O
the	O
file	O
outside	O
the	O
python	O
environment	O
also	O
.	O

The	O
following	O
code	O
demonstrates	O
how	O
to	O
get	O
the	O
indices	O
of	O
some	O
vertex	O
(	O
number	O
17	O
,	O
in	O
this	O
example	O
):	O
#CODE	O

@USER	O
:	O
the	O
idea	O
is	O
possibly	O
that	O
two	O
calculation	O
that	O
both	O
arrive	O
at	O
positive	O
infinity	O
could	O
get	O
there	O
via	O
**	O
wildly	O
**	O
different	O
calculations	O
.	O

Given	O
a	O
wavelength	O
(	O
or	O
band	O
number	O
)	O
,	O
I	O
would	O
like	O
to	O
extract	O
the	O
2D	O
image	O
corresponding	O
to	O
that	O
wavelength	O
.	O

(	O
d	O
/	O
dx	O
)	O
^n	O
(	O
d	O
/	O
dy	O
)	O
^m	O
f	O
(	O
x	O
,	O
y	O
)	O

The	O
`	O
a	O
[:	O
,	O
0	O
]	O
<3	O
`	O
will	O
create	O
an	O
array	O
of	O
`	O
bool	O
`	O
with	O
the	O
same	O
dimension	O
as	O
`	O
a	O
`	O
,	O
which	O
says	O
which	O
elements	O
go	O
into	O
the	O
selection	O
.	O

(	O
Maybe	O
I	O
should	O
add	O
this	O
to	O
this	O
answer	O
.	O
)	O

Count	O
elements	O
in	O
a	O
box	O

The	O
problem	O
may	O
cook	O
down	O
to	O
mean	O
being	O
subtracted	O
over	O
all	O
numbers	O
,	O
but	O
in	O
the	O
next	O
step	O
they	O
are	O
not	O
used	O
anymore	O
...	O

I	O
wrote	O
a	O
function	O
that	O
works	O
,	O
but	O
it	O
is	O
extremely	O
slow	O
.	O

The	O
plot	O
commands	O
split	O
the	O
arrays	O
in	O
two	O
halfs	O
and	O
swap	O
them	O
to	O
get	O
a	O
nicer	O
picture	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
!	O

`	O
be	O
replaced	O
with	O
if	O
`	O
d	O
`	O
should	O
become	O
`	O
array	O
([[	O
1	O
,	O
1	O
]	O
,	O
[	O
2	O
,	O
2	O
]	O
,	O
[	O
3	O
,	O
3	O
]])`	O
?	O

How	O
big	O
is	O
the	O
triangular	O
matrix	O
?	O

Program	O
is	O
to	O
add	O
two	O
signals	O
using	O
Matlab	O

This	O
tax	O
makes	O
sense	O
when	O
you	O
are	O
doing	O
CPU	O
bound	O
operations	O
like	O
matrix	O
decompositions	O
and	O
whose	O
processing	O
time	O
takes	O
longer	O
than	O
the	O
time	O
it	O
takes	O
to	O
copy	O
the	O
data	O
.	O

Numpy	O
object	O
array	O
of	O
numerical	O
arrays	O

After	O
looking	O
at	O
these	O
page	O
and	O
other	O
I	O
got	O
it	O
working	O
using	O
raw	O
uncoded	O
buffers	O
using	O
mencoder	O
(	O
ffmpeg	O
solution	O
still	O
wanted	O
)	O
.	O

thanks	O
seberg	O
.	O
but	O
I	O
can	O
create	O
an	O
array	O
of	O
objects	O
using	O
numpy	O
,	O
then	O
I	O
can	O
assign	O
an	O
arbitrary	O
array	O
to	O
each	O
element	O
of	O
array	O
(	O
in	O
python	O
interpreter	O
)	O
.	O
what	O
do	O
you	O
think	O
of	O
this	O
?	O

Check	O
if	O
values	O
in	O
a	O
set	O
are	O
in	O
a	O
numpy	O
array	O
in	O
python	O

Would	O
you	O
know	O
of	O
a	O
way	O
to	O
**	O
average	O
**	O
the	O
duplicates	O
instead	O
of	O
sum	O
them	O
?	O

I	O
think	O
that	O
I	O
phrased	O
the	O
question	O
badly	O
;	O
what	O
I	O
meant	O
is	O
I	O
want	O
a	O
list	O
when	O
I	O
input	O
a	O
list	O
and	O
I	O
want	O
a	O
numpy	O
array	O
when	O
I	O
input	O
a	O
numpy	O
array	O
.	O

I	O
have	O
a	O
list	O
of	O
numbers	O
and	O
I	O
need	O
to	O
split	O
into	O
to	O
corresponding	O
arrays	O
of	O
different	O
sizes	O
,	O
but	O
that	O
make	O
up	O
all	O
the	O
combinations	O
of	O
the	O
array	O
splitting	O
up	O
.	O

Yes	O
,	O
it	O
is	O
true	O
that	O
before	O
you	O
ask	O
any	O
question	O
on	O
stackoverflow	O
,	O
you	O
should	O
perform	O
a	O
minimum	O
of	O
research	O
which	O
includes	O
looking	O
for	O
existing	O
answers	O
on	O
stackoverflow	O
.	O

This	O
is	O
probably	O
the	O
thing	O
that	O
is	O
most	O
important	O
for	O
numpy	O
to	O
know	O
...	O
although	O
there	O
may	O
be	O
other	O
subtle	O
differences	O
(	O
if	O
numpy	O
is	O
doing	O
some	O
dirty	O
hacking	O
to	O
get	O
at	O
information	O
stored	O
in	O
a	O
common	O
block	O
for	O
instance	O
)	O
.	O

You	O
might	O
want	O
to	O
add	O
this	O
link	O
to	O
the	O
response	O
:	O
#URL	O

A	O
list	O
takes	O
up	O
significantly	O
more	O
memory	O
than	O
a	O
comparably	O
sized	O
numpy	O
array	O
(	O
factor	O
of	O
~2	O
)	O
--	O
So	O
why	O
are	O
you	O
going	O
back	O
to	O
using	O
lists	O
?	O

From	O
my	O
understanding	O
,	O
when	O
you	O
use	O
python	O
standard	O
operators	O
,	O
these	O
are	O
fairly	O
similar	O
to	O
using	O
the	O
ones	O
from	O
"	O
import	O
operator	O
.	O

This	O
gives	O
you	O
4000	O
samples	O
of	O
your	O
function	O
,	O
sampled	O
at	O
33.33	O
Hz	O
,	O
representing	O
120	O
seconds	O
of	O
data	O
.	O

Before	O
,	O
what	O
you	O
were	O
doing	O
was	O
having	O
SWIG	O
convert	O
the	O
C++	O
`	O
std	O
::	O
vector	O
`	O
objects	O
into	O
Python	O
tuples	O
,	O
and	O
then	O
passing	O
those	O
tuples	O
back	O
down	O
to	O
`	O
numpy	O
`	O
-	O
where	O
they	O
were	O
converted	O
again	O
.	O

Currently	O
I	O
am	O
generating	O
a	O
list	O
of	O
7	O
numbers	O
with	O
random	O
values	O
from	O
[	O
0-1	O
)	O
then	O
multiplying	O
by	O
[	O
X1	O
..	O
X7	O
]	O

Introducing	O
the	O
transposing	O
of	O
the	O
matrix	O
everything	O
is	O
working	O
correctly	O
.	O

So	O
I	O
did	O
everything	O
,	O
but	O
I	O
feel	O
the	O
slicing	O
method	O
I	O
used	O
(	O
and	O
the	O
initialisation	O
of	O
`	O
b	O
`)	O
is	O
not	O
pythonic	O
at	O
all	O
:	O
#CODE	O

The	O
python	O
extension	O
calls	O
this	O
function	O
and	O
places	O
it	O
into	O
the	O
module-level	O
numpy	O
array	O
variable	O
`	O
arr	O
`	O
(	O
and	O
I	O
make	O
it	O
read-only	O
for	O
good	O
measure	O
):	O
#CODE	O

Depending	O
on	O
the	O
rig	O
you	O
have	O
at	O
the	O
moment	O
,	O
optimizing	O
your	O
SciPy	O

Examples	O
would	O
be	O
the	O
git	O
commit	O
id	O
of	O
the	O
current	O
version	O
,	O
and	O
the	O
input	O
parameters	O
used	O
to	O
generate	O
the	O
data	O
so	O
that	O
later	O
I	O
can	O
look	O
at	O
the	O
data	O
and	O
know	O
exactly	O
how	O
I	O
created	O
it	O
.	O

There	O
are	O
other	O
ways	O
to	O
do	O
this	O
(	O
you	O
may	O
want	O
to	O
avoid	O
storing	O
a	O
reference	O
to	O
a	O
specific	O
numpy	O
array	O
in	O
each	O
`	O
point	O
`	O
,	O
for	O
example	O
)	O
,	O
but	O
I	O
hope	O
it's	O
a	O
useful	O
example	O
.	O

I	O
downloaded	O
a	O
new	O
version	O
of	O
`	O
pip	O
`	O
and	O
installed	O
locally	O
in	O
my	O
home	O
directory	O
but	O
the	O
system	O
wide	O
old	O
one	O
is	O
still	O
used	O
when	O
I	O
type	O
`	O
pip	O
`	O
at	O
the	O
prompt	O
.	O

I	O
need	O
to	O
iterate	O
over	O
the	O
matrix	O
summing	O
all	O
elements	O
in	O
rows	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
only	O

If	O
you	O
compare	O
point	O
i	O
to	O
point	O
i+1	O
and	O
remove	O
all	O
for	O
which	O
the	O
distance	O
is	O
less	O
than	O
your	O
threshold	O
,	O
then	O
you	O
will	O
miss	O
the	O
cumulative	O
effect	O
of	O
many	O
small	O
steps	O
in	O
the	O
same	O
direction	O
.	O

In	O
my	O
output	O
array	O
I	O
only	O
want	O
to	O
include	O
rows	O
for	O
position	O
values	O
which	O
appear	O
in	O
all	O
3	O
input	O
arrays	O
.	O

Perhaps	O
you	O
should	O
change	O
the	O
title	O
of	O
this	O
question	O
to	O
more	O
accurately	O
reflect	O
your	O
specific	O
problem	O
.	O

Perhaps	O
there	O
is	O
a	O
good	O
choice	O
for	O
this	O
special	O
case	O
.	O

it	O
must	O
be	O
a	O
record	O
in	O
syntax	O
boycotting	O
!	O

Addressing	O
ranges	O
in	O
a	O
Scipy	O
sparse	O
matrix	O

Still	O
,	O
I	O
would	O
like	O
something	O
much	O
more	O
computationally	O
efficient	O
,	O
like	O
relying	O
on	O
builtin	O
numpy	O
functions	O
,	O
but	O
I	O
cannot	O
find	O
relevant	O
functions	O
,	O
can	O
someone	O
help	O
me	O
?	O

You	O
can	O
run	O
the	O
test	O
suite	O
to	O
see	O
if	O
the	O
build	O
works	O
.	O

The	O
bit	O
where	O
you	O
index	O
into	O
the	O
original	O
CSR	O
matrix	O
is	O
surely	O
expensive	O
.	O

I	O
don't	O
believe	O
there's	O
a	O
way	O
to	O
do	O
what	O
you're	O
asking	O
(	O
it	O
would	O
require	O
unaligned	O
access	O
,	O
which	O
is	O
highly	O
inefficient	O
on	O
some	O
architectures	O
)	O
.	O

This	O
should	O
give	O
a	O
large	O
speedup	O
compared	O
with	O
iterating	O
over	O
each	O
row	O
in	O
the	O
array	O
...	O

Not	O
sure	O
what	O
addition	O
you're	O
talking	O
about	O
nor	O
what	O
random	O
replacements	O
you	O
mean	O
.	O

I	O
have	O
a	O
counter	O
for	O
c	O
,	O
and	O
if	O
it	O
hits	O
50	O
I	O
want	O
it	O
to	O
print	O
out	O
that	O
You	O
have	O
been	O
mauled	O
by	O
a	O
bear	O
,	O
and	O
then	O
on	O
the	O
screen	O
have	O
a	O
bear	O
pop	O
up	O
,	O
whether	O
the	O
bear	O
image	O
is	O
just	O
a	O
file	O
in	O
the	O
same	O
folder	O
,	O
or	O
if	O
it	O
links	O
to	O
a	O
webpage	O
that	O
I	O
have	O
the	O
bear	O
image	O
hosted	O
at	O
.	O

I	O
have	O
yet	O
to	O
find	O
anything	O
in	O
the	O
python	O
documentation	O
that	O
states	O
how	O
a	O
list	O
of	O
list	O
is	O
assembled	O
,	O
is	O
it	O
like	O
:	O
#CODE	O

I'm	O
trying	O
to	O
use	O
leastsq	O
for	O
this	O
,	O
but	O
I'm	O
unsure	O
how	O
to	O
adjust	O
the	O
line	O
to	O
be	O
below	O
all	O
points	O
instead	O
of	O
the	O
line	O
of	O
best	O
fit	O
.	O

I	O
do	O
not	O
want	O
to	O
store	O
the	O
array	O
objects	O
,	O
I	O
want	O
to	O
store	O
the	O
lists	O
of	O
numbers	O
in	O
a	O
record	O
list	O
.	O

I	O
have	O
tried	O
two	O
different	O
methods	O
but	O
both	O
of	O
them	O
are	O
slow	O
.	O

Where	O
can	O
I	O
find	O
information	O
regarding	O
the	O
`	O
L	O
`	O
option	O
and	O
other	O
options	O
?	O

The	O
essential	O
problem	O
was	O
that	O
when	O
the	O
array	O
is	O
1d	O
you	O
call	O
it	O
array	O
[	O
i	O
]	O
when	O
it	O
is	O
2d	O
you	O
call	O
it	O
array	O
[	O
i	O
]	O
[	O
j	O
]	O
,	O
without	O
two	O
separate	O
cases	O
I	O
don't	O
know	O
how	O
to	O
handle	O
this	O
.	O

You	O
can	O
iterate	O
through	O
your	O
input	O
file	O
(	O
in	O
chunks	O
if	O
possible	O
)	O
and	O
convert	O
the	O
incoming	O
data	O
and	O
insert	O
them	O
as	O
rows	O
into	O
a	O
memory-mapped	O
numpy	O
array	O
.	O

This	O
all	O
works	O
great	O
when	O
I	O
run	O
the	O
Python	O
(	O
command	O
line	O
)	O
tool	O
that	O
comes	O
with	O
Python	O
.	O

The	O
standard	O
linear	O
algebra	O
methods	O
you	O
seem	O
to	O
be	O
thinking	O
of	O
cannot	O
(	O
to	O
the	O
best	O
of	O
my	O
knowledge	O
)	O
be	O
used	O
to	O
solve	O
this	O
sort	O
of	O
constrained	O
integer	O
problem	O
.	O

You	O
will	O
probably	O
find	O
answers	O
to	O
all	O
your	O
questions	O
regarding	O
NumPy	O
and	O
parallel	O
programming	O
on	O
the	O
official	O
wiki	O
.	O

Also	O
the	O
size	O
will	O
increase	O
as	O
I	O
process	O
data	O
with	O
higher	O
and	O
higher	O
horizontal	O
resolution	O
.	O

Where	O
each	O
row	O
(	O
of	O
a	O
fixed	O
arbitrary	O
width	O
)	O
is	O
shifted	O
by	O
one	O
.	O

ATLAS	O
3.10	O
doesn't	O
know	O
how	O
to	O
handle	O
a	O
lower	O
number	O
of	O
cores	O
than	O
the	O
number	O
it	O
had	O
at	O
build	O
time	O
and	O
generate	O
an	O
exception	O
.	O

This	O
doesn't	O
result	O
in	O
a	O
`	O
NaN	O
`	O
in	O
the	O
last	O
place	O
of	O
your	O
array	O
though	O
.	O

I've	O
tried	O
to	O
add	O
-march=i486	O
to	O
the	O
gcc	O
line	O
,	O
as	O
suggested	O
in	O
this	O
post	O
:	O

I	O
tried	O
indexing	O
it	O
before	O
but	O
i	O
didn't	O
get	O
the	O
trick	O
of	O
adding	O
1	O
to	O
the	O
size	O
of	O
label	O
1	O
before	O
.	O

Merging	O
ND	O
array	O
into	O
single	O
array	O
and	O
list	O

Its	O
not	O
complaning	O
any	O
error	O
,	O
so	O
I	O
don't	O
know	O
what	O
to	O
do	O
in	O
this	O
case	O
.	O

Here	O
is	O
a	O
sample	O
implementation	O
:	O
#CODE	O

And	O
then	O
proceed	O
with	O
the	O
split	O
of	O
each	O
shuffled	O
array	O
as	O
in	O
HYRY's	O
answer	O
.	O

This	O
is	O
quite	O
a	O
generic	O
solution	O
:	O
#CODE	O

List	O
comprehensions	O
and	O
generator	O
expressions	O
are	O
fairly	O
fast	O
,	O
and	O
they	O
don't	O
suffer	O
any	O
overhead	O
from	O
trying	O
to	O
guess	O
what	O
the	O
type	O
or	O
size	O
of	O
the	O
returned	O
item	O
should	O
be	O
,	O
as	O
they	O
don't	O
care	O
.	O

Examples	O
and	O
further	O
explanation	O
of	O
this	O
40-year-old	O
algorithm	O
at	O
the	O
matplotlib	O
FAQ	O
.	O

The	O
copy	O
will	O
only	O
copy	O
the	O
memory	O
page	O
on	O
which	O
the	O
refcount	O
integer	O
resides	O
.	O

What	O
is	O
the	O
cleanest	O
way	O
to	O
add	O
a	O
field	O
to	O
a	O
structured	O
numpy	O
array	O
?	O

Is	O
there	O
any	O
way	O
to	O
redefine	O
my	O
function	O
so	O
it	O
will	O
pass	O
without	O
warnings	O
?	O

@USER	O
:	O
the	O
reference	O
count	O
might	O
be	O
needed	O
(	O
though	O
I'm	O
not	O
entirely	O
sure	O
in	O
this	O
case	O
)	O
because	O
no	O
other	O
thread	O
must	O
deallocate	O
the	O
array	O
.	O

I	O
looked	O
around	O
but	O
couldn't	O
find	O
anything	O
syntax	O
wise	O
regarding	O
this	O
specific	O
scenario	O
.	O

While	O
this	O
involves	O
copying	O
,	O
do	O
you	O
do	O
this	O
often	O
enough	O
for	O
the	O
cost	O
of	O
the	O
copy	O
to	O
be	O
a	O
problem	O
?	O

I	O
think	O
you	O
can	O
see	O
where	O
this	O
is	O
going	O
.	O

Here	O
is	O
a	O
sample	O
function	O
(	O
you	O
need	O
to	O
have	O
the	O
pyopencv	O
module	O
installed	O
):	O
#CODE	O

I	O
have	O
learned	O
now	O
that	O
numpy	O
does	O
internally	O
create	O
a	O
temporary	O
array	O
for	O
the	O
output	O
and	O
in	O
the	O
end	O
copies	O
this	O
array	O
,	O
that	O
is	O
why	O
it	O
fails	O
for	O
the	O
values	O
that	O
are	O
zero	O
in	O
the	O
original	O
array	O
.	O

If	O
your	O
list	O
is	O
sorted	O
,	O
you	O
can	O
achieve	O
very	O
quick	O
search	O
of	O
index	O
with	O
the	O
'	O
bisect	O
'	O
package	O
.	O

How	O
to	O
save	O
a	O
boolean	O
matrix	O
?	O

I	O
have	O
need	O
to	O
slice	O
an	O
array	O
where	O
I	O
would	O
like	O
zero	O
to	O
be	O
assumed	O
for	O
every	O
dimension	O
except	O
the	O
first	O
.	O

will	O
compile	O
machine	O
code	O
that	O
will	O
execute	O
fast	O
and	O
with	O
minimal	O
memory	O
overhead	O
,	O
taking	O
care	O
of	O
memory	O
locality	O
stuff	O
(	O
and	O
thus	O
cache	O
optimization	O
)	O
if	O
the	O
same	O
array	O
occurs	O
several	O
times	O
in	O
your	O
expression	O
,	O

First	O
,	O
note	O
that	O
for	O
most	O
everyday	O
uses	O
,	O
you	O
probably	O
won't	O
require	O
an	O
array	O
(	O
which	O
is	O
a	O
special	O
datatype	O
in	O
Numpy	O
)	O
.	O

Not	O
sure	O
if	O
it	O
helps	O
but	O
if	O
you	O
add	O
another	O
array	O
of	O
a	O
different	O
shape	O
,	O
it	O
converts	O
back	O
to	O
the	O
types	O
you	O
want	O
:	O
#CODE	O

plus	O
lists	O
of	O
known	O
objects	O
falling	O
inside	O
the	O
field	O
of	O
view	O
.	O

Look	O
at	O
the	O
documentation	O
here	O
and	O
here	O
to	O
see	O
how	O
to	O
set	O
your	O
backend	O
.	O

numpy	O
array	O
plot	O
matrix	O
matplotlib	O

After	O
the	O
records	O
are	O
loaded	O
,	O
I	O
can	O
access	O
them	O
in	O
the	O
normal	O
NumPy	O
fashion	O
.	O

Eventually	O
,	O
I'm	O
looking	O
for	O
a	O
way	O
of	O
creating	O
graphs	O
similar	O
to	O
the	O
one	O
below	O
using	O
naive	O
Python	O
(	O
with	O
any	O
"	O
standard	O
"	O
library	O
such	O
as	O
numpy	O
,	O
matplotlib	O
etc	O
,	O
but	O
without	O
using	O
R	O
or	O
other	O
external	O
tools	O
)	O
.	O

On	O
a	O
general	O
note	O
however	O
,	O
in	O
numpy	O
it	O
is	O
better	O
to	O
always	O
use	O
base	O
class	O
arrays	O
unless	O
you	O
are	O
doing	O
a	O
lot	O
of	O
matrix	O
multiplications	O
,	O
etc	O
.	O

Exact	O
,	O
in	O
optimization	O
context	O
,	O
and	O
as	O
far	O
as	O
Powell	O
Badly	O
Scaled	O
function	O
is	O
used	O
for	O
test	O
,	O
I	O
impose	O
some	O
box	O
constraints	O
.	O

At	O
the	O
moment	O
I	O
have	O
the	O
lines	O
in	O
a	O
list	O
of	O
lists	O
then	O
looping	O
through	O
and	O
testing	O
for	O
identity	O
with	O
the	O
previous	O
value	O
at	O
index	O
0	O
in	O
the	O
list	O
but	O
this	O
is	O
very	O
clumsy	O
.	O

Calculating	O
the	O
exact	O
dimensions	O
of	O
this	O
array	O
:	O
I	O
tried	O
len	O
(	O
x	O
[	O
0	O
])	O
and	O
len	O
(	O
x	O
)	O
to	O
get	O
the	O
both	O
dimensional	O
coordinates	O
,	O
but	O
this	O
way	O
seems	O
a	O
bit	O
hackish	O
.	O

If	O
you	O
know	O
the	O
size	O
,	O
you	O
might	O
want	O
to	O
consider	O
pre-allocating	O
the	O
array	O
and	O
parsing	O
it	O
yourself	O
.	O

What	O
does	O
the	O
autocorrelation	O
array	O
look	O
like	O
if	O
you	O
plot	O
it	O
?	O

Where	O
it	O
says	O
:	O
#CODE	O
