@USER	O
Pennington	O
:	O
So	O
I	O
was	O
able	O
convert	O
my	O
~	O
1,000	O
line	O
program	O
easily	O
to	O
using	O
pandas	O
.	O
great	O
call	O
...	O
any	O
idea	O
how	O
I	O
might	O
get	O
my	O
compound	O
return	O
series	O
created	O
?	O

I	O
was	O
was	O
thinking	O
of	O
using	O
a	O
lambda	O
function	O
in	O
the	O
apply	O
method	O
of	O
DataMatrix	O
but	O
I'm	O
having	O
some	O
challenges	O
...	O

Thanks	O

I	O
tested	O
with	O
apply	O
,	O
it	O
seems	O
that	O
when	O
there	O
are	O
many	O
sub	O
groups	O
,	O
it's	O
very	O
slow	O
.	O
the	O
groups	O
attribute	O
of	O
grouped	O
is	O
a	O
dict	O
,	O
you	O
can	O
choice	O
index	O
directly	O
from	O
it	O
:	O
#CODE	O

Just	O
as	O
a	O
small	O
addition	O
,	O
you	O
can	O
also	O
do	O
an	O
apply	O
if	O
you	O
have	O
a	O
complex	O
function	O
that	O
you	O
apply	O
to	O
a	O
single	O
column	O
:	O

probably	O
x	O
is	O
a	O
confusing	O
name	O
for	O
the	O
column	O
name	O
and	O
the	O
row	O
variable	O
,	O
though	O
I	O
agree	O
apply	O
is	O
easiest	O
way	O
to	O
do	O
it	O
:)	O

just	O
to	O
add	O
,	O
`	O
apply	O
`	O
can	O
also	O
be	O
applied	O
to	O
multiple	O
columns	O
:	O

Can	O
apply	O
take	O
in	O
a	O
function	O
defined	O
elsewhere	O
in	O
code	O
?	O

this	O
is	O
so	O
that	O
we	O
can	O
introduce	O
a	O
more	O
complicated	O
function	O

How	O
to	O
apply	O
slicing	O
on	O
pandas	O
Series	O
of	O
strings	O

I'm	O
playing	O
with	O
pandas	O
and	O
trying	O
to	O
apply	O
string	O
slicing	O
on	O
a	O
Series	O
of	O
strings	O
object	O
.	O

`	O
apply	O
`	O
first	O
tries	O
to	O
apply	O
the	O
function	O
to	O
the	O
whole	O
series	O
.	O

Only	O
if	O
that	O
fails	O
it	O
maps	O
the	O
given	O
function	O
to	O
each	O
element	O
.	O

`	O
[:	O
2	O
]`	O
is	O
a	O
valid	O
function	O
on	O
a	O
series	O
,	O
`	O
+	O
'	O
qwerty	O
'`	O
apparently	O
isn't	O
,	O
that's	O
why	O
you	O
do	O
get	O
the	O
implicit	O
mapping	O
on	O
the	O
latter	O
.	O

If	O
you	O
always	O
want	O
to	O
do	O
the	O
mapping	O
you	O
can	O
use	O
`	O
s.map	O
`	O
.	O

`	O
apply	O
`'	O
s	O
source	O
code	O
for	O
reference	O
:	O
#CODE	O

To	O
clarify	O
:	O
The	O
`	O
any	O
(	O
1	O
)`	O
approach	O
wouldn't	O
work	O
if	O
you	O
had	O
other	O
values	O
in	O
the	O
table	O
that	O
you	O
didn't	O
want	O
to	O
filter	O
.	O

Suppose	O
there	O
are	O
many	O
columns	O
and	O
you	O
only	O
want	O
the	O
`	O
any	O
`	O
to	O
apply	O
to	O
a	O
subset	O
of	O
them	O
(	O
you	O
know	O
the	O
subset's	O
labels	O
)	O
.	O

Then	O
,	O
using	O
the	O
ability	O
to	O
apply	O
multiple	O
aggregation	O
functions	O
following	O
a	O
groupby	B-API
,	O
you	O
can	O
say	O
:	O
#CODE	O

That's	O
OK	O
,	O
although	O
it	O
has	O
the	O
problem	O
that	O
I	O
don't	O
even	O
know	O
the	O
number	O
of	O
columns	O
beforehand	O
.	O

I	O
think	O
I	O
will	O
continue	O
converting	O
the	O
dataframe	B-API
after	O
loading	O
with	O
the	O
apply	O
method	O
.	O

I	O
see	O
that	O
Pandas	O
does	O
not	O
allow	O
duplicate	O
time	O
series	O
indexes	O
yet	O
(	O
#URL	O
)	O
,	O
but	O
will	O
be	O
added	O
soon	O
.	O

I	O
am	O
wondering	O
if	O
there	O
is	O
a	O
good	O
way	O
to	O
apply	O
rolling	O
window	O
means	O
to	O
a	O
dataset	O
with	O
duplicate	O
times	O
by	O
a	O
multi-index	O
tag	O
/	O
column	O

However	O
mine	O
uses	O
the	O
apply	O
function	O
of	O
a	O
dataframe	B-API
instead	O
of	O
the	O
aggregate	O
.	O

and	O
apply	O
agg()	B-API
with	O
it	O
:	O
#CODE	O

I	O
tried	O
all	O
manner	O
of	O
`	O
strftime	B-API
`	O
methods	O
on	O
cdiff.DATE	O
with	O
no	O
success	O
.	O

It	O
wants	O
to	O
apply	O
the	O
to	O
strings	O
,	O
not	O
series	O
object	O
.	O

I	O
am	O
trying	O
do	O
use	O
a	O
pandas	O
multiindex	O
to	O
select	O
a	O
partial	O
slice	O
at	O
the	O
top	O
level	O
index	O
(	O
date	O
)	O
,	O
and	O
apply	O
a	O
list	O
to	O
the	O
second	O
level	O
index	O
(	O
stock	O
symbol	O
)	O
.	O

I.e.	O
below	O
I	O
want	O
the	O
data	O
for	O
AAPL	O
and	O
MSFT	O
in	O
the	O
range	O
#URL	O

AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
reset_index	B-API
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

I	O
think	O
the	O
same	O
concepts	O
apply	O
to	O
an	O
index	O
of	O
floats	O
.	O

You	O
just	O
need	O
to	O
write	O
your	O
own	O
method	O
to	O
group	O
samples	O
into	O
a	O
period	O
group	O
and	O
time	O
step	O
within	O
the	O
group	O
.	O

Hope	O
that	O
helps	O

I	O
don't	O
think	O
underlying	O
mathematics	O
apply	O
that	O
sum	O
of	O
interpolation	O
equal	O
to	O
interpolation	O
of	O
sum	O
.	O

it	O
only	O
holds	O
at	O
special	O
case	O

Is	O
there	O
a	O
more	O
performant	O
and	O
/	O
or	O
more	O
idiomatic	O
way	O
to	O
do	O
this	O
?	O

I	O
know	O
about	O
apply	O
,	O
but	O
sometimes	O
it's	O
more	O
convenient	O
to	O
use	O
a	O
for	O
loop	O
.	O

Thanks	O
in	O
advance	O
.	O

Thanks	O
.	O

Is	O
apply	O
more	O
efficient	O
than	O
iterrows	B-API
?	O

Returning	O
multiple	O
values	O
from	O
pandas	O
apply	O
on	O
a	O
DataFrame	B-API

Now	O
,	O
supposing	O
I	O
have	O
"	O
a	O
"	O
and	O
"	O
b	O
"	O
as	O
one	O
group	O
,	O
and	O
"	O
c	O
"	O
and	O
"	O
d	O
"	O
at	O
the	O
other	O
,	O
I'm	O
performing	O
the	O
t-test	O
row-wise	O
.	O

This	O
is	O
fairly	O
trivial	O
with	O
pandas	O
,	O
using	O
`	O
apply	O
`	O
with	O
axis=1	O
.	O

However	O
,	O
I	O
can	O
either	O
return	O
a	O
DataFrame	B-API
of	O
the	O
same	O
shape	O
if	O
my	O
function	O
doesn't	O
aggregate	O
,	O
or	O
a	O
Series	O
if	O
it	O
aggregates	O
.	O

Why	O
are	O
you	O
using	O
`	O
apply	O
`	O
in	O
the	O
first	O
place	O
?	O

Your	O
result	O
is	O
a	O
new	O
`	O
DataFrame	B-API
`	O
with	O
a	O
shape	O
different	O
from	O
the	O
input	O
(	O
both	O
rows	O
and	O
columns	O
)	O
,	O
therefore	O
it's	O
a	O
completely	O
new	O
obj	O
.	O

You	O
could	O
just	O
have	O
`	O
t_test_and_mean	O
`	O
accept	O
your	O
input	O
dataframe	B-API
(	O
and	O
the	O
columns	O
to	O
group	O
by	O
)	O
and	O
return	O
a	O
1-row-2-columns	O
dataframe	B-API
,	O
without	O
using	O
`	O
apply	O
`	O
.	O

Some	O
of	O
the	O
tables	O
I'm	O
displaying	O
would	O
be	O
much	O
easier	O
to	O
read	O
with	O
a	O
little	O
bit	O
of	O
formatting	O
.	O

I'd	O
really	O
like	O
something	O
like	O
"	O
zebra	O
tables	O
"	O
where	O
every	O
other	O
row	O
is	O
shaded	O
.	O

I	O
read	O
here	O
about	O
how	O
this	O
formatting	O
can	O
be	O
implemented	O
via	O
css	O
.	O

Is	O
there	O
a	O
really	O
straight	O
forward	O
way	O
to	O
apply	O
a	O
css	O
to	O
an	O
IPython	O
Notebook	O
and	O
then	O
have	O
tables	O
rendered	O
using	O
the	O
style	O
sheet	O
?	O

If	O
you	O
just	O
stick	O
that	O
in	O
one	O
of	O
your	O
markdown	O
cells	O
,	O
then	O
it	O
will	O
apply	O
to	O
everything	O
on	O
the	O
page	O
.	O

How	O
to	O
optimally	O
apply	O
a	O
function	O
on	O
all	O
items	O
of	O
a	O
dataframe	B-API
using	O
inputs	O
from	O
another	O
dataframe	B-API
?	O

I	O
am	O
new	O
in	O
python	O
and	O
I	O
am	O
currenlt	O
struggly	O
to	O
do	O
simple	O
things	O
with	O
pandas	O
.	O

I	O
would	O
like	O
to	O
apply	O
the	O
same	O
function	O
to	O
each	O
item	O
of	O
a	O
given	O
dataset	O
but	O
using	O
a	O
time-dependent	O
parameter	O
.	O

I'm	O
having	O
a	O
bit	O
of	O
trouble	O
altering	O
a	O
duplicated	O
pandas	O
DataFrame	B-API
and	O
not	O
having	O
the	O
edits	O
apply	O
to	O
both	O
the	O
duplicate	O
and	O
the	O
original	O
DataFrame	B-API
.	O

Then	O
I	O
assign	O
the	O
'	O
d	O
'	O
dataframe	B-API
to	O
variable	O
'	O
e	O
'	O
and	O
apply	O
some	O
arbitrary	O
math	O
to	O
column	O
'	O
a	O
'	O
using	O
apply	O
:	O
#CODE	O

The	O
problem	O
arises	O
in	O
that	O
the	O
apply	O
function	O
apparently	O
applies	O
to	O
both	O
the	O
duplicate	O
DataFrame	B-API
'	O
e	O
'	O
and	O
original	O
DataFrame	B-API
'	O
d	O
'	O
,	O
which	O
I	O
cannot	O
for	O
the	O
life	O
of	O
me	O
figure	O
out	O
:	O
#CODE	O

So	O
,	O
apply	O
this	O
function	O
to	O
each	O
of	O
those	O
3	O
columns	O
:	O
#CODE	O

You	O
want	O
to	O
use	O
the	O
apply	O
function	O
and	O
a	O
lambda	O
:	O
#CODE	O

I	O
don't	O
believe	O
you	O
can	O
avoid	O
iteration	O
100%	O
with	O
what	O
you	O
are	O
trying	O
to	O
do	O
.	O

You	O
can	O
possibly	O
duplicate	O
the	O
`	O
quote	O
`	O
column	O
twice	O
shifting	O
it	O
by	O
one	O
each	O
direction	O
and	O
apply	O
it	O
to	O
your	O
dataset	O
to	O
create	O
a	O
pivot	B-API
table	O
based	O
on	O
entries	O
where	O
`	O
quote	O
`	O
is	O
!	O

=	O
to	O
`	O
quote_next	O
`	O
and	O
`	O
quote_prev	O
`	O
.	O

I'm	O
using	O
the	O
excellent	O
`	O
pandas	O
`	O
package	O
to	O
deal	O
with	O
a	O
large	O
amount	O
of	O
varied	O
meteorological	O
diagnostic	O
data	O
and	O
I'm	O
quickly	O
running	O
out	O
of	O
dimensions	O
as	O
I	O
stitch	O
the	O
data	O
together	O
.	O

Looking	O
at	O
the	O
documentation	O
,	O
it	O
may	O
be	O
that	O
using	O
the	O
`	O
MultiIndex	O
`	O
may	O
solve	O
my	O
problem	O
,	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
apply	O
it	O
to	O
my	O
situation	O
-	O
the	O
documentation	O
shows	O
examples	O
of	O
creating	O
MultiIndexes	O
with	O
random	O
data	O
and	O
DataFrames	O
,	O
but	O
not	O
Series	O
with	O
pre-existing	O
timeseries	O
data	O
.	O

I've	O
run	O
out	O
of	O
dimensions	O
(	O
up	O
to	O
3-D	O
with	O
a	O
Panel	O
)	O
and	O
I'm	O
also	O
not	O
able	O
to	O
use	O
things	O
like	O
`	O
dropna	B-API
`	O
to	O
remove	O
empty	O
columns	O
once	O
everything	O
is	O
aligned	O
in	O
the	O
Panel	O
(	O
this	O
has	O
led	O
to	O
several	O
bugs	O
when	O
plotting	O
summary	O
statistics	O
)	O
.	O

Reading	O
about	O
using	O
pandas	O
with	O
higher-dimensional	O
data	O
has	O
led	O
to	O
reading	O
about	O
the	O
`	O
MultiIndex	O
`	O
and	O
its	O
use	O
.	O

I've	O
tried	O
the	O
examples	O
given	O
in	O
the	O
documentation	O
,	O
but	O
I'm	O
still	O
a	O
little	O
unclear	O
how	O
to	O
apply	O
it	O
to	O
my	O
situation	O
.	O

Any	O
direction	O
would	O
be	O
useful	O
.	O

I'd	O
like	O
to	O
be	O
able	O
to	O
:	O

Once	O
I	O
have	O
the	O
frame	O
given	O
by	O
this	O
routine	O
,	O
I	O
can	O
easily	O
apply	O
the	O
various	O
operations	O
suggested	O
below	O
-	O
of	O
particular	O
utility	O
is	O
being	O
able	O
to	O
use	O
the	O
`	O
names	O
`	O
field	O
when	O
I	O

How	O
can	O
I	O
iterate	O
and	O
apply	O
a	O
function	O
over	O
a	O
single	O
level	O
of	O
a	O
DataFrame	B-API
with	O
MultiIndex	O
?	O

This	O
works	O
for	O
lists	O
in	O
general	O
and	O
I	O
am	O
familiar	O
with	O
it	O
.	O

How	O
do	O
I	O
apply	O
it	O
to	O
a	O
pandas	O
DataFrame	B-API
?	O

I	O
would	O
like	O
to	O
roll	O
through	O
my	O
data	O
by	O
date	O
and	O
on	O
each	O
date	O
take	O
a	O
time	O
slice	O
in	O
the	O
past	O
apply	O
a	O
function	O
to	O
every	O
time	O
series	O
so	O
I	O
get	O
a	O
result	O
such	O
as	O
this	O
where	O
X	O
is	O
the	O
output	O
of	O
the	O
function	O
of	O
timeslice	O
.	O

#CODE	O

Also	O
is	O
there	O
some	O
other	O
way	O
to	O
do	O
the	O
following.Using	O
Apply	O
function	O
seems	O
to	O
be	O
very	O
slow	O
for	O
large	O
dataset	O
.	O

Similar	O
to	O
this	O
R	O
question	O
,	O
I'd	O
like	O
to	O
apply	O
a	O
function	O
to	O
each	O
item	O
in	O
a	O
Series	O
(	O
or	O
each	O
row	O
in	O
a	O
DataFrame	B-API
)	O
using	O
Pandas	O
,	O
but	O
want	O
to	O
use	O
as	O
an	O
argument	O
to	O
this	O
function	O
the	O
index	O
or	O
id	O
of	O
that	O
row	O
.	O

As	O
a	O
trivial	O
example	O
,	O
suppose	O
one	O
wants	O
to	O
create	O
a	O
list	O
of	O
tuples	O
of	O
the	O
form	O
[(	O
index_i	O
,	O
value_i	O
)	O
,	O
...,	O
(	O
index_n	O
,	O
value_n	O
)]	O
.	O

Using	O
a	O
simple	O
Python	O
for	O
loop	O
,	O
I	O
can	O
do	O
:	O

But	O
there	O
must	O
be	O
a	O
more	O
efficient	O
way	O
to	O
do	O
this	O
?	O

Perhaps	O
something	O
more	O
Panda-ish	O
like	O
Series.apply	B-API
?	O

In	O
reality	O
,	O
I'm	O
not	O
worried	O
(	O
in	O
this	O
case	O
)	O
about	O
returning	O
anything	O
meaningful	O
,	O
but	O
more	O
for	O
the	O
efficiency	O
of	O
something	O
like	O
'	O
apply	O
'	O
.	O

Any	O
ideas	O
?	O

If	O
you	O
use	O
the	O
apply	O
method	O
with	O
a	O
function	O
what	O
happens	O
is	O
that	O
every	O
item	O
in	O
the	O
Series	O
will	O
be	O
mapped	O
with	O
such	O
a	O
function	O
.	O

E.g.	O

#CODE	O

A	O
more	O
complex	O
usage	O
of	O
apply	O
would	O
be	O
this	O
one	O
:	O
#CODE	O

Following	O
the	O
OP's	O
question	O
for	O
clarifications	O
:	O
Don't	O
confuse	O
Series	O
(	O
1D	O
)	O
with	O
DataFrames	O
(	O
2D	O
)	O
#URL	O
-	O
as	O
I	O
don't	O
really	O
see	O
how	O
you	O
can	O
talk	O
about	O
rows	O
.	O

However	O
you	O
can	O
include	O
indices	O
in	O
your	O
function	O
by	O
creating	O
a	O
new	O
series	O
(	O
apply	O
wont	O
give	O
you	O
any	O
information	O
about	O
the	O
current	O
index	O
):	O
#CODE	O

grouped	O
pandas	O
DataFrames	O
:	O
how	O
do	O
I	O
apply	O
scipy.stats.sem	O
to	O
them	O
?	O

I	O
know	O
that	O
I	O
can	O
apply	O
numpy	O
methods	O
by	O
doing	O
the	O
following	O
:	O

The	O
trick	O
here	O
is	O
to	O
use	O
the	O
`	O
axis=1	O
`	O
option	O
in	O
the	O
`	O
apply	O
`	O
to	O
pass	O
elements	O
to	O
the	O
lambda	O
function	O
row	O
by	O
row	O
,	O
as	O
opposed	O
to	O
column	O
by	O
column	O
.	O

Why	O
map	O
instead	O
of	O
apply	O
?	O

Also	O
,	O
you	O
don't	O
really	O
need	O
the	O
lambda	O
here	O
,	O
just	O
feeding	O
`	O
np.mean	B-API
`	O
would	O
work	O
too	O
,	O
but	O
I	O
left	O
the	O
lambda	O
in	O
to	O
illustrate	O
how	O
you	O
would	O
solve	O
this	O
when	O
more	O
general	O
functions	O
that	O
you	O
want	O
to	O
apply	O
aren't	O
working	O
in	O
their	O
default	O
ways	O
.	O

The	O
`	O
.apply	B-API
`	O
function	O
is	O
very	O
powerful	O
in	O
Pandas	O
.	O

I	O
went	O
ahead	O
and	O
did	O
a	O
tiny	O
benchmark	O
in	O
IPython	O
.	O

First	O
is	O
for	O
`	O
vtype	O
`	O
above	O
,	O
then	O
for	O
the	O
`	O
apply	O
`	O
route	O
.	O

I	O
repeated	O
it	O
a	O
dozen	O
or	O
so	O
times	O
,	O
and	O
this	O
example	O
run	O
is	O
pretty	O
typical	O
on	O
my	O
machine	O
.	O

I	O
often	O
need	O
to	O
apply	O
a	O
function	O
to	O
the	O
groups	O
of	O
a	O
very	O
large	O
`	O
DataFrame	B-API
`	O
(	O
of	O
mixed	O
data	O
types	O
)	O
and	O
would	O
like	O
to	O
take	O
advantage	O
of	O
multiple	O
cores	O
.	O

Thanks	O
to	O
the	O
help	O
of	O
this	O
forum	O
i	O
managed	O
to	O
solve	O
a	O
similar	O
question	O
using	O
groupBy	B-API
and	O
the	O
apply	O
function	O
but	O
i	O
would	O
love	O
to	O
also	O
use	O
the	O
cool	O
resample	O
function	O
.	O

A	O
combination	O
of	O
boolean	O
indexing	O
and	O
apply	O
can	O
do	O
the	O
trick	O
.	O

Quite	O
neat	O
.	O

However	O
,	O
I	O
think	O
that	O
you	O
can	O
get	O
away	O
with	O
`	O
.max	B-API
(	O
axis=1	O
)`	O
instead	O
of	O
`	O
apply	O
(	O
...	O
)`	O
.	O

`	O
max()	B-API
`	O
is	O
ok	O
too	O
of	O
course	O
,	O
i	O
think	O
i	O
got	O
biased	O
towards	O
`	O
apply	O
`	O
by	O
the	O
way	O
you	O
asked	O
the	O
question	O
:-)	O

The	O
problem	O
in	O
your	O
code	O
is	O
that	O
you	O
want	O
to	O
apply	O
the	O
operation	O
on	O
every	O
row	O
.	O

The	O
way	O
you've	O
written	O
it	O
though	O
takes	O
the	O
whole	O
'	O
bar	O
'	O
and	O
'	O
foo	O
'	O
columns	O
,	O
converts	O
them	O
to	O
strings	O
and	O
gives	O
you	O
back	O
one	O
big	O
string	O
.	O

You	O
can	O
write	O
it	O
like	O
:	O
#CODE	O

Most	O
operations	O
in	O
`	O
pandas	O
`	O
can	O
be	O
accomplished	O
with	O
operator	O
chaining	O
(	O
`	O
groupby	B-API
`	O
,	O
`	O
aggregate	O
`	O
,	O
`	O
apply	O
`	O
,	O
etc	O
)	O
,	O
but	O
the	O
only	O
way	O
I've	O
found	O
to	O
filter	O
rows	O
is	O
via	O
normal	O
bracket	O
indexing	O
#CODE	O

If	O
you	O
would	O
like	O
to	O
apply	O
all	O
of	O
the	O
common	O
boolean	O
masks	O
as	O
well	O
as	O
a	O
general	O
purpose	O
mask	O
you	O
can	O
chuck	O
the	O
following	O
in	O
a	O
file	O
and	O
then	O
simply	O
assign	O
them	O
all	O
as	O
follows	O
:	O
#CODE	O

and	O
than	O
apply	O
it	O
by	O
passing	O
the	O
function	O
and	O
the	O
args	O
to	O
`	O
agg	O
`	O
:	O
#CODE	O

Should	O
I	O
use	O
a	O
lambda	O
with	O
`	O
apply	O
`	O
?	O

(	O
If	O
so	O
,	O
how	O
do	O
I	O
get	O
a	O
reference	O
to	O
the	O
given	O
column	O
,	O
as	O
opposed	O
to	O
a	O
whole	O
row	O
)	O
.	O

python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O

I	O
want	O
to	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O
in	O
python	O
pandas	O
:	O
#CODE	O

The	O
documentation	O
describes	O
support	O
for	O
an	O
apply	O
method	O
,	O
but	O
it	O
doesn't	O
accept	O
any	O
arguments	O
.	O

Is	O
there	O
a	O
different	O
method	O
that	O
accepts	O
arguments	O
?	O

Alternatively	O
,	O
am	O
I	O
missing	O
a	O
simple	O
workaround	O
?	O

The	O
documentation	O
explains	O
this	O
clearly	O
.	O

The	O
apply	O
method	O
accept	O
a	O
python	O
function	O
which	O
should	O
have	O
a	O
single	O
parameter	O
.	O

If	O
you	O
want	O
to	O
pass	O
more	O
parameters	O
you	O
should	O
use	O
`	O
functools.partial	O
`	O
as	O
suggested	O
by	O
Joel	O
Cornett	O
in	O
his	O
comment	O
.	O

For	O
a	O
DataFrame	B-API
apply	O
method	O
accepts	O
`	O
args	O
`	O
argument	O
,	O
which	O
is	O
a	O
tuple	O
holding	O
additional	O
positional	O
arguments	O
or	O
**	O
kwds	O
for	O
named	O
ones	O
.	O

I	O
created	O
an	O
issue	O
to	O
have	O
this	O
also	O
for	O
Series.apply()	B-API
#URL	O

I	O
want	O
to	O
apply	O
a	O
groupby	B-API
operation	O
that	O
computes	O
cap-weighted	O
average	O
return	O
across	O
everything	O
,	O
per	O
each	O
date	O
in	O
the	O
"	O
yearmonth	O
"	O
column	O
.	O

This	O
still	O
requires	O
me	O
to	O
save	O
out	O
the	O
groupby	B-API
computation	O
,	O
rather	O
than	O
having	O
the	O
assignment	O
directly	O
on	O
the	O
LHS	O
on	O
the	O
line	O
where	O
I	O
perform	O
the	O
groupby	B-API
operation	O
.	O

Apply	O
might	O
be	O
a	O
bit	O
better	O
than	O
the	O
loop	O
in	O
my	O
hack	O
at	O
the	O
bottom	O
of	O
the	O
question	O
,	O
but	O
they	O
are	O
basically	O
the	O
same	O
idea	O
.	O

While	O
I'm	O
still	O
exploring	O
all	O
of	O
the	O
incredibly	O
smart	O
ways	O
that	O
`	O
apply	O
`	O
concatenates	O
the	O
pieces	O
it's	O
given	O
,	O
here's	O
another	O
way	O
to	O
add	O
a	O
new	O
column	O
in	O
the	O
parent	O
after	O
a	O
groupby	B-API
operation	O
.	O

#CODE	O

Is	O
there	O
an	O
efficient	O
way	O
to	O
apply	O
this	O
disaggregation	O
map	O
to	O
get	O
a	O
new	O
dataframe	B-API
at	O
a	O
State	O
level	O
?	O

There	O
might	O
be	O
a	O
slick	O
vectorized	O
way	O
to	O
do	O
this	O
,	O
but	O
I'd	O
just	O
apply	O
the	O
obvious	O
per-entry	O
function	O
to	O
the	O
values	O
and	O
get	O
on	O
with	O
my	O
day	O
:	O
#CODE	O

The	O
function	O
to	O
apply	O
is	O
like	O
:	O
#CODE	O

I	O
don't	O
suppose	O
you	O
have	O
nny	O
ideas	O
on	O
the	O
second	O
part	O
,	O
viz	O
referencing	O
neighbouring	O
rows	O
in	O
the	O
dataframe	B-API
from	O
within	O
the	O
map	O
/	O
apply	O
function	O
?	O

The	O
exact	O
code	O
will	O
vary	O
for	O
each	O
of	O
the	O
columns	O
you	O
want	O
to	O
do	O
,	O
but	O
it's	O
likely	O
you'll	O
want	O
to	O
use	O
the	O
`	O
map	O
`	O
and	O
`	O
apply	O
`	O
functions	O
.	O

In	O
some	O
cases	O
you	O
can	O
just	O
compute	O
using	O
the	O
existing	O
columns	O
directly	O
,	O
since	O
the	O
columns	O
are	O
Pandas	O
Series	O
objects	O
,	O
which	O
also	O
work	O
as	O
Numpy	O
arrays	O
,	O
which	O
automatically	O
work	O
element-wise	O
for	O
usual	O
mathematical	O
operations	O
.	O

#CODE	O

If	O
you	O
need	O
to	O
use	O
operations	O
like	O
max	O
and	O
min	O
within	O
a	O
row	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
to	O
apply	O
any	O
function	O
you	O
like	O
to	O
each	O
row	O
.	O

Here's	O
an	O
example	O
that	O
computes	O
`	O
min	O
(	O
A	O
,	O
B	O
)	O
-C	O
`	O
,	O
which	O
seems	O
to	O
be	O
like	O
your	O
"	O
lower	O
wick	O
"	O
:	O
#CODE	O

For	O
the	O
second	O
part	O
,	O
I	O
would	O
recommend	O
introducing	O
a	O
column	O
indicating	O
the	O
pattern	O
for	O
each	O
row	O
and	O
writing	O
a	O
family	O
of	O
functions	O
which	O
deal	O
with	O
each	O
pattern	O
.	O

Then	O
groupby	B-API
the	O
pattern	O
and	O
apply	O
the	O
appropriate	O
function	O
to	O
each	O
group	O
.	O

Note	O
that	O
a	O
simple	O
`	O
apply	O
`	O
will	O
not	O
work	O
here	O
,	O
since	O
it	O
won't	O
know	O
how	O
to	O
make	O
sense	O
of	O
the	O
possibly	O
differently-sized	O
result	O
arrays	O
for	O
each	O
group	O
.	O

What	O
problems	O
are	O
you	O
running	O
into	O
with	O
`	O
apply	O
`	O
?	O

It	O
works	O
for	O
this	O
toy	O
example	O
here	O
and	O
the	O
group	O
lengths	O
are	O
different	O
:	O
#CODE	O

Python	O
Pandas	O
:	O
How	O
to	O
broadcast	O
an	O
operation	O
using	O
apply	O
without	O
writing	O
a	O
secondary	O
function	O

It	O
seems	O
logical	O
to	O
use	O
the	O
`	O
apply	O
`	O
function	O
for	O
this	O
,	O
but	O
it	O
doesn't	O
work	O
like	O
expected	O
.	O

It	O
does	O
not	O
even	O
seem	O
to	O
be	O
consistent	O
with	O
other	O
uses	O
of	O
`	O
apply	O
`	O
.	O

See	O
below	O
.	O

#CODE	O

Based	O
on	O
this	O
,	O
it	O
appears	O
that	O
`	O
apply	O
`	O
does	O
nothing	O
but	O
perform	O
the	O
NumPy	O
equivalent	O
of	O
whatever	O
is	O
called	O
inside	O
.	O

That	O
is	O
,	O
`	O
apply	O
`	O
seems	O
to	O
execute	O
the	O
same	O
thing	O
as	O
`	O
arr	O
+	O
"	O
cat	O
"`	O
in	O
the	O
first	O
example	O
.	O

And	O
if	O
NumPy	O
happens	O
to	O
broadcast	O
that	O
,	O
then	O
it	O
will	O
work	O
.	O

If	O
not	O
,	O
then	O
it	O
won't	O
.	O

But	O
this	O
seems	O
to	O
break	O
from	O
what	O
`	O
apply	O
`	O
promises	O
in	O
the	O
docs	O
.	O

Below	O
is	O
the	O
quotation	O
for	O
what	O
pandas.Series.apply	B-API
should	O
expect	O
:	O

Is	O
there	O
some	O
way	O
of	O
using	O
`	O
apply	O
`	O
that	O
I	O
am	O
missing	O
here	O
?	O

and	O
I	O
verified	O
that	O
this	O
version	O
does	O
work	O
with	O
Pandas	O
`	O
apply	O
`	O
.	O

But	O
this	O
is	O
beside	O
the	O
point	O
.	O

It	O
would	O
be	O
easier	O
to	O
write	O
something	O
that	O
operated	O
externally	O
on	O
top	O
of	O
a	O
Series	O
object	O
than	O
to	O
have	O
to	O
constantly	O
write	O
wrappers	O
that	O
use	O
list	O
comprehensions	O
to	O
effectively	O
loop	O
over	O
the	O
contents	O
of	O
the	O
Series	O
.	O

Isn't	O
this	O
specifically	O
what	O
`	O
apply	O
`	O
is	O
supposed	O
to	O
abstract	O
away	O
from	O
the	O
user	O
?	O

and	O
use	O
this	O
in	O
`	O
apply	O
`	O
:	O
#CODE	O

This	O
works	O
,	O
but	O
I	O
consider	O
it	O
a	O
workaround	O
as	O
well	O
,	O
since	O
it	O
doesn't	O
address	O
the	O
fact	O
that	O
`	O
apply	O
`	O
isn't	O
working	O
as	O
promised	O
.	O

Can	O
you	O
verify	O
that	O
`	O
map	O
`	O
will	O
work	O
in	O
all	O
the	O
same	O
situations	O
where	O
`	O
apply	O
`	O
will	O
work	O
?	O

I	O
also	O
don't	O
like	O
the	O
inconsistency	O
in	O
going	O
from	O
`	O
map	O
`	O
for	O
a	O
Series	O
to	O
`	O
applymap	B-API
`	O
for	O
a	O
DataFrame	B-API
.	O

That	O
contradicts	O
the	O
docs	O
for	O
`	O
apply	O
`	O
,	O
as	O
well	O
as	O
its	O
0.8.1	O
behavior	O
,	O
in	O
which	O
it	O
successfully	O
performs	O
the	O
elementwise	O
version	O
of	O
my	O
example	O
above	O
,	O
whereas	O
version	O
0.7.3	O
seems	O
to	O
use	O
the	O
logic	O
you	O
describe	O
.	O

Since	O
`	O
apply	O
`	O
should	O
work	O
in	O
0.7.3	O
as	O
it	O
does	O
in	O
0.8.1	O
(	O
according	O
to	O
the	O
docs	O
)	O
,	O
that's	O
why	O
I	O
think	O
it's	O
a	O
workaround	O
.	O

`	O
map	O
`	O
is	O
fine	O
,	O
but	O
`	O
apply	O
`	O
should	O
work	O
.	O

I'm	O
on	O
github	O
master	O
and	O
it	O
does	O
not	O
work	O
;	O
it	O
probably	O
worked	O
in	O
0.8.1	O
by	O
accident	O
.	O

`	O
apply	O
`	O
is	O
designed	O
so	O
that	O
you	O
can	O
apply	O
a	O
ufunc	O
and	O
get	O
back	O
a	O
Series	O
with	O
the	O
index	O
intact	O
.	O

Take	O
a	O
look	O
at	O
the	O
source	O
code	O
,	O
it	O
tries	O
to	O
call	O
func	O
(	O
self	O
)	O
and	O
wraps	O
that	O
in	O
a	O
try	O
/	O
except	O
block	O
and	O
then	O
calls	O
map_infer	O
in	O
the	O
except	O
.	O

In	O
your	O
example	O
,	O
the	O
function	O
you	O
gave	O
*	O
can	O
*	O
take	O
a	O
Series	O
and	O
return	O
a	O
Series	O
but	O
doesn't	O
do	O
element-wise	O
operations	O
so	O
the	O
code	O
cannot	O
know	O
to	O
trigger	O
the	O
element-wise	O
case	O
.	O

To	O
be	O
explicit	O
that	O
you	O
want	O
the	O
input	O
function	O
to	O
be	O
applied	O
element-wise	O
,	O
you	O
have	O
to	O
use	O
`	O
Series.map	B-API
`	O
.	O

Though	O
I	O
do	O
agree	O
with	O
you	O
the	O
docstring	O
for	O
apply	O
is	O
very	O
unclear	O
about	O
this	O
aspect	O
.	O

We	O
can	O
improve	O
the	O
documentation	O
for	O
apply	O
.	O

In	O
fact	O
,	O
by	O
saying	O
that	O
`	O
apply	O
`	O
can	O
take	O
any	O
function	O
that	O
expect	O
a	O
*	O
single	O
*	O
argument	O
,	O
it's	O
not	O
just	O
unclear	O
,	O
but	O
plain	O
misleading	O
.	O

I'm	O
glad	O
you	O
confirmed	O
by	O
hunch	O
about	O
that	O
try-except	O
block	O
.	O

So	O
to	O
be	O
clear	O
,	O
we	O
should	O
use	O
`	O
apply	O
`	O
whenever	O
we	O
have	O
a	O
vectorized	O
/	O
ufunc	O
already	O
,	O
and	O
`	O
map	O
`	O
when	O
we	O
literally	O
want	O
to	O
apply	O
an	O
elementwise	O
operation	O
to	O
a	O
series	O
?	O

Yup	O
,	O
that's	O
exactly	O
right	O
on	O
`	O
apply	O
`	O
vs	O
`	O
map	O
`	O
.	O

The	O
inner	O
syntax	O
`	O
(	O
df	O
!	O
=0	O
)	O
.any()	B-API
`	O
doesn't	O
work	O
.	O

A	O
DataFrame	B-API
object	O
doesn't	O
have	O
the	O
`	O
any	O
`	O
function	O
,	O
at	O
least	O
not	O
in	O
0.7.3	O
.	O

You'd	O
have	O
to	O
map	O
that	O
to	O
the	O
columns	O
using	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
or	O
something	O
.	O

How	O
to	O
groupby	B-API
the	O
first	O
level	O
index	O
and	O
apply	O
function	O
to	O
the	O
second	O
index	O
in	O
Pandas	O

And	O
I	O
want	O
to	O
apply	O
a	O
function	O
`	O
func	O
`	O
(	O
exp	O
:	O
`'	O
lambda	O
x	O
:	O
x*10	O
'`)	O
to	O
`	O
second	O
`	O
,	O
somewhat	O
like	O
:	O
#CODE	O

This	O
way	O
,	O
the	O
index	O
column	O
is	O
not	O
dropped	O
and	O
still	O
accessible	O
for	O
your	O
`	O
apply	O
`	O
.	O

PS	O
:	O
but	O
if	O
you	O
really	O
just	O
want	O
the	O
last	O
column	O
,	O
`	O
apply	O
`	O
would	O
suffice	O
:	O
#CODE	O

(	O
I	O
think	O
it	O
can	O
be	O
some	O
problem	O
with	O
`	O
lambda	O
`	O
When	O
I	O
want	O
to	O
apply	O
my	O
function	O
to	O
the	O
column	O
I	O
have	O
an	O
error	O
:	O
`	O
TypeError	O
:	O
only	O
length-1	O
arrays	O
can	O
be	O
converted	O
to	O
Python	O
scalars	O
`)	O

On	O
top	O
of	O
a	O
dodgy	O
converter	O
,	O
i	O
think	O
you	O
apply	O
the	O
converter	O
to	O
the	O
wrong	O
column	O
(	O
look	O
at	O
the	O
exception	O
you	O
get	O
)	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
for	O
this	O
,	O
and	O
it's	O
a	O
bit	O
neater	O
:	O
#CODE	O

If	O
you	O
want	O
that	O
done	O
on	O
every	O
row	O
in	O
the	O
dataframe	B-API
,	O
you	O
can	O
use	O
apply	O
(	O
with	O
axis=1	O
to	O
select	O
rows	O
instead	O
of	O
columns	O
):	O
#CODE	O

At	O
the	O
moment	O
for	O
conversion	O
I	O
use	O
as	O
below	O
,	O
but	O
need	O
remove	O
unwanted	O
rows	O
first	O
to	O
apply	O
it	O
to	O
all	O
df	O
.	O

#CODE	O

is	O
there	O
an	O
existing	O
built-in	O
way	O
to	O
apply	O
two	O
different	O
aggregating	O
functions	O
to	O
the	O
same	O
column	O
,	O
without	O
having	O
to	O
call	O
`	O
agg	O
`	O
multiple	O
times	O
?	O

N	O
/	O
M	O
I	O
didn't	O
see	O
the	O
extra	O
call	O
to	O
`	O
returns	O
`	O
in	O
there	O
.	O

So	O
this	O
is	O
the	O
Series	O
version	O
of	O
aggregate	O
?	O

I'm	O
looking	O
to	O
do	O
the	O
DataFrame	B-API
version	O
of	O
aggregate	O
,	O
and	O
I	O
want	O
to	O
apply	O
several	O
different	O
aggregations	O
to	O
each	O
column	O
all	O
at	O
once	O
.	O

An	O
alternative	O
slightly	O
more	O
flexible	O
way	O
,	O
might	O
be	O
to	O
use	O
`	O
apply	O
`	O
(	O
or	O
equivalently	O
`	O
map	O
`	O
)	O
to	O
do	O
this	O
:	O
#CODE	O

First	O
,	O
I	O
think	O
you	O
have	O
to	O
either	O
specify	O
named	O
parameters	O
or	O
use	O
`	O
args	O
`	O
to	O
pass	O
additional	O
arguments	O
to	O
`	O
apply	O
`	O
.	O

Your	O
second	O
argument	O
is	O
probably	O
being	O
interpreted	O
as	O
an	O
axis	O
.	O

But	O
if	O
you	O
use	O
#CODE	O

because	O
`	O
apply	O
`	O
doesn't	O
act	O
elementwise	O
,	O
it	O
acts	O
on	O
entire	O
Series	O
objects	O
.	O

Other	O
approaches	O
include	O
using	O
`	O
applymap	B-API
`	O
or	O
boolean	O
indexing	O
,	O
i.e.	O
#CODE	O

One	O
way	O
to	O
do	O
this	O
is	O
to	O
use	O
apply	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
change	O
the	O
values	O
in	O
only	O
one	O
column	O
you	O
can	O
still	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

Note	O
:	O
since	O
`	O
my_fun2	O
`	O
returns	O
a	O
single	O
value	O
,	O
this	O
time	O
`	O
apply	O
`	O
return	O
a	O
Series	O
,	O
so	O
we	O
need	O
to	O
slightly	O
change	O
the	O
way	O
we	O
apply	O
apply	O
.	O

Looks	O
like	O
this	O
is	O
going	O
to	O
work	O
.	O

Thanks	O
for	O
your	O
help	O
!	O

In	O
general	O
,	O
though	O
,	O
is	O
there	O
a	O
prefered	O
approach	O
to	O
Split-Apply-Combine	O
where	O
Apply	O
returns	O
a	O
dataframe	B-API
of	O
arbitrary	O
size	O
(	O
but	O
consistent	O
for	O
all	O
chunks	O
)	O
,	O
and	O
Combine	O
just	O
vstacks	O
the	O
returned	O
DFs	O
?	O

Pandas	O
DataFrame	B-API
:	O
apply	O
function	O
to	O
all	O
columns	O

Is	O
there	O
a	O
more	O
pythonic	O
way	O
to	O
apply	O
a	O
function	O
to	O
all	O
columns	O
or	O
the	O
entire	O
frame	O
(	O
without	O
a	O
loop	O
)	O
?	O

I	O
have	O
found	O
a	O
workaround	O
which	O
is	O
listed	O
at	O
the	O
end	O
of	O
this	O
post	O
,	O
but	O
its	O
not	O
at	O
all	O
'	O
panda-style	O
'	O
and	O
prone	O
to	O
errors	O
.	O

The	O
apply	O
or	O
transform	O
function	O
on	O
a	O
group	O
seems	O
like	O
the	O
right	O
way	O
to	O
go	O
but	O
after	O
hours	O
of	O
trying	O
i	O
still	O
do	O
not	O
succeed	O
.	O

I	O
figured	O
the	O
correct	O
way	O
should	O
be	O
something	O
like	O
:	O
#CODE	O

Having	O
the	O
apply	O
/	O
transform	O
mechanism	O
be	O
able	O
to	O
output	O
structured	O
values	O
and	O
those	O
broadcast	O
into	O
colums	O
(	O
i.e.	O
if	O
a	O
tuple	O
is	O
produced	O
by	O
the	O
applied	O
function	O
,	O
the	O
components	O
go	O
in	O
separate	O
columns	O
instead	O
of	O
the	O
tuple	O
becoming	O
an	O
atomic	O
element	O
in	O
a	O
single	O
column	O
)	O
would	O
be	O
a	O
fantastic	O
feature	O
,	O
even	O
if	O
it	O
is	O
only	O
syntactic	O
sugar	O
.	O

Probably	O
with	O
another	O
method	O
name	O
,	O
to	O
make	O
intent	O
clear	O
(	O
applyfork	O
or	O
something	O
like	O
that	O
,	O
or	O
a	O
keyword	O
splitseq=True	O
in	O
apply	O
)	O
.	O

It	O
is	O
important	O
to	O
say	O
that	O
I	O
already	O
have	O
a	O
function	O
that	O
returns	O
a	O
distance	O
between	O
two	O
points	O
(	O
two	O
coordinate	O
pairs	O
)	O
,	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
it	O
with	O
a	O
single	O
array	O
operation	O
instead	O
of	O
looping	O
through	O
row	O
pairs	O
.	O

pandas	O
:	O
apply	O
function	O
to	O
DataFrame	B-API
that	O
can	O
return	O
multiple	O
rows	O

One	O
possibility	O
might	O
be	O
to	O
allow	O
`	O
DataFrame.applymap	B-API
`	O
function	O
return	O
multiple	O
rows	O
(	O
akin	O
`	O
apply	O
`	O
method	O
of	O
`	O
GroupBy	B-API
`)	O
.	O

However	O
,	O
I	O
do	O
not	O
think	O
it	O
is	O
possible	O
in	O
pandas	O
now	O
.	O

Thanks	O
for	O
reporting	O
.	O

Is	O
there	O
any	O
work	O
around	O
I	O
could	O
apply	O
before	O
it	O
is	O
fixed	O
?	O

I	O
notice	O
Pandas	O
can	O
apply	O
different	O
function	O
to	O
different	O
column	O
by	O
passing	O
a	O
dict	O
.	O

But	O
I	O
have	O
a	O
long	O
column	O
list	O
and	O
just	O
want	O
parameters	O
to	O
set	O
or	O
tip	O
to	O
simply	O
tell	O
Pandas	O
to	O
bypass	O
some	O
columns	O
and	O
apply	O
`	O
my_func()	O
`	O
to	O
rest	O
of	O
columns	O
?	O

(	O
Otherwise	O
I	O
have	O
to	O
build	O
a	O
long	O
dict	O
)	O

One	O
simple	O
(	O
and	O
general	O
)	O
approach	O
is	O
to	O
create	O
a	O
view	O
of	O
the	O
dataframe	B-API
with	O
the	O
subset	O
you	O
are	O
interested	O
in	O
(	O
or	O
,	O
stated	O
for	O
your	O
case	O
,	O
a	O
view	O
with	O
all	O
columns	O
except	O
the	O
ones	O
you	O
want	O
to	O
ignore	O
)	O
,	O
and	O
then	O
use	O
APPLY	O
for	O
that	O
view	O
.	O

#CODE	O

Apply	O
your	O
function	O
to	O
that	O
view	O
.	O

(	O
Note	O
this	O
doesn't	O
yet	O
change	O
anything	O
in	O
df	O
.	O
)	O
#CODE	O

Starting	O
with	O
row	O
number	O
2	O
,	O
or	O
in	O
this	O
case	O
,	O
I	O
guess	O
it's	O
250	O
(	O
PS	O
-	O
is	O
that	O
the	O
index	O
?	O
)	O
,	O
I	O
want	O
to	O
calculate	O
the	O
difference	O
between	O
2011-01-03	O
and	O
2011-01-04	O
,	O
for	O
every	O
entry	O
in	O
this	O
dataframe	B-API
.	O

I	O
believe	O
the	O
appropriate	O
way	O
is	O
to	O
write	O
a	O
function	O
that	O
takes	O
the	O
current	O
row	O
,	O
then	O
figures	O
out	O
the	O
previous	O
row	O
,	O
and	O
calculates	O
the	O
difference	O
between	O
them	O
,	O
the	O
use	O
the	O
`	O
pandas	O
`	O
`	O
apply	O
`	O
function	O
to	O
update	O
the	O
dataframe	B-API
with	O
the	O
value	O
.	O

How	O
to	O
apply	O
condition	O
on	O
level	O
of	O
pandas.multiindex	B-API
?	O

I.e.	O
,	O
I	O
would	O
like	O
to	O
apply	O
np.mean	B-API
over	O
all	O
counts	O
of	O
the	O
detectors	O
of	O
1	O
channel	O
at	O
each	O
time	O
separately	O
.	O

Thank	O
you	O
@	O
root	O
,	O
that's	O
very	O
helpful	O
!	O

As	O
a	O
follow-up	O
question	O
,	O
how	O
would	O
you	O
go	O
about	O
to	O
apply	O
the	O
same	O
function	O
on	O
groups	O
?	O

(	O
See	O
updated	O
question	O
)	O
.	O

Thanks	O
again	O
!	O

It	O
is	O
only	O
applied	O
to	O
a	O
time	O
series	O
,	O
so	O
you	O
would	O
have	O
to	O
apply	O
`	O
reset_index	B-API
`	O
to	O
your	O
`	O
DataFrame	B-API
`	O

This	O
can	O
be	O
accomplished	O
quite	O
simply	O
with	O
the	O
DataFrame	B-API
method	O
`	O
apply	O
`	O
.	O

#CODE	O

Now	O
that	O
we	O
have	O
our	O
`	O
DataFrame	B-API
`	O
and	O
`	O
Series	O
`	O
we	O
need	O
a	O
function	O
to	O
pass	O
to	O
`	O
apply	O
`	O
.	O

#CODE	O

`	O
df.apply	B-API
`	O
acts	O
column-wise	O
by	O
default	O
,	O
but	O
it	O
can	O
can	O
also	O
act	O
row-wise	O
by	O
passing	O
`	O
axis=1	O
`	O
as	O
an	O
argument	O
to	O
`	O
apply	O
`	O
.	O

#CODE	O

This	O
could	O
be	O
done	O
more	O
concisely	O
by	O
defining	O
the	O
anonymous	O
function	O
inside	O
`	O
apply	O
`	O
#CODE	O

I	O
know	O
no	O
easy	O
solution	O
to	O
get	O
to	O
align	O
to	O
the	O
closest	O
and	O
I	O
find	O
the	O
current	O
version	O
quite	O
logical	O
.	O

But	O
with	O
`	O
label=	O
'	O
left	O
'`	O
you	O
can	O
achieve	O
what	O
you	O
want	O
with	O
the	O
current	O
data	O
,	O
still	O
it	O
doesn't	O
align	O
to	O
the	O
closest	O
,	O
so	O
overall	O
you	O
probably	O
have	O
to	O
figure	O
out	O
something	O
else	O
(	O
like	O
using	O
apply	O
to	O
change	O
the	O
dates	O
so	O
they	O
would	O
conform	O
as	O
you	O
wish	O
)	O
.	O

#CODE	O

Since	O
resample()	B-API
requires	O
a	O
TimeSeries-indexed	O
frame	O
/	O
series	O
,	O
setting	O
the	O
index	O
during	O
creation	O
eliminates	O
the	O
need	O
to	O
set	O
the	O
index	O
for	O
each	O
group	O
individually	O
.	O

GroupBy	B-API
objects	O
also	O
have	O
an	O
apply	O
method	O
,	O
which	O
is	O
basically	O
syntactic	O
sugar	O
around	O
the	O
"	O
combine	O
"	O
step	O
done	O
with	O
pd.concat()	B-API
above	O
.	O

#CODE	O

I	O
would	O
like	O
to	O
apply	O
a	O
function	O
to	O
a	O
dataframe	B-API
and	O
receive	O
a	O
single	O
dictionary	O
as	O
a	O
result	O
.	O
pandas.apply	O
gives	O
me	O
a	O
Series	O
of	O
dicts	O
,	O
and	O
so	O
currently	O
I	O
have	O
to	O
combine	O
keys	O
from	O
each	O
.	O

I'll	O
use	O
an	O
example	O
to	O
illustrate	O
.	O

However	O
,	O
my	O
goal	O
is	O
to	O
be	O
able	O
to	O
use	O
a	O
row-wise	O
function	O
in	O
the	O
`	O
DataFrame.apply()	B-API
`	O
method	O
(	O
so	O
I	O
can	O
apply	O
the	O
desired	O
functionality	O
to	O
other	O
functions	O
I	O
build	O
)	O
.	O

I've	O
tried	O
:	O
#CODE	O

Row-wise	O
functionality	O
should	O
be	O
possible	O
with	O
apply	O
.	O

For	O
example	O
,	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
sum	O
(	O
x**2	O
)	O
,	O
axis	O
=	O
1	O
)`	O

The	O
"	O
problem	O
"	O
is	O
that	O
the	O
chaining	O
breaks	O
the	O
fillna	B-API
ability	O
to	O
update	O
the	O
original	O
dataframe	B-API
.	O

I	O
put	O
"	O
problem	O
"	O
in	O
quotes	O
because	O
there	O
are	O
good	O
reasons	O
for	O
the	O
design	O
decisions	O
that	O
led	O
to	O
not	O
interpreting	O
through	O
these	O
chains	O
in	O
certain	O
situations	O
.	O

Also	O
,	O
this	O
is	O
a	O
complex	O
example	O
(	O
though	O
I	O
really	O
ran	O
into	O
it	O
)	O
,	O
but	O
the	O
same	O
may	O
apply	O
to	O
fewer	O
levels	O
of	O
indexes	O
depending	O
on	O
how	O
you	O
slice	O
.	O

It's	O
one	O
line	O
,	O
reads	O
reasonably	O
well	O
(	O
sort	O
of	O
)	O
and	O
eliminates	O
any	O
unnecessary	O
messing	O
with	O
intermediate	O
variables	O
or	O
loops	O
while	O
allowing	O
you	O
to	O
apply	O
fillna	B-API
to	O
any	O
multi-level	O
slice	O
you	O
like	O
!	O

How	O
to	O
apply	O
a	O
function	O
to	O
two	O
columns	O
of	O
Pandas	O
dataframe	B-API

Now	O
I	O
want	O
to	O
apply	O
the	O
`	O
f	O
`	O
to	O
`	O
df	O
`'	O
s	O
two	O
columns	O
`'	O
col_1	O
'	O
,	O
'	O
col_2	O
'`	O
to	O
element-wise	O
calculate	O
a	O
new	O
column	O
`'	O
col_3	O
'`	O
,	O
somewhat	O
like	O
:	O
#CODE	O

can	O
you	O
apply	O
f	O
directly	O
to	O
columns	O
:	O
df	O
[	O
'	O
col_3	O
']	O
=	O
f	O
(	O
df	O
[	O
'	O
col_1	O
']	O
,	O
df	O
[	O
'	O
col_2	O
'])	O

Here's	O
an	O
example	O
using	O
`	O
apply	O
`	O
on	O
the	O
dataframe	B-API
,	O
which	O
I	O
am	O
calling	O
with	O
`	O
axis	O
=	O
1	O
`	O
.	O

Depending	O
on	O
your	O
use	O
case	O
,	O
it	O
is	O
sometimes	O
helpful	O
to	O
create	O
a	O
pandas	O
`	O
group	O
`	O
object	O
,	O
and	O
then	O
use	O
`	O
apply	O
`	O
on	O
the	O
group	O
.	O

Yes	O
,	O
i	O
tried	O
to	O
use	O
apply	O
,	O
but	O
can't	O
find	O
the	O
valid	O
syntax	O
expression	O
.	O

And	O
if	O
each	O
row	O
of	O
df	O
is	O
unique	O
,	O
still	O
use	O
groupby	B-API
?	O

i	O
provide	O
a	O
detail	O
sample	O
in	O
question	O
.	O

How	O
to	O
use	O
Pandas	O
'	O
apply	O
'	O
function	O
to	O
create	O
'	O
col_3	O
'	O
?	O

Use	O
apply	O
on	O
the	O
whole	O
dataframe	B-API
,	O
passing	O
in	O
rows	O
with	O
df.apply	B-API
(	O
f	O
,	O
axis=1	O
)	O
.	O

Then	O
rewrite	O
your	O
function	O
`	O
get_sublist	O
(	O
x	O
)`	O
to	O
index	O
the	O
col	O
values	O
like	O
this	O
`	O
start_idx	O
=	O
x	O
[	O
1	O
]	O
,	O
end_idx	O
=	O
x	O
[	O
2	O
]`	O
.	O

Pandas	O
rolling	O
apply	O
with	O
missing	O
data	O

I	O
think	O
a	O
partial	O
answer	O
to	O
this	O
question	O
is	O
probably	O
via	O
using	O
the	O
keyword	O
argument	O
min_periods	O
in	O
the	O
rolling	O
apply	O
function	O
.	O

Ex	O
:	O
pandas.rolling_apply	B-API
(	O
x2	O
,	O
3	O
,	O
foo	O
,	O
min_periods=1	O
)	O
helps	O
.	O

You	O
can	O
use	O
groupby	B-API
and	O
then	O
apply	O
to	O
achieve	O
what	O
you	O
want	O
:	O
#CODE	O

I've	O
already	O
explored	O
Panda's	O
fillna	B-API
,	O
but	O
it	O
doesn't	O
seem	O
to	O
meet	O
my	O
needs	O
.	O

I've	O
also	O
considered	O
the	O
np.where	B-API
method	O
,	O
but	O
I'm	O
not	O
sure	O
how'd	O
it	O
work	O
in	O
this	O
situation	O
.	O

I'm	O
pretty	O
new	O
to	O
Pandas	O
,	O
but	O
maybe	O
the	O
map	O
/	O
apply	O
function	O
are	O
what	O
I	O
need	O
?	O

This	O
can	O
probably	O
be	O
accomplished	O
a	O
thousand	O
different	O
ways	O
,	O
but	O
looking	O
for	O
something	O
that	O
won't	O
crawl	O
given	O
the	O
size	O
of	O
the	O
data	O
.	O

The	O
paired	O
dict	O
has	O
the	O
city	O
as	O
the	O
key	O
and	O
the	O
borough	O
as	O
the	O
value	O
.	O

Now	O
the	O
last	O
step	O
is	O
to	O
apply	O
/	O
map	O
it	O
back	O
to	O
the	O
borough	O
column	O
...	O
how	O
do	O
I	O
do	O
that	O
?	O

I'm	O
also	O
puzzled	O
why	O
the	O
`	O
apply	O
`	O
version	O
along	O
`	O
axis=1	O
`	O
is	O
so	O
much	O
slower	O
.	O

It	O
should	O
literally	O
be	O
just	O
a	O
shortening	O
of	O
the	O
syntax	O
,	O
no	O
?	O

Currently	O
I	O
think	O
you	O
need	O
to	O
create	O
a	O
custom	O
subclass	O
.	O

You'd	O
need	O
to	O
override	O
the	O
`	O
apply	O
`	O
and	O
`	O
onOffset	O
`	O
methods	O
to	O
take	O
into	O
account	O
your	O
holiday	O
calendar	O
.	O

Update	O
:	O
A	O
useful	O
workaround	O
is	O
to	O
just	O
smash	O
this	O
with	O
the	O
DatetimeIndex	B-API
constructor	O
(	O
which	O
is	O
usually	O
much	O
faster	O
than	O
an	O
apply	O
)	O
,	O
for	O
example	O
:	O
#CODE	O

With	O
more	O
complicated	O
selections	O
like	O
this	O
one	O
you	O
can	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

problems	O
with	O
apply	O
function	O
in	O
pandas	O
after	O
update	O

I	O
tried	O
to	O
apply	O
'	O
manually	O
'	O
the	O
function	O
recursively	O
to	O
see	O
if	O
some	O
of	O
the	O
dates	O
passed	O
as	O
the	O
x	O
parameter	O
in	O
the	O
lambda	O
definition	O
where	O
wrong	O
,	O
but	O
managed	O
to	O
get	O
correct	O
results	O
any	O
time	O
.	O

But	O
the	O
`	O
apply	O
`	O
method	O
just	O
seem	O
not	O
to	O
work	O
anymore	O
,	O
and	O
cannot	O
understand	O
why	O
.	O

You	O
need	O
to	O
use	O
`	O
|	O
`	O
instead	O
of	O
`	O
or	O
`	O
.	O

The	O
`	O
and	O
`	O
and	O
`	O
or	O
`	O
operators	O
are	O
special	O
in	O
Python	O
and	O
don't	O
interact	O
well	O
with	O
things	O
like	O
numpy	O
and	O
pandas	O
that	O
try	O
to	O
apply	O
to	O
them	O
elementwise	O
across	O
a	O
collection	O
.	O

So	O
for	O
these	O
contexts	O
,	O
they've	O
redefined	O
the	O
"	O
bitwise	O
"	O
operators	O
`	O
`	O
and	O
`	O
|	O
`	O
to	O
mean	O
"	O
and	O
"	O
and	O
"	O
or	O
"	O
.	O

Actually	O
,	O
many	O
of	O
DataFrameGroupBy	B-API
object	O
methods	O
such	O
as	O
(	O
apply	O
,	O
transform	O
,	O
aggregate	O
,	O
head	O
,	O
first	O
,	O
last	O
)	O
return	O
a	O
DataFrame	B-API
object	O
.	O

I	O
used	O
the	O
method	O
`	O
filter	O
`	O
in	O
[	O
one	O
]	O
(	O
#URL	O
)	O
of	O
my	O
blog	O
posts	O
.	O

Define	O
the	O
function	O
you	O
want	O
to	O
apply	O
.	O

#CODE	O

Then	O
,	O
apply	O
it	O
.	O

#CODE	O

Efficient	O
way	O
to	O
apply	O
multiple	O
filters	O
to	O
pandas	O
DataFrame	B-API
or	O
Series	O

I	O
have	O
a	O
scenario	O
where	O
a	O
user	O
wants	O
to	O
apply	O
several	O
filters	O
to	O
a	O
Pandas	O
DataFrame	B-API
or	O
Series	O
object	O
.	O

Essentially	O
,	O
I	O
want	O
to	O
efficiently	O
chain	O
a	O
bunch	O
of	O
filtering	O
(	O
comparison	O
operations	O
)	O
together	O
that	O
are	O
specified	O
at	O
run-time	O
by	O
the	O
user	O
.	O

I	O
want	O
to	O
take	O
a	O
dictionary	O
of	O
the	O
following	O
form	O
and	O
apply	O
each	O
operation	O
to	O
a	O
given	O
Series	O
object	O
and	O
return	O
a	O
'	O
filtered	O
'	O
Series	O
object	O
.	O

#CODE	O

Your	O
right	O
,	O
boolean	O
is	O
more	O
efficient	O
since	O
it	O
doesn't	O
make	O
a	O
copy	O
of	O
the	O
data	O
.	O

However	O
,	O
my	O
scenario	O
is	O
a	O
bit	O
more	O
tricky	O
than	O
your	O
example	O
.	O

The	O
input	O
I	O
receive	O
is	O
a	O
dictionary	O
defining	O
what	O
filters	O
to	O
apply	O
.	O

My	O
example	O
could	O
do	O
something	O
like	O
`	O
df	O
[(	O
ge	O
(	O
df	O
[	O
'	O
col1	O
']	O
,	O
1	O
)	O
&	O
le	O
(	O
df	O
[	O
'	O
col1	O
']	O
,	O
1	O
)]`	O
.	O

The	O
issue	O
for	O
me	O
really	O
is	O
the	O
dictionary	O
with	O
the	O
filters	O
could	O
contain	O
lots	O
of	O
operators	O
and	O
chaining	O
them	O
together	O
is	O
cumbersome	O
.	O

Maybe	O
I	O
could	O
add	O
each	O
intermediate	O
boolean	O
array	O
to	O
a	O
big	O
array	O
and	O
then	O
just	O
use	O
`	O
map	O
`	O
to	O
apply	O
the	O
`	O
and	O
`	O
operator	O
to	O
them	O
?	O

Similar	O
to	O
@USER	O
suggestion	O
,	O
you	O
can	O
apply	O
`	O
difflib	O
`	O
'	O
s	O
`	O
get_closest_matches	O
`	O
to	O
`	O
df2	O
`'	O
s	O
index	O
and	O
then	O
apply	O
a	O
`	O
join	O
`	O
:	O
#CODE	O

If	O
these	O
were	O
columns	O
,	O
in	O
the	O
same	O
vein	O
you	O
could	O
apply	O
to	O
the	O
column	O
then	O
`	O
merge	O
`	O
:	O
#CODE	O

As	O
a	O
heads	O
up	O
,	O
this	O
basically	O
works	O
,	O
except	O
if	O
no	O
match	O
is	O
found	O
,	O
or	O
if	O
you	O
have	O
NaNs	O
in	O
either	O
column	O
.	O

Instead	O
of	O
directly	O
applying	O
`	O
get_close_matches	O
`	O
,	O
I	O
found	O
it	O
easier	O
to	O
apply	O
the	O
following	O
function	O
.	O

The	O
choice	O
of	O
NaN	O
replacements	O
will	O
depend	O
a	O
lot	O
on	O
your	O
dataset	O
.	O

#CODE	O

I	O
used	O
this	O
and	O
DataFrame.apply	B-API
to	O
apply	O
it	O
to	O
all	O
major	O
columns	O
in	O
the	O
dataframe	B-API
.	O

After	O
thinking	O
about	O
it	O
a	O
bit	O
more	O
,	O
I	O
think	O
this	O
is	O
the	O
intended	O
design	O
,	O
and	O
it	O
perfectly	O
accomplishes	O
the	O
goal	O
.	O

You	O
can	O
either	O
load	O
the	O
file	O
and	O
then	O
filter	O
using	O
`	O
df	O
[	O
df	O
[	O
'	O
field	O
']	O
constant	O
]`	O
,	O
or	O
if	O
you	O
have	O
a	O
very	O
large	O
file	O
and	O
you	O
are	O
worried	O
about	O
memory	O
running	O
out	O
,	O
then	O
use	O
an	O
iterator	O
and	O
apply	O
the	O
filter	O
as	O
you	O
concatenate	O
chunks	O
of	O
your	O
file	O
e.g.	O
:	O
#CODE	O

Think	O
of	O
np.datetime64	O
the	O
same	O
way	O
you	O
would	O
about	O
np.int8	O
,	O
np.int16	O
,	O
etc	O
and	O
apply	O
the	O
same	O
methods	O
to	O
convert	O
beetween	O
Python	O
objects	O
such	O
as	O
int	O
,	O
datetime	O
and	O
corresponding	O
numpy	O
objects	O
.	O

In	O
this	O
case	O
they're	O
equivalent	O
.	O

Apply	O
can	O
also	O
do	O
aggregation	O
and	O
other	O
things	O

You	O
are	O
looking	O
for	O
`	O
apply	O
`	O
(	O
`	O
merge	O
`	O
is	O
like	O
a	O
database	O
join	O
.	O
):	O
#CODE	O

Update	O
:	O
if	O
you're	O
doing	O
this	O
to	O
a	O
DatetimeIndex	B-API
/	O
datetime64	O
column	O
a	O
better	O
way	O
is	O
to	O
use	O
`	O
np.round	O
`	O
directly	O
rather	O
than	O
via	O
an	O
apply	O
/	O
map	O
:	O
#CODE	O

Hence	O
you	O
can	O
apply	O
this	O
to	O
the	O
entire	O
index	O
:	O
#CODE	O

@USER	O
you're	O
right	O
of	O
course	O
!	O

I	O
forgot	O
about	O
milli-seconds	O
...	O
whoops	O
!	O

I	O
have	O
corrected	O
this	O
and	O
added	O
how	O
to	O
apply	O
this	O
to	O
the	O
entire	O
dt_index	O
.	O

The	O
`	O
for	O
`	O
loops	O
and	O
`	O
append	O
`	O
s	O
will	O
not	O
be	O
efficient	O
and	O
should	O
be	O
avoided	O
.	O

Try	O
rewrting	O
these	O
using	O
numpy	O
functions	O
and	O
/	O
or	O
the	O
DataFrame	B-API
`	O
apply	O
`	O
method	O
...	O

Also	O
,	O
would	O
you	O
agree	O
then	O
,	O
using	O
your	O
suggestion	O
,	O
if	O
we	O
want	O
to	O
apply	O
a	O
function	O
/	O
algorithm	O
restricted	O
every	O
unique	O
date	O
in	O
the	O
file	O
one	O
should	O
just	O
groupby	B-API
the	O
'	O
datetime	O
'	O
object	O
?	O

When	O
you	O
do	O
`	O
len	O
(	O
df	O
[	O
'	O
column	O
name	O
'])`	O
you	O
are	O
just	O
getting	O
one	O
number	O
,	O
namely	O
the	O
number	O
of	O
rows	O
in	O
the	O
DataFrame	B-API
(	O
i.e.	O
,	O
the	O
length	O
of	O
the	O
column	O
itself	O
)	O
.	O

If	O
you	O
want	O
to	O
apply	O
`	O
len	O
`	O
to	O
each	O
element	O
in	O
the	O
column	O
,	O
use	O
`	O
df	O
[	O
'	O
column	O
name	O
']	O
.map	B-API
(	O
len	O
)`	O
.	O

So	O
try	O
#CODE	O

`	O
transform	O
`	O
is	O
not	O
that	O
well	O
documented	O
,	O
but	O
it	O
seems	O
that	O
the	O
way	O
it	O
works	O
is	O
that	O
what	O
the	O
transform	O
function	O
is	O
passed	O
is	O
not	O
the	O
entire	O
group	O
as	O
a	O
dataframe	B-API
,	O
but	O
a	O
single	O
column	O
of	O
a	O
single	O
group	O
.	O

I	O
don't	O
think	O
it's	O
really	O
meant	O
for	O
what	O
you're	O
trying	O
to	O
do	O
,	O
and	O
your	O
solution	O
with	O
`	O
apply	O
`	O
is	O
fine	O
.	O

So	O
basically	O
,	O
you	O
don't	O
need	O
to	O
use	O
transform	O
here	O
.	O

`	O
apply	O
`	O
is	O
the	O
appropriate	O
function	O
here	O
,	O
because	O
`	O
apply	O
`	O
really	O
does	O
operate	O
on	O
each	O
group	O
as	O
a	O
single	O
DataFrame	B-API
,	O
while	O
`	O
transform	O
`	O
operates	O
on	O
each	O
column	O
of	O
each	O
group	O
.	O

If	O
it's	O
already	O
in	O
the	O
DataFrame	B-API
you	O
could	O
use	O
`	O
apply	O
`	O
to	O
convert	O
those	O
strings	O
which	O
are	O
numbers	O
into	O
integers	O
(	O
using	O
`	O
str.isdigit	B-API
`	O
):	O
#CODE	O

@USER	O
uncommented	O
,	O
and	O
commented	O
the	O
`	O
to_dict()	B-API
`	O
.	O

Although	O
,	O
`	O
apply	O
`	O
is	O
the	O
important	O
bit	O
of	O
my	O
answer	O
(	O
weirdly	O
no	O
other	O
answers	O
seem	O
to	O
use	O
it	O
)	O
.	O

Many	O
thanks	O
!	O

I	O
was	O
under	O
the	O
impression	O
that	O
apply	O
was	O
preferable	O
to	O
loops	O
.	O

Looking	O
at	O
the	O
source	O
,	O
I'm	O
not	O
that	O
sure	O
,	O
as	O
it	O
is	O
just	O
regular	O
python	O
with	O
more	O
functionality	O
than	O
the	O
one	O
I	O
need	O
.	O

Moreover	O
,	O
I	O
assumed	O
that	O
Pandas	O
indexes	O
provided	O
enough	O
performance	O
.	O

A	O
dict	O
is	O
just	O
perfect	O
--	O
I	O
just	O
have	O
to	O
find	O
the	O
way	O
to	O
put	O
the	O
data	O
in	O
the	O
files	O
as	O
a	O
dict	O
instead	O
than	O
as	O
df	O
,	O
since	O
originally	O
it	O
was	O
precisely	O
a	O
dict	O
--	O

apply	O
on	O
group	O
replicating	O
complete	O
MultiIndex	O

I	O
would	O
like	O
to	O
fill	O
gaps	O
in	O
a	O
column	O
in	O
my	O
DataFrame	B-API
using	O
a	O
cubic	O
spline	O
.	O

If	O
I	O
were	O
to	O
export	O
to	O
a	O
list	O
then	O
I	O
could	O
use	O
the	O
numpy's	O
`	O
interp1d	O
`	O
function	O
and	O
apply	O
this	O
to	O
the	O
missing	O
values	O
.	O

OK	O
thanks	O
for	O
your	O
help	O
!	O
and	O
last	O
thing	O
I	O
hope	O
.	O

I	O
have	O
multiple	O
columns	O
each	O
containing	O
NaN	O
data	O
.	O

Sol	O
the	O
df.dropna()	B-API
drops	O
too	O
many	O
rows	O
.	O

How	O
do	O
you	O
apply	O
that	O
to	O
one	O
column	O
only	O
(	O
i.e.	O
'	O
data1	O
')	O

Apply	O
function	O
on	O
Pandas	O
dataframe	B-API

I'm	O
a	O
newbie	O
to	O
pandas	O
dataframe	B-API
,	O
and	O
I	O
wanted	O
to	O
apply	O
a	O
function	O
to	O
each	O
column	O
so	O
that	O
it	O
computes	O
for	O
each	O
element	O
x	O
,	O
x	O
/	O
max	O
of	O
column	O
.	O

Pandas	O
DataFrame	B-API
:	O
apply	O
function	O
to	O
all	O
columns	O

How	O
to	O
apply	O
function	O
to	O
date	O
indexed	O
DataFrame	B-API

Then	O
`	O
apply	O
`	O
this	O
to	O
each	O
state	O
in	O
the	O
DataFrame	B-API
:	O
#CODE	O

The	O
real	O
issue	O
is	O
--	O
and	O
now	O
comes	O
a	O
threefold	O
question	O
:	O
how	O
can	O
it	O
be	O
that	O
just	O
importing	O
pandas	O
broke	O
matplotlib's	O
ability	O
to	O
handle	O
datetime	O
objects	O
,	O
when	O
just	O
two	O
lines	O
earlier	O
pandas	O
was	O
clearly	O
not	O
even	O
involved	O
in	O
that	O
same	O
operation	O
?	O

Does	O
pandas	O
upon	O
import	O
silently	O
alter	O
other	O
modules	O
in	O
the	O
top	O
level	O
namespace	O
to	O
force	O
them	O
to	O
make	O
use	O
of	O
pandas	O
methods	O
?	O

And	O
is	O
this	O
acceptable	O
behavour	O
for	O
a	O
python	O
module	O
?	O

Because	O
I	O
need	O
to	O
be	O
able	O
to	O
rely	O
on	O
it	O
that	O
importing	O
,	O
say	O
,	O
a	O
random	O
number	O
module	O
,	O
won't	O
silently	O
change	O
,	O
say	O
,	O
the	O
pickle	O
module	O
to	O
apply	O
a	O
random	O
salt	O
to	O
everything	O
it	O
writes	O
..	O

I	O
have	O
a	O
time	O
series	O
object	O
`	O
grouped	O
`	O
of	O
the	O
type	O
`	O
pandas.core.groupby.SeriesGroupBy	B-API
object	O
at	O
0x03F1A9F0	O
`	O
.	O

`	O
grouped.sum()	O
`	O
gives	O
the	O
desired	O
result	O
but	O
I	O
cannot	O
get	O
rolling_sum	B-API
to	O
work	O
with	O
the	O
`	O
groupby	B-API
`	O
object	O
.	O

Is	O
there	O
any	O
way	O
to	O
apply	O
rolling	O
functions	O
to	O
`	O
groupby	B-API
`	O
objects	O
?	O

For	O
example	O
:	O
#CODE	O

I'm	O
not	O
sure	O
of	O
the	O
mechanics	O
,	O
but	O
this	O
works	O
.	O

Note	O
,	O
the	O
returned	O
value	O
is	O
just	O
an	O
ndarray	B-API
.	O

I	O
think	O
you	O
could	O
apply	O
any	O
cumulative	O
or	O
"	O
rolling	O
"	O
function	O
in	O
this	O
manner	O
and	O
it	O
should	O
have	O
the	O
same	O
result	O
.	O

Pass	O
the	O
`	O
axis	O
`	O
option	O
to	O
the	O
`	O
apply	O
`	O
function	O
:	O
#CODE	O

Great	O
.	O

Does	O
apply	O
pass	O
the	O
columns	O
including	O
item1	O
,	O
item2	O
when	O
I	O
use	O
axis=0	O
?	O

What	O
happens	O
when	O
there	O
is	O
a	O
hierarchical	O
indexing	O
in	O
the	O
columns	O
and	O
the	O
rows	O
?	O

You	O
can	O
use	O
the	O
DataFrame	B-API
`	O
apply	O
`	O
method	O
:	O
#CODE	O

You	O
may	O
find	O
it	O
faster	O
to	O
extract	O
the	O
index	O
as	O
a	O
column	O
and	O
use	O
`	O
apply	O
`	O
and	O
`	O
bfill	B-API
`	O
.	O

Here's	O
one	O
(	O
slow	O
!	O
)	O
workaround	O
to	O
do	O
it	O
using	O
`	O
apply	O
`	O
,	O
not	O
ideal	O
but	O
it	O
works	O
:	O
#CODE	O

It	O
seems	O
like	O
a	O
bug	O
(	O
that	O
you	O
can't	O
do	O
`	O
apply	O
(	O
lambda	O
x	O
:	O
x.month	O
)`)	O
,	O
perhaps	O
worth	O
adding	O
as	O
an	O
issue	O
on	O
github	O
.	O

As	O
Wes	O
would	O
say	O
:	O
"	O
welcome	O
to	O
hell	O
"	O
.	O

This	O
happens	O
when	O
using	O
apply	O
as	O
well	O
#CODE	O

How	O
to	O
apply	O
quantile	O
to	O
pandas	O
groupby	B-API
object	O
?	O

I	O
ran	O
a	O
formula	O
on	O
the	O
price	O
col	O
of	O
the	O
csv	O
file	O
.	O

Indeed	O
,	O
they	O
are	O
all	O
"	O
numbers	O
"	O
.	O
apply	O
(	O
float	O
)	O
for	O
some	O
reason	O
was	O
rejected	O
w	O
/	O
ValueError	O
:	O
could	O
not	O
convert	O
string	O
to	O
float	O
:	O
price	O
.	O

`	O
applymap()	B-API
`	O
can	O
be	O
used	O
to	O
apply	O
a	O
function	O
to	O
every	O
element	O
of	O
a	O
`	O
dataframe	B-API
`	O
#CODE	O

Have	O
you	O
tested	O
the	O
`	O
calcvol	O
`	O
function	O
separately	O
?	O

It's	O
good	O
practice	O
to	O
do	O
that	O
first	O
before	O
you	O
apply	O
.	O

(	O
I	O
don't	O
suppose	O
this	O
is	O
a	O
simple	O
as	O
a	O
forgotten	O
axis	O
argument	O
:	O
`	O
optionsData.apply	O
(	O
calcvol	O
,	O
axis=1	O
)`	O
?	O

You	O
could	O
create	O
a	O
function	O
which	O
takes	O
an	O
entry	O
in	O
`	O
df.D	O
`	O
columns	O
and	O
returns	O
a	O
Series	O
.	O

Then	O
you	O
can	O
use	O
Series	O
`	O
apply	O
`	O
with	O
this	O
function	O
:	O
#CODE	O

Subset	O
the	O
`	O
dataframe	B-API
`	O
to	O
only	O
those	O
records	O
with	O
the	O
desired	O
Status	O
.	O

`	O
Groupby	B-API
`	O
the	O
ID	O
and	O
apply	O
the	O
lambda	O
function	O
`	O
diff()	B-API
.sum()	B-API
`	O
to	O
each	O
group	O
.	O

Use	O
`	O
transform	O
`	O
instead	O
of	O
`	O
apply	O
`	O
because	O
`	O
transform	O
`	O
returns	O
an	O
indexed	O
series	O
which	O
you	O
can	O
use	O
to	O
assign	O
to	O
a	O
new	O
column	O
'	O
diff	O
'	O
.	O

The	O
modeling	O
process	O
requires	O
that	O
I	O
analyze	O
every	O
column	O
,	O
look	O
for	O
interesting	O
relationships	O
with	O
some	O
outcome	O
variable	O
,	O
and	O
create	O
new	O
compound	O
columns	O
that	O
describe	O
those	O
relationships	O
.	O

The	O
columns	O
that	O
I	O
explore	O
are	O
usually	O
done	O
in	O
small	O
sets	O
.	O

For	O
example	O
,	O
I	O
will	O
focus	O
on	O
a	O
set	O
of	O
say	O
20	O
columns	O
just	O
dealing	O
with	O
property	O
values	O
and	O
observe	O
how	O
they	O
relate	O
to	O
defaulting	O
on	O
a	O
loan	O
.	O

Once	O
those	O
are	O
explored	O
and	O
new	O
columns	O
are	O
created	O
,	O
I	O
then	O
move	O
on	O
to	O
another	O
group	O
of	O
columns	O
,	O
say	O
college	O
education	O
,	O
and	O
repeat	O
the	O
process	O
.	O

What	O
I'm	O
doing	O
is	O
creating	O
candidate	O
variables	O
that	O
explain	O
the	O
relationship	O
between	O
my	O
data	O
and	O
some	O
outcome	O
.	O

At	O
the	O
very	O
end	O
of	O
this	O
process	O
,	O
I	O
apply	O
some	O
learning	O
techniques	O
that	O
create	O
an	O
equation	O
out	O
of	O
those	O
compound	O
columns	O
.	O

You	O
say	O
that	O
the	O
best	O
way	O
is	O
to	O
plot	O
each	O
condition	O
(	O
like	O
`	O
subset_a	O
`	O
,	O
`	O
subset_b	O
`)	O
separately	O
.	O

What	O
if	O
you	O
have	O
many	O
conditions	O
,	O
e.g.	O
you	O
want	O
to	O
split	O
up	O
the	O
scatters	O
into	O
4	O
types	O
of	O
points	O
or	O
even	O
more	O
,	O
plotting	O
each	O
in	O
different	O
shape	O
/	O
color	O
.	O

How	O
can	O
you	O
elegantly	O
apply	O
condition	O
a	O
,	O
b	O
,	O
c	O
,	O
etc	O
.	O
and	O
make	O
sure	O
you	O
then	O
plot	O
"	O
the	O
rest	O
"	O
(	O
things	O
not	O
in	O
any	O
of	O
these	O
conditions	O
)	O
as	O
the	O
last	O
step	O
?	O

"	O
AssertionError	O
when	O
using	O
apply	O
after	O
GroupBy	B-API
"	O
.	O

It's	O
since	O
been	O
fixed	O
.	O

Is	O
there	O
any	O
workaround	O
on	O
0.10	O
?	O

In	O
some	O
cases	O
I	O
can	O
get	O
`	O
apply	O
`	O
working	O
after	O
`	O
groupby	B-API
`	O
and	O
in	O
other	O
cases	O
not	O
.	O

Now	O
groupby	B-API
both	O
columns	O
and	O
apply	O
the	O
lambda	O
function	O
:	O
#CODE	O

I	O
actually	O
think	O
it	O
won't	O
always	O
make	O
sense	O
to	O
apply	O
`	O
reshape	O
`	O
to	O
a	O
Series	O
(	O
do	O
you	O
ignore	O
the	O
index	O
?	O
)	O
,	O
and	O
that	O
you're	O
correct	O
in	O
thinking	O
it's	O
just	O
numpy's	O
reshape	O
:	O

You	O
can	O
groupby	B-API
the	O
index	O
and	O
apply	O
a	O
function	O
that	O
returns	O
one	O
value	O
per	O
index	O
group	O
.	O

Here	O
,	O
I	O
take	O
the	O
first	O
value	O
:	O
#CODE	O

In	O
SQL	O
,	O
this	O
is	O
standard	O
set	O
logic	O
,	O
accomplished	O
differently	O
depending	O
on	O
the	O
dialect	O
,	O
but	O
a	O
standard	O
function	O
.	O

How	O
do	O
I	O
elegantly	O
apply	O
this	O
in	O
Pandas	O
?	O

I	O
would	O
love	O
to	O
input	O
some	O
code	O
,	O
but	O
nothing	O
I	O
have	O
is	O
even	O
remotely	O
correct	O
.	O

It's	O
a	O
situation	O
in	O
which	O
I	O
don't	O
know	O
what	O
I	O
don't	O
know	O
.....	O

Pandas	O
has	O
set	O
logic	O
for	O
intersection	O
and	O
union	O
,	O
but	O
nothing	O
for	O
disjoint	O
.	O

The	O
`	O
Target	O
`	O
is	O
just	O
a	O
constant	O
,	O
so	O
instead	O
of	O
trying	O
to	O
find	O
the	O
root	O
for	O
`	O
f	O
(	O
x	O
)	O
=	O
0	O
`	O
,	O
you'd	O
define	O
`	O
g	O
(	O
x	O
)	O
=	O
f	O
(	O
x	O
)	O
-	O
Target	O
`	O
and	O
apply	O
`	O
newton	O
`	O
to	O
`	O
g	O
`	O
.	O

EDIT	O
:	O
Thanks	O
for	O
the	O
two	O
responses	O
,	O
I	O
can	O
reproduce	O
those	O
with	O
no	O
problem	O
.	O

However	O
when	O
I	O
use	O
the	O
apply	O
function	O
to	O
my	O
case	O
I	O
get	O
an	O
'	O
unhashable	O
type	O
'	O
error	O
.	O

#CODE	O

You	O
are	O
just	O
printing	O
these	O
and	O
not	O
`	O
apply	O
`	O
-ing	O
them	O
to	O
the	O
DataFrame	B-API
,	O
here's	O
one	O
way	O
to	O
do	O
it	O
:	O

If	O
I	O
understand	O
you	O
right	O
,	O
you're	O
looking	O
for	O
the	O
`	O
apply	O
`	O
method	O
:	O
#CODE	O

apply	O
a	O
function	O
to	O
a	O
pandas	O
Dataframe	B-API
whose	O
retuned	O
value	O
is	O
based	O
on	O
other	O
rows	O

I	O
want	O
to	O
apply	O
the	O
same	O
process	O
to	O
the	O
whole	O
quantity	O
column	O
.	O

I	O
don't	O
know	O
how	O
to	O
approach	O
this	O
problem	O
with	O
the	O
pandas	O
library	O
other	O
than	O
looping	O
through	O
the	O
Dataframe	B-API
row	O
by	O
row	O
.	O

Here	O
,	O
we	O
groupby	B-API
`	O
[	O
'	O
item	O
'	O
,	O
'	O
price	O
']`	O
and	O
apply	O
the	O
function	O
above	O
.	O

The	O
output	O
is	O
a	O
series	O
of	O
relative	O
weights	O
for	O
the	O
unique	O
combinations	O
of	O
item	O
and	O
price	O
.	O

#CODE	O

After	O
building	O
basic	O
class	O
with	O
`	O
__str__	B-API
`	O
and	O
plotData()	O
methods	O
I	O
would	O
like	O
to	O
apply	O
some	O
filters	O
and	O
build	O
a	O
new	O
class	O
where	O
additional	O
column	O
is	O
the	O
filter	O
.	O

I	O
would	O
like	O
to	O
do	O
that	O
in	O
`	O
__init__	O
`	O
but	O
keep	O
everything	O
what	O
already	O
was	O
done	O
.	O

In	O
another	O
words	O
I	O
don't	O
want	O
to	O
re-write	O
the	O
whole	O
`	O
__init__	O
`	O
only	O
want	O
to	O
add	O
new	O
column	O
to	O
the	O
basic	O
dataframe	B-API
.	O

However	O
,	O
when	O
stored	O
(	O
and	O
retrieved	O
)	O
dates	O
are	O
`	O
unicode	O
`	O
rather	O
than	O
`	O
Timestamp	O
`	O
.	O

To	O
convert	O
back	O
to	O
what	O
we	O
started	O
with	O
we	O
could	O
`	O
apply	O
`	O
`	O
Timestamp	O
`	O
to	O
the	O
column	O
and	O
`	O
set_index	B-API
`	O
:	O
#CODE	O

I	O
try	O
to	O
apply	O
exactly	O
the	O
same	O
logic	O
to	O
my	O
original	O
problem	O
with	O
large	O
dataframe	B-API
inside	O
a	O
class	O
.	O

The	O
code	O
is	O
:	O
#CODE	O

I	O
found	O
in	O
here	O
that	O
there	O
could	O
be	O
a	O
problem	O
with	O
type	O
of	O
the	O
columns	O
but	O
Depth	O
is	O
type	O
`	O
numpy.float64	O
`	O
Hper	O
is	O
type	O
`	O
float	O
`	O
Vper	O
is	O
type	O
`	O
float	O
`	O
so	O
I	O
understand	O
how	O
it	O
can	O
apply	O
to	O
my	O
problem	O
.	O

Construct	O
the	O
index	O
as	O
desired	O
and	O
apply	O
it	O
to	O
the	O
dataframe	B-API

Now	O
create	O
the	O
desired	O
index	O
and	O
apply	O
it	O
.	O

Here	O
are	O
several	O
approaches	O
for	O
the	O
index	O
.	O

#CODE	O

Apply	O
multiple	O
functions	O
to	O
multiple	O
groupby	B-API
columns	O

The	O
docs	O
show	O
how	O
to	O
apply	O
multiple	O
functions	O
on	O
a	O
groupby	B-API
object	O
at	O
a	O
time	O
using	O
a	O
dict	O
with	O
the	O
output	O
column	O
names	O
as	O
the	O
keys	O
:	O
#CODE	O

What	O
I	O
want	O
to	O
do	O
is	O
apply	O
multiple	O
functions	O
to	O
several	O
columns	O
(	O
but	O
certain	O
columns	O
will	O
be	O
operated	O
on	O
multiple	O
times	O
)	O
.	O

Also	O
,	O
some	O
functions	O
will	O
depend	O
on	O
other	O
columns	O
in	O
the	O
groupby	B-API
object	O
(	O
like	O
sumif	O
functions	O
)	O
.	O

My	O
current	O
solution	O
is	O
to	O
go	O
column	O
by	O
column	O
,	O
and	O
doing	O
something	O
like	O
the	O
code	O
above	O
,	O
using	O
lambdas	O
for	O
functions	O
that	O
depend	O
on	O
other	O
rows	O
.	O

But	O
this	O
is	O
taking	O
a	O
long	O
time	O
,	O
(	O
I	O
think	O
it	O
takes	O
a	O
long	O
time	O
to	O
iterate	O
through	O
a	O
groupby	B-API
object	O
)	O
.	O

I'll	O
have	O
to	O
change	O
it	O
so	O
that	O
I	O
iterate	O
through	O
the	O
whole	O
groupby	B-API
object	O
in	O
a	O
single	O
run	O
,	O
but	O
I'm	O
wondering	O
if	O
there's	O
a	O
built	O
in	O
way	O
in	O
pandas	O
to	O
do	O
this	O
somewhat	O
cleanly	O
.	O

@USER	O
--	O
My	O
first	O
thought	O
was	O
also	O
that	O
it	O
worked	O
the	O
same	O
,	O
but	O
I	O
think	O
DataFrame	B-API
tries	O
to	O
apply	O
it	O
to	O
the	O
columns	O
(	O
without	O
the	O
ix	O
)	O
.	O

I	O
need	O
to	O
apply	O
some	O
function	O
for	O
every	O
columns	O
and	O
create	O
new	O
columns	O
in	O
this	O
DataFrame	B-API
with	O
special	O
name	O
.	O

#CODE	O

I	O
would	O
skip	O
the	O
`	O
apply	O
`	O
method	O
and	O
just	O
define	O
the	O
columns	O
directly	O
.	O

#CODE	O

Not	O
as	O
elegant	O
as	O
DSM's	O
solution	O
.	O

But	O
for	O
whatever	O
reason	O
I	O
avoid	O
`	O
apply	O
`	O
unless	O
I	O
really	O
need	O
it	O
.	O

add	O
column	O
with	O
time	O
rounded	O
to	O
millisec	O
and	O
groupby	B-API
it	O
,	O
apply	O
cumsum	B-API
within	O
each	O
group	O

Apply	O
a	O
lambda	O
function	O
that	O
indexes	O
the	O
current	O
time	O
from	O
the	O
ts	O
series	O
.	O

The	O
function	O
returns	O
the	O
sum	O
of	O
all	O
ts	O
entries	O
between	O
`	O
x	O
-	O
ms	O
and	O
x	O
`	O
.	O

#CODE	O

But	O
it	O
seems	O
inefficient	O
to	O
compute	O
cumsum	B-API
on	O
each	O
call	O
.	O

Is	O
there	O
a	O
way	O
to	O
first	O
compute	O
the	O
cumsums	O
and	O
then	O
apply	O
'	O
ohcl	O
'	O
to	O
the	O
data	O
?	O

#CODE	O

Here	O
I	O
create	O
a	O
dictionary	O
of	O
dictionaries	O
.	O

The	O
outer	O
key	O
references	O
the	O
columns	O
you	O
want	O
to	O
apply	O
the	O
functions	O
to	O
.	O

The	O
inner	O
key	O
contains	O
the	O
names	O
of	O
your	O
aggregation	O
functions	O
and	O
the	O
inner	O
values	O
are	O
the	O
functions	O
you	O
want	O
to	O
apply	O
:	O
#CODE	O

@USER	O
You	O
can	O
probably	O
create	O
a	O
two-level	O
index	O
`	O
[	O
'	O
date	O
'	O
,	O
'	O
time	O
']`	O
and	O
then	O
apply	O
time	O
filtering	O
for	O
the	O
second	O
level	O
,	O
but	O
that	O
is	O
beyond	O
my	O
current	O
level	O
of	O
pandas-fu	O
now	O
.	O

Then	O
we	O
apply	O
this	O
to	O
a	O
slice	O
of	O
the	O
`	O
_rt	O
`	O
columns	O
:	O
#CODE	O

All	O
the	O
values	O
which	O
we're	O
using	O
are	O
within	O
3	O
standard	O
deviations	O
,	O
so	O
this	O
cut	O
isn't	O
very	O
interesting	O
,	O
but	O
we	O
can	O
apply	O
it	O
anyhow	O
:	O
#CODE	O

I'm	O
new	O
to	O
pandas	O
(	O
and	O
python	O
)	O
and	O
have	O
been	O
slowly	O
working	O
my	O
way	O
trying	O
to	O
apply	O
things	O
learned	O
to	O
my	O
own	O
datasets	O
.	O

How	O
to	O
apply	O
conditional	O
logic	O
to	O
a	O
Pandas	O
DataFrame	B-API
.	O

I	O
could	O
apply	O
a	O
loop	O
and	O
do	O
re-construct	O
the	O
DataFrame	B-API
...	O
but	O
that	O
would	O
be	O
'	O
un-pythonic	O
'	O

You	O
want	O
to	O
apply	O
a	O
function	O
that	O
conditionally	O
returns	O
a	O
value	O
based	O
on	O
the	O
selected	O
dataframe	B-API
column	O
.	O

#CODE	O

I	O
thought	O
it	O
was	O
from	O
the	O
calculation	O
.	O

But	O
if	O
I	O
apply	O
(	O
np.float64	O
)	O
it	O
changes	O
the	O
numbers	O
to	O
what	O
I	O
need	O
.	O

Thanks	O
.	O

And	O
`	O
apply	O
`	O
it	O
(	O
row-wise	O
):	O
#CODE	O

but	O
now	O
,	O
I	O
need	O
to	O
apply	O
this	O
(	O
multiparameters	O
)	O
function	O
along	O
0-axis	O
.	O

Then	O
use	O
`	O
apply	O
`	O
across	O
each	O
row	O
,	O
to	O
replace	O
each	O
NaN	O
with	O
its	O
groups	O
mean	O
:	O
#CODE	O

How	O
to	O
apply	O
linregress	O
in	O
Pandas	O
bygroup	O

I	O
would	O
like	O
to	O
apply	O
a	O
scipy.stats.linregress	O
within	O
Pandas	O
ByGroup	O
.	O

I	O
had	O
looked	O
through	O
the	O
documentation	O
but	O
all	O
I	O
could	O
see	O
was	O
how	O
to	O
apply	O
something	O
to	O
a	O
single	O
column	O
like	O
#CODE	O

But	O
how	O
do	O
I	O
apply	O
a	O
linregress	O
which	O
has	O
TWO	O
inputs	O
X	O
and	O
Y	O
?	O

and	O
if	O
using	O
a	O
groupby	B-API
you	O
can	O
similarly	O
`	O
apply	O
`	O
(	O
to	O
each	O
group	O
):	O
#CODE	O

Thanks	O
Andy	O
,	O
Yes	O
it	O
can	O
accept	O
it	O
.	O

The	O
question	O
is	O
how	O
to	O
do	O
it	O
BYGROUP	O
.	O

For	O
example	O
I	O
have	O
datetime	O
that	O
I	O
have	O
GROUPED	O
into	O
Year	O
and	O
month	O
.	O

I	O
want	O
to	O
do	O
the	O
linear	O
regression	O
for	O
each	O
of	O
the	O
groups	O
then	O
return	O
the	O
values	O
from	O
the	O
lin	O
regression	O
.	O

Also	O
I	O
have	O
a	O
DataFram	O
so	O
how	O
can	O
I	O
apply	O
that	O
using	O
two	O
columns	O
in	O
the	O
DF	O
?	O

Thanks	O
Jason	O

but	O
when	O
i	O
apply	O
a	O
function	O
from	O
scikit-learn	O
i	O
loose	O
the	O
informations	O
about	O
columns	O
:	O
#CODE	O

Is	O
there	O
a	O
way	O
to	O
apply	O
scikit	O
or	O
numpy	O
function	O
to	O
DataFrames	O
without	O
loosing	O
the	O
information	O
?	O

How	O
to	O
Apply	O
an	O
equation	O
to	O
a	O
Pandas	O
dataframe	B-API
ByGroup	O

I	O
have	O
been	O
reading	O
all	O
day	O
by	O
cant	O
find	O
and	O
exact	O
solution	O
.	O

Now	O
my	O
question	O
is	O
how	O
do	O
apply	O
this	O
back	O
to	O
the	O
original	O
data	O
frame	O
.	O

I	O
would	O
like	O
a	O
new	O
column	O
in	O
the	O
DF	O
that	O
applies	O
the	O
linear	O
regression	O
y=mx+c	O
to	O
each	O
line	O
in	O
the	O
original	O
data	O
using	O
the	O
column	O
3	O
as	O
the	O
input	O
BUT	O
to	O
do	O
that	O
using	O
the	O
specific	O
coefficients	O
(	O
slope	O
,	O
intercept	O
)	O
that	O
are	O
different	O
for	O
each	O
YEAR	O
and	O
MONTH	O
.	O

Any	O
ideas	O
most	O
welcomed	O
:)	O

So	O
I	O
would	O
like	O
to	O
apply	O
that	O
relationship	O
back	O
to	O
all	O
the	O
Year=2010	O
and	O
Month=1	O
to	O
look	O
like	O
this	O
.	O

Then	O
for	O
the	O
rest	O
of	O
the	O
DF	O
apply	O
the	O
same	O
approach	O
for	O
each	O
month	O
of	O
each	O
year	O
.	O

#CODE	O

I	O
don't	O
think	O
it's	O
entirely	O
clear	O
(	O
to	O
me	O
)	O
what	O
you	O
are	O
asking	O
,	O
perhaps	O
it	O
would	O
help	O
to	O
provide	O
an	O
example	O
DF	O
and	O
what	O
you	O
want	O
it	O
to	O
be	O
?	O

Perhaps	O
you	O
want	O
an	O
`	O
apply	O
`	O
which	O
refers	O
to	O
`	O
Corr_grouped	O
`	O
(	O
?	O
)	O

Okat	O
,	O
I	O
think	O
I	O
got	O
it	O
.	O

Instead	O
of	O
resampling	O
,	O
you	O
can	O
`	O
groupby	B-API
`	O
where	O
the	O
group	O
is	O
a	O
unit	O
of	O
time	O
.	O

To	O
this	O
group	O
you	O
can	O
apply	O
a	O
function	O
of	O
your	O
choice	O
,	O
for	O
example	O
your	O
directionAverage	O
function	O
.	O

Apply	O
a	O
lambda	O
testing	O
for	O
the	O
conditions	O
you	O
want	O
to	O
drop	O
:	O
#CODE	O

You	O
can	O
use	O
`	O
applymap	B-API
`	O
to	O
apply	O
your	O
function	O
to	O
the	O
elements	O
of	O
the	O
`	O
DataFrame	B-API
`	O
:	O
#CODE	O

`	O
applymap	B-API
`	O
was	O
the	O
key	O
to	O
getting	O
the	O
`	O
re.match	O
`	O
function	O
to	O
work	O
for	O
me	O
.	O

It	O
failed	O
when	O
using	O
just	O
`	O
apply	O
`	O

One	O
of	O
my	O
favorite	O
aspects	O
of	O
using	O
the	O
`	O
ggplot2	O
`	O
library	O
in	O
R	O
is	O
the	O
ability	O
to	O
easily	O
specify	O
aesthetics	O
.	O

I	O
can	O
quickly	O
make	O
a	O
scatterplot	O
and	O
apply	O
color	O
associated	O
with	O
a	O
specific	O
column	O
and	O
I	O
would	O
love	O
to	O
be	O
able	O
to	O
do	O
this	O
with	O
python	O
/	O
pandas	O
/	O
matplotlib	O
.	O

I'm	O
wondering	O
if	O
there	O
are	O
there	O
any	O
convenience	O
functions	O
that	O
people	O
use	O
to	O
map	O
colors	O
to	O
values	O
using	O
pandas	O
dataframes	O
and	O
Matplotlib	O
?	O

#CODE	O

I	O
wondering	O
if	O
I	O
can	O
apply	O
the	O
`	O
pandas.ols	O
`	O
model	O
to	O
a	O
data	O
frame	O
of	O
multiple	O
response	O
variables	O
against	O
one	O
independent	O
variable	O
at	O
one	O
time	O
.	O

@USER	O
whoops	O
typo	O
:)	O
.	O

Yes	O
,	O
it	O
does	O
seem	O
silly	O
using	O
a	O
dummy	O
(	O
tbh	O
I	O
could've	O
been	O
more	O
clever	O
with	O
my	O
apply	O
[	O
12	O
]	O
to	O
do	O
it	O
in	O
one	O
,	O
and	O
it	O
may	O
well	O
be	O
more	O
efficient	O
,	O
but	O
I	O
decided	O
I	O
wouldn't	O
like	O
to	O
be	O
the	O
person	O
reading	O
it	O
...	O
)	O
.	O

Like	O
I	O
say	O
,	O
I	O
think	O
there	O
is	O
a	O
clever	O
way	O
to	O
do	O
this	O
kind	O
of	O
comlex	O
sort	O
:	O
s	O

I	O
want	O
to	O
replace	O
df.ix	B-API
[	O
0	O
]	O
[	O
'	O
date2	O
']	O
with	O
df.ix	B-API
[	O
1	O
]	O
[	O
'	O
date2	O
']	O
for	O
each	O
symbol	O
--	O
the	O
symbol	O
changes	O
through	O
the	O
dataframe	B-API
so	O
I	O
can't	O
just	O
apply	O
this	O
through	O
the	O
whole	O
dataframe	B-API
.	O

plus	O
1	O
for	O
using	O
.apply()	B-API
where	O
my	O
solution	O
used	O
a	O
for	O
loop	O
.	O

I	O
always	O
forget	O
about	O
apply	O
.	O

1	O
E.g.	O
,	O
any	O
approach	O
I	O
can	O
think	O
of	O
involving	O
the	O
`	O
filter	O
`	O
built-in	O
is	O
probably	O
ineffiencient	O
,	O
since	O
it	O
would	O
apply	O
the	O
criterion	O
(	O
some	O
lambda	O
function	O
)	O
by	O
iterating	O
,	O
"	O
in	O
Python	O
"	O
,	O
over	O
the	O
panda	O
(	O
or	O
numpy	O
)	O
object	O
...	O

How	O
to	O
apply	O
"	O
first	O
"	O
and	O
"	O
last	O
"	O
functions	O
to	O
columns	O
while	O
using	O
group	O
by	O
in	O
pandas	O
?	O

In	O
some	O
sense	O
there's	O
three	O
types	O
of	O
mapping	O
here	O
:	O
aggregation	O
,	O
apply	O
and	O
filter	O
(	O
the	O
above	O
is	O
kind	O
of	O
a	O
filter	O
,	O
although	O
it	O
uses	O
the	O
agg	O
verb	O
)	O
.	O

This	O
is	O
complicated	O
thing	O
is	O
that	O
you	O
can	O
use	O
**	O
either	O
**	O
agg	O
or	O
apply	O
to	O
get	O
the	O
`	O
.iloc	B-API
[	O
0	O
]`	O
job	O
done	O
,	O
not	O
sure	O
why	O
I	O
used	O
agg	O
,	O
apply	O
is	O
probably	O
a	O
better	O
description	O
.	O

Since	O
this	O
post	O
I	O
fixed	O
nth	O
to	O
work	O
better	O
so	O
IMO	O
that's	O
the	O
preferred	O
solution	O
here	O
.	O

In	O
the	O
above	O
illustration	O
the	O
result	O
of	O
the	O
`	O
apply()	B-API
`	O
function	O
is	O
a	O
Pandas	O
Series	O
.	O

And	O
it	O
lacks	O
the	O
groupby	B-API
columns	O
from	O
the	O
`	O
df.groupby	B-API
`	O
.	O

The	O
essence	O
of	O
what	O
I'm	O
struggling	O
with	O
is	O
how	O
do	O
I	O
create	O
a	O
function	O
which	O
I	O
apply	O
to	O
a	O
groupby	B-API
which	O
returns	O
both	O
the	O
result	O
of	O
the	O
function	O
AND	O
the	O
columns	O
on	O
which	O
it	O
was	O
grouped	O
?	O

In	O
the	O
example	O
you've	O
appended	O
,	O
what's	O
the	O
purpose	O
of	O
the	O
groupby	B-API
(	O
it'll	O
just	O
find	O
dupes	O
)	O
,	O
you	O
can	O
just	O
do	O
an	O
apply	O
to	O
df	O
itself	O
and	O
add	O
that	O
as	O
a	O
column	O
:	O
`	O
df	O
[	O
'	O
func3	O
']	O
=	O
df.apply	B-API
(	O
lambda	O
row	O
:	O
row	O
[	O
'	O
col2	O
']	O
**	O
2	O
,	O
axis=1	O
)`	O
.	O

?	O

I	O
don't	O
can't	O
see	O
an	O
example	O
where	O
it	O
makes	O
sense	O
to	O
groupby	B-API
all	O
columns	O
and	O
apply	O
,	O
rather	O
than	O
just	O
apply	O
(	O
DataFrames	O
apply	O
can	O
be	O
very	O
non-trivial	O
and	O
save	O
to	O
multiple	O
columns	O
)	O
.	O

(	O
Also	O
you	O
don't	O
need	O
to	O
create	O
a	O
dfout	O
return	O
variable	O
,	O
you	O
can	O
just	O
return	O
the	O
calculation	O
e.g.	O
`	O
return	O
df	O
[	O
'	O
col3	O
']	O
**2	O
`	O
:)	O
)	O

example	O
updated	O
...	O
and	O
now	O
it	O
works	O
!	O

Geesh	O
.	O

It	O
appears	O
that	O
when	O
the	O
apply	O
is	O
on	O
every	O
row	O
it	O
does	O
not	O
return	O
the	O
keys	O
,	O
but	O
if	O
the	O
apply	O
results	O
in	O
aggregation	O
it	O
does	O
return	O
the	O
keys	O

The	O
best	O
way	O
to	O
understand	O
how	O
your	O
apply	O
is	O
going	O
to	O
work	O
is	O
to	O
inspect	O
each	O
action	O
group-wise	O
:	O
#CODE	O

I	O
am	O
interested	O
in	O
this	O
question	O
in	O
the	O
context	O
of	O
the	O
`	O
groupby	B-API
`	O
operation	O
.	O

If	O
we	O
apply	O
this	O
operation	O
to	O
a	O
data	O
frame	O
,	O
as	O
a	O
result	O
we	O
do	O
not	O
get	O
another	O
data	O
frame	O
.	O

I	O
wonder	O
why	O
not	O
.	O

Why	O
not	O
to	O
have	O
another	O
data	O
frame	O
that	O
has	O
lists	O
as	O
values	O
for	O
some	O
cells	O
?	O

The	O
index	O
option	O
has	O
a	O
format	O
method	O
that	O
lets	O
you	O
apply	O
a	O
formatter	O
in	O
the	O
form	O
of	O
a	O
function	O
:	O
#CODE	O

how	O
to	O
apply	O
functions	O
to	O
grouped	O
dataframes	O
in	O
Python	O
pandas	O
?	O

I	O
would	O
like	O
to	O
apply	O
a	O
function	O
per	O
group	O
that	O
does	O
something	O
specific	O
with	O
a	O
subset	O
of	O
the	O
columns	O
in	O
`	O
grouped_iris	O
`	O
.	O

How	O
could	O
I	O
apply	O
a	O
function	O
that	O
for	O
each	O
group	O
(	O
each	O
value	O
of	O
`	O
Name	O
`)	O
sums	O
`	O
PetalLength	O
`	O
and	O
`	O
PetalWidth	O
`	O
and	O
puts	O
it	O
in	O
a	O
new	O
column	O
called	O
`	O
SumLengthWidth	O
`	O
?	O

I	O
know	O
that	O
I	O
can	O
sum	O
all	O
the	O
columns	O
per	O
group	O
with	O
`	O
agg	O
`	O
like	O
this	O
:	O
#CODE	O

and	O
apply	O
set	O
intersection	O
:	O
#CODE	O

Apply	O
a	O
function	O
that	O
returns	O
the	O
group	O
row	O
that	O
has	O
the	O
index	O
of	O
the	O
minimum	O
'	O
q	O
'	O
value	O
.	O

I	O
have	O
written	O
a	O
function	O
(	O
below	O
)	O
that	O
works	O
with	O
`	O
apply	O
`	O
to	O
perform	O
this	O
,	O
but	O
it	O
is	O
unacceptably	O
slow	O
.	O

Instead	O
,	O
is	O
there	O
a	O
way	O
to	O
use	O
`	O
pandas.ols	O
`	O
to	O
directly	O
perform	O
this	O
sort	O
of	O
cumulative	O
regression	O
?	O

Here	O
is	O
the	O
function	O
I	O
am	O
able	O
to	O
use	O
with	O
`	O
apply	O
`	O
on	O
the	O
identifier-grouped	O
object	O
:	O
#CODE	O

pandas	O
does	O
offer	O
cumsum	B-API
(	O
cumulative	O
sum	O
)	O
and	O
cumprod	B-API
(	O
cumulative	O
product	O
)	O
that	O
you	O
could	O
apply	O
to	O
a	O
series	O
.	O

If	O
you	O
can	O
break	O
down	O
you	O
reduce	O
your	O
function	O
into	O
products	O
and	O
sums	O
you	O
could	O
achieve	O
what	O
you	O
are	O
trying	O
to	O
do	O
...	O

Following	O
on	O
the	O
advice	O
in	O
the	O
comments	O
,	O
I	O
created	O
my	O
own	O
function	O
that	O
can	O
be	O
used	O
with	O
`	O
apply	O
`	O
and	O
which	O
relies	O
on	O
`	O
cumsum	B-API
`	O
to	O
accumulate	O
all	O
the	O
individual	O
needed	O
terms	O
for	O
expressing	O
the	O
coefficient	O
from	O
an	O
OLS	O
univariate	O
regression	O
vectorially	O
.	O

#CODE	O

Is	O
it	O
possible	O
to	O
apply	O
user	O
defined	O
functions	O
to	O
series	O
in	O
pandas	O
?	O

If	O
we	O
have	O
two	O
series	O
`	O
s1	O
`	O
and	O
`	O
s2	O
`	O
we	O
can	O
apply	O
arithmetic	O
operations	O
to	O
them	O
:	O
`	O
s1	O
+	O
s2	O
`	O
or	O
`	O
s1*s2	O
`	O
.	O

The	O
arithmetic	O
operation	O
will	O
be	O
applied	O
pairwise	O
(	O
assuming	O
that	O
the	O
two	O
series	O
have	O
the	O
same	O
length	O
)	O
as	O
a	O
result	O
we	O
get	O
a	O
new	O
series	O
.	O

This	O
feature	O
makes	O
a	O
lot	O
of	O
things	O
much	O
more	O
easier	O
.	O

Now	O
,	O
I	O
try	O
to	O
define	O
my	O
own	O
operator	O
and	O
apply	O
it	O
to	O
two	O
series	O
:	O
#CODE	O

And	O
I	O
try	O
to	O
apply	O
it	O
to	O
two	O
series	O
:	O
`	O
f	O
(	O
s1	O
,	O
s2	O
)`	O
.	O

It	O
does	O
not	O
work	O
.	O

It	O
is	O
expectable	O
,	O
to	O
a	O
certain	O
extent	O
,	O
since	O
the	O
user-defined	O
function	O
doers	O
not	O
know	O
how	O
to	O
treat	O
series	O
.	O

So	O
,	O
my	O
question	O
is	O
if	O
there	O
is	O
an	O
elegant	O
way	O
to	O
do	O
what	O
I	O
want	O
to	O
do	O
?	O

Apply	O
function	O
to	O
each	O
row	O
of	O
pandas	O
dataframe	B-API
to	O
create	O
two	O
new	O
columns	O

I	O
want	O
to	O
create	O
two	O
new	O
columns	O
for	O
this	O
dataframe	B-API
based	O
on	O
applying	O
a	O
function	O
to	O
each	O
row	O
of	O
the	O
dataframe	B-API
.	O

I	O
don't	O
want	O
to	O
have	O
to	O
call	O
the	O
function	O
multiple	O
times	O
(	O
eg	O
.	O
by	O
doing	O
two	O
separate	O
`	O
apply	O
`	O
calls	O
)	O
as	O
it	O
is	O
rather	O
computationally	O
intensive	O
.	O

I	O
have	O
tried	O
doing	O
this	O
in	O
two	O
ways	O
,	O
and	O
neither	O
of	O
them	O
work	O
:	O

Using	O
`	O
apply	O
`	O
:	O

Trying	O
to	O
apply	O
this	O
to	O
the	O
DataFrame	B-API
gives	O
an	O
error	O
:	O
#CODE	O

I	O
was	O
then	O
going	O
to	O
assign	O
the	O
values	O
returned	O
from	O
`	O
apply	O
`	O
to	O
two	O
new	O
columns	O
using	O
the	O
method	O
shown	O
in	O
this	O
question	O
.	O

However	O
,	O
I	O
can't	O
even	O
get	O
to	O
this	O
point	O
!	O

This	O
all	O
works	O
fine	O
if	O
I	O
just	O
return	O
one	O
value	O
.	O

To	O
make	O
the	O
first	O
approach	O
work	O
,	O
try	O
returning	O
a	O
Series	O
instead	O
of	O
a	O
tuple	O
(	O
apply	O
is	O
throwing	O
an	O
exception	O
because	O
it	O
doesn't	O
know	O
how	O
to	O
glue	O
the	O
rows	O
back	O
together	O
as	O
the	O
number	O
of	O
columns	O
doesn't	O
match	O
the	O
original	O
frame	O
)	O
.	O

#CODE	O

The	O
solution	O
to	O
the	O
second	O
approach	O
works	O
-	O
thanks	O
:-)	O
.	O

However	O
,	O
I	O
can't	O
get	O
the	O
first	O
approach	O
to	O
work	O
.	O

Returning	O
a	O
series	O
works	O
,	O
and	O
I	O
get	O
a	O
'	O
mini-df	O
'	O
returned	O
,	O
but	O
I	O
can't	O
seem	O
to	O
get	O
the	O
values	O
returned	O
from	O
the	O
`	O
apply	O
`	O
function	O
into	O
the	O
original	O
dataframe	B-API
.	O

Using	O
`	O
st	O
[	O
'	O
a	O
']	O
,	O
st	O
[	O
'	O
b	O
']	O
=	O
st.apply	O
(	O
calculate	O
,	O
axis=1	O
)`	O
doesn't	O
work	O
,	O
and	O
neither	O
does	O
wrapping	O
the	O
right-hand	O
side	O
in	O
`	O
zip	O
(	O
*	O
)`	O
.	O

Any	O
ideas	O
about	O
what	O
I'm	O
doing	O
wrong	O
here	O
?	O

Apply	O
pandas	O
function	O
which	O
returns	O
multiple	O
values	O
?	O

The	O
general	O
idea	O
now	O
is	O
to	O
apply	O
these	O
calibration	O
data	O
to	O
the	O
measurements	O
.	O

Pass	O
`	O
numpy.argsort	B-API
`	O
to	O
the	O
`	O
apply	O
`	O
method	O
instead	O
of	O
using	O
it	O
directly	O
.	O

This	O
way	O
,	O
NaNs	O
/	O
NaTs	O
persist	O
.	O

For	O
your	O
example	O
:	O
#CODE	O

@USER	O
,	O
The	O
originals	O
are	O
datetime64	O
[	O
ns	O
]	O
and	O
the	O
return	O
index	O
after	O
the	O
apply	O
are	O
objects	O
.	O

I	O
ma	O
using	O
version	O
0.11.0.dev-3790f16	O
.	O

To	O
complement	O
unutbu's	O
answer	O
,	O
here's	O
an	O
approach	O
using	O
`	O
apply	O
`	O
on	O
the	O
groupby	B-API
object	O
.	O

#CODE	O

Apply	O
different	O
functions	O
to	O
different	O
items	O
in	O
group	O
object	O
:	O
Python	O
pandas	O

I	O
want	O
to	O
group	O
a	O
duplicate	O
data	O
at	O
time	O
`	O
14:42	O
:	O
10	O
`	O
and	O
apply	O
different	O
functions	O
to	O
`	O
exe_price	O
`	O
and	O
`	O
exe_vol	O
`	O
(	O
e.g.	O
,	O
sum	O
the	O
`	O
exe_vol	O
`	O
and	O
compute	O
volume	O
weighted	O
average	O
of	O
`	O
exe_price	O
`)	O
.	O

I	O
know	O
that	O
I	O
can	O
do	O
#CODE	O

Is	O
there	O
a	O
way	O
to	O
group	O
and	O
then	O
apply	O
different	O
(	O
written	O
by	O
me	O
)	O
functions	O
to	O
values	O
in	O
different	O
column	O
?	O

Thank	O
you	O
for	O
your	O
quick	O
response	O
.	O

I	O
wonder	O
since	O
my	O
'	O
grouped	O
'	O
is	O
now	O
a	O
panda	O
DataFrameGroupBy	B-API
object	O
,	O
I	O
cannot	O
really	O
apply	O
your	O
fucntion	O
directly	O
can	O
I	O
?	O

Apply	O
your	O
own	O
function	O
:	O
#CODE	O

I	O
was	O
surprised	O
to	O
see	O
that	O
there	O
was	O
no	O
"	O
rolling	O
"	O
function	O
built	O
into	O
pandas	O
for	O
this	O
,	O
but	O
I	O
was	O
hoping	O
somebody	O
could	O
help	O
with	O
a	O
function	O
that	O
I	O
can	O
then	O
apply	O
to	O
the	O
df	O
[	O
'	O
Alpha	O
']	O
column	O
using	O
pd.rolling_apply	B-API
.	O

We	O
can	O
apply	O
column	O
operations	O
and	O
get	O
boolean	O
Series	O
objects	O
:	O
#CODE	O

Alternative	O
,	O
you	O
could	O
use	O
`	O
apply	O
`	O
.	O

`	O
apply	O
`'	O
s	O
callable	O
is	O
passed	O
a	O
sub-DataFrame	O
which	O
gives	O
you	O
access	O
to	O
all	O
the	O
columns	O
:	O
#CODE	O

Using	O
`	O
idxmax	B-API
`	O
and	O
`	O
loc	O
`	O
is	O
typically	O
faster	O
than	O
`	O
apply	O
`	O
,	O
especially	O
for	O
large	O
DataFrames	O
.	O

Using	O
IPython's	O
%timeit	O
:	O
#CODE	O

Due	O
to	O
the	O
very	O
large	O
nature	O
of	O
the	O
problem	O
,	O
I'm	O
using	O
the	O
pandas	O
as	O
the	O
main	O
Database	O
API	O
as	O
its	O
very	O
easy	O
to	O
apply	O
function	O
to	O
column	O
.	O

Apply	O
function	O
to	O
pandas	O
groupby	B-API

This	O
code	O
throws	O
an	O
error	O
,	O
'	O
DataFrame	B-API
object	O
has	O
no	O
attribute	O
'	O
size	O
'	O
.	O

How	O
can	O
I	O
apply	O
a	O
function	O
to	O
calculate	O
this	O
in	O
Pandas	O
?	O

`	O
apply	O
`	O
takes	O
a	O
function	O
to	O
apply	O
to	O
each	O
value	O
,	O
not	O
the	O
series	O
,	O
and	O
accepts	O
kwargs	O
.	O

I	O
have	O
a	O
pandas	O
DataFrame	B-API
that	O
includes	O
a	O
pipe-separated	O
string	O
in	O
one	O
of	O
the	O
fields	O
.	O

I've	O
split	O
this	O
into	O
a	O
list	O
inside	O
an	O
`	O
apply	O
`	O
and	O
added	O
it	O
to	O
the	O
DataFrame	B-API
.	O

The	O
number	O
and	O
content	O
of	O
the	O
values	O
in	O
the	O
pipe-separated	O
string	O
vary	O
.	O

#CODE	O

But	O
A	O
)	O
I'm	O
not	O
sure	O
how	O
to	O
apply	O
the	O
conditional	O
logic	O
and	O
B	O
)	O
I	O
have	O
to	O
apply	O
the	O
logic	O
to	O
each	O
column	O
iteratively	O
rather	O
than	O
to	O
the	O
dataframe	B-API
as	O
a	O
whole	O
.	O

How	O
can	O
I	O
apply	O
conditional	O
logic	O
to	O
the	O
non-null	O
values	O
of	O
a	O
dataframe	B-API
,	O
preserving	O
the	O
nullity	O
of	O
the	O
other	O
fields	O
?	O

There	O
isn't	O
,	O
but	O
if	O
you	O
want	O
to	O
only	O
apply	O
to	O
unique	O
values	O
,	O
just	O
do	O
that	O
yourself	O
.	O

Get	O
`	O
mySeries.unique()	O
`	O
,	O
then	O
use	O
your	O
function	O
to	O
pre-calculate	O
the	O
mapped	O
alternatives	O
for	O
those	O
unique	O
values	O
and	O
create	O
a	O
dictionary	O
with	O
the	O
resulting	O
mappings	O
.	O

Then	O
use	O
pandas	O
`	O
map	O
`	O
with	O
the	O
dictionary	O
.	O

This	O
should	O
be	O
about	O
as	O
fast	O
as	O
you	O
can	O
expect	O
.	O

In	O
this	O
case	O
,	O
how	O
can	O
we	O
execute	O
the	O
groupby	B-API
on	O
values	O
of	O
A	O
,	O
then	O
apply	O
this	O
computation	O
to	O
each	O
individual	O
group	O
,	O
and	O
finally	O
plot	O
the	O
D	O
values	O
for	O
the	O
two	O
groups	O
?	O

Rolling	O
apply	O
question	O

For	O
each	O
group	O
in	O
the	O
groupby	B-API
object	O
,	O
we	O
will	O
want	O
to	O
apply	O
a	O
function	O
:	O
#CODE	O

We	O
want	O
to	O
take	O
the	O
Times	O
column	O
,	O
and	O
for	O
each	O
time	O
,	O
apply	O
a	O
function	O
.	O

That's	O
done	O
with	O
`	O
applymap	B-API
`	O
:	O
#CODE	O

#URL	O
will	O
provide	O
an	O
error	O
for	O
your	O
code	O
here	O
(	O
because	O
you	O
are	O
trying	O
to	O
min_itemsize	O
with	O
a	O
column	O
that	O
is	O
not	O
queryable	O
)	O
.	O

Also	O
,	O
you	O
can	O
use	O
lib.max_len_string_array	O
(	O
s.values	O
)	O
for	O
a	O
quick	O
max	O
in	O
your	O
apply	O
(	O
faster	O
and	O
you	O
don't	O
need	O
to	O
test	O
for	O
object	O
type	O
)	O

I	O
don't	O
understand	O
what	O
is	O
your	O
question	O
.	O

Also	O
,	O
what	O
is	O
that	O
`	O
apply	O
`	O
method	O
?	O

and	O
the	O
"	O
reshape	O
"	O
feature	O
(	O
does	O
not	O
apply	O
to	O
3-d	O
case	O
though	O
...	O
):	O
#CODE	O

How	O
to	O
apply	O
custom	O
column	O
order	O
to	O
boxplot	O
?	O

How	O
can	O
I	O
apply	O
my	O
custom	O
column	O
order	O
to	O
the	O
boxplot	O
columns	O
?	O

(	O
other	O
than	O
ugly	O
kludging	O
the	O
column	O
names	O
with	O
a	O
prefix	O
to	O
force	O
ordering	O
)	O

not	O
where	O
I	O
was	O
headed	O
.	O

I	O
typically	O
just	O
use	O
`	O
apply	O
`	O
with	O
a	O
hard-coded	O
lookup	O
table	O
.	O
see	O
my	O
edited	O
response	O
for	O
a	O
different	O
approach	O
,	O
though	O
.	O

Then	O
apply	O
the	O
groupby	B-API
function	O
and	O
add	O
a	O
column	O
City	O
:	O
#CODE	O

I	O
have	O
finally	O
decided	O
to	O
use	O
apply	O
which	O
I	O
understand	O
is	O
more	O
flexible	O
.	O

I	O
finally	O
decided	O
to	O
use	O
apply	O
.	O

apply	O
is	O
more	O
flexible	O
than	O
agg	O
and	O
transform	O
because	O
you	O
can	O
define	O
your	O
own	O
function	O
.	O

The	O
`	O
rename	O
`	O
function	O
should	O
convert	O
the	O
the	O
dictionary	O
to	O
a	O
mapper	O
and	O
apply	O
it	O
to	O
each	O
index	O
.	O

However	O
,	O
for	O
the	O
`	O
MultiIndex	O
`	O
case	O
,	O
it	O
only	O
walk	O
through	O
each	O
tuple	O
but	O
not	O
each	O
index	O
.	O

Should	O
I	O
apply	O
the	O
`	O
df.sortlevel	B-API
(	O
level=	O
'	O
Transition	O
')`	O
after	O
each	O
`	O
df.set_value()	O
`	O
call	O
?	O

Group	O
by	O
k1	O
,	O
select	O
column	O
k2	O
and	O
apply	O
a	O
lambda	O
function	O
.	O

The	O
lambda	O
gets	O
frequency	O
counts	O
for	O
each	O
level	O
of	O
k2	O
within	O
k1	O
and	O
then	O
we	O
divide	O
by	O
the	O
count	O
of	O
k1	O
:	O
#CODE	O

First	O
using	O
`	O
apply	O
`	O
you	O
could	O
add	O
a	O
column	O
with	O
the	O
signed	O
shares	O
(	O
positive	O
for	O
Buy	O
negative	O
for	O
Sell	O
):	O
#CODE	O

Note	O
that	O
`	O
numpy.rollaxis	B-API
`	O
brings	O
the	O
specified	O
axis	O
to	O
the	O
first	O
dimension	O
and	O
then	O
let's	O
us	O
iterate	O
over	O
arrays	O
with	O
the	O
remaining	O
dimensions	O
,	O
i.e.	O
,	O
if	O
we	O
want	O
to	O
shuffle	O
along	O
the	O
first	O
dimension	O
(	O
columns	O
)	O
,	O
we	O
need	O
to	O
roll	O
the	O
second	O
dimension	O
to	O
the	O
front	O
,	O
so	O
that	O
we	O
apply	O
the	O
shuffling	O
to	O
views	O
over	O
the	O
first	O
dimension	O
.	O

Still	O
not	O
sure	O
what	O
you're	O
asking	O
,	O
but	O
if	O
you	O
have	O
a	O
function	O
for	O
one	O
value	O
,	O
you	O
can	O
then	O
use	O
Series	O
/	O
DataFrame	B-API
`	O
apply	O
`	O
or	O
index's	O
`	O
map	O
`	O
,	O
e.g.	O
`	O
df.index.map	O
(	O
lambda	O
t	B-API
:	O
t.value	O
)`	O
?	O

You	O
can	O
also	O
use	O
the	O
standard	O
time	O
functions	O
yearmon()	O
or	O
yearqtr()	O
,	O
or	O
custom	O
functions	O
for	O
both	O
split	O
and	O
apply	O
.	O

This	O
method	O
is	O
as	O
syntactically	O
sweet	O
as	O
that	O
of	O
pandas	O
.	O

can	O
u	O
give	O
a	O
small	O
example	O
of	O
what	O
kind	O
of	O
functions	O
u	O
r	O
going	O
to	O
apply	O
with	O
the	O
group	O
?	O
and	O
a	O
small	O
example	O
frame	O
would	O
be	O
helpful	O
.	O

It	O
goes	O
a	O
bit	O
against	O
Pandas	O
'	O
philosophy	O
,	O
which	O
seems	O
to	O
see	O
`	O
Series	O
`	O
as	O
a	O
one-dimensional	O
data	O
structure	O
.	O

Therefore	O
you	O
have	O
to	O
create	O
the	O
`	O
Series	O
`	O
by	O
hand	O
,	O
tell	O
them	O
that	O
they	O
have	O
data	O
type	O
`"	O
object	O
"`	O
.	O

This	O
means	O
don't	O
apply	O
any	O
automatic	O
data	O
conversions	O
.	O

I'm	O
not	O
sure	O
there's	O
a	O
vectorized	O
hook	O
,	O
but	O
you	O
can	O
use	O
`	O
apply	O
`	O
,	O
anyhow	O
:	O
#CODE	O

In	O
essence	O
you	O
are	O
flattening	O
the	O
blink	O
frame	O
to	O
a	O
series	O
that	O
you	O
then	O
can	O
apply	O
to	O
each	O
of	O
the	O
trial	O

Group	O
them	O
and	O
then	O
apply	O
our	O
customized	O
function	O

Then	O
you	O
can	O
`	O
apply	O
`	O
this	O
(	O
row-wise	O
):	O
#CODE	O

apply	O
changes	O
to	O
the	O
column	O
names	O
of	O
a	O
dataframe	B-API

There	O
are	O
a	O
few	O
approaches	O
.	O

Using	O
`	O
apply	O
`	O
:	O
#CODE	O

Is	O
there	O
a	O
TimeSeries	O
method	O
to	O
apply	O
`	O
.replace	B-API
(	O
tzinfo=None	O
)`	O
to	O
each	O
date	O
in	O
the	O
index	O
?	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
do	O
this	O
:	O
#CODE	O

@USER	O
are	O
you	O
saying	O
the	O
above	O
worked	O
on	O
newer	O
or	O
older	O
pandas	O
?	O

There	O
are	O
a	O
few	O
edge	O
cases	O
in	O
pandas	O
'	O
apply	O
which	O
have	O
been	O
tweaked	O
over	O
last	O
few	O
releases	O
so	O
this	O
could	O
be	O
one	O
of	O
them	O
!	O

You	O
can	O
convert	O
this	O
column	O
to	O
integers	O
by	O
`	O
apply	O
`	O
-ing	O
`	O
int	O
`	O
:	O
#CODE	O

Thanks	O
I	O
guess	O
I	O
just	O
have	O
to	O
iterate	O
over	O
each	O
of	O
the	O
hierarchy	O
and	O
apply	O
pivot_table	B-API
to	O
get	O
my	O
desire	O
output	O
.	O

It's	O
less	O
complicated	O
and	O
faster	O
than	O
using	O
`	O
apply	O
`	O
or	O
`	O
map	O
`	O
.	O

Something	O
like	O
`	O
np.dstack	B-API
`	O
is	O
twice	O
as	O
fast	O
as	O
`	O
zip	O
`	O
,	O
but	O
wouldn't	O
give	O
you	O
tuples	O
.	O

The	O
midpoint	O
formula	O
that	O
I	O
wish	O
to	O
apply	O
is	O
dependent	O
on	O
the	O
bid	O
/	O
ask	O
spread	O
of	O
the	O
instrument	O
.	O

If	O
the	O
current	O
spread	O
is	O
wider	O
than	O
the	O
minimum	O
tick	O
increment	O
,	O
the	O
midpoint	O
will	O
be	O
the	O
simple	O
average	O
of	O
bid	O
and	O
ask	O
prices	O
at	O
that	O
moment	O
.	O

If	O
the	O
spread	O
is	O
equal	O
to	O
the	O
minimum	O
,	O
the	O
midpoint	O
is	O
weighted	O
based	O
on	O
the	O
bid	O
and	O
ask	O
quantity	O
.	O

I'm	O
not	O
sure	O
this	O
used	O
to	O
work	O
.	O

If	O
I'm	O
reading	O
the	O
code	O
right	O
,	O
the	O
intent	O
is	O
to	O
apply	O
this	O
function	O
to	O
corresponding	O
elements	O
of	O
the	O
four	O
`	O
DataFrames	O
`	O
.	O

But	O
that's	O
not	O
what	O
it	O
did	O
in	O
olden	O
times	O
--	O
previously	O
,	O
I'm	O
pretty	O
sure	O
the	O
first	O
branch	O
would	O
have	O
been	O
taken	O
,	O
because	O
`	O
(	O
ask_price	O
-	O
bid_price	O
)	O
>	O
tick_increment	O
`	O
was	O
non-empty	O
,	O
and	O
thus	O
truthlike	O
.	O

So	O
I	O
suspect	O
this	O
code	O
was	O
buggy	O
in	O
the	O
past	O
.	O

We	O
can	O
write	O
a	O
vectorized	O
version	O
of	O
this	O
which	O
can	O
work	O
,	O
at	O
the	O
cost	O
of	O
doing	O
twice	O
the	O
work	O
,	O
but	O
if	O
there's	O
a	O
multi-DataFrame	O
version	O
of	O
`	O
applymap	B-API
`	O
I'm	O
not	O
sure	O
I've	O
used	O
it	O
.	O

@USER	O
it	O
definitely	O
ran	O
without	O
errors	O
,	O
though	O
I'm	O
not	O
certain	O
it	O
was	O
getting	O
the	O
right	O
result	O
.	O

I	O
may	O
try	O
installing	O
an	O
older	O
version	O
to	O
find	O
out	O
what	O
was	O
actually	O
getting	O
calculated	O
.	O

I	O
think	O
you	O
are	O
understanding	O
what	O
I	O
am	O
aiming	O
to	O
do	O
-	O
essentially	O
apply	O
the	O
midpoint	O
formula	O
for	O
each	O
symbol	O
,	O
and	O
at	O
each	O
timestamp	O
,	O
in	O
the	O
same	O
way	O
that	O
I	O
could	O
get	O
a	O
DataFrame	B-API
of	O
bid	O
/	O
ask	O
spreads	O
using	O
`	O
spread	O
=	O
ap	O
-	O
bp	O
`	O
.	O

You	O
need	O
this	O
odd	O
apply	O
at	O
the	O
end	O
because	O
not	O
yet	O
full	O
support	O
for	O
timedelta64	O
[	O
ns	O
]	O
scalars	O
(	O
e.g.	O
like	O
how	O
we	O
use	O
Timestamps	O
now	O
for	O
datetime64	O
[	O
ns	O
]	O
,	O
coming	O
in	O
0.12	O
)	O

PS	O
:	O
the	O
same	O
dict-based	O
approach	O
will	O
work	O
if	O
you	O
only	O
want	O
to	O
apply	O
the	O
replace	O
to	O
certain	O
columns	O
,	O
but	O
you'd	O
have	O
to	O
restrict	O
the	O
application	O
.	O

For	O
example	O
,	O
if	O
you	O
wanted	O
to	O
go	O
the	O
other	O
way	O
,	O
you	O
probably	O
wouldn't	O
want	O
the	O
`	O
2	O
`	O
in	O
the	O
weight	O
column	O
to	O
become	O
`	O
fou	O
`	O
.	O

But	O
,	O
to	O
answer	O
your	O
question	O
,	O
you	O
can	O
apply	O
`	O
list	O
`	O
.	O

#CODE	O

Pass	O
a	O
function	O
to	O
`	O
apply	O
`	O
and	O
specify	O
`	O
axis=1	O
`	O
.	O

This	O
still	O
does	O
not	O
work	O
.	O

I	O
think	O
the	O
na_values	O
option	O
does	O
not	O
apply	O
to	O
the	O
columns	O
that	O
is	O
being	O
parsed	O
as	O
dates	O
.	O

The	O
problem	O
is	O
really	O
parse_dates	O
does	O
not	O
work	O
for	O
columns	O
with	O
missing	O
values	O
.	O

Apply	O
pandas	O
function	O
to	O
column	O
to	O
create	O
multiple	O
new	O
columns	O
?	O

However	O
an	O
apply	O
within	O
an	O
apply	O
still	O
isn't	O
going	O
to	O
be	O
particularly	O
efficient	O
...	O

How	O
to	O
apply	O
a	O
function	O
to	O
several	O
columns	O
of	O
a	O
GroupBy	B-API
object	O
?	O

If	O
you	O
dont	O
specify	O
a	O
function	O
per	O
column	O
,	O
all	O
columns	O
will	O
be	O
passed	O
to	O
the	O
function	O
(	O
for	O
both	O
apply	O
and	O
agg	O
)	O
.	O

So	O
:	O
#CODE	O

This	O
can	O
also	O
be	O
done	O
using	O
apply	O
,	O
no	O
need	O
to	O
sort	O
.	O

#CODE	O

As	O
a	O
workaround	O
,	O
in	O
earlier	O
pandas	O
you	O
can	O
use	O
apply	O
:	O
#CODE	O

@USER	O
tranform	O
expects	O
one	O
result	O
to	O
all	O
the	O
things	O
in	O
the	O
group	O
,	O
whereas	O
apply	O
expects	O
a	O
value	O
for	O
each	O
row	O
in	O
the	O
group	O
.	O

Although	O
both	O
act	O
of	O
the	O
groups	O
(	O
sub	O
DataFrames	O
)	O
so	O
it	O
is	O
a	O
little	O
confusing	O
.	O

That	O
makes	O
sense	O
,	O
but	O
doesn't	O
seem	O
to	O
be	O
very	O
clearly	O
documented	O
.	O

For	O
example	O
[	O
here	O
]	O
(	O
#URL	O
)	O
it	O
starts	O
by	O
describing	O
transform	O
as	O
a	O
form	O
of	O
apply	O
,	O
and	O
later	O
makes	O
them	O
sound	O
almost	O
equivalent	O
:	O
"	O
...	O

For	O
these	O
,	O
use	O
the	O
apply	O
function	O
,	O
which	O
can	O
be	O
substituted	O
for	O
both	O
aggregate	O
and	O
transform	O
in	O
many	O
standard	O
use	O
cases	O
.	O

However	O
,	O
apply	O
can	O
handle	O
some	O
exceptional	O
use	O
cases	O
,	O
for	O
example	O
...	O

"	O

But	O
I	O
can't	O
see	O
any	O
easy	O
way	O
of	O
doing	O
the	O
same	O
thing	O
with	O
my	O
'	O
recd	O
'	O
or	O
'	O
ship	O
'	O
date	O
fields	O
.	O

For	O
example	O
,	O
generate	O
a	O
similar	O
table	O
of	O
counts	O
broken	O
down	O
by	O
(	O
say	O
)	O
monthly	O
buckets	O
of	O
recd	O
and	O
ship	O
.	O

It	O
seems	O
like	O
resample()	B-API
has	O
all	O
of	O
the	O
machinery	O
to	O
bucket	O
into	O
periods	O
,	O
but	O
I	O
can't	O
figure	O
out	O
how	O
to	O
apply	O
it	O
here	O
.	O

The	O
buckets	O
(	O
or	O
levels	O
)	O
in	O
the	O
'	O
date	O
cut	O
'	O
would	O
be	O
equivalent	O
to	O
a	O
pandas.PeriodIndex	O
,	O
and	O
then	O
I	O
want	O
to	O
label	O
each	O
value	O
of	O
df	O
[	O
'	O
recd	O
']	O
with	O
the	O
period	O
it	O
falls	O
into	O
?	O

The	O
second	O
line	O
uses	O
the	O
`	O
apply	O
`	O
method	O
on	O
groupby	B-API
to	O
replace	O
the	O
dataframe	B-API
of	O
near-duplicate	O
rows	O
,	O
`	O
g	O
`	O
,	O
with	O
a	O
new	O
dataframe	B-API
`	O
g.apply	O
(	O
lambda	O
row	O
:	O
g.irow	O
(	O
0	O
)	O
,	O
axis=1	O
)`	O
.	O

That	O
uses	O
the	O
`	O
apply	O
`	O
method	O
on	O
dataframes	O
to	O
replace	O
each	O
row	O
with	O
the	O
first	O
row	O
of	O
the	O
group	O
.	O

You	O
can	O
create	O
a	O
column	O
in	O
your	O
`	O
DataFrame	B-API
`	O
based	O
on	O
your	O
Days	O
Late	O
column	O
by	O
using	O
the	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
functions	O
as	O
follows	O
.	O

Let's	O
first	O
create	O
some	O
sample	O
data	O
.	O

#CODE	O

Group	O
your	O
`	O
DataFrame	B-API
`	O
by	O
`	O
country	O
`	O
and	O
`	O
countrycode	O
`	O
and	O
then	O
apply	O
your	O
own	O
function	O
:	O
#CODE	O

Pandas	O
:	O
How	O
to	O
use	O
apply	O
function	O
to	O
multiple	O
columns	O

I	O
have	O
some	O
problems	O
with	O
the	O
Pandas	O
apply	O
function	O
,	O
when	O
using	O
multiple	O
columns	O
with	O
the	O
following	O
dataframe	B-API
#CODE	O

When	O
I	O
try	O
to	O
apply	O
this	O
function	O
with	O
:	O
#CODE	O

If	O
you	O
just	O
want	O
to	O
compute	O
(	O
column	O
a	O
)	O
%	O
(	O
column	O
b	O
)	O
,	O
you	O
don't	O
need	O
`	O
apply	O
`	O
,	O
just	O
do	O
it	O
directly	O
:	O
#CODE	O

@USER	O
following	O
[	O
53-54	O
]	O
allow	O
you	O
to	O
apply	O
more	O
complex	O
functions	O
.	O

This	O
is	O
obviously	O
using	O
the	O
data	O
generated	O
below	O
,	O
but	O
you	O
can	O
easily	O
apply	O
to	O
your	O
example	O
.	O

You	O
probably	O
need	O
`	O
apply	O
`	O
,	O
so	O
something	O
like	O
:	O
#CODE	O

Wrapping	O
it	O
in	O
a	O
Series	O
in	O
the	O
apply	O
returns	O
a	O
DataFrame	B-API
:	O
#CODE	O

You	O
could	O
also	O
`	O
apply	O
`	O
`	O
np.prod	B-API
`	O
,	O
which	O
is	O
what	O
I'd	O
originally	O
done	O
,	O
but	O
usually	O
when	O
available	O
the	O
direct	O
methods	O
are	O
faster	O
.	O

#CODE	O

I've	O
seen	O
a	O
few	O
solutions	O
which	O
map	O
/	O
do	O
list	O
comprehension	O
to	O
'	O
manually	O
'	O
put	O
the	O
dataframe	B-API
together	O
.	O

Is	O
that	O
the	O
only	O
way	O
?	O

I	O
was	O
hoping	O
pandas	O
had	O
some	O
basic	O
function	O
to	O
magically	O
do	O
this	O
kind	O
of	O
thing	O
...	O
apply	O
?	O

join	O
?	O

To	O
restrict	O
to	O
Business	O
days	O
within	O
business	O
hours	O
(	O
apply	O
these	O
in	O
either	O
order	O
)	O
.	O

I	O
am	O
generating	O
some	O
delimited	O
files	O
from	O
hive	O
queries	O
into	O
multiple	O
HDFS	O
directories	O
.	O

As	O
the	O
next	O
step	O
,	O
I	O
would	O
like	O
to	O
read	O
the	O
files	O
into	O
a	O
single	O
pandas	O
dataframe	B-API
in	O
order	O
to	O
apply	O
standard	O
non-distributed	O
algorithms	O
.	O

You	O
could	O
just	O
apply	O
the	O
Series	O
constructor	O
to	O
that	O
column	O
:	O
#CODE	O

Hmmm	O
,	O
a	O
simple	O
is	O
to	O
just	O
apply	O
something	O
like	O
`	O
make_series	O
=	O
lambda	O
x	O
:	O
pd.Series	B-API
(	O
x	O
)	O
if	O
x	O
==	O
nan	O
else	O
x	O
`	O
,	O
there's	O
probably	O
a	O
more	O
efficient	O
way	O
though	O
.	O

Have	O
a	O
look	O
at	O
#URL	O
more	O
specifically	O
at	O
the	O
apply	O
and	O
transform	O
sections	O

After	O
you've	O
read	O
in	O
the	O
DataFrame	B-API
(	O
without	O
restricting	O
dtype	B-API
)	O
you	O
can	O
then	O
convert	O
it	O
(	O
using	O
technique	O
from	O
this	O
post	O
)	O
with	O
`	O
apply	O
`	O
:	O
#CODE	O

You	O
shouldn't	O
edit	O
the	O
question	O
,	O
but	O
rather	O
ask	O
a	O
new	O
one	O
:)	O
.	O

It's	O
essentially	O
the	O
same	O
trick	O
in	O
both	O
cases	O
(	O
just	O
define	O
a	O
function	O
which	O
does	O
it	O
to	O
a	O
single	O
string	O
and	O
then	O
apply	O
it	O
the	O
column	O
)	O
.	O

You	O
do	O
not	O
need	O
groupby	B-API
/	O
apply	O
to	O
compute	O
the	O
diff	O
column	O
.	O

df4	O
[	O
'	O
Diff	O
']	O
=	O
abs	O
(	O
df4	O
[(	O
'	O
acctual	O
'	O
,	O
'	O
Quantity	O
')]	O
-	O
df4	O
[(	O
'	O
trend	O
'	O
,	O
'	O
Quantity	O
')])	O
.	O

From	O
this	O
aggregated	O
data	O
can	O
be	O
computed	O
with	O
groupby	B-API
e.g	O
df4.groupby	O
([	O
df4	O
[	O
'	O
Start	O
']	O
.map	B-API
(	O
lambda	O
x	O
:	O
x.year	O
)	O
,	O
df4	O
[	O
'	O
Start	O
']	O
.map	B-API
(	O
lambda	O
x	O
:	O
x.week	O
)	O
,	O
df4	O
[	O
'	O
Product	O
']])	O
.sum()	B-API
.	O

Not	O
that	O
the	O
latter	O
does	O
not	O
have	O
a	O
Trader	O
column	O
.	O

Are	O
you	O
sure	O
that	O
the	O
groupby	B-API
you	O
are	O
doing	O
is	O
what	O
you	O
want	O
?	O

Some	O
funky	O
mapping	O
Trader	O
<->	O
week	O
.	O

Is	O
there	O
a	O
way	O
to	O
do	O
this	O
?	O

I	O
think	O
the	O
easiest	O
way	O
is	O
to	O
apply	O
a	O
function	O
of	O
dividing	O
by	O
index1	O
values	O
by	O
3	O
,	O
but	O
not	O
sure	O
how	O
you	O
apply	O
a	O
function	O
to	O
an	O
index	O
.	O

Perhaps	O
though	O
pandas	O
has	O
it's	O
own	O
methods	O
for	O
redefining	O
index	O
values	O
to	O
have	O
groupings	O
like	O
this	O
which	O
are	O
still	O
unique	O
when	O
you	O
consider	O
both	O
indexes	O
?	O

your	O
data	O
is	O
2-d	O
,	O
how	O
do	O
you	O
want	O
to	O
make	O
it	O
1-d	O
?	O

e.g.	O
take	O
a	O
single	O
column	O
for	O
example	O
,	O
or	O
apply	O
a	O
function	O
across	O
all	O
the	O
columns	O
in	O
a	O
reduction	O
operation	O
,	O
or	O
concatenate	O
the	O
data	O

Hmm	O
...	O
why	O
the	O
downvote	O
,	O
gang	O
?	O

This	O
seems	O
like	O
a	O
well	O
stated	O
use	O
case	O
that	O
may	O
apply	O
to	O
others	O
.	O

However	O
,	O
this	O
doesn't	O
carry	O
over	O
directly	O
to	O
pandas	O
Series	O
.	O

I	O
seems	O
that	O
map	O
/	O
apply	O
/	O
lambda	O
seems	O
the	O
way	O
to	O
go	O
.	O

I've	O
arrived	O
at	O
this	O
piece	O
of	O
code	O
,	O
but	O
getting	O
an	O
invalid	O
syntax	O
error	O
.	O

#CODE	O

You	O
can	O
just	O
use	O
an	O
apply	O
with	O
the	O
same	O
method	O
suggested	O
there	O
:	O
#CODE	O

Hmm	O
not	O
too	O
sure	O
,	O
think	O
you	O
may	O
be	O
better	O
off	O
just	O
with	O
the	O
apply	O
,	O
but	O
something	O
using	O
match	O
could	O
be	O
possible	O
:	O
`	O
s.str.findall	O
(	O
r	O
'	O
(	O
?	O

<=	O
\	O
(	O
)	O
[	O
^	O
(	O
]	O
*	O
(	O
?	O
=\	O
))')`	O

The	O
issue	O
came	O
up	O
with	O
apply	O
in	O
fact	O
.	O

Findall	B-API
works	O
!	O

Last	O
thing	O
-	O
how	O
do	O
I	O
get	O
rid	O
of	O
the	O
square	O
brackets	O
around	O
the	O
results	O
other	O
than	O
stripping	O
them	O
after	O
the	O
fact	O
?	O

pandas	O
-	O
apply	O
function	O
to	O
current	O
row	O
against	O
all	O
other	O
rows	O

Interesting	O
.	O

I	O
replaced	O
my	O
list	O
comprehension	O
with	O
a	O
slightly	O
nicer	O
nested	O
apply	O
.	O

But	O
this	O
is	O
even	O
more	O
compact	O
.	O

I	O
wonder	O
if	O
``	O
np.equal	B-API
``	O
can	O
be	O
worked	O
into	O
it	O
....	O

When	O
subsequently	O
doing	O
an	O
apply	O
/	O
map	O
,	O
you'll	O
usually	O
want	O
the	O
function	O
to	O
return	O
a	O
Series	O
...	O

When	O
I	O
do	O
'	O
g	O
=	O
df.groupby	B-API
(	O
'	O
author_id	O
')'	O
g	O
is	O
then	O
just	O
'	O
'	O
and	O
I	O
cant	O
seem	O
to	O
be	O
able	O
to	O
apply	O
the	O
function	O
...	O

Yes	O
,	O
it	O
returns	O
a	O
groupby	B-API
object	O
.	O

You	O
apply	O
the	O
function	O
using	O
`	O
g.apply	O
(	O
some_function	O
)`	O
,	O
whether	O
you	O
can	O
apply	O
it	O
depends	O
on	O
the	O
function	O
...	O

The	O
output	O
of	O
the	O
unique	O
function	O
is	O
a	O
numpy	O
array	O
,	O
which	O
doesn't	O
provide	O
the	O
apply	O
method	O
.	O

You	O
can	O
create	O
a	O
`	O
Series	O
`	O
by	O
that	O
array	O
and	O
then	O
apply	O
your	O
function	O
:	O
#CODE	O

Error	O
when	O
trying	O
to	O
apply	O
log	O
method	O
to	O
pandas	O
data	O
frame	O
column	O
in	O
Python	O

Pandas	O
doesn't	O
complain	O
,	O
because	O
now	O
you	O
have	O
an	O
array	O
of	O
Python	O
objects	O
.	O

[	O
but	O
this	O
is	O
really	O
just	O
cheating	O
around	O
the	O
typecheck	O
]	O
.	O

And	O
if	O
you	O
want	O
to	O
convert	O
back	O
to	O
array	O
,	O
just	O
apply	O
`	O
np.array	B-API
`	O
to	O
it	O
.	O

#CODE	O

Apply	O
iterates	O
through	O
every	O
item	O
in	O
the	O
dataframe	B-API
.	O

Then	O
just	O
apply	O
the	O
aggregation	O
function	O
and	O
boom	O
you're	O
done	O
:	O
#CODE	O

I	O
wonder	O
whether	O
`	O
to_datetime	B-API
`	O
is	O
faster	O
that	O
`	O
apply	O
(	O
pd.Timestamp	O
)`	O
?	O

Certainly	O
that'll	O
be	O
the	O
only	O
choice	O
come	O
0.11.1	O
:)	O

``	O
pd.to_datetime	B-API
``	O
should	O
be	O
faster	O
if	O
the	O
cython	O
doesn't	O
raise	O
(	O
in	O
which	O
case	O
it	O
essentially	O
falls	O
back	O
on	O
``	O
apply	O
(	O
Timestamp	O
)``	O
.	O

Apply	O
`	O
histogram	O
`	O
to	O
each	O
group	O
.	O

#CODE	O

Here	O
is	O
the	O
canonical	O
way	O
of	O
doing	O
it	O
,	O
while	O
not	O
necessarily	O
more	O
concise	O
,	O
is	O
more	O
flexible	O
(	O
in	O
that	O
you	O
can	O
apply	O
this	O
to	O
arbitrary	O
columns	O
)	O
#CODE	O

I	O
am	O
on	O
window	O
7	O
,	O
python	O
2.7.2	O
,	O
pandas	O
0.11.0	O
,	O
django	O
1.4	O
,	O
wsgi	O
and	O
apache	O
2.2	O
.	O

I	O
have	O
a	O
pandas	O
script	O
that	O
works	O
fine	O
if	O
I	O
run	O
it	O
directly	O
with	O
python	O
and	O
also	O
works	O
in	O
ipython	O
with	O
%run	O
.	O

However	O
,	O
when	O
I	O
run	O
pandas	O
in	O
my	O
view	O
i	O
get	O
"	O
LookupError	O
:	O
unknown	O
encoding	O
:	O
cp0	O
"	O
.	O

This	O
only	O
happens	O
when	O
using	O
ols	O
in	O
pandas	O
within	O
the	O
view	O
.	O

I'm	O
also	O
a	O
little	O
confused	O
why	O
py3compat.py	O
is	O
entering	O
the	O
picture	O
as	O
i'm	O
using	O
python	O
2.7	O
.	O

Also	O
,	O
I	O
have	O
seen	O
some	O
posts	O
about	O
wrapping	O
a	O
printed	O
variable	O
in	O
a	O
str()	B-API
,	O
but	O
I'm	O
not	O
sure	O
how	O
that	O
would	O
apply	O
here	O
.	O

The	O
whole	O
traceback	O
is	O
:	O
#CODE	O

I	O
kind	O
of	O
think	O
that	O
the	O
first	O
one	O
is	O
incorrect	O
behaviour	O
here	O
.	O

It's	O
like	O
the	O
popular	O
saying	O
:	O
"	O
Writing	O
aggregation	O
functions	O
is	O
hard	O
...	O

let's	O
go	O
write	O
apply	O
functions	O
.	O

"	O

If	O
you	O
pass	O
a	O
`	O
dict	O
`	O
or	O
`	O
list	O
`	O
to	O
apply	O
,	O
you	O
will	O
have	O
item-by-item	O
agg	O
,	O
IOW	O
,	O
you	O
will	O
get	O
a	O
`	O
Series	O
`	O

I	O
know	O
i	O
should	O
do	O
df.groupby	B-API
(	O
'	O
channel	O
')	O
and	O
then	O
apply	O
function	O
to	O
each	O
group	O
.	O

In	O
this	O
case	O
the	O
apply	O
value	O
already	O
returns	O
the	O
exact	O
same	O
df	O
with	O
only	O
different	O
cost	O
values	O
.	O

So	O
you	O
can	O
do	O
:	O
`	O
df	O
=	O
df.groupby	B-API
(	O
'	O
channel	O
')	O
.apply	B-API
(	O
myfunc	O
)`	O
.	O

But	O
if	O
you	O
insist	O
on	O
only	O
modifying	O
the	O
cost	O
column	O
this	O
would	O
also	O
work	O
:	O
`	O
df	O
[	O
'	O
cost	O
']	O
=	O
df.groupby	B-API
(	O
'	O
channel	O
')	O
.apply	B-API
(	O
myfunc	O
)	O
[	O
'	O
cost	O
']`	O
.	O

But	O
i	O
wouldnt	O
use	O
the	O
latter	O
since	O
a	O
change	O
in	O
the	O
index	O
might	O
cause	O
misalignment	O
,	O
even	O
though	O
it	O
would	O
work	O
in	O
this	O
case	O
.	O

(	O
Some	O
operating	O
systems	O
provide	O
record-oriented	O
files	O
that	O
have	O
more	O
complex	O
internal	O
structure	O
than	O
the	O
common	O
flat	O
file	O
.	O
The	O
above	O
does	O
not	O
apply	O
to	O
them	O
.	O
)	O

@USER	O
give	O
an	O
index	O
to	O
the	O
Series	O
when	O
you	O
apply	O
;	O
they	O
will	O
become	O
column	O
names	O

I'm	O
having	O
a	O
little	O
trouble	O
with	O
the	O
amount	O
of	O
memory	O
that	O
this	O
method	O
consumes	O
and	O
I'm	O
wondering	O
if	O
you	O
could	O
give	O
me	O
a	O
little	O
advice	O
.	O

I	O
have	O
a	O
DataFrame	B-API
that	O
contains	O
about	O
8000	O
rows	O
,	O
each	O
with	O
a	O
string	O
containing	O
9216	O
space	O
delimited	O
8-b	O
it	O
integers	O
.	O

This	O
is	O
roughly	O
75MB	O
,	O
but	O
when	O
I	O
apply	O
the	O
last	O
solution	O
verbatim	O
,	O
Python	O
eats	O
2GB	O
of	O
my	O
memory	O
.	O

Can	O
you	O
point	O
me	O
in	O
the	O
direction	O
of	O
some	O
source	O
that	O
would	O
tell	O
me	O
why	O
this	O
is	O
,	O
and	O
what	O
I	O
can	O
do	O
to	O
get	O
around	O
it	O
?	O

Thanks	O
.	O

Now	O
you	O
can	O
apply	O
the	O
respective	O
`	O
fillna	B-API
`	O
s	O
,	O
one	O
cheeky	O
way	O
:	O
#CODE	O

You	O
get	O
one	O
string	O
per	O
line	O
and	O
the	O
other	O
cells	O
are	O
`	O
NaN	O
`	O
,	O
then	O
the	O
math	O
to	O
apply	O
is	O
to	O
ask	O
for	O
the	O
`	O
max	O
`	O
value	O
:	O
#CODE	O

I	O
knew	O
there	O
was	O
something	O
,	O
I	O
just	O
couldn't	O
find	O
it	O
!	O

FWIW	O
the	O
`	O
isin	B-API
`	O
method	O
is	O
about	O
10	O
times	O
faster	O
than	O
using	O
`	O
apply	O
`	O
on	O
my	O
particular	O
dataset	O
.	O

then	O
apply	O
this	O
function	O
across	O
each	O
group	O
:	O
#CODE	O

Awesome	O
,	O
thanks	O
@USER	O
.	O

Knew	O
it	O
was	O
going	O
to	O
be	O
a	O
groupby	B-API
,	O
but	O
couldn't	O
figure	O
out	O
how	O
to	O
apply	O
it	O
properly	O
.	O

here	O
cols	O
is	O
df	O
[	O
'	O
C	O
']	O
and	O
values	O
is	O
df	O
[	O
'	O
D	O
']	O
.	O

We	O
group	O
those	O
two	O
things	O
by	O
cols	O
and	O
then	O
apply	O
the	O
aggregating	O
function	O
,	O
which	O
in	O
this	O
case	O
is	O
np.size	O
.	O

Each	O
row	O
looks	O
like	O
#CODE	O

How	O
can	O
I	O
apply	O
the	O
testfunction	O
on	O
x	O
which	O
returns	O
the	O
two	O
c	O
[	O
1	O
]	O
values	O
?	O

Do	O
you	O
mean	O
to	O
say	O
,	O
you	O
need	O
to	O
apply	O
testfunction	O
on	O
df1	O
and	O
df2	O
individually	O
and	O
store	O
the	O
result	O
somewhere	O
?	O

Like	O
`	O
y	O
=	O
map	O
(	O
testfunction	O
,	O
x	O
)`	O
?	O

This	O
will	O
apply	O
testfunction	O
to	O
every	O
item	O
of	O
the	O
iterable	O
you	O
pass	O
and	O
return	O
a	O
list	O
of	O
the	O
results	O
.	O

Thank	O
you	O
very	O
much	O
Brian	O
for	O
your	O
answer	O
!	O

I	O
just	O
spent	O
2.5	O
hours	O
on	O
this	O
problem	O
.	O

I	O
thought	O
that	O
I	O
need	O
to	O
apply	O
a	O
"	O
for	O
loop	O
"	O
...	O

This	O
will	O
apply	O
the	O
function	O
`	O
testfunction	O
`	O
to	O
every	O
item	O
in	O
`	O
x	O
`	O
and	O
return	O
a	O
list	O
of	O
the	O
results	O
.	O

Is	O
there	O
any	O
equivalent	O
function	O
like	O
"	O
apply	O
"	O
for	O
rows	O
.	O

Since	O
apply	O
seems	O
to	O
work	O
on	O
"	O
columns	O
"	O
only	O
.	O

@USER	O
`	O
apply	O
`	O
takes	O
an	O
`	O
axis	O
`	O
kwarg	O
to	O
toggle	O
between	O
rows	O
and	O
columns	O

The	O
result	O
you	O
currently	O
have	O
is	O
a	O
`	O
Series	O
`	O
with	O
a	O
`	O
MultiIndex	O
`	O
,	O
so	O
all	O
the	O
usual	O
rules	O
will	O
apply	O
.	O

If	O
your	O
result	O
is	O
called	O
`	O
res	O
`	O
,	O
then	O
`	O
res.ix	O
[	O
False	O
]`	O
gives	O
you	O
just	O
the	O
Falses	O
,	O
indexed	O
now	O
by	O
only	O
`	O
user_id	O
`	O
.	O

Likewise	O
for	O
`	O
res.ix	O
[	O
True	O
]`	O
.	O

See	O
the	O
docs	O
.	O

Hmm	O
...	O

I'm	O
running	O
into	O
a	O
bit	O
of	O
trouble	O
here	O
.	O

The	O
matrix	O
includes	O
1.00	O
identities	O
(	O
perfect	O
matches	O
)	O
across	O
the	O
diagonal	O
.	O

However	O
,	O
when	O
I	O
apply	O
the	O
"	O
unpack	O
"	O
function	O
,	O
all	O
of	O
those	O
turn	O
into	O
a	O
value	O
0.939085	O
,	O
for	O
which	O
I'm	O
not	O
sure	O
how	O
it's	O
happening	O
.	O

In	O
less	O
than	O
a	O
few	O
minutes	O
,	O
I	O
will	O
update	O
the	O
original	O
question	O
with	O
the	O
data	O
set	O
I'm	O
working	O
with	O
.	O

Well	O
I	O
don't	O
know	O
anything	O
about	O
robot_detection	O
module	O
,	O
but	O
a	O
DataFrame	B-API
with	O
50000	O
lines	O
doesn't	O
sound	O
that	O
much	O
,	O
really	O
.	O

And	O
looking	O
at	O
your	O
for-loop	O
it	O
seems	O
like	O
the	O
function	O
`	O
is_robot	O
`	O
is	O
not	O
applied	O
to	O
the	O
whole	O
DataFrame	B-API
but	O
to	O
each	O
line	O
,	O
which	O
I	O
assume	O
to	O
contain	O
one	O
entry	O
of	O
the	O
log	O
.	O

Thus	O
I	O
suggested	O
to	O
use	O
`	O
apply	O
`	O
instead	O
.	O

I	O
see	O
,	O
I	O
guess	O
then	O
you	O
can	O
split	O
the	O
DataFrame	B-API
,	O
apply	O
`	O
value_counts()	B-API
`	O
to	O
each	O
split	O
,	O
and	O
then	O
sum	O
all	O
the	O
splits	O
to	O
get	O
the	O
final	O
result	O
.	O

Thanks	O
Very	O
Much	O
!	O

In	O
addition	O
to	O
this	O
I	O
want	O
to	O
apply	O
some	O
function	O
to	O
each	O
group	O
?	O

How	O
to	O
access	O
groups	O
one	O
by	O
one	O
?	O

I'm	O
splitting	O
the	O
dataframe	B-API
since	O
it	O
is	O
too	O
large	O
.	O

I	O
want	O
to	O
take	O
the	O
first	O
group	O
and	O
apply	O
the	O
function	O
,	O
then	O
the	O
second	O
group	O
and	O
apply	O
function	O
etc	O
.	O

so	O
how	O
do	O
I	O
access	O
each	O
group	O
?	O

subset	O
before	O
you	O
apply	O
#CODE	O

2nd	O
part	O
,	O
row-wise	O
apply	O
,	O
returning	O
'	O
sum	O
'	O
of	O
elements	O
in	O
A	O
and	O
B	O
columns	O
.	O

You	O
can	O

pretty	O
much	O
what	O
what	O
you	O
want	O
in	O
apply	O
.	O

#CODE	O

This	O
is	O
cool	O
-	O
how	O
would	O
I	O
do	O
a	O
row-wise	O
apply	O
taking	O
two	O
values	O
from	O
different	O
columns	O
but	O
in	O
the	O
same	O
row	O
into	O
the	O
apply	O
function	O
?	O

Say	O
two	O
columns	O
were	O
first	O
/	O
name	O
and	O
family	O
/	O
name	O
strings	O
and	O
I	O
wanted	O
to	O
take	O
value1	O
and	O
value2	O
and	O
do	O
stuff	O
to	O
them	O
.	O

neat	O
apply	O
tricks	O
#CODE	O

To	O
select	O
rows	O
with	O
one	O
item	O
you're	O
interested	O
in	O
,	O
you	O
can	O
`	O
apply	O
`	O
a	O
`	O
lambda	O
`	O
function	O
.	O

For	O
example	O
:	O
#CODE	O

thanks	O
for	O
mentioning	O
`	O
grouper	B-API
`	O
,	O
as	O
it	O
is	O
not	O
documented	O
!	O

I	O
finally	O
found	O
a	O
solution	O
to	O
change	O
rows	O
in	O
original	O
dataframe	B-API
while	O
iterating	O
over	O
its	O
grouped	O
object	O
,	O
using	O
`	O
grouped.grouper.indices	O
`	O
.	O

I	O
had	O
to	O
use	O
it	O
because	O
I	O
have	O
duplicate	O
DateTime	O
indices	O
in	O
the	O
dataframe	B-API
.	O

Also	O
the	O
transformation	O
is	O
too	O
complicated	O
to	O
fit	O
a	O
`	O
grouped	O
`	O
then	O
`	O
apply	O
`	O
paradigm	O
,	O
it	O
involves	O
clustering	O
and	O
filling	O
in	O
multiple	O
dataframes	O
at	O
once	O
while	O
going	O
through	O
each	O
group	O
.	O

You	O
could	O
use	O
`	O
apply	O
`	O
,	O
e.g.	O
:	O
#CODE	O

Essentially	O
an	O
apply	O
,	O
but	O
with	O
control	O
over	O
how	O
exactly	O
its	O
combined	O
.	O

#CODE	O

You	O
can	O
use	O
`	O
groupby	B-API
`	O
,	O
`	O
apply	O
`	O
,	O
`	O
reset_index	B-API
`	O
to	O
create	O
a	O
multiindex	O
Series	O
,	O
and	O
then	O
call	O
`	O
unstack	O
`	O
:	O
#CODE	O

I	O
have	O
a	O
DataFrame	B-API
with	O
an	O
index	O
called	O
`	O
city_id	O
`	O
of	O
cities	O
in	O
the	O
format	O
`	O
[	O
city	O
]	O
,	O
[	O
state	O
]`	O
(	O
e.g.	O
,	O
`	O
new	O
york	O
,	O
ny	O
`	O
containing	O
integer	O
counts	O
in	O
the	O
columns	O
.	O

The	O
problem	O
is	O
that	O
I	O
have	O
multiple	O
rows	O
for	O
the	O
same	O
city	O
,	O
and	O
I	O
want	O
to	O
collapse	O
the	O
rows	O
sharing	O
a	O
`	O
city_id	O
`	O
by	O
adding	O
their	O
column	O
values	O
.	O

I	O
looked	O
at	O
`	O
groupby()	B-API
`	O
but	O
it	O
wasn't	O
immediately	O
obvious	O
how	O
to	O
apply	O
it	O
to	O
this	O
problem	O
.	O

So	O
its	O
not	O
necessary	O
to	O
groupby	B-API
month	O
first	O
,	O
unless	O
you	O
have	O
other	O
reasons	O
to	O
do	O
so	O
.	O

If	O
so	O
,	O
you	O
can	O
also	O
apply	O
the	O
last	O
groupby	B-API
on	O
the	O
monthly	O
df	O
as	O
well	O
.	O

Ah	O
.	O
thanks	O
tshauck	O
,	O
I	O
guess	O
that	O
was	O
actually	O
what	O
i	O
was	O
trying	O
to	O
do	O
.	O

The	O
result	O
to	O
that	O
test	O
actually	O
printed	O
the	O
count	O
for	O
each	O
field	O
i.e.Field1	O
=	O
10	O
and	O
next	O
line	O
Field2	O
=	O
10	O
.	O

I	O
guess	O
you	O
could	O
also	O
apply	O
the	O
count	O
to	O
one	O
particular	O
Field	O
?	O

How	O
to	O
apply	O
to_datetime	B-API
or	O
with	O
sort_index	B-API
so	O
that	O
the	O
dates	O
are	O
sorted	O
?	O

I	O
don't	O
know	O
how	O
to	O
apply	O
to_datetime	B-API
,	O
because	O
the	O
output	O
of	O
the	O
dates	O
are	O
not	O
sorted	O
.	O

#CODE	O

At	O
the	O
moment	O
you	O
can	O
do	O
this	O
with	O
an	O
apply	O
or	O
the	O
delta	O
attribute	O
:	O
#CODE	O

`	O
copy()	B-API
`	O
doesnt	O
prevent	O
that	O
.	O

Using	O
`	O
copy	O
`	O
seems	O
to	O
only	O
apply	O
on	O
the	O
data	O
,	O
not	O
the	O
index	O
.	O

Which	O
is	O
a	O
bit	O
strange	O
,	O
reading	O
your	O
spreadsheet	O
twice	O
might	O
be	O
the	O
best	O
option	O
,	O
altough	O
not	O
terribly	O
efficient	O
.	O

@USER	O
It's	O
not	O
really	O
clear	O
what	O
you	O
expect	O
that	O
to	O
do	O
,	O
but	O
using	O
groupby	B-API
ensures	O
each	O
groups	O
is	O
a	O
DataFrame	B-API
and	O
then	O
,	O
for	O
example	O
,	O
you	O
can	O
apply	O
a	O
function	O
to	O
that	O
.	O

@USER	O
if	O
you	O
really	O
wanted	O
to	O
do	O
it	O
manually	O
you	O
could	O
use	O
:	O
`	O
g	O
=	O
df1.groupy	O
(	O
'	O
time	O
')	O
;	O
[	O
g.get_group	O
(	O
x	O
)	O
for	O
x	O
in	O
g.groups	O
]`	O
,	O
but	O
I	O
recommend	O
apply	O
.	O

Thanks	O
falsetrue	O
!	O

this	O
has	O
been	O
SOO	O
helpful	O
I	O
can	O
apply	O
this	O
to	O
everything	O
now	O
!	O

:)	O
I	O
can't	O
tell	O
you	O
how	O
long	O
this	O
has	O
taken	O
me	O
!	O

I	O
have	O
been	O
doing	O
Pandas	O
,	O
in	O
which	O
I	O
apply	O
a	O
`	O
.groupby	B-API
(	O
'	O
Subtype	O
')`	O
on	O
the	O
dataframe	B-API
,	O
but	O
after	O
I	O
do	O
that	O
,	O
I'm	O
not	O
sure	O
how	O
to	O
proceed	O
further	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
!	O

Then	O
you	O
can	O
use	O
this	O
in	O
a	O
groupby	B-API
`	O
apply	O
`	O
:	O
#CODE	O

@USER	O
it	O
looks	O
like	O
you've	O
tried	O
to	O
apply	O
shift	O
to	O
a	O
Timestamp	O
rather	O
than	O
a	O
column	O
/	O
Series	O
(	O
not	O
sure	O
how	O
you	O
did	O
that	O
though	O
)	O
.	O

[	O
Using	O
Python3	O
]	O
I'm	O
using	O
pandas	O
to	O
read	O
a	O
csv	O
file	O
,	O
group	O
the	O
dataframe	B-API
,	O
apply	O
a	O
function	O
to	O
the	O
grouped	O
data	O
and	O
add	O
these	O
results	O
back	O
to	O
the	O
original	O
dataframe	B-API
.	O

Basically	O
I'm	O
trying	O
to	O
group	O
by	O
`	O
cc	O
`	O
and	O
calculate	O
the	O
percentile	O
rank	O
for	O
each	O
value	O
in	O
`	O
total_value	O
`	O
within	O
that	O
group	O
.	O

Secondly	O
I	O
want	O
to	O
apply	O
a	O
flow	O
statement	O
to	O
these	O
results	O
.	O

I	O
need	O
these	O
results	O
to	O
be	O
added	O
back	O
to	O
the	O
original	O
/	O
parent	O
DataFrame	B-API
.	O

Such	O
that	O
it	O
would	O
look	O
something	O
like	O
this	O
:	O
#CODE	O

Another	O
option	O
is	O
to	O
use	O
an	O
apply	O
:	O
#CODE	O

Another	O
option	O
is	O
promote	O
the	O
'	O
day	O
'	O
level	O
to	O
a	O
column	O
and	O
then	O
use	O
an	O
apply	O
.	O

Note	O
you	O
can	O
apply	O
strftime	B-API
directly	O
from	O
a	O
Timestamp	O
object	O
e.g.	O
`	O
rng.map	O
(	O
lambda	O
t	B-API
:	O
t.strftime	O
(	O
'	O
%Y-%m-%d	O
'))`	O
.	O

2	O
)	O
I	O
tried	O
filtering	O
using	O
the	O
apply	O
function	O
:	O
#CODE	O

How	O
to	O
apply	O
condition	O
on	O
level	O
of	O
pandas.multiindex	B-API
?	O

You	O
should	O
check	O
out	O
`	O
scipy.sparse	O
`	O
(	O
link	O
)	O
.	O

You	O
can	O
apply	O
operations	O
on	O
those	O
sparse	O
matrices	O
just	O
like	O
how	O
you	O
use	O
a	O
normal	O
matrix	O
.	O

Here's	O
one	O
way	O
(	O
though	O
it	O
feels	O
this	O
should	O
work	O
in	O
one	O
go	O
with	O
an	O
apply	O
,	O
I	O
can't	O
get	O
it	O
)	O
.	O

#CODE	O

but	O
I'm	O
not	O
able	O
to	O
apply	O
this	O
on	O
each	O
"	O
name	O
"	O
group	O
of	O
my	O
dataframe	B-API

Your	O
desired	O
result	O
suggests	O
that	O
you	O
actually	O
want	O
to	O
normalize	O
the	O
values	O
in	O
each	O
name	O
group	O
with	O
reference	O
to	O
the	O
elements	O
in	O
`	O
value1	O
`	O
and	O
`	O
value2	O
`	O
.	O

For	O
something	O
like	O
that	O
,	O
you	O
can	O
apply	O
a	O
function	O
to	O
each	O
group	O
individually	O
,	O
and	O
reassemble	O
the	O
result	O
.	O

#CODE	O

I	O
read	O
about	O
the	O
.stack	B-API
method	O
but	O
couldn't	O
figure	O
out	O
how	O
to	O
apply	O
it	O
for	O
this	O
case	O
.	O

I'm	O
not	O
aware	O
of	O
a	O
method	O
on	O
DataFrame	B-API
to	O
do	O
this	O
.	O

Do	O
you	O
expect	O
things	O
like	O
count	O
and	O
the	O
quantiles	O
to	O
change	O
?	O

Or	O
just	O
the	O
mean	O
and	O
standard	O
deviation	O
?	O

Can	O
you	O
apply	O
the	O
weighting	O
first	O
and	O
then	O
call	O
describe	O
on	O
the	O
resulting	O
series	O
?	O

Thanks	O
TomAuspurger	O
...	O
that	O
was	O
my	O
suspicion	O
,	O
but	O
I	O
was	O
hoping	O
to	O
avoid	O
that	O
extra	O
coding	O
...	O

I'd	O
expect	O
it	O
to	O
apply	O
to	O
all	O
of	O
the	O
metrics	O
.	O

Assume	O
you	O
have	O
70%	O
of	O
the	O
population	O
with	O
revenue	O
0	O
,	O
and	O
30%	O
with	O
revenue	O
1	O
.	O

You'd	O
want	O
median	O
revenue	O
weighted	O
by	O
population	O
to	O
be	O
0	O
.	O

If	O
you	O
multiply	O
revenue	O
by	O
weight	O
and	O
apply	O
describe	O
...	O
you	O
probably	O
get	O
a	O
median	O
of	O
0.15	O
(	O
vector	O
0	O
,	O
0.3	O
)	O
which	O
is	O
irrelevant	O
.	O

I	O
have	O
a	O
pandas	O
series	O
of	O
booleans	O
and	O
was	O
wondering	O
what	O
the	O
best	O
way	O
is	O
to	O
apply	O
"	O
or	O
"	O
or	O
"	O
and	O
"	O
to	O
the	O
whole	O
series	O
.	O

I	O
am	O
thinking	O
something	O
along	O
the	O
lines	O
of	O
a	O
Haskell	O
#CODE	O

will	O
apply	O
a	O
function	O
to	O
each	O
element	O
in	O
the	O
series	O
so	O
doesn't	O
seem	O
to	O
do	O
what	O
I	O
need	O
.	O

`	O
replace	O
`	O
seems	O
to	O
apply	O
to	O
DataFrame	B-API
not	O
to	O
a	O
Serie	O

As	O
you	O
say	O
,	O
looping	O
(	O
iterrows	B-API
)	O
is	O
a	O
last	O
resort	O
.	O

Try	O
this	O
,	O
which	O
uses	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
instead	O
of	O
iterating	O
through	O
rows	O
.	O

#CODE	O

Thanks	O
a	O
lot	O
.	O

Very	O
helpful	O
.	O

I've	O
been	O
trying	O
to	O
apply	O
that	O
to	O
a	O
larger	O
DataFrame	B-API
and	O
keep	O
on	O
getting	O
this	O
error	O

If	O
the	O
criteria	O
I	O
apply	O
return	O
a	O
single	O
row	O
,	O
I'd	O
expect	O
to	O
be	O
able	O
to	O
set	O
the	O
value	O
of	O
a	O
certain	O
column	O
in	O
that	O
row	O
in	O
an	O
easy	O
way	O
,	O
but	O
my	O
first	O
attempt	O
doesn't	O
work	O
:	O
#CODE	O

A	O
nested	O
apply	O
will	O
do	O
it	O
#CODE	O

suppose	O
I	O
have	O
a	O
dataframe	B-API
with	O
index	O
as	O
monthy	O
timestep	O
,	O
I	O
know	O
I	O
can	O
use	O
`	O
dataframe.groupby	B-API
(	O
lambda	O
x	O
:	O
x.year	O
)`	O
to	O
group	O
monthly	O
data	O
into	O
yearly	O
and	O
apply	O
other	O
operations	O
.	O

Is	O
there	O
some	O
way	O
I	O
could	O
quick	O
group	O
them	O
,	O
let's	O
say	O
by	O
decade	O
?	O

I	O
have	O
tried	O
several	O
variants	O
on	O
:	O
(	O
I	O
assume	O
I'll	O
need	O
to	O
apply	O
the	O
limits	O
to	O
each	O
plot	O
..	O
but	O
since	O
I	O
can't	O
get	O
one	O
working	O
...	O

From	O
the	O
Matplotlib	O
doc	O
it	O
seems	O
that	O
I	O
need	O
to	O
set	O
ylim	O
,	O
but	O
can't	O
figure	O
the	O
syntax	O
to	O
do	O
so	O
.	O

#CODE	O

You	O
are	O
using	O
an	O
indexing	O
short-cut	O
which	O
doesn't	O
apply	O
,	O
see	O
here	O
:	O
#URL	O

To	O
do	O
this	O
over	O
each	O
group	O
you	O
have	O
to	O
groupby	B-API
category	O
first	O
and	O
then	O
apply	O
this	O
function	O
:	O
#CODE	O

Apply	O
the	O
function	O
(	O
you	O
could	O
group	O
by	O
uuid	O
,	O
site	O
if	O
you	O
want	O
as	O
well	O
)	O
#CODE	O

When	O
you	O
apply	O
your	O
own	O
function	O
,	O
there	O
is	O
not	O
automatic	O
exclusions	O
of	O
non-numeric	O
columns	O
.	O

This	O
is	O
slower	O
,	O
though	O
(	O
that	O
the	O
applicatino	O
of	O
`	O
.sum()	B-API
`	O
to	O
the	O
groupby	B-API
#CODE	O

Thanks	O
Jeff	O
.	O

How	O
could	O
I	O
apply	O
different	O
functions	O
on	O
several	O
columns	O
in	O
one	O
go	O
as	O
well	O
,	O
e.g.	O
sum	O
on	O
column	O
"	O
B	O
"	O
and	O
set	O
on	O
column	O
"	O
C	O
"	O
?	O

each	O
group	O
get's	O
passed	O
a	O
``	O
DataFrame	B-API
``	O
(	O
called	O
x	O
)	O
,	O
so	O
x	O
[	O
'	O
A	O
']	O
is	O
a	O
``	O
Series	O
``	O
,	O
just	O
like	O
regular	O
indexing	O
(	O
but	O
its	O
just	O
the	O
rows	O
in	O
that	O
group	O
)	O
.	O
the	O
``	O
x	O
[	O
'	O
A	O
']	O
.sum()	B-API
``	O
thus	O
reduces	O
to	O
a	O
scalar	O
value	O
,	O
as	O
do	O
the	O
other	O
terms	O
.	O

Net	O
you	O
are	O
returning	O
a	O
``	O
Series	O
``	O
with	O
values	O
for	O
the	O
``	O
index	O
=[	O
'	O
A	O
'	O
,	O
'	O
B	O
'	O
,	O
'	O
C	O
']``	O
.	O

These	O
are	O
stacked	O
(	O
row-wise	O
)	O
to	O
form	O
the	O
result	O
frame	O
at	O
the	O
very	O
end	O
of	O
the	O
apply	O
.	O

You	O
can	O
do	O
bare	O
strings	O
for	O
the	O
keys	O
when	O
you	O
use	O
``	O
dict	O
``	O
,	O
equiv	O
is	O
``	O
{	O
'	O
A	O
'	O
:	O
x	O
[	O
'	O
A	O
']	O
.sum()	B-API
}	O
``	O

great	O
!	O

just	O
to	O
point	O
out	O
though	O
,	O
you	O
should	O
still	O
do	O
the	O
aggregation	O
on	O
A	O
and	O
B	O
via	O
a	O
direct	O
``	O
.sum()	B-API
``	O
rather	O
than	O
apply	O
because	O
these	O
are	O
cythonized	O
.	O

The	O
apply	O
going	O
to	O
be	O
slower	O
,	O
so	O
do	O
only	O
where	O
you	O
really	O
need	O
it	O
.	O

Great	O
answer	O
!	O

A	O
slightly	O
more	O
direct	O
way	O
to	O
apply	O
different	O
functions	O
on	O
several	O
columns	O
is	O
to	O
use	O
the	O
`	O
agg	O
`	O
function	O
,	O
so	O
`	O
df.groupby	B-API
(	O
'	O
A	O
')	O
.agg	B-API
(	O
dict	O
(	O
A	O
=	O
'	O
sum	O
'	O
,	O
B	O
=	O
'	O
sum	O
'	O
,	O
C	O
=	O
lambda	O
x	O
:	O
'	O
{%s}	O
'	O
%	O
'	O
,	O
'	O
.join	B-API
(	O
x	O
)))`	O

Thanks	O
a	O
lot	O
,	O
I	O
have	O
been	O
looking	O
into	O
the	O
`	O
agg	O
`	O
function	O
.	O

Any	O
ideas	O
how	O
that	O
would	O
compare	O
performance-wise	O
to	O
apply	O
?	O

they	O
are	O
the	O
same	O
;	O
apply	O
is	O
a	O
bit	O
more	O
flexible	O
in	O
how	O
it	O
looks	O
at	O
the	O
output	O
(	O
just	O
slightly	O
)	O

You	O
can	O
use	O
the	O
`	O
apply	O
`	O
method	O
to	O
apply	O
an	O
arbitrary	O
function	O
to	O
the	O
grouped	O
data	O
.	O

So	O
if	O
you	O
want	O
a	O
set	O
,	O
apply	O
`	O
set	O
`	O
.	O

If	O
you	O
want	O
a	O
list	O
,	O
apply	O
`	O
list	O
`	O
.	O

#CODE	O

If	O
you	O
want	O
something	O
else	O
,	O
just	O
write	O
a	O
function	O
that	O
does	O
what	O
you	O
want	O
and	O
then	O
`	O
apply	O
`	O
that	O
.	O

Why	O
am	O
I	O
unable	O
to	O
apply	O
my	O
function	O
elementwise	O
on	O
my	O
`	O
Series	O
`	O
object	O
?	O

You	O
could	O
write	O
a	O
function	O
and	O
`	O
apply	O
`	O
it	O
to	O
each	O
DataFrame	B-API
in	O
the	O
panel	O
you	O
get	O
from	O
Yahoo	O
.	O

I	O
have	O
calibration	O
factors	O
that	O
need	O
to	O
be	O
applied	O
after	O
specific	O
dates	O
and	O
for	O
certain	O
ranges	O
of	O
instrument	O
readings	O
ie	O
.	O

a	O
higher	O
reading	O
will	O
require	O
a	O
different	O
calibration	O
factor	O
.	O

I	O
am	O
way	O
I	O
am	O
trying	O
to	O
apply	O
a	O
lookup	O
table	O
that	O
is	O
based	O
on	O
the	O
time	O
and	O
also	O
the	O
raw	O
instrument	O
reading	O
through	O
the	O
use	O
of	O
a	O
nested	O
python	O
dictionary	O
.	O

is	O
there	O
a	O
way	O
to	O
iterate	O
through	O
my	O
dataframe	B-API
to	O
apply	O
these	O
calibration	O
factors	O
with	O
the	O
nested	O
dict	O
as	O
a	O
form	O
of	O
a	O
lookup	O
table	O
?	O

Till	O
`	O
pandas	O
`	O
is	O
not	O
officially	O
implemented	O
in	O
`	O
plt.fill_between	B-API
`	O
function	O
,	O
you	O
can	O
still	O
apply	O
`	O
pd.Series	B-API
`	O
or	O
`	O
pd.DataFrame	B-API
`	O
as	O
`	O
pd.Series()	B-API
.values	B-API
`	O
and	O
`	O
pd.DataFrame()	B-API
.values	B-API
`	O
to	O
make	O
`	O
fill_between	B-API
`	O
plots	O
.	O

``	O
apply	O
``	O
would	O
return	O
a	O
shorter	O
Series	O
,	O
with	O
one	O
entry	O
per	O
group	O
.	O

Instead	O
,	O
we	O
want	O
a	O
Series	O
of	O
the	O
same	O
length	O
as	O
the	O
original	O
one	O
,	O
with	O
each	O
group's	O
entire	O
contents	O
mapped	O
to	O
``	O
True	O
``	O
or	O
``	O
False	O
``	O
as	O
a	O
block	O
.	O

Then	O
we	O
can	O
use	O
that	O
boolean	O
Series	O
to	O
mask	O
the	O
original	O
Series	O
.	O

See	O
the	O
[	O
documentation	O
]	O
(	O
#URL	O
)	O
for	O
more	O
.	O

And	O
then	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

Alternatively	O
you	O
could	O
use	O
`	O
apply	O
`	O
(	O
but	O
this	O
will	O
usually	O
be	O
slower	O
):	O
#CODE	O

How	O
to	O
apply	O
a	O
function	O
to	O
two	O
columns	O
of	O
Pandas	O
dataframe	B-API

Pandas	O
:	O
How	O
to	O
use	O
apply	O
function	O
to	O
multiple	O
columns	O

And	O
apply	O
the	O
function	O
like	O
this	O
:	O
#CODE	O

Any	O
Ideas	O
on	O
how	O
to	O
get	O
around	O
the	O
axis	O
parameter	O
error	O
?	O

Or	O
a	O
more	O
elegant	O
way	O
to	O
calculate	O
the	O
pct	O
change	O
?	O

The	O
kicker	O
with	O
my	O
problem	O
is	O
that	O
I	O
needs	O
be	O
able	O
to	O
apply	O
this	O
function	O
across	O
several	O
different	O
column	O
pairs	O
,	O
so	O
hard	O
coding	O
the	O
column	O
names	O
like	O
the	O
answer	O
in	O
2nd	O
question	O
is	O
undesirable	O
.	O

Thanks	O
!	O

The	O
confusion	O
stems	O
from	O
two	O
different	O
(	O
but	O
equally	O
named	O
)	O
`	O
apply	O
`	O
functions	O
,	O
one	O
on	O
Series	O
/	O
DataFrame	B-API
and	O
one	O
on	O
groupby	B-API
.	O

#CODE	O

The	O
DataFrame	B-API
apply	O
method	O
takes	O
an	O
axis	O
argument	O
:	O
#CODE	O

The	O
groupby	B-API
apply	O
doesn't	O
,	O
and	O
the	O
kwarg	O
is	O
passed	O
to	O
the	O
function	O
:	O
#CODE	O

Thanks	O
for	O
your	O
answer	O
Andy	O
.	O

If	O
I	O
stick	O
with	O
the	O
groupby	B-API
apply	O
and	O
remove	O
the	O
axis	O
param	O
,	O
I	O
get	O
a	O
key	O
error	O
`	O
KeyError	O
:	O
u'no	O
item	O
named	O
0	O
'`	O
for	O
accessing	O
the	O
elements	O
as	O
`	O
row	O
[	O
0	O
]`	O
ect	O
.	O

Is	O
there	O
a	O
way	O
to	O
use	O
the	O
groupby	B-API
apply	O
and	O
still	O
use	O
a	O
notation	O
that	O
keeps	O
it	O
easy	O
to	O
apply	O
to	O
several	O
differently	O
named	O
column	O
pairs	O
?	O

@USER	O
updated	O
,	O
you	O
can	O
use	O
the	O
groupby	B-API
with	O
axis=1	O
,	O
you	O
can	O
apply	O
pct_change	B-API
to	O
entire	O
dataframe	B-API
.	O

Or	O
perhaps	O
you	O
want	O
to	O
do	O
this	O
one	O
each	O
group	O
using	O
an	O
apply	O
(	O
`	O
lambda	O
x	O
:	O
x.pct_change()	O
`)	O
.	O

@USER	O
you	O
need	O
to	O
tweak	O
delta	O
a	O
bit	O
,	O
see	O
my	O
last	O
example	O
(	O
assuming	O
that's	O
from	O
the	O
apply	O
)	O

@USER	O
not	O
sure	O
I	O
have	O
a	O
good	O
reference	O
,	O
but	O
a	O
good	O
trick	O
is	O
to	O
set	O
up	O
a	O
break	O
point	O
in	O
the	O
function	O
you're	O
going	O
to	O
apply	O
and	O
then	O
see	O
how	O
you	O
can	O
access	O
things	O
you	O
want	O

You	O
could	O
define	O
a	O
function	O
to	O
subtract	O
the	O
quarterly	O
totals	O
from	O
the	O
annual	O
number	O
,	O
and	O
then	O
apply	O
the	O
function	O
to	O
each	O
row	O
,	O
storing	O
the	O
result	O
in	O
a	O
new	O
column	O
.	O

#CODE	O

Assuming	O
these	O
are	O
just	O
strings	O
you	O
could	O
simply	O
add	O
them	O
together	O
(	O
with	O
a	O
space	O
)	O
,	O
allowing	O
you	O
to	O
apply	O
`	O
to_datetime	B-API
`	O
:	O
#CODE	O

A	O
purely	O
pandas	O
way	O
might	O
be	O
to	O
apply	O
the	O
Series	O
constructor	O
to	O
put	O
this	O
into	O
one	O
DataFrame	B-API
and	O
stack	O
into	O
a	O
Series	O
(	O
so	O
you	O
can	O
use	O
value_counts	B-API
)	O
...	O

if	O
you	O
didn't	O
care	O
about	O
the	O
index	O
/	O
timestamp	O
you	O
could	O
use	O
collections	O
(	O
which	O
may	O
be	O
faster	O
):	O
#CODE	O

`	O
Apply	O
`	O
Series	O
constructor	O
to	O
get	O
a	O
DataFrame	B-API
and	O
`	O
stack	O
`	O
it	O
into	O
a	O
Series	O
:	O
#CODE	O

The	O
result	O
of	O
`	O
df.groupby	B-API
(	O
...	O
)`	O
is	O
not	O
a	O
DataFrame	B-API
.	O

To	O
get	O
a	O
DataFrame	B-API
back	O
,	O
you	O
have	O
to	O
apply	O
a	O
function	O
to	O
each	O
group	O
,	O
transform	O
each	O
element	O
of	O
a	O
group	O
,	O
or	O
filter	O
the	O
groups	O
.	O

I	O
came	O
out	O
with	O
the	O
following	O
solution	O
.	O

As	O
preparation	O
steps	O
,	O
I	O
ll	O
group	O
by	O
speaker	O
name	O
and	O
set	O
the	O
file	O
name	O
as	O
index	O
by	O
the	O
set_index	B-API
method	O
.	O

I	O
will	O
then	O
iterate	O
over	O
the	O
groupbyObj	O
and	O
apply	O
the	O
calculation	O
function	O
,	O
which	O
will	O
return	O
the	O
selected	O
speaker	O
and	O
the	O
files	O
to	O
be	O
marked	O
as	O
used	O
.	O

1	O
.	O

How	O
can	O
I	O
approach	O
a	O
specific	O
group	O
by	O
a	O
groupby	B-API
object	O
?	O

bcz	O
I	O
thought	O
maybe	O
instead	O
of	O
setting	O
the	O
files	O
as	O
indexed	O
,	O
grouping	O
by	O
a	O
file	O
,	O
and	O
the	O
using	O
that	O
groupby	B-API
obj	O
to	O
apply	O
a	O
changing	O
function	O
to	O
all	O
of	O
its	O
occurrences	O
.	O

But	O
I	O
didn	O
t	B-API
find	O
a	O
way	O
to	O
approach	O
a	O
specific	O
group	O
and	O
passing	O
the	O
group	O
name	O
as	O
parameter	O
and	O
calling	O
apply	O
on	O
all	O
the	O
groups	O
and	O
then	O
acting	O
only	O
on	O
one	O
of	O
them	O
seemed	O
not	O
"	O
right	O
"	O
to	O
me	O
.	O

`	O
apply	O
`	O
on	O
a	O
series	O
returns	O
a	O
DataFrame	B-API
if	O
the	O
function	O
wich	O
is	O
applied	O
returns	O
a	O
Series	O
for	O
each	O
element	O
of	O
the	O
series	O
,	O
where	O
the	O
different	O
elements	O
of	O
the	O
returned	O
Series	O
become	O
the	O
values	O
of	O
the	O
different	O
columns	O
of	O
one	O
row	O
.	O

So	O
in	O
this	O
case	O
first	O
the	O
`	O
list	O
`	O
function	O
converts	O
the	O
string	O
in	O
BINDATA	O
to	O
a	O
list	O
,	O
which	O
is	O
then	O
converted	O
to	O
a	O
Series	O
(	O
see	O
also	O
the	O
answer	O
of	O
@USER	O
,	O
which	O
does	O
actually	O
the	O
same	O
but	O
is	O
written	O
a	O
little	O
bit	O
different	O
)	O

I'm	O
not	O
sure	O
I	O
follow	O
exactly	O
what	O
aggregation	O
you	O
want	O
,	O
but	O
you	O
should	O
be	O
able	O
to	O
apply	O
`	O
groupby	B-API
`	O
however	O
you	O
like	O
.	O

For	O
example	O
:	O
#CODE	O

How	O
can	O
I	O
apply	O
formatting	O
to	O
the	O
secondary	O
Y-axis	O
(	O
the	O
one	O
that	O
displays	O
on	O
the	O
right	O
)	O
?	O

Actually	O
,	O
you	O
can't	O
just	O
apply	O
Series	O
to	O
a	O
set	O
(	O
which	O
is	O
annoying	O
)	O
`	O
TypeError	O
:	O
Set	O
value	O
is	O
unordered	O
`	O
,	O
seems	O
unnecessary	O
restriction	O
/	O
not	O
very	O
duck	O
.	O

@USER	O
exactly	O
right	O
;	O
apply	O
DOES	O
call	O
things	O
twice	O
(	O
on	O
purpose	O
)	O
to	O
see	O
if	O
there	O
are	O
modifies	O
in	O
place	O
(	O
in	O
which	O
case	O
slow	O
path	O
is	O
taken	O
);	O
otherwise	O
a	O
faster	O
path	O
can	O
be	O
taken	O
.	O

How	O
to	O
merge	O
two	O
DataFrame	B-API
columns	O
and	O
apply	O
pandas.to_datetime	B-API
to	O
it	O
?	O

What	O
would	O
be	O
a	O
more	O
pythonic	O
way	O
to	O
merge	O
two	O
columns	O
,	O
and	O
apply	O
a	O
function	O
into	O
the	O
result	O
?	O

Just	O
apply	O
the	O
`	O
min	O
`	O
function	O
along	O
the	O
axis=1	O
.	O

#CODE	O

Then	O
use	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

I'm	O
trying	O
to	O
apply	O
simple	O
functions	O
to	O
groups	O
in	O
pandas	O
.	O

I	O
have	O
this	O
dataframe	B-API
which	O
I	O
can	O
group	O
by	O
`	O
type	O
`	O
:	O
#CODE	O

I	O
want	O
to	O
apply	O
a	O
function	O
like	O
`	O
np.log2	B-API
`	O
only	O
to	O
the	O
groups	O
before	O
taking	O
the	O
mean	O
of	O
each	O
group	O
.	O

This	O
does	O
not	O
work	O
since	O
`	O
apply	O
`	O
is	O
element	O
wise	O
and	O
`	O
type	O
`	O
(	O
as	O
well	O
as	O
potentially	O
other	O
columns	O
in	O
`	O
df	O
`	O
in	O
a	O
real	O
scenario	O
)	O
is	O
not	O
numeric	O
:	O
#CODE	O

is	O
there	O
a	O
way	O
to	O
apply	O
`	O
np.log2	B-API
`	O
only	O
to	O
the	O
groups	O
prior	O
to	O
taking	O
the	O
mean	O
?	O

I	O
thought	O
`	O
transform	O
`	O
would	O
be	O
the	O
answer	O
but	O
the	O
problem	O
is	O
that	O
it	O
returns	O
a	O
dataframe	B-API
that	O
does	O
not	O
have	O
the	O
original	O
`	O
type	O
`	O
columns	O
:	O
#CODE	O

The	O
first	O
proposal	O
gives	O
`	O
(	O
'	O
Not	O
implemented	O
for	O
this	O
type	O
'	O
,	O
u'occurred	O
at	O
index	O
type	O
')`	O
.	O

The	O
second	O
one	O
works	O
but	O
it	O
drops	O
the	O
`	O
type	O
`	O
,	O
so	O
you	O
can't	O
group	O
afterwards	O
.	O

`	O
_get_numeric_data()	O
`	O
can't	O
be	O
used	O
with	O
groups	O
I	O
believe	O
.	O

So	O
can't	O
think	O
of	O
how	O
to	O
use	O
the	O
second	O
one	O
to	O
apply	O
`	O
np.log2	B-API
`	O
to	O
numeric	O
data	O
only	O
and	O
then	O
group	O
or	O
group	O
first	O
and	O
then	O
apply	O
only	O
to	O
groups	O

I	O
think	O
you'll	O
be	O
able	O
to	O
`	O
apply	O
`	O
a	O
different	O
function	O
here	O
(	O
rather	O
than	O
sum	O
)	O
to	O
achieve	O
the	O
desired	O
result	O
.	O

@USER	O
then	O
sum	O
or	O
more	O
complicated	O
analysis	O
e.g.	O
via	O
apply	O
:)	O

Thanks	O
for	O
helping	O
.	O

Your	O
suggestion	O
works	O
just	O
fine	O
for	O
the	O
those	O
dfs	O
.	O

I'm	O
trying	O
to	O
modify	O
your	O
code	O
to	O
apply	O
lambda	O
function	O
for	O
each	O
MAPINFO	O
at	O
once	O
.	O

Acctually	O
,	O
those	O
df	O
are	O
huge.Best	O
.	O

Apply	O
function	O
to	O
a	O
MultiIndex	O
dataframe	B-API
with	O
pandas	O
/	O
python	O

I	O
have	O
the	O
following	O
`	O
DataFrame	B-API
`	O
that	O
I	O
wish	O
to	O
apply	O
some	O
date	O
range	O
calculations	O
to	O
.	O

I	O
want	O
to	O
select	O
rows	O
in	O
the	O
date	O
frame	O
where	O
the	O
the	O
date	O
difference	O
between	O
samples	O
for	O
unique	O
persons	O
(	O
from	O
sample_date	O
)	O
is	O
less	O
than	O
8	O
weeks	O
and	O
keep	O
the	O
row	O
with	O
the	O
oldest	O
date	O
(	O
i.e.	O
the	O
first	O
sample	O
)	O
.	O

I	O
normally	O
use	O
R	O
for	O
the	O
procedure	O
and	O
generate	O
a	O
list	O
of	O
dataframes	O
based	O
on	O
the	O
name	O
/	O
dob	O
combination	O
and	O
sort	O
each	O
dataframe	B-API
by	O
sample_date	O
.	O

I	O
then	O
would	O
use	O
a	O
list	O
apply	O
function	O
to	O
determine	O
if	O
the	O
difference	O
in	O
date	O
between	O
the	O
fist	O
and	O
last	O
index	O
within	O
each	O
dataframe	B-API
to	O
return	O
the	O
oldest	O
if	O
it	O
was	O
less	O
than	O
8	O
weeks	O
from	O
the	O
most	O
recent	O
date	O
.	O

It	O
takes	O
forever	O
.	O

pandas	O
groupby	B-API
apply	O
on	O
multiple	O
columns	O

I	O
am	O
trying	O
to	O
apply	O
the	O
same	O
function	O
to	O
multiple	O
columns	O
of	O
a	O
groupby	B-API
object	O
,	O
such	O
as	O
:	O
#CODE	O

What	O
is	O
the	O
correct	O
way	O
to	O
apply	O
the	O
function	O
to	O
multiple	O
columns	O
at	O
once	O
?	O

Apply	O
by	O
the	O
columns	O
of	O
the	O
object	O
you	O
want	O
to	O
map	O
(	O
df2	O
);	O
find	O
the	O
rows	O
that	O
are	O
not	O
in	O
the	O
set	O
(	O
`	O
isin	B-API
`	O
is	O
like	O
a	O
set	O
operator	O
)	O
#CODE	O

`	O
apply	O
`	O
should	O
generally	O
be	O
much	O
faster	O
than	O
a	O
for	O
loop	O
.	O

This	O
example	O
you	O
provided	O
is	O
:	O
`	O
(	O
df	O
[	O
'	O
A	O
']	O
==	O
999	O
)	O
&	O
(	O
df	O
[	O
'	O
B	O
']	O
==	O
999	O
)`	O
,	O
But	O
if	O
you	O
have	O
a	O
branches	O
with	O
else	O
statement	O
also	O
you	O
should	O
use	O
`	O
apply	O
`	O
along	O
the	O
asix	O
.	O

I	O
added	O
an	O
example	O
to	O
the	O
answer	O
that	O
covers	O
that	O
case	O
(	O
using	O
`	O
apply	O
`)	O
.	O

In	O
cases	O
where	O
you	O
have	O
multiple	O
branching	O
statements	O
it's	O
best	O
to	O
create	O
a	O
function	O
that	O
accepts	O
a	O
row	O
and	O
then	O
apply	O
it	O
along	O
the	O
`	O
axis=1	O
`	O
.	O

This	O
is	O
usually	O
much	O
faster	O
then	O
iteration	O
through	O
rows	O
.	O

#CODE	O

I	O
have	O
tried	O
using	O
`	O
pd.cut	B-API
`	O
or	O
`	O
np.digitize	B-API
`	O
with	O
different	O
combinations	O
of	O
`	O
map	O
`	O
,	O
`	O
apply	O
`	O
,	O
but	O
without	O
success	O
.	O

This	O
is	O
a	O
good	O
candidate	O
for	O
.apply	B-API
.	O

You	O
can	O
do	O
this	O
in	O
the	O
same	O
line	O
where	O
you	O
compute	O
column	O
values	O
by	O
putting	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
/	O
np.timedelta64	O
(	O
1	O
,	O
'	O
D	O
'))	O
at	O
the	O
end	O
to	O
apply	O
the	O
conversion	O
at	O
the	O
column	O
level	O
.	O

e.g.	O
s3	O
=(	O
s1-s2	O
)	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
/	O
np.timedelta64	O
(	O
1	O
,	O
'	O
D	O
'))	O
.	O

I	O
understand	O
now	O
the	O
source	O
for	O
most	O
of	O
my	O
problems	O
using	O
groupby	B-API
.	O

To	O
my	O
taste	O
,	O
the	O
groupby	B-API
mechanism	O
is	O
logically	O
too	O
ambiguous	O
and	O
the	O
design	O
encourages	O
the	O
user	O
to	O
use	O
it	O
in	O
the	O
wrong	O
why	O
.	O

The	O
way	O
I	O
saw	O
this	O
,	O
the	O
whole	O
idea	O
behinds	O
data	O
analysis	O
with	O
pandas	O
is	O
to	O
group	O
and	O
apply	O
.	O

I	O
thought	O
grouping	O
is	O
the	O
most	O
expensive	O
task	O
,	O
so	O
I	O
imagined	O
the	O
proper	O
use	O
would	O
be	O
to	O
group	O
only	O
once	O
,	O
and	O
then	O
do	O
what	O
ever	O
you	O
want	O
with	O
the	O
groups	O
.	O
as	O
long	O
as	O
the	O
group	O
members	O
dont	O
change	O
,	O
you	O
shouldn't	O
regroup	O
a	O
dataframe	B-API
.	O

This	O
idea	O
is	O
also	O
implied	O
from	O
the	O
design	O
,	O
as	O
you	O
can	O
save	O
a	O
groupby	B-API
object	O
,	O
which	O
for	O
me	O
implies	O
that	O
the	O
author	O
of	O
pandas	O
wanted	O
as	O
to	O
create	O
a	O
groupby	B-API
object	O
only	O
once	O
.	O

If	O
Im	O
right	O
,	O
the	O
linkage	O
between	O
a	O
groupby	B-API
element	O
to	O
a	O
dataframe	B-API
is	O
quite	O
weak	O
,	O
and	O
the	O
results	O
of	O
several	O
dataframe	B-API
modifications	O
and	O
groupby	B-API
operations	O
cannot	O
be	O
fully	O
anticipated	O
.	O

So	O
what	O
is	O
the	O
solution	O
?	O

running	O
groupby	B-API
for	O
each	O
and	O
every	O
apply	O
operation	O
?	O
that	O
seems	O
redundant	O
..	O

You	O
just	O
need	O
to	O
return	O
the	O
frame	O
in	O
your	O
function	O
.	O

Apply	O
takes	O
the	O
output	O
of	O
the	O
function	O
and	O
creates	O
a	O
new	O
frame	O
(	O
of	O
the	O
applied	O
data	O
);	O
if	O
you	O
return	O
`	O
None	O
`	O
in	O
your	O
function	O
then	O
it	O
uses	O
the	O
original	O
(	O
and	O
if	O
you	O
don't	O
return	O
a	O
value	O
,	O
then	O
you	O
are	O
implicity	O
returning	O
`	O
None	O
`)	O
#CODE	O

Sorry	O
,	O
didn't	O
get	O
it	O
completely	O
..	O
what	O
do	O
you	O
mean	O
by	O
"	O
if	O
you	O
return	O
NONE	O
n	O
your	O
function	O
then	O
it	O
uses	O
the	O
original	O
"	O
you	O
mean	O
that	O
the	O
underlying	O
dataframe	B-API
is	O
determined	O
according	O
to	O
my	O
apply	O
function	O
returning	O
or	O
not	O
returning	O
a	O
value	O
?	O

Im	O
still	O
confused	O
about	O
what	O
going	O
on	O
under	O
the	O
hood	O
here	O
.	O

I	O
thought	O
that	O
a	O
groupby	B-API
object	O
simply	O
holds	O
the	O
index	O
of	O
all	O
gruop	O
and	O
their	O
members	O
.	O
but	O
this	O
is	O
clearly	O
not	O
so	O
.	O

So	O
what	O
,	O
groupby	B-API
object	O
holds	O
a	O
copy	O
of	O
the	O
original	O
dataframe	B-API
?	O

Please	O
elaborate	O
more	O
and	O
be	O
more	O
clear	O
..	O

also	O
,	O
this	O
implies	O
regrouping	O
the	O
dataframe	B-API
for	O
each	O
apply	O
operation	O
,	O
which	O
can	O
be	O
expensive	O
and	O
redundent	O
(	O
see	O
my	O
edits	O
..	O
)	O

Maybe	O
you	O
can	O
explain	O
in	O
a	O
simple	O
example	O
what	O
your	O
problem	O
is	O
.	O

Optimizing	O
is	O
often	O
the	O
last	O
step	O
.	O

Make	O
sure	O
you	O
have	O
correctness	O
first	O
.	O

Profile	O
,	O
THEN	O
optimize	O
if	O
needed	O
.	O

Groupby	B-API
is	O
a	O
cheap	O
operation	O
;	O
the	O
apply	O
can	O
be	O
more	O
expensive	O
.	O

But	O
unless	O
you	O
have	O
LOTS	O
of	O
groups	O
this	O
shouldn't	O
matter	O
.	O

why	O
don't	O
you	O
group	O
by	O
both	O
columns	O
then	O
?	O

If	O
your	O
process	O
is	O
iterative	O
then	O
just	O
groupby	B-API
(	O
and	O
apply	O
after	O
each	O
iteration	O
)	O

I	O
was	O
writing	O
up	O
a	O
version	O
using	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
,	O
but	O
this	O
works	O
too	O
.	O

:	O
^	O
)	O

You	O
should	O
apply	O
your	O
function	O
along	O
the	O
axis=1	O
.	O

Function	O
will	O
receive	O
a	O
row	O
as	O
an	O
argument	O
,	O
and	O
anything	O
it	O
returns	O
will	O
be	O
collected	O
into	O
a	O
new	O
series	O
object	O
#CODE	O

As	O
for	O
the	O
second	O
part	O
of	O
the	O
question	O
:	O
row	O
wise	O
operations	O
,	O
even	O
optimised	O
ones	O
,	O
using	O
pandas	O
`	O
apply	O
`	O
,	O
are	O
not	O
the	O
fastest	O
solution	O
there	O
is	O
.	O

They	O
are	O
certainly	O
a	O
lot	O
faster	O
than	O
a	O
python	O
for	O
loop	O
,	O
but	O
not	O
the	O
fastest	O
.	O

You	O
can	O
test	O
that	O
by	O
timing	O
operations	O
and	O
you'll	O
see	O
the	O
difference	O
.	O

Some	O
operation	O
could	O
be	O
converted	O
to	O
column	O
oriented	O
ones	O
(	O
one	O
in	O
my	O
example	O
could	O
be	O
easily	O
converted	O
to	O
just	O
`	O
df	O
[	O
'	O
a	O
']	O
+	O
df	O
[	O
'	O
b	O
']`)	O
,	O
but	O
others	O
cannot	O
.	O

Especially	O
if	O
you	O
have	O
a	O
lot	O
of	O
branching	O
,	O
special	O
cases	O
or	O
other	O
logic	O
that	O
should	O
be	O
perform	O
on	O
your	O
row	O
.	O

In	O
that	O
case	O
,	O
if	O
the	O
`	O
apply	O
`	O
is	O
too	O
slow	O
for	O
you	O
,	O
I	O
would	O
suggest	O
"	O
Cython-izing	O
"	O
your	O
code	O
.	O

Cython	O
plays	O
really	O
nicely	O
with	O
the	O
NumPy	O
C	O
api	O
and	O
will	O
give	O
you	O
the	O
maximal	O
speed	O
you	O
can	O
achieve	O
.	O

@USER	O
I	O
saw	O
that	O
you	O
rarely	O
use	O
apply	O
along	O
`	O
axis=1	O
`	O
.	O

Is	O
there	O
any	O
specific	O
performance	O
reason	O
?	O

Shouldn't	O
that	O
be	O
the	O
fastest	O
way	O
to	O
itterate	O
over	O
the	O
array	O
row	O
wise	O
?	O

Well	O
,	O
I	O
thought	O
about	O
something	O
similar	O
to	O
your	O
solution	O
,	O
however	O
I	O
didn't	O
pursue	O
it	O
further	O
because	O
I	O
want	O
to	O
apply	O
it	O
to	O
millions	O
of	O
rows	O
,	O
so	O
I'm	O
afraid	O
this	O
won't	O
scale	O
well	O
.	O

Wonder	O
if	O
there	O
should	O
be	O
a	O
native	O
way	O
to	O
do	O
apply	O
across	O
multiple	O
dataframes	O
...	O

and	O
I	O
want	O
to	O
apply	O
a	O
function	O
which	O
uses	O
the	O
index	O
of	O
the	O
row	O
:	O
#CODE	O

I	O
don't	O
believe	O
`	O
apply	O
`	O
has	O
access	O
to	O
the	O
index	O
;	O
it	O
treats	O
each	O
row	O
as	O
a	O
numpy	O
object	O
,	O
not	O
a	O
Series	O
,	O
as	O
you	O
can	O
see	O
:	O
#CODE	O

To	O
get	O
around	O
this	O
limitation	O
,	O
promote	O
the	O
indexes	O
to	O
columns	O
,	O
apply	O
your	O
function	O
,	O
and	O
recreate	O
a	O
Series	O
with	O
the	O
original	O
index	O
.	O

#CODE	O

In	O
my	O
case	O
(	O
a	O
dataframe	B-API
,	O
with	O
axis=1	O
)	O
,	O
x.name()	O
returns	O
the	O
value	O
of	O
the	O
index	O
when	O
I	O
apply	O
a	O
function	O
lambda	O
x	O
:	O
x	O
...	O

so	O
when	O
calling	O
`	O
apply	O
`	O
on	O
`	O
DataFrame	B-API
`	O
its	O
index	O
will	O
be	O
accessible	O
through	O
`	O
name	O
`	O
of	O
each	O
series	O
?	O

I	O
see	O
this	O
also	O
is	O
true	O
for	O
`	O
DateTimeIndex	B-API
`	O
but	O
it	O
is	O
a	O
little	O
weird	O
to	O
use	O
something	O
similar	O
to	O
`	O
x.name	O
==	O
Time	O
(	O
2015-06-27	O
20:08	O
:	O
32.097333	O
+	O
00:00	O
)`	O

You	O
may	O
find	O
it	O
faster	O
to	O
use	O
`	O
where	O
`	O
rather	O
than	O
`	O
apply	O
`	O
here	O
:	O
#CODE	O

I	O
recommend	O
testing	O
for	O
speed	O
(	O
as	O
efficiency	O
against	O
apply	O
will	O
depend	O
on	O
the	O
function	O
)	O
.	O

Although	O
,	O
I	O
find	O
that	O
`	O
apply	O
`	O
s	O
are	O
more	O
readable	O
...	O

Excellent	O
point	O
,	O
did	O
not	O
think	O
about	O
that	O
!	O

There	O
is	O
filter	O
I	O
apply	O
that	O
filters	O
out	O
about	O
90%	O
of	O
the	O
data	O
.	O

(	O
However	O
the	O
rest	O
of	O
the	O
calculations	O
have	O
to	O
be	O
done	O
over	O
the	O
concatenated	O
DataFrame	B-API
.	O
)	O
Thanks	O
a	O
lot	O
!	O

I	O
guess	O
I	O
could	O
write	O
a	O
function	O
using	O
`	O
try	O
`	O
and	O
then	O
use	O
pandas	O
`	O
apply	O
`	O
or	O
`	O
map	O
`	O
,	O
but	O
that	O
seems	O
like	O
an	O
inelegant	O
solution	O
.	O

This	O
must	O
be	O
a	O
fairly	O
common	O
problem	O
,	O
right	O
?	O

In	O
fact	O
,	O
you	O
can	O
apply	O
this	O
to	O
the	O
entire	O
DataFrame	B-API
:	O
#CODE	O

If	O
you	O
really	O
wanted	O
to	O
do	O
this	O
you	O
could	O
use	O
a	O
groupby	B-API
apply	O
:	O
#CODE	O

and	O
apply	O
the	O
function	O
to	O
each	O
group	O
,	O
and	O
then	O
`	O
unstack	O
`	O
from	O
a	O
Series	O
to	O
a	O
DataFrame	B-API
:	O
#CODE	O

@USER	O
Not	O
sure	O
I	O
do	O
fully	O
either	O
,	O
I	O
think	O
I	O
should	O
probably	O
put	O
it	O
up	O
as	O
an	O
issue	O
on	O
github	O
to	O
discuss	O
/	O
fix	O
,	O
suspect	O
it	O
is	O
untested	O
behaviour	O
,	O
but	O
it	O
seemed	O
that	O
you	O
can	O
only	O
apply	O
aggfunc	O
to	O
columns	O
which	O
were	O
going	O
to	O
be	O
in	O
your	O
pivot_table	B-API
(	O
IIRC	O
the	O
rest	O
are	O
not	O
passed	O
to	O
the	O
function	O
so	O
couldn't	O
be	O
used	O
)	O
,	O
also	O
I	O
was	O
seeing	O
SNDArrays	O
which	O
was	O
confusing	O
...	O

I	O
need	O
to	O
investigate	O
a	O
further	O
.	O

Thanks	O
!	O

what	O
if	O
you	O
don't	O
want	O
to	O
apply	O
a	O
rolling	O
mean	O
but	O
an	O
arbitrary	O
function	O
in	O
rolling	O
overlapped	O
windows	O
?	O

Assuming	O
you	O
have	O
indexed	O
by	O
datetime	O
can	O
use	O
groupby	B-API
apply	O
:	O
#CODE	O

It's	O
also	O
present	O
in	O
apply	O
though	O
(	O
with	O
both	O
our	O
answers	O
)	O
.	O

?	O

(	O
see	O
also	O
Pandas	O
:	O
How	O
to	O
use	O
apply	O
function	O
to	O
multiple	O
columns	O
)	O
.	O

This	O
means	O
you	O
can	O
invert	O
np.percentile	B-API
using	O
map	O
,	O
and	O
then	O
apply	O
a	O
shift	O
and	O
a	O
subtract	O
to	O
get	O
the	O
"	O
percentage	O
if	O
array	O
in	O
interval	O
"	O
you're	O
after	O
.	O

It	O
feels	O
like	O
there	O
ought	O
to	O
be	O
a	O
neat	O
way	O
using	O
stack	O
(	O
essentially	O
separating	O
into	O
away	O
/	O
home	O
,	O
enabling	O
a	O
groupby	B-API
apply	O
)	O
.	O

Create	O
a	O
`	O
defualtdict	O
`	O
(	O
with	O
default	O
value	O
0	O
)	O
where	O
you	O
will	O
keep	O
the	O
current	O
scores	O
of	O
the	O
teams	O
,	O
and	O
apply	O
along	O
the	O
`	O
axis=1	O
`	O
a	O
function	O
that	O
updates	O
this	O
dictionary	O
and	O
returns	O
a	O
tuple	O
of	O
results	O
.	O

Then	O
just	O
concatenate	O
your	O
DataFrame	B-API
and	O
the	O
resulting	O
DataFrame	B-API
from	O
the	O
`	O
apply	O
`	O
function	O
along	O
`	O
axis=1	O
`	O
.	O

#CODE	O

stack	O
/	O
groupby	B-API
/	O
apply	O
is	O
*	O
significantly	O
*	O
faster	O
than	O
this	O
method	O
(	O
once	O
there's	O
more	O
than	O
40	O
or	O
so	O
rows	O
)	O
!	O

@USER	O
how	O
is	O
it	O
independent	O
when	O
in	O
one	O
case	O
it	O
takes	O
32x	O
more	O
memory	O
and	O
in	O
the	O
other	O
it	O
takes	O
only	O
4x	O
more	O
memory	O
?	O

And	O
the	O
global	O
can	O
be	O
passed	O
as	O
an	O
argument	O
to	O
apply	O
,	O
but	O
that	O
is	O
not	O
the	O
an	O
issue	O
:)	O

You	O
could	O
use	O
`	O
pd.to_numeric	B-API
`	O
method	O
and	O
apply	O
it	O
for	O
the	O
dataframe	B-API
with	O
arg	O
'	O
coerce	O
'	O
.	O

#CODE	O

If	O
your	O
final	O
game	O
plan	O
involves	O
doing	O
on	O
of	O
these	O
...	O
just	O
use	O
these	O
.	O

If	O
it's	O
something	O
else	O
,	O
consider	O
writing	O
it	O
as	O
a	O
generic	O
rolling	O
apply	O
.	O

You	O
can	O
simply	O
use	O
an	O
`	O
apply	O
`	O
to	O
do	O
this	O
:	O
#CODE	O

I	O
am	O
trying	O
to	O
transform	O
the	O
data	O
points	O
in	O
a	O
DataFrame	B-API
to	O
a	O
two	O
dimensional	O
array	O
group	O
by	O
group	O
and	O
then	O
transform	O
the	O
same	O
data	O
to	O
a	O
different	O
one	O
dimensional	O
array	O
.	O

For	O
example	O
,	O
the	O
two	O
dimensional	O
array	O
can	O
be	O
the	O
independent	O
variables	O
of	O
a	O
regression	O
while	O
the	O
one	O
dimensional	O
array	O
can	O
be	O
the	O
dependent	O
variable	O
.	O

I	O
could	O
have	O
written	O
two	O
functions	O
,	O
one	O
for	O
each	O
array	O
,	O
and	O
apply	O
them	O
separately	O
,	O
but	O
that	O
would	O
be	O
very	O
slow	O
.	O

So	O
traverse	O
the	O
data	O
once	O
and	O
generate	O
both	O
arrays	O
would	O
be	O
preferred	O
.	O

You	O
don't	O
need	O
to	O
use	O
apply	O
here	O
,	O
and	O
unless	O
you	O
are	O
using	O
a	O
cythonized	O
function	O
which	O
can	O
operate	O
on	O
a	O
frame	O
/	O
series	O
,	O
it	O
doesn't	O
make	O
any	O
difference	O
in	O
perf	O
.	O

I'm	O
working	O
on	O
replacing	O
an	O
Excel	O
financial	O
model	O
into	O
Python	O
Pandas	O
.	O

By	O
financial	O
model	O
I	O
mean	O
forecasting	O
a	O
cash	O
flow	O
,	O
profit	O
loss	O
statement	O
and	O
balance	O
sheet	O
over	O
time	O
for	O
a	O
business	O
venture	O
as	O
opposed	O
to	O
pricing	O
swaps	O
/	O
options	O
or	O
working	O
with	O
stock	O
price	O
data	O
that	O
are	O
also	O
referred	O
to	O
as	O
financial	O
models	O
.	O

It's	O
quite	O
possible	O
that	O
the	O
same	O
concepts	O
and	O
issues	O
apply	O
to	O
the	O
latter	O
types	O
I	O
just	O
don't	O
know	O
them	O
that	O
well	O
so	O
can't	O
comment	O
.	O

If	O
not	O
,	O
could	O
you	O
suggest	O
how	O
to	O
modify	O
Pandas	O
in	O
order	O
to	O
provide	O
irregular	O
duration	O
`	O
Period	O
`	O
objects	O
?	O

(	O
this	O
comment	O
suggests	O
that	O
it	O
might	O
be	O
possible	O
"	O
using	O
custom	O
DateOffset	O
classes	O
with	O
appropriately	O
crafted	O
onOffset	O
,	O
rollforward	O
,	O
rollback	O
,	O
and	O
apply	O
methods	O
")	O

Since	O
i	O
tried	O
tu	O
find	O
the	O
prediction	O
values	O
of	O
my	O
variables	O
...	O

For	O
that	O
,	O
i'm	O
developping	O
this	O
code	O
and	O
i	O
tried	O
to	O
apply	O
what	O
i	O
found	O
in	O
this	O
link	O
#URL	O

The	O
`	O
apply	O
`	O
method	O
applies	O
a	O
function	O
to	O
each	O
of	O
the	O
aforementioned	O
subsets	O
and	O
concatenates	O
the	O
result	O
(	O
if	O
needed	O
)	O
.	O

One	O
thing	O
to	O
note	O
is	O
my	O
use	O
of	O
`	O
g.name	O
`	O
.	O

This	O
doesn't	O
normally	O
exist	O
as	O
an	O
attribute	O
on	O
`	O
DataFrame	B-API
`	O
s	O
(	O
you	O
can	O
of	O
course	O
define	O
it	O
yourself	O
if	O
you	O
want	O
to	O
)	O
,	O
but	O
is	O
there	O
so	O
you	O
can	O
perform	O
computations	O
that	O
may	O
require	O
the	O
group	O
name	O
.	O

In	O
this	O
case	O
that's	O
the	O
"	O
current	O
"	O
fruit	O
you're	O
looking	O
at	O
when	O
you	O
apply	O
your	O
function	O
.	O

When	O
I	O
apply	O
the	O
below	O
code	O
pandas	O
is	O
considering	O
NaN	O
as	O
Zero	O
and	O
returing	O
the	O
sum	O
of	O
remaining	O
days	O
.	O

#CODE	O

You	O
are	O
looking	O
for	O
apply	O
.	O

Your	O
example	O
would	O
look	O
like	O
this	O
:	O
#CODE	O

Apply	O
function	O
to	O
values	O
and	O
index	O
of	O
series	O

I	O
like	O
the	O
idea	O
and	O
is	O
along	O
the	O
lines	O
of	O
what	O
I	O
was	O
thinking	O
about	O
.	O

The	O
trouble	O
is	O
I	O
can't	O
make	O
it	O
work	O
,	O
if	O
I	O
apply	O
your	O
exact	O
code	O
(	O
plus	O
my	O
def	O
of	O
dates	O
)	O
I	O
get	O
a	O
Type	O
Error	O
:	O
`	O
TypeError	O
:	O
(	O
"	O
unsupported	O
operand	O
type	O
(	O
s	O
)	O
for	O
/:	O
'	O
buffer	O
'	O
and	O
'	O
int	O
'"	O
,	O
u'occurred	O
at	O
index	O
2012-04-01	O
00:00	O
:	O
00	O
')`	O

And	O
you	O
/	O
are	O
working	O
on	O
a	O
`	O
DataFrame	B-API
`	O
object	O
inside	O
of	O
`	O
apply	O
`	O
indeed	O
.	O

Actually	O
inside	O
`	O
apply	O
`	O
we	O
seem	O
to	O
be	O
working	O
with	O
a	O
`	O
Series	O
`	O
object	O
,	O
the	O
name	O
of	O
which	O
is	O
the	O
index	O
of	O
the	O
`	O
DataFrame	B-API
`	O
we're	O
iterating	O
through	O
.	O

This	O
is	O
why	O
your	O
name	O
suggestion	O
works	O
for	O
accessing	O
the	O
value	O
of	O
the	O
index	O
.	O

It	O
seems	O
`	O
apply	O
`	O
collapses	O
a	O
"	O
dimension	O
"	O
of	O
the	O
initiating	O
object	O
so	O
this	O
is	O
why	O
working	O
on	O
a	O
`	O
TimeSeries	O
`	O
directly	O
only	O
left	O
me	O
with	O
a	O
value	O
object	O
and	O
no	O
way	O
to	O
access	O
the	O
value	O
of	O
the	O
index	O
.	O

Not	O
a	O
perfect	O
solution	O
then	O
but	O
def	O
better	O
than	O
where	O
I	O
was	O
.	O

Thanks	O
again	O
for	O
all	O
the	O
help	O
.	O

That	O
doesn't	O
work	O
(	O
although	O
it	O
looks	O
like	O
it	O
should	O
!	O
)	O
.	O

When	O
I	O
apply	O
your	O
solution	O
I	O
get	O
`	O
s	O
`	O
where	O
`	O
s.index.month	O
%	O
3	O
==	O
1	O
`	O
and	O
`	O
s	O
/	O
4	O
`	O
where	O
`	O
s.index.month	O
%	O
3	O
!	O

=	O
1	O
`	O
;	O
I	O
wanted	O
`	O
s	O
/	O
4	O
`	O
and	O
`	O
0	O
`	O
respectively	O

Just	O
use	O
the	O
`	O
apply	O
`	O
function	O
along	O
the	O
`	O
axis=1	O
`	O
and	O
pass	O
the	O
`	O
pattern	O
`	O
parameter	O
as	O
an	O
additional	O
argument	O
to	O
the	O
function	O
.	O

#CODE	O

Like	O
regexp	O
;)	O
I	O
agree	O
,	O
I	O
just	O
always	O
give	O
the	O
simplest	O
,	O
predictable	O
in	O
speed	O
solution	O
to	O
the	O
OP	O
,	O
and	O
live	O
the	O
exotic	O
ones	O
to	O
you	O
:)	O
`	O
apply	O
`	O
should	O
always	O
be	O
`	O
O	O
(	O
N	O
)`	O
if	O
I'm	O
not	O
wrong	O
.	O

I	O
don't	O
even	O
know	O
how	O
to	O
calculate	O
how	O
`	O
melt	B-API
`	O
with	O
`	O
groupby	B-API
`	O
behaves	O
?	O

`	O
O	O
(	O
?	O
)`	O

Just	O
apply	O
the	O
Timestamp	O
`	O
time	O
`	O
method	O
to	O
items	O
in	O
the	O
date	O
column	O
:	O
#CODE	O

Using	O
the	O
method	O
Andy	O
created	O
on	O
Index	O
is	O
faster	O
than	O
apply	O
#CODE	O

And	O
then	O
apply	O
the	O
function	O
along	O
the	O
`	O
axis=1	O
`	O
.	O

#CODE	O

Now	O
`	O
apply	O
`	O
needs	O
to	O
return	O
a	O
`	O
Series	O
`	O
,	O
not	O
a	O
`	O
DataFrame	B-API
`	O
.	O

One	O
way	O
to	O
turn	O
a	O
`	O
DataFrame	B-API
`	O
into	O
a	O
`	O
Series	O
`	O
is	O
to	O
use	O
`	O
stack	O
`	O
.	O

Look	O
at	O
what	O
happens	O
if	O
we	O

Wow	O
,	O
awesome	O
walkthrough	O
!	O

`	O
apply	O
`	O
is	O
now	O
among	O
my	O
top	O
5	O
functions	O
to	O
always	O
remember	O
.	O

Concerning	O
the	O
`	O
pivot_table	B-API
`	O
solution	O
:	O
At	O
which	O
point	O
am	O
I	O
supposed	O
to	O
enter	O
the	O
line	O
?	O

No	O
matter	O
when	O
in	O
my	O
attempt	O
above	O
,	O
I	O
always	O
get	O
`	O
no	O
item	O
named	O
Edge	O
`	O
.	O

I	O
would	O
like	O
to	O
divide	O
my	O
data	O
table	O
called	O
(	O
my_data2	O
)	O
in	O
two	O
samples	O
called	O
(	O
learning	O
sample	O
and	O
test	O
sample	O
)	O
.	O

How	O
to	O
apply	O
the	O
logistic	O
regression	O
on	O
the	O
first	O
part	O
of	O
my	O
table	O
(	O
the	O
first	O
sample	O
)	O
,	O
then	O
apply	O
predict	O
on	O
the	O
second	O
part	O
?	O

Thank	O
you	O
.	O

One	O
solution	O
could	O
be	O
to	O
use	O
get	O
dummies	O
(	O
which	O
should	O
be	O
more	O
efficient	O
that	O
apply	O
):	O
#CODE	O

You	O
could	O
use	O
an	O
apply	O
with	O
a	O
couple	O
of	O
locs	O
:	O
#CODE	O

You	O
can	O
apply	O
to_json	B-API
to	O
any	O
DataFrame	B-API
:	O
#CODE	O

you	O
can	O
what	O
I	O
do	O
in	O
the	O
apply	O
,	O
its	O
operating	O
on	O
the	O
numpy	O
arrays	O
directly	O
.	O

I	O
don't	O
think	O
readsav	O
can	O
do	O
this	O
conversion	O
.	O

I	O
tried	O
to	O
make	O
this	O
algorithm	O
:	O
random	O
draw	O
between	O
0	O
and	O
1	O
(	O
tir	O
)	O
.si	O
tir	O
'	O
'	O
pred	O
then	O
Xestime2=	O
1	O
else	O
Xestime2=0	O
.	O

I	O
wish	O
apply	O
this	O
algorithm	O
in	O
df	O
[	O
'	O
X3	O
']	O
but	O
I	O
had	O
0	O
in	O
all	O
the	O
values	O
??	O
of	O
X3	O
columns	O
.	O

Which	O
explains	O
thats	O
i	O
have	O
an	O
error	O
in	O
my	O
code	O
.	O

I	O
understand	O
your	O
code	O
but	O
when	O
I	O
try	O
to	O
apply	O
it	O
to	O
my	O
code	O
it	O
does	O
not	O
work	O
!!	O

I	O
tried	O
to	O
apply	O
what	O
you	O
made	O
but	O
i	O
have	O
an	O
error	O
!!	O

My	O
coding	O

I'm	O
hoping	O
there's	O
something	O
I've	O
overlooked	O
in	O
the	O
pandas	O
library	O
/	O
documentation	O
that	O
allows	O
one	O
to	O
know	O
the	O
progress	O
of	O
a	O
split-apply-combine	O
.	O

A	O
simple	O
implementation	O
would	O
maybe	O
look	O
at	O
the	O
total	O
number	O
of	O
data	O
frame	O
subsets	O
upon	O
which	O
the	O
`	O
apply	O
`	O
function	O
is	O
working	O
and	O
report	O
progress	O
as	O
the	O
completed	O
fraction	O
of	O
those	O
subsets	O
.	O

have	O
u	O
done	O
a	O
%prun	O
(	O
profile	O
)	O
on	O
the	O
code	O
?	O

sometimes	O
you	O
can	O
do	O
operations	O
on	O
the	O
whole	O
frame	O
before	O
you	O
apply	O
to	O
eliminate	O
bottlenecks	O

I	O
did	O
the	O
above	O
in	O
my	O
answer	O
,	O
also	O
cheeky	O
percentage	O
update	O
.	O

Actually	O
I	O
couldn't	O
get	O
yours	O
working	O
...	O

I	O
think	O
with	O
the	O
wraps	O
bit	O
.	O

If	O
your	O
using	O
it	O
for	O
the	O
apply	O
it's	O
not	O
so	O
important	O
anyway	O
.	O

Note	O
:	O
the	O
apply	O
progress	O
percentage	O
updates	O
inline	O
.	O

If	O
your	O
function	O
stdouts	O
then	O
this	O
won't	O
work	O
.	O

#CODE	O

@USER	O
DataFrame's	O
apply	O
is	O
row-wise	O
so	O
I	O
don't	O
*	O
think	O
*	O
dropna	B-API
can	O
be	O
written	O
in	O
terms	O
of	O
apply	O
(	O
needed	O
to	O
use	O
this	O
answer	O
)	O
.	O

Also	O
,	O
dropna	B-API
is	O
written	O
in	O
cython	O
(	O
not	O
pure	O
python	O
)	O
so	O
doing	O
something	O
like	O
this	O
will	O
be	O
much	O
slower	O
.	O

I	O
came	O
across	O
what	O
looks	O
like	O
the	O
perfect	O
solution	O
on	O
another	O
SO	O
answer	O
(	O
#URL	O
)	O
but	O
when	O
trying	O
to	O
apply	O
to	O
this	O
series	O
,	O
I'm	O
getting	O
an	O
exception	O
:	O
#CODE	O

I	O
really	O
want	O
to	O
be	O
able	O
to	O
apply	O
the	O
changes	O
within	O
the	O
dataframe	B-API
to	O
apply	O
and	O
reapply	O
groupby	B-API
conditions	O
and	O
perform	O
the	O
plots	O
efficiently	O
-	O
and	O
would	O
love	O
to	O
learn	O
more	O
about	O
how	O
the	O
.apply()	B-API
method	O
works	O
.	O

As	O
far	O
as	O
the	O
`	O
apply	O
`	O
method	O
goes	O
,	O
it	O
does	O
slightly	O
different	O
things	O
for	O
different	O
objects	O
.	O

For	O
example	O
,	O
`	O
DataFrame.apply()	B-API
`	O
will	O
apply	O
the	O
passed	O
in	O
callable	O
across	O
the	O
columns	O
by	O
default	O
,	O
but	O
you	O
can	O
pass	O
`	O
axis=1	O
`	O
to	O
apply	O
it	O
along	O
the	O
rows	O
.	O

You	O
can	O
reproduce	O
it	O
with	O
dupes	O
in	O
the	O
findall	B-API
(	O
see	O
my	O
answer	O
)	O
,	O
I	O
think	O
Jeff's	O
apply	O
solution	O
should	O
work	O
fine	O
with	O
dupes	O
in	O
the	O
DatetimeIndex	B-API
.	O

Thanks	O
@USER	O
-	O
your	O
answer	O
did	O
help	O
remove	O
my	O
confusion	O
around	O
the	O
duplicate	O
index	O
,	O
as	O
I	O
know	O
that	O
a	O
pandas	O
index	O
will	O
take	O
duplicates	O
in	O
the	O
index	O
,	O
so	O
I	O
now	O
understand	O
it's	O
the	O
index	O
within	O
the	O
.apply()	B-API
that	O
was	O
kicking	O
out	O
the	O
error	O
.	O

Your	O
explanation	O
of	O
how	O
apply	O
works	O
as	O
well	O
is	O
really	O
useful	O
,	O
so	O
even	O
though	O
it's	O
not	O
a	O
solution	O
to	O
the	O
original	O
question	O
it's	O
really	O
appreciated	O
.	O

If	O
you	O
try	O
to	O
return	O
multiple	O
values	O
from	O
the	O
function	O
that	O
is	O
passed	O
to	O
`	O
apply	O
`	O
,	O
and	O
the	O
DataFrame	B-API
you	O
call	O
the	O
`	O
apply	O
`	O
on	O
has	O
the	O
same	O
number	O
of	O
item	O
along	O
the	O
axis	O
(	O
in	O
this	O
case	O
columns	O
)	O
as	O
the	O
number	O
of	O
values	O
you	O
returned	O
,	O
Pandas	O
will	O
create	O
a	O
DataFrame	B-API
from	O
the	O
return	O
values	O
with	O
the	O
same	O
labels	O
as	O
the	O
original	O
DataFrame	B-API
.	O

You	O
can	O
see	O
this	O
if	O
you	O
just	O
do	O
:	O
#CODE	O

To	O
fix	O
the	O
index	O
,	O
you	O
could	O
just	O
add	O
the	O
X	O
as	O
this	O
index	O
,	O
you	O
could	O
first	O
apply	O
set_index	B-API
:	O
#CODE	O

If	O
you	O
want	O
to	O
preserve	O
some	O
of	O
the	O
original	O
timestamps	O
(	O
but	O
you	O
have	O
to	O
choose	O
which	O
if	O
you	O
are	O
binning	O
them	O
)	O
,	O
you	O
can	O
specify	O
a	O
function	O
to	O
apply	O
on	O
the	O
individual	O
columns	O
.	O

For	O
example	O
take	O
the	O
first	O
:	O
#CODE	O

`	O
as_index	O
`	O
and	O
`	O
apply	O
`	O
will	O
only	O
work	O
on	O
pandas	O
git	O
master	O
.	O

If	O
you're	O
not	O
using	O
master	O
,	O
then	O
you'll	O
get	O
the	O
following	O
:	O
#CODE	O

How	O
to	O
apply	O
a	O
complex	O
formula	O
using	O
Pandas	O
in	O
Python	O
?	O

I	O
need	O
to	O
apply	O
a	O
specially	O
designed	O
moving	O
average	O
filter	O
on	O
a	O
traffic	O
dataset	O
(	O
NGSim	O
)	O
.	O

This	O
process	O
is	O
very	O
tedious	O
in	O
Excel	O
not	O
only	O
because	O
dataset	O
is	O
very	O
large	O
but	O
also	O
because	O
the	O
formula	O
has	O
to	O
look	O
into	O
columns	O
for	O
getting	O
some	O
values	O
and	O
sum	O
them	O
up	O
.	O

I	O
was	O
wondering	O
if	O
there	O
are	O
any	O
examples	O
like	O
this	O
or	O
any	O
other	O
complicated	O
formulas	O
used	O
in	O
Pandas	O
,	O
Python	O
.	O

Kindly	O
provide	O
any	O
example	O
resources	O
.	O

Apply	O
per-column	O
the	O
mean	O
of	O
that	O
columns	O
and	O
fill	O
#CODE	O

hmmm	O
,	O
apologies	O
for	O
being	O
a	O
novice	O
at	O
this	O
,	O
but	O
I	O
can't	O
figure	O
it	O
out	O
.	O

I	O
can	O
get	O
the	O
'	O
or	O
'	O
logic	O
to	O
work	O
using	O
numpy	O
comparison	O
functions	O
,	O
but	O
ultimately	O
the	O
logic	O
I	O
need	O
is	O
not	O
'	O
or	O
'	O
...	O

I'm	O
trying	O
to	O
apply	O
a	O
case-statement-like	O
function	O
element	O
wise	O
that	O
works	O
on	O
groups	O
:	O
if	O
element	O
above	O
1.2	O
*	O
group_median	O
,	O
then	O
assign	O
'	O
h	O
'	O
,	O
if	O
it's	O
below	O
.8	O
*group_median	O
,	O
then	O
assign	O
'	O
l	O
'	O
,	O
the	O
third	O
logical	O
possibility	O
(	O
it's	O
within	O
.2	O
of	O
the	O
group	O
median	O
)	O
is	O
ignored	O
or	O
assigned	O
'	O
n	O
'	O
.	O

Any	O
thoughts	O
?	O

To	O
expand	O
a	O
little	O
on	O
what's	O
going	O
on	O
here	O
,	O
during	O
the	O
apply	O
the	O
function	O
is	O
called	O
on	O
each	O
group	O
(	O
in	O
this	O
case	O
there	O
are	O
two	O
,	O
one	O
for	O
B=	O
'	O
c	O
'	O
and	O
one	O
for	O
B=	O
'	O
d	O
')	O
,	O
here's	O
the	O
c	O
group	O
:	O
#CODE	O

Apply	O
then	O
outputs	O
this	O
together	O
with	O
the	O
B=	O
'	O
d	O
'	O
group	O
to	O
get	O
the	O
desired	O
result	O
.	O

You	O
could	O
groupby	B-API
person	O
and	O
then	O
apply	O
a	O
shift	O
to	O
the	O
values	O
:	O
#CODE	O

You	O
can	O
apply	O
`	O
value_counts	B-API
`	O
to	O
the	O
Series	O
groupby	B-API
:	O
#CODE	O

It	O
seems	O
cool	O
,	O
and	O
an	O
approach	O
I	O
had	O
not	O
concieved	O
of	O
.	O

They	O
are	O
all	O
time	O
stamps	O
,	O
I'm	O
just	O
slow	O
on	O
the	O
uptake	O
,,	O
need	O
to	O
think	O
about	O
it	O
,	O
I'm	O
sure	O
you	O
are	O
right	O
I	O
just	O
need	O
to	O
catch	O
up	O
!	O

And	O
apply	O
the	O
code	O
,	O

You	O
could	O
reset_index	B-API
.	O

Also	O
,	O
perhaps	O
use	O
a	O
df.index.map	O
,	O
rather	O
than	O
apply	O
.	O

?	O

And	O
if	O
you	O
wan't	O
a	O
list	O
of	O
the	O
prices	O
per	O
day	O
then	O
just	O
do	O
a	O
groupby	B-API
per	O
day	O
and	O
return	O
the	O
list	O
of	O
all	O
the	O
prices	O
from	O
every	O
group	O
using	O
the	O
`	O
apply	O
`	O
on	O
the	O
grouped	O
object	O
:	O
#CODE	O

In	O
R	O
,	O
it	O
is	O
easy	O
to	O
aggregate	O
values	O
and	O
apply	O
a	O
function	O
(	O
in	O
this	O
case	O
,	O
`	O
sum	O
`)	O
#CODE	O

You	O
can	O
use	O
groupby	B-API
,	O
which	O
can	O
apply	O
a	O
function	O
to	O
the	O
index	O
values	O
(	O
in	O
this	O
case	O
looking	O
at	O
the	O
first	O
element	O
):	O
#CODE	O

I	O
want	O
to	O
group	O
by	O
the	O
columns	O
:	O
date	O
,	O
textA	O
and	O
textB	O
-	O
but	O
want	O
to	O
apply	O
"	O
sum	O
"	O
to	O
numberA	O
,	O
but	O
"	O
min	O
"	O
to	O
numberB	O
.	O

#CODE	O

...	O
but	O
I	O
cannot	O
see	O
how	O
to	O
then	O
apply	O
two	O
different	O
aggregate	O
functions	O
,	O
to	O
two	O
different	O
columns	O
?	O

You	O
can	O
apply	O
a	O
`	O
join	O
`	O
operation	O
between	O
your	O
original	O
dataframe	B-API
and	O
the	O
resulting	O
aggregated	O
data	O
:	O
#CODE	O

Now	O
that	O
we	O
have	O
the	O
grouping	O
,	O
we	O
can	O
apply	O
the	O
aggregator	O
:	O
#CODE	O

And	O
you	O
can	O
do	O
an	O
apply	O
over	O
the	O
major	O
axis	O
:	O
#CODE	O

Hmm	O
,	O
it	O
doesn't	O
look	O
like	O
this	O
lets	O
me	O
store	O
it	O
the	O
way	O
I	O
want	O
,	O
but	O
it	O
does	O
let	O
me	O
access	O
the	O
data	O
in	O
a	O
way	O
which	O
may	O
let	O
me	O
do	O
what	O
I	O
need	O
.	O

I	O
clearly	O
had	O
not	O
looked	O
close	O
enough	O
at	O
Panels	O
.	O

I	O
will	O
have	O
to	O
look	O
into	O
how	O
apply	O
more	O
carefully	O
,	O
I	O
don't	O
understand	O
why	O
you	O
would	O
have	O
the	O
function	O
return	O
1	O
.	O

Thanks	O
though	O
!	O

Hmm	O
,	O
well	O
trying	O
it	O
out	O
doesn't	O
quite	O
seem	O
to	O
do	O
what	O
I	O
want	O
.	O

The	O
return	O
value	O
needs	O
to	O
be	O
of	O
length	O
of	O
the	O
panel	O
,	O
where	O
if	O
I	O
want	O
to	O
operate	O
on	O
the	O
whole	O
array	O
to	O
compute	O
a	O
single	O
object	O
it	O
won't	O
let	O
me	O
return	O
that	O
.	O

Apply	O
doesn't	O
let	O
me	O
reduce	O
the	O
panel	O
.	O

For	O
example	O
as	O
a	O
test	O
I	O
wanted	O
to	O
apply	O
`	O
np.reshape	B-API
(	O
x	O
,	O
(	O
2	O
,	O
2	O
))`	O
on	O
a	O
panel	O
of	O
4	O
dfs	O
and	O
it	O
fails	O
.	O

I	O
guess	O
I	O
need	O
to	O
do	O
all	O
my	O
work	O
within	O
the	O
apply	O
,	O
and	O
flatten	O
it	O
back	O
out	O
.	O

This	O
has	O
me	O
on	O
the	O
right	O
track	O
now	O
I	O
think	O
so	O
thanks	O
again	O
.	O

So	O
then	O
I	O
tried	O
applying	O
with	O
axis=0	O
(	O
per	O
column	O
basis	O
)	O
and	O
modifying	O
the	O
function	O
so	O
it	O
only	O
applies	O
this	O
to	O
the	O
'	O
Date	O
'	O
column	O
(	O
I	O
can't	O
see	O
how	O
to	O
apply	O
this	O
to	O
just	O
one	O
column	O
)	O
#CODE	O

That	O
doesn't	O
work	O
because	O
the	O
empty	O
'	O
Date	O
'	O
values	O
are	O
not	O
'	O
NaN	O
'	O
they	O
are	O
empty	O
strings	O
.	O

Also	O
,	O
ideally	O
,	O
I	O
want	O
to	O
do	O
this	O
using	O
`	O
apply	O
`	O
as	O
there	O
are	O
other	O
things	O
I	O
want	O
to	O
do	O
within	O
that	O
function	O
which	O
I	O
removed	O
to	O
simplify	O
this	O
question	O
.	O

then	O
show	O
what	O
you	O
actually	O
want	O
;	O
this	O
is	O
the	O
efficient	O
way	O
of	O
doing	O
it	O
,	O
apply	O
is	O
essentially	O
a	O
loop	O
in	O
python	O
space	O

the	O
shift	O
index	O
looks	O
like	O
a	O
better	O
fix	O
,	O
still	O
would	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
date	O
add	O
function	O
,	O
which	O
is	O
how	O
I'd	O
do	O
it	O
in	O
sql	O
,	O
that	O
could	O
apply	O
?	O

I	O
see	O
that	O
,	O
and	O
I	O
like	O
it	O
..	O

I'd	O
still	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
DateAdd	O
type	O
function	O
that	O
I	O
could	O
use	O
that	O
might	O
also	O
apply	O
for	O
use	O
elsewhere	O
if	O
needed	O
?	O

Each	O
list	O
in	O
this	O
column	O
can	O
be	O
passed	O
to	O
`	O
set.update	O
`	O
function	O
to	O
get	O
unique	O
values	O
.	O

Use	O
`	O
apply	O
`	O
to	O
do	O
so	O
:	O
#CODE	O

If	O
it's	O
already	O
in	O
your	O
DataFrame	B-API
,	O
you	O
could	O
use	O
an	O
apply	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
add	O
additional	O
calculated	O
columns	O
to	O
each	O
DataFrame	B-API
that	O
is	O
inside	O
the	O
Panel	O
,	O
preferably	O
without	O
a	O
for-loop	O
.	O

I'm	O
attempting	O
to	O
use	O
the	O
apply	O
function	O
to	O
the	O
panel	O
and	O
name	O
the	O
new	O
columns	O
based	O
on	O
the	O
original	O
column	O
name	O
appended	O
with	O
a	O
'	O
p	O
'	O
(	O
for	O
easier	O
indexing	O
later	O
)	O
.	O

Below	O
is	O
the	O
code	O
I	O
am	O
currently	O
using	O
.	O

#CODE	O

The	O
code	O
above	O
currently	O
duplicates	O
each	O
DataFrame	B-API
with	O
the	O
calculated	O
columns	O
instead	O
of	O
appending	O
them	O
to	O
each	O
DataFrame	B-API
.	O

The	O
apply	O
function	O
I'm	O
using	O
operates	O
on	O
a	O
Series	O
object	O
,	O
which	O
in	O
this	O
case	O
would	O
be	O
a	O
passed	O
column	O
.	O

My	O
question	O
is	O
how	O
can	O
I	O
use	O
the	O
apply	O
function	O
on	O
a	O
Panel	O
such	O
that	O
it	O
calculates	O
new	O
columns	O
and	O
appends	O
them	O
to	O
each	O
DataFrame	B-API
?	O

If	O
you	O
want	O
to	O
add	O
a	O
new	O
column	O
via	O
`	O
apply	O
`	O
simply	O
assign	O
the	O
output	O
of	O
the	O
apply	O
operation	O
to	O
the	O
column	O
you	O
desire	O
:	O
#CODE	O

Or	O
,	O
in	O
this	O
case	O
,	O
simply	O
``	O
apply	O
(	O
newCalculation	O
)``	O
.	O

Assume	O
you	O
would	O
like	O
to	O
evaluate	O
a	O
time	O
series	O
ts	O
on	O
a	O
different	O
datetime_index	O
.	O

This	O
index	O
and	O
the	O
index	O
of	O
ts	O
may	O
overlap	O
.	O

I	O
recommend	O
to	O
use	O
the	O
following	O
groupby	B-API
trick	O
.	O

This	O
essentially	O
gets	O
rid	O
of	O
dubious	O
double	O
stamps	O
.	O

I	O
then	O
forward	O
interpolate	O
but	O
feel	O
free	O
to	O
apply	O
more	O
fancy	O
methods	O
#CODE	O

Pandas	O
Dataframe	B-API
,	O
Apply	O
Function	O
,	O
Return	O
Index	O

Then	O
I	O
can	O
apply	O
the	O
function	O
to	O
my	O
dataframe	B-API
,	O
grouped	O
by	O
I	O
D:	O
#CODE	O

I'm	O
a	O
newbie	O
to	O
Pandas	O
and	O
I'm	O
trying	O
to	O
apply	O
it	O
to	O
a	O
script	O
that	O
I	O
have	O
already	O
written	O
.	O

Apply	O
`	O
tolist	B-API
`	O
on	O
each	O
of	O
the	O
group's	O
column	O
B	O
:	O
#CODE	O

Unfortunately	O
you	O
can't	O
just	O
do	O
an	O
apply	O
(	O
since	O
it	O
fits	O
it	O
back	O
to	O
a	O
DataFrame	B-API
):	O
#CODE	O

I	O
have	O
a	O
dataset	O
created	O
with	O
pytables	O
that	O
I	O
am	O
trying	O
to	O
import	O
into	O
a	O
pandas	O
dataframe	B-API
.	O

I	O
can't	O
apply	O
a	O
`	O
where	O
`	O
filter	O
to	O
the	O
`	O
read_hdf	B-API
`	O
step	O
.	O

I'm	O
on	O
pandas	O
'	O
0.12.0	O
'	O

I'm	O
having	O
trouble	O
with	O
Pandas	O
'	O
groupby	B-API
functionality	O
.	O

I've	O
read	O
the	O
documentation	O
,	O
but	O
I	O
can't	O
see	O
to	O
figure	O
out	O
how	O
to	O
apply	O
aggregate	O
functions	O
to	O
multiple	O
columns	O
and	O
have	O
custom	O
names	O
for	O
those	O
columns	O
.	O

To	O
understand	O
why	O
your	O
approach	O
didn't	O
work	O
,	O
remember	O
that	O
the	O
function	O
`	O
round	O
`	O
needs	O
two	O
arguments	O
,	O
the	O
number	O
of	O
decimal	O
places	O
and	O
the	O
data	O
to	O
be	O
rounded	O
.	O

In	O
general	O
,	O
to	O
apply	O
functions	O
that	O
take	O
two	O
arguments	O
,	O
you	O
can	O
"	O
curry	O
"	O
the	O
function	O
like	O
so	O
:	O
#CODE	O

For	O
a	O
modestly	O
sized	O
`	O
DataFrame	B-API
`	O
,	O
`	O
applymap	B-API
`	O
will	O
be	O
horrendously	O
slow	O
,	O
since	O
it	O
is	O
applying	O
a	O
Python	O
function	O
element	O
by	O
element	O
in	O
Python	O
(	O
i.e.	O
,	O
there's	O
no	O
Cython	O
speeding	O
this	O
up	O
)	O
.	O

It's	O
faster	O
to	O
use	O
`	O
apply	O
`	O
with	O
`	O
functools.partial	O
`	O
:	O
#CODE	O

You	O
could	O
even	O
make	O
a	O
function	O
that	O
returns	O
a	O
partial	O
function	O
that	O
you	O
can	O
apply	O
:	O
#CODE	O

Why	O
not	O
use	O
`	O
numpy.round	O
`	O
and	O
pass	O
the	O
`	O
DataFrame	B-API
`	O
as	O
an	O
argument	O
?	O

`	O
100	O
*	O
np.round	O
(	O
df	O
,	O
2	O
)`	O
seems	O
to	O
solve	O
the	O
problem	O
for	O
me	O
.	O

If	O
some	O
columns	O
have	O
type	O
inappropriate	O
for	O
`	O
round	O
`	O
,	O
just	O
exclude	O
them	O
before	O
passing	O
to	O
the	O
`	O
round	O
`	O
function	O
.	O

This	O
should	O
avoid	O
overhead	O
from	O
`	O
apply	O
`	O
-like	O
things	O
.	O

This	O
link	O
is	O
useful	O
,	O
although	O
I	O
cannot	O
figure	O
out	O
how	O
to	O
apply	O
it	O
to	O
my	O
situation	O
.	O

I	O
use	O
Pandas	O
in	O
IPython	O
Notebook	O
rather	O
than	O
IPython	O
as	O
a	O
terminal	O
shell	O
,	O
I	O
don't	O
see	O
any	O
options	O
in	O
`	O
set_option	B-API
`	O
that	O
supports	O
the	O
colouring	O
,	O
it	O
maybe	O
something	O
that	O
could	O
be	O
done	O
as	O
a	O
plugin	O
to	O
apply	O
some	O
css	O
or	O
output	O
formatting	O
.	O

This	O
is	O
the	O
only	O
way	O
I	O
think	O
you	O
could	O
achieve	O
this	O

Sounds	O
like	O
you're	O
looking	O
for	O
the	O
`	O
DataFrame.apply()	B-API
`	O
method	O
.	O

The	O
`	O
apply	O
`	O
method	O
is	O
a	O
very	O
general	O
way	O
to	O
apply	O
a	O
function	O
across	O
either	O
the	O
columns	O
or	O
rows	O
of	O
a	O
`	O
DataFrame	B-API
`	O
:	O
#CODE	O

By	O
default	O
it	O
applies	O
a	O
function	O
to	O
the	O
columns	O
,	O
but	O
by	O
passing	O
`	O
axis=1	O
`	O
you	O
can	O
apply	O
a	O
function	O
to	O
each	O
row	O
:	O
#CODE	O

You	O
can	O
apply	O
the	O
swap_axes	O
method	O
after	O
construction	O
:	O
#CODE	O

@USER	O
wasn't	O
aware	O
of	O
that	O
I	O
knew	O
that	O
`	O
apply	O
`	O
did	O
iterate	O
but	O
thought	O
`	O
map	O
`	O
didn't	O

You	O
can	O
just	O
use	O
`	O
apply	O
`	O
and	O
assign	O
direct	O
to	O
the	O
column	O
like	O
so	O
`	O
df	O
[	O
'	O
start_time	O
']	O
=	O
df	O
[	O
'	O
start_time	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
dt.datetime.fromtimestamp	O
(	O
x	O
))`	O
,	O
this	O
is	O
better	O
than	O
a	O
list	O
comprehension	O

Use	O
`	O
apply	O
`	O
#CODE	O

Python	O
using	O
lambda	O
to	O
apply	O
pd.DataFrame	B-API
instead	O
for	O
nested	O
loop	O
is	O
it	O
possible	O
?	O

I'm	O
trying	O
to	O
avoid	O
nested	O
loop	O
in	O
python	O
here	O
by	O
using	O
lambda	O
apply	O
to	O
create	O
a	O
new	O
column	O

Your	O
apply	O
doesn't	O
work	O
as	O
by	O
default	O
it	O
works	O
column	O
wise	O
,	O
plus	O
you	O
misunderstand	O
what	O
the	O
lambda	O
parameters	O
actually	O
represent	O
so	O
your	O
lambda	O
func	O
does	O
not	O
map	O
to	O
the	O
columns	O
as	O
you	O
expected	O
.	O

If	O
you	O
wanted	O
it	O
to	O
work	O
row	O
wise	O
you	O
need	O
to	O
do	O
something	O
like	O
this	O
`	O
df	O
[	O
'	O
c	O
']	O
=	O
df.apply	B-API
(	O
lambda	O
row	O
:	O
row.A	O
+	O
row.B	O
,	O
axis=1	O
)`	O
but	O
@USER	O
'	O
s	O
answer	O
will	O
achieve	O
what	O
you	O
want	O
and	O
is	O
simpler	O

As	O
@USER	O
points	O
out	O
in	O
the	O
comment	O
,	O
the	O
argument	O
to	O
the	O
function	O
in	O
`	O
apply	O
`	O
is	O
a	O
series	O
,	O
by	O
default	O
on	O
axis	O
`	O
0	O
`	O
which	O
are	O
rows	O
(	O
axis	O
`	O
1	O
`	O
means	O
columns	O
):	O
#CODE	O

Notice	O
the	O
overlap	O
between	O
IDs	O
0	O
and	O
1	O
and	O
1	O
and	O
2	O
at	O
the	O
edges	O
(	O
I	O
dont	O
want	O
that	O
,	O
messes	O
up	O
my	O
calculations	O
)	O
.	O

One	O
possible	O
way	O
to	O
get	O
around	O
this	O
is	O
to	O
using	O
groupby	B-API
on	O
IDs	O
and	O
then	O
loop	O
through	O
that	O
groupby	B-API
and	O
then	O
apply	O
a	O
rolling_sum	B-API

The	O
data	O
look	O
roughly	O
like	O
this	O
,	O
where	O
I	O
only	O
want	O
this	O
to	O
apply	O
to	O
columns	O
starting	O
with	O
T_	O
:	O
#CODE	O

This	O
gets	O
the	O
job	O
done	O
,	O
except	O
that	O
I	O
need	O
to	O
apply	O
it	O
to	O
only	O
6	O
of	O
the	O
many	O
columns	O
in	O
my	O
dataframe	B-API
.	O

I	O
should	O
have	O
made	O
it	O
more	O
clear	O
above	O
that	O
there	O
are	O
additional	O
columns	O
containing	O
strings	O
that	O
I	O
don't	O
need	O
to	O
replace	O
.	O

How	O
would	O
I	O
do	O
that	O
?	O

Update	O
:	O
I've	O
combined	O
this	O
solution	O
with	O
using	O
a	O
dict	O
to	O
apply	O
the	O
fillna	B-API
method	O
as	O
suggested	O
here	O
.	O

I	O
wouldn't	O
have	O
known	O
how	O
to	O
use	O
zip	O
to	O
create	O
a	O
handy	O
dict	O
,	O
though	O
,	O
so	O
the	O
answer	O
is	O
rather	O
split	O
between	O
the	O
two	O
of	O
you	O
.	O

Either	O
way	O
,	O
learned	O
a	O
ton	O
from	O
this	O
so	O
thanks	O
.	O

If	O
you	O
perform	O
an	O
operation	O
on	O
a	O
single	O
column	O
the	O
return	O
will	O
be	O
a	O
series	O
with	O
multiindex	O
and	O
you	O
can	O
simply	O
apply	O
`	O
pd.DataFrame	B-API
`	O
to	O
it	O
and	O
then	O
reset_index	B-API
.	O

Also	O
,	O
you	O
might	O
instead	O
want	O
to	O
look	O
at	O
using	O
`	O
apply	O
`	O
,	O
which	O
lets	O
you	O
return	O
an	O
entire	O
DataFrame	B-API
.	O

This	O
way	O
you	O
could	O
,	O
instead	O
of	O
collapsing	O
the	O
items	O
into	O
a	O
list	O
,	O
actually	O
return	O
a	O
new	O
grouped	O
table	O
with	O
one	O
row	O
for	O
each	O
unique	O
value	O
in	O
the	O
source	O
column	O
.	O

Where	O
the	O
argument	O
x	O
is	O
the	O
Column	O
int	O
he	O
DF	O
?	O

Thanks	O
this	O
is	O
helpful	O
.	O

It	O
seems	O
I	O
don't	O
need	O
to	O
actually	O
iterate	O
over	O
the	O
index	O
within	O
each	O
group	O
.	O

How	O
would	O
one	O
do	O
that	O
if	O
it	O
were	O
necessary	O
?	O

Apply	O
seems	O
like	O
it	O
could	O
be	O
useful	O
as	O
well	O
,	O
and	O
that	O
seems	O
to	O
work	O
in	O
prety	O
much	O
the	O
same	O
way	O
.	O

I'll	O
have	O
a	O
look	O
now	O
.	O
thanks	O
a	O
lot	O
.	O

I	O
am	O
trying	O
to	O
apply	O
Logistic	O
Regression	O
in	O
Python	O
using	O
statsmodel.api.Logit	O
.	O

When	O
I	O
want	O
to	O
resample	O
my	O
time	O
series	O
data	O
,	O
it	O
is	O
very	O
straightforward	O
to	O
apply	O
the	O
arithmetic	O
mean	O
function	O
.	O

`	O
df.date	O
=	O
df.date.apply	O
(	O
lambda	O
d	O
:	O
datetime.strptime	O
(	O
d	O
,	O
"	O
%Y-%m-%d	O
"))`	O
here	O
which	O
doesn't	O
work	O
since	O
I'm	O
working	O
with	O
integers	O
,	O
not	O
strings	O
.	O

I	O
think	O
I	O
need	O
to	O
use	O
`	O
datetime.date.fromtimestamp	O
`	O
but	O
I'm	O
not	O
quite	O
sure	O
how	O
to	O
apply	O
this	O
to	O
the	O
whole	O
of	O
df.date	O
.	O

Thanks	O
.	O

I	O
think	O
I	O
have	O
finally	O
solved	O
the	O
problem	O
.	O

I	O
suspect	O
that	O
yemu's	O
answer	O
is	O
good	O
,	O
but	O
I	O
prefer	O
this	O
as	O
it	O
was	O
an	O
exercise	O
in	O
finally	O
learning	O
how	O
to	O
apply	O
my	O
own	O
functions	O
:	O
#CODE	O

Working	O
and	O
tuning	O
your	O
data	O
from	O
the	O
stacked	O
dataframe	B-API
above	O
is	O
straightforward	O
.	O

You	O
can	O
follow	O
by	O
resetting	O
the	O
index	O
,	O
split	O
it	O
into	O
year	O
month	O
day	O
columns	O
,	O
and	O
apply	O
the	O
math	O
on	O
the	O
non	O
NaN	O
data	O
that	O
are	O
in	O
a	O
single	O
column	O
now	O
.	O

So	O
you	O
need	O
to	O
apply	O
an	O
aggregation	O
operation	O
(	O
e.g.	O
`	O
sum	O
`	O
,	O
or	O
use	O
`	O
apply	O
`)	O
to	O
your	O
grouped	O
frame	O
,	O
which	O
will	O
then	O
create	O
a	O
new	O
frame	O
,	O
which	O
you	O
can	O
`	O
to_excel	B-API
`	O
.	O

This	O
makes	O
sense	O
.	O

I	O
suppose	O
I	O
should	O
be	O
using	O
code	O
that	O
just	O
sorts	O
if	O
I	O
want	O
to	O
organize	O
by	O
groups	O
for	O
the	O
output	O
,	O
but	O
not	O
apply	O
any	O
aggregation	O
operations	O
.	O

Thanks	O
for	O
the	O
clear	O
explanation	O
-	O
the	O
fact	O
that	O
some	O
output	O
did	O
make	O
it	O
to	O
the	O
excel	O
file	O
made	O
me	O
think	O
it	O
ought	O
to	O
work	O
the	O
way	O
I	O
supposed	O
,	O
but	O
obviously	O
not	O
.	O

But	O
for	O
a	O
larger	O
set	O
of	O
replaces	O
you	O
would	O
want	O
to	O
use	O
one	O
of	O
the	O
two	O
other	O
methods	O
or	O
use	O
"	O
apply	O
"	O
with	O
a	O
lambda	O
function	O
(	O
for	O
value	O
transformations	O
)	O
.	O

Last	O
but	O
not	O
least	O
:	O
you	O
can	O
use	O
.fillna	B-API
(	O
'	O
bla	O
')	O
to	O
rapidly	O
fill	O
up	O
NA	O
values	O
.	O

Your	O
question	O
is	O
a	O
little	O
unclear	O
,	O
but	O
you	O
seem	O
to	O
be	O
trying	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
of	O
the	O
DataFrame	B-API
.	O

Try	O
#CODE	O

I	O
would	O
consider	O
using	O
a	O
[	O
Pandas	O
DataFrame	B-API
]	O
(	O
#URL	O
)	O
.	O

You	O
could	O
have	O
an	O
index	O
for	O
the	O
ID	O
(	O
dict	O
key	O
in	O
your	O
example	O
)	O
.	O

Then	O
perform	O
an	O
outer	O
join	O
operation	O
and	O
apply	O
a	O
function	O
that	O
does	O
the	O
comparison	O
to	O
the	O
result	O
.	O

Of	O
course	O
there	O
will	O
be	O
ways	O
to	O
do	O
it	O
with	O
`	O
dict	O
`	O
,	O
but	O
it	O
seems	O
like	O
you	O
really	O
need	O
a	O
bit	O
of	O
relational	O
logic	O
on	O
the	O
IDs	O
followed	O
by	O
application	O
of	O
an	O
arbitrary	O
piece	O
of	O
code	O
(	O
the	O
comparison	O
operations	O
)	O
.	O

That's	O
what	O
Pandas	O
is	O
good	O
at	O
.	O

One	O
of	O
the	O
distance	O
metrics	O
(	O
jaro	O
,	O
perhaps	O
)	O
in	O
the	O
`	O
jellyfish	O
`	O
library	O
would	O
probably	O
apply	O
.	O

Here	O
is	O
an	O
[	O
example	O
answer	O
]	O
(	O
#URL	O
)	O
that	O
prints	O
out	O
words	O
of	O
a	O
certain	O
distance	O
,	O
but	O
you	O
could	O
just	O
as	O
easily	O
print	O
out	O
the	O
distance	O
itself	O
...	O

Iv'e	O
tried	O
to	O
use	O
the	O
groupby	B-API
mechanism	O
,	O
but	O
with	O
no	O
success	O
.	O
using	O
the	O
simple	O
apply	O
mechanism	O
is	O
ok	O
,	O
but	O
seems	O
a	O
little	O
cumbersome	O
(	O
I'll	O
need	O
to	O
keep	O
a	O
dictionary	O
containing	O
a	O
counter	O
of	O
appearances	O
for	O
each	O
ID	O
)	O

Can	O
you	O
explain	O
what	O
is	O
happing	O
here	O
?	O

because	O
i	O
was	O
trying	O
to	O
use	O
groupby	B-API
and	O
apply	O
and	O
what	O
i	O
got	O
back	O
was	O
a	O
series	O
with	O
the	O
ID	O
as	O
index	O
and	O
the	O
modified	O
ID's	O
as	O
lists	O
for	O
each	O
index	O
.	O
what	O
is	O
going	O
on	O
here	O
under	O
the	O
hood	O
?	O

what	O
is	O
the	O
translation	O
into	O
natural	O
language	O
of	O
the	O
code	O
above	O
?	O

`	O
apply	O
`	O
and	O
`	O
transform	O
`	O
do	O
similar	O
things	O
.	O

`	O
apply	O
`	O
is	O
a	O
complicated	O
beast	O
because	O
it	O
behaves	O
differently	O
depending	O
on	O
the	O
type	O
of	O
object	O
the	O
function	O
returns	O
.	O

I	O
have	O
not	O
attempted	O
to	O
memorize	O
[	O
the	O
rules	O
which	O
govern	O
this	O
behavior	O
]	O
(	O
#URL	O
)	O
,	O
I	O
simply	O
try	O
a	O
few	O
plausible	O
variations	O
until	O
I	O
find	O
the	O
one	O
that	O
works	O
.	O

In	O
this	O
case	O
,	O
since	O
I	O
knew	O
transform	O
is	O
intended	O
for	O
changing	O
a	O
Series	O
to	O
another	O
Series	O
*	O
of	O
equal	O
length*	O
,	O
I	O
tried	O
transform	O
.	O

Possibly	O
useful	O
,	O
but	O
this	O
doesn't	O
say	O
how	O
to	O
apply	O
the	O
transformation	O
to	O
the	O
date	O
index	O
...	O

On	O
`	O
groupby	B-API
`	O
object	O
,	O
the	O
`	O
agg	O
`	O
function	O
can	O
take	O
a	O
list	O
to	O
apply	O
several	O
aggregation	O
methods	O
at	O
once	O
.	O

This	O
should	O
give	O
you	O
the	O
result	O
you	O
need	O
:	O
#CODE	O

Python	O
Pandas	O
:	O
Groupby	B-API
and	O
Apply	O
multi-column	O
operation	O

It	O
doesn't	O
usually	O
make	O
sense	O
to	O
perform	O
`	O
value_counts	B-API
`	O
on	O
a	O
DataFrame	B-API
,	O
though	O
I	O
suppose	O
you	O
could	O
apply	O
it	O
to	O
every	O
entry	O
by	O
flattening	O
the	O
underlying	O
values	O
array	O
:	O
#CODE	O

I	O
know	O
about	O
the	O
apply	O
function	O
but	O
it	O
is	O
too	O
easy	O
in	O
my	O
case	O
..	O

In	O
the	O
dataframe	B-API
above	O
I	O
would	O
like	O
to	O
apply	O
the	O
qcut	B-API
function	O
to	O
B	O
while	O
partitioning	O
on	O
A	O
to	O
return	O
C	O
.	O

To	O
apply	O
your	O
custom	O
function	O
to	O
each	O
row	O
,	O
use	O
`	O
apply	O
`	O
with	O
the	O
keyword	O
argument	O
`	O
axis=1	O
`	O
.	O

#CODE	O

I	O
have	O
a	O
long	O
dataframe	B-API
with	O
daily	O
dates	O
starting	O
from	O
1999	O
.	O

I	O
apply	O
a	O
filter	O
to	O
the	O
original_dataframe	O
to	O
create	O
a	O
new_dataframe_1	O
and	O
another	O
filter	O
to	O
create	O
new_dataframe_2	O
.	O

You	O
can	O
apply	O
value_counts	B-API
to	O
the	O
SeriesGroupby	B-API
(	O
for	O
the	O
column	O
):	O
#CODE	O

Interesting	O
,	O
I	O
will	O
give	O
it	O
a	O
go	O
.	O

I	O
have	O
been	O
looking	O
up	O
normalization	O
on	O
the	O
unicodedata	O
module	O
.	O

I	O
was	O
not	O
sure	O
if	O
that	O
would	O
apply	O
to	O
this	O
situation	O
however	O
.	O

I	O
also	O
discovered	O
from	O
zope.component	O
import	O
getUtility	O

Hey	O
this	O
is	O
awesome	O
.	O

Thanks	O
for	O
exposing	O
me	O
to	O
the	O
fuzzywuzzy	O
article	O
.	O

I	O
will	O
take	O
some	O
time	O
to	O
check	O
it	O
out	O
and	O
see	O
how	O
I	O
can	O
apply	O
it	O
.	O

The	O
5	O
in	O
the	O
lambda	O
above	O
comes	O
from	O
the	O
correct	O
width	O
.	O

You'd	O
need	O
to	O
select	O
out	O
all	O
the	O
columns	O
that	O
need	O
leading	O
zeros	B-API
and	O
apply	O
the	O
function	O
(	O
with	O
the	O
correct	O
width	O
)	O
to	O
each	O
.	O

The	O
result	O
obtained	O
,	O
I	O
need	O
to	O
apply	O
the	O
following	O
conditions	O
#CODE	O

You	O
can	O
make	O
your	O
own	O
aggregate	O
functions	O
to	O
apply	O
to	O
grouped	O
data	O
#URL	O
.	O

So	O
for	O
your	O
case	O
you	O
could	O
try	O
something	O
like	O
:	O
#CODE	O

yes	O
....	O
the	O
issue	O
is	O
the	O
Series	O
vector	O
(	O
e.g.	O
``	O
df.D	O
>	O
1	O
``)	O
*	O
looks	O
*	O
like	O
it	O
should	O
work	O
,	O
but	O
its	O
ambiguous	O
how	O
it	O
should	O
broadcast	O
,	O
e.g.	O
should	O
that	O
Series	O
named	O
D	O
apply	O
to	O
all	O
of	O
the	O
other	O
columns	O
(	O
in	O
which	O
case	O
what	O
should	O
it	O
do	O
?	O
)	O
,	O
or	O
should	O
it	O
effectively	O
have	O
no	O
name	O
which	O
means	O
it	O
SHOULD	O
broadcast	O
.	O

You	O
problem	O
could	O
also	O
be	O
solved	O
by	O
using	O
``	O
df	O
>	O
1.0	O
``	O
because	O
I	O
think	O
that	O
is	O
what	O
you	O
intend	O
(	O
e.g.	O
that	O
it	O
DOES	O
broadcast	O
)	O

Problem	O
!	O

Though	O
this	O
works	O
,	O
it	O
ends	O
up	O
being	O
really	O
memory	O
inefficient	O
.	O

I'm	O
working	O
with	O
a	O
13	O
million	O
row	O
dataframe	B-API
,	O
and	O
attempting	O
to	O
run	O
the	O
apply	O
(	O
sequence_id	O
)	O
bit	O
ends	O
maxing	O
out	O
the	O
20gb	O
of	O
ram	O
I	O
have	O
available	O
.	O

I've	O
worked	O
with	O
bigger	O
dataframes	O
,	O
so	O
it	O
must	O
be	O
something	O
to	O
do	O
with	O
this	O
particular	O
operation	O
.	O

Any	O
thoughts	O
on	O
how	O
we	O
could	O
optimize	O
it	O
?	O

@USER	O
:	O
You	O
could	O
apply	O
any	O
of	O
the	O
above	O
methods	O
to	O
the	O
Series	O
`	O
df1	O
[	O
'	O
col	O
']`	O
and	O
`	O
df2	O
[	O
'	O
col	O
']`	O
.	O

For	O
example	O
,	O
@USER	O
'	O
s	O
answer	O
would	O
look	O
like	O
this	O
:	O
`	O
pd.concat	B-API
((	O
df1	O
[	O
'	O
col	O
']	O
,	O
df2	O
[	O
'	O
col	O
'])	O
,	O
axis=1	O
)	O
.mean	B-API
(	O
axis=1	O
)`	O
.	O

you	O
can	O
use	O
apply	O
function	O
:	O
#CODE	O

very	O
close	O
!	O

I	O
had	O
to	O
convert	O
dates	O
to	O
'	O
12	O
10	O
'	O
instead	O
of	O
'	O
12	O
Oct	O
'	O
because	O
pandas	O
crosstab	B-API
alphabetizes	O
and	O
the	O
3-letter	O
months	O
messes	O
that	O
up	O
.	O

So	O
if	O
I	O
can	O
isolate	O
the	O
two-digit	O
month	O
,	O
I	O
can	O
apply	O
calendar.month_abbr	O
[	O
##	O
]	O
to	O
get	O
that	O
3-letter	O
month	O
.	O

Thanks	O
!	O

Why	O
they're	O
being	O
converted	O
like	O
that	O
:	O
I'm	O
not	O
sure	O
.	O

Might	O
be	O
a	O
bug	O
,	O
but	O
it	O
should	O
be	O
simple	O
enough	O
to	O
`	O
apply	O
`	O
something	O
keep	O
it	O
all	O
straight	O
.	O

So	O
how	O
can	O
I	O
apply	O
this	O
to	O
the	O
full	O
dataframe	B-API
,	O
ffill-ing	O
the	O
observations	O
(	O
but	O
also	O
the	O
item_id	O
index	O
)	O
such	O
that	O
each	O
item_id	O
has	O
properly	O
filled	O
rows	O
for	O
all	O
the	O
dates	O
in	O
baseDateRange	O
?	O

Essentially	O
for	O
each	O
group	O
you	O
want	O
to	O
reindex	O
and	O
ffill	B-API
.	O

The	O
apply	O
gets	O
passed	O
a	O
data	O
frame	O
that	O
has	O
the	O
item_id	O
and	O
date	O
still	O
in	O
the	O
index	O
,	O
so	O
reset	O
,	O
then	O
set	O
and	O
reindex	O
with	O
filling	O
.	O

answer	O
to	O
your	O
first	O
part	O
is	O
yes	O
that	O
is	O
reasonable	O
,	O
you	O
can	O
drop	O
on	O
the	O
reset_index	B-API
to	O
not	O
have	O
a	O
dup	O
.	O
for	O
the	O
second	O
,	O
I	O
think	O
the	O
apply	O
is	O
a	O
bit	O
confused	O
by	O
the	O
index	O
because	O
of	O
the	O
way	O
you	O
are	O
aggregating	O
(	O
so	O
it's	O
dropping	O
the	O
name	O
of	O
the	O
index	O
)	O
.	O

You	O
can	O
do	O
another	O
reset_index	B-API
inside	O
the	O
apply	O
,	O
then	O
at	O
the	O
very	O
end	O
(	O
after	O
the	O
apply	O
,	O
``	O
.reset_index	B-API
(	O
drop=True	O
)	O
.set_index	B-API
([	O
'	O
date	O
'	O
,	O
'	O
item_id	O
'])``	O
,	O
so	O
reset	O
the	O
mi	O

It	O
you	O
want	O
to	O
apply	O
these	O
to	O
all	O
your	O
pandas	O
tables	O
you	O
can	O
use	O
css	O
.	O

A	O
(	O
not	O
recommended	O
)	O
way	O
is	O
put	O
the	O
following	O
into	O
a	O
markdown	O
cell	O
of	O
the	O
active	O
notebook	O
.	O

#CODE	O

I	O
need	O
the	O
apply	O
function	O
that	O
returns	O
several	O
value	O
from	O
several	O
complex	O
calculations	O
.	O

I	O
can	O
return	O
those	O
values	O
in	O
a	O
tuple	O
,	O
and	O
thus	O
the	O
outcome	O
of	O
the	O
groupby-apply	O
action	O
would	O
be	O
a	O
Series	O
with	O
group	O
name	O
as	O
indexes	O
and	O
the	O
tuple	O
as	O
values	O
.	O

I	O
would	O
like	O
it	O
to	O
return	O
a	O
DataFrame	B-API
instead	O
,	O
So	O
I	O
could	O
keep	O
all	O
the	O
pandas	O
functionality	O
and	O
flexibility	O
.	O

In	O
general	O
,	O
The	O
outcome	O
of	O
a	O
groupby-apply	O
operation	O
would	O
be	O
a	O
Series	O
In	O
the	O
case	O
apply	O
returning	O
1	O
value	O
.	O

In	O
the	O
case	O
of	O
apply	O
returning	O
2	O
or	O
more	O
values	O
,	O
I	O
would	O
like	O
the	O
outcome	O
to	O
be	O
a	O
dataframe	B-API
.	O

so	O
my	O
question	O
is	O
how	O
to	O
do	O
that	O
.	O

See	O
the	O
original	O
Q	O
for	O
more	O
details	O
and	O
examples	O

Based	O
on	O
the	O
edited	O
question	O
,	O
maybe	O
this	O
is	O
what	O
you	O
are	O
looking	O
for	O
.	O

Returning	O
a	O
series	O
in	O
the	O
apply	O
call	O
results	O
being	O
collated	O
into	O
a	O
dataframe	B-API
(	O
guessing	O
that	O
is	O
what	O
you	O
are	O
looking	O
for	O
)	O

That's	O
definitely	O
answer	O
the	O
example	O
I	O
gave	O
,	O
but	O
not	O
my	O
problem	O
.	O
which	O
means	O
that	O
I	O
gave	O
a	O
bad	O
example	O
..	O

Imagine	O
that	O
I	O
need	O
the	O
apply	O
function	O
to	O
retrieve	O
few	O
complex	O
calculations	O
.	O

A	O
function	O
that	O
is	O
not	O
a	O
built-in	O
function	O
.	O

In	O
the	O
case	O
of	O
apply	O
returning	O
1	O
value	O
,	O
the	O
outcome	O
is	O
a	O
series	O
.	O

In	O
the	O
case	O
of	O
apply	O
returning	O
2	O
or	O
more	O
values	O
,	O
I	O
would	O
like	O
the	O
outcome	O
to	O
be	O
a	O
dataframe	B-API
.	O

so	O
my	O
question	O
is	O
how	O
to	O
do	O
that	O
.	O

On	O
12+	O
dev	O
of	O
Pandas	O
..	O

so	O
I'll	O
try	O
apply	O
(	O
int	O
)	O
I	O
still	O
don't	O
get	O
why	O
the	O
Dtype={	O
does	O
not	O
work	O
on	O
read_csv	B-API
?	O

The	O
second	O
command	O
causes	O
the	O
following	O
error	O
which	O
I	O
do	O
not	O
understand	O
.	O

Any	O
thoughts	O
on	O
what	O
might	O
be	O
going	O
on	O
here	O
?	O

I	O
replaced	O
map	O
with	O
apply	O
and	O
that	O
didn't	O
help	O
matters	O
.	O

#CODE	O

Perfect	O
Jeff	O
,	O
thank	O
you	O
!	O

Once	O
I	O
got	O
rid	O
of	O
the	O
rows	O
with	O
missing	O
data	O
,	O
I	O
could	O
directly	O
apply	O
this	O
to	O
the	O
new	O
problem	O
.	O

;-)	O

I'm	O
exploring	O
Pandas	O
-	O
trying	O
to	O
learn	O
and	O
apply	O
it	O
.	O

Currently	O
I	O
have	O
a	O
csv	O
file	O
populated	O
with	O
a	O
financial	O
timeseries	O
data	O
of	O
following	O
structure	O
:	O

now	O
apply	O
the	O
lambda	O
function	O
,	O
doing	O
what	O
the	O
parser	O
should	O
have	O
done	O
:	O
#CODE	O

datetime.date	O
creating	O
many	O
problems	O
with	O
set_index	B-API
,	O
groupby	B-API
,	O
and	O
apply	O
in	O
Pandas	O
0.8.1	O

Now	O
here	O
is	O
what	O
happens	O
when	O
I	O
try	O
to	O
work	O
with	O
these	O
using	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

If	O
I	O
save	O
the	O
`	O
groupby	B-API
`	O
object	O
and	O
attempt	O
to	O
apply	O
`	O
foo	O
`	O
myself	O
,	O
then	O
in	O
the	O
straightforward	O
way	O
,	O
this	O
also	O
fails	O
:	O
#CODE	O

I	O
can	O
simplify	O
the	O
problem	O
just	O
to	O
the	O
`	O
set_index	B-API
`	O
call	O
within	O
the	O
`	O
apply	O
`	O
function	O
.	O

But	O
this	O
is	O
getting	O
really	O
weird	O
.	O

Here's	O
an	O
example	O
with	O
a	O
simpler	O
test	O
DataFrame	B-API
,	O
just	O
with	O
`	O
set_index	B-API
`	O
.	O

#CODE	O

By	O
adding	O
a	O
call	O
to	O
reset	O
the	O
index	O
inside	O
of	O
the	O
function	O
to	O
be	O
applied	O
with	O
`	O
apply	O
`	O
,	O
it	O
gets	O
rid	O
of	O
the	O
problem	O
:	O
#CODE	O

Thanks	O
,	O
that	O
seems	O
to	O
work	O
well	O
.	O

I	O
have	O
some	O
back	O
up	O
questions	O
if	O
you	O
don't	O
mind	O
.	O

1	O
)	O
What	O
is	O
being	O
passed	O
to	O
the	O
function	O
f	O
when	O
it	O
is	O
called	O
with	O
apply	O
?	O

Is	O
it	O
each	O
groupe	O
of	O
data	O
sequentially	O
?	O

I	O
assume	O
it	O
must	O
be	O
.	O

2	O
)	O
How	O
can	O
the	O
function	O
be	O
called	O
with	O
multiple	O
columns	O
so	O
people2	O
=	O
Grouped.apply	O
(	O
f	O
(	O
'	O
a	O
'	O
,	O
'	O
b	O
'	O
,	O
'	O
c	O
'))	O
?	O

Clearly	O
the	O
fucntion	O
would	O
have	O
to	O
be	O
changed	O
,	O
but	O
in	O
your	O
example	O
the	O
function	O
is	O
not	O
very	O
abstract	O
.	O

I	O
would	O
want	O
to	O
write	O
def	O
f	O
(	O
df	O
,	O
col1	O
,	O
col2	O
,	O
col3	O
)	O
-	O
so	O
that	O
it	O
could	O
be	O
used	O
beyond	O
the	O
columns	O
referenced	O
inside	O
the	O
function	O
.	O

+1	O
,	O
the	O
main	O
part	O
of	O
answer	O
I	O
think	O
is	O
to	O
use	O
apply	O
instead	O
of	O
transform	O

Would	O
it	O
be	O
right	O
to	O
say	O
then	O
that	O
calling	O
transform	O
passes	O
only	O
the	O
named	O
column	O
,	O
or	O
each	O
column	O
in	O
the	O
DF	O
to	O
the	O
function	O
individually	O
and	O
it	O
is	O
not	O
possible	O
to	O
pass	O
more	O
than	O
one	O
column	O
,	O
whereas	O
apply	O
passes	O
the	O
whole	O
data	O
frame	O
and	O
then	O
column	O
values	O
can	O
be	O
used	O
within	O
the	O
function	O
?	O

I	O
think	O
that	O
was	O
where	O
I	O
was	O
getting	O
it	O
wrong	O
...	O

ok	O
,	O
I	O
think	O
apply	O
as	O
in	O
@USER	O
answer	O
is	O
more	O
appropriate	O
here	O
?	O

You're	O
welcome	O
!	O

If	O
you	O
really	O
want	O
to	O
thank	O
me	O
,	O
look	O
up	O
the	O
functions	O
I'm	O
using	O
there	O
and	O
figure	O
out	O
how	O
each	O
of	O
those	O
things	O
is	O
implemented	O
,	O
play	O
around	O
with	O
them	O
and	O
apply	O
it	O
in	O
your	O
own	O
code	O
:)	O

did	O
you	O
try	O
to	O
use	O
`	O
axis=0	O
`	O
?	O

This	O
should	O
be	O
the	O
case	O
since	O
you	O
want	O
to	O
apply	O
the	O
function	O
for	O
each	O
row	O
...	O

I	O
just	O
tried	O
it	O
and	O
it	O
didn't	O
work	O
.	O

According	O
to	O
#URL	O
axis=1	O
is	O
to	O
apply	O
to	O
each	O
row	O
.	O

I	O
also	O
experienced	O
this	O
error	O
.	O

It	O
turned	O
out	O
that	O
the	O
pandas	O
Time	O
Series	O
data	O
type	O
was	O
causing	O
the	O
problem	O
.	O

When	O
I	O
applied	O
the	O
function	O
with	O
the	O
time	O
expressed	O
in	O
epoch	O
(	O
or	O
anything	O
)	O
success	O
,	O
but	O
with	O
the	O
time	O
converted	O
to	O
pandas	O
Time	O
Series	O
,	O
there	O
was	O
this	O
error	O
.	O

So	O
my	O
suggestion	O
would	O
be	O
to	O
convert	O
to	O
Time	O
Series	O
after	O
you	O
apply	O
the	O
function	O
,	O
which	O
obviously	O
is	O
contingent	O
that	O
you	O
don't	O
need	O
your	O
time	O
variable	O
in	O
the	O
function	O
being	O
applied	O
.	O

*	O
apply	O
function	O
not	O
tested	O
with	O
pandas	O
Time	O
Spans	O
.	O

You	O
could	O
`	O
apply	O
`	O
the	O
conversion	O
on	O
the	O
appropriate	O
column	O
:	O
#CODE	O

Hi	O
Jeff	O
,	O
thank	O
you	O
for	O
your	O
reply	O
and	O
this	O
is	O
a	O
great	O
idea	O
,	O
but	O
it	O
somehow	O
does	O
not	O
really	O
solve	O
the	O
complete	O
problem	O
.	O

The	O
standard	O
grouping	O
method	O
of	O
"	O
resample	O
"	O
is	O
"	O
how=	O
'	O
mean	O
'"	O
.	O

Is	O
it	O
defined	O
anywhere	O
how	O
I	O
can	O
change	O
that	O
to	O
something	O
more	O
useful	O
?	O

I	O
have	O
to	O
apply	O
a	O
custom	O
function	O
.	O

The	O
point	O
is	O
that	O
I	O
also	O
have	O
multiple	O
entries	O
per	O
day	O
and	O
your	O
resample-solution	O
is	O
only	O
correct	O
with	O
the	O
"	O
mean	O
"	O
method	O
when	O
there	O
is	O
only	O
one	O
entry	O
per	O
day	O
.	O

`	O
argmin()	B-API
`	O
is	O
not	O
an	O
agg	O
function	O
,	O
you	O
can	O
use	O
apply	O
to	O
get	O
the	O
closest	O
index	O
of	O
every	O
group	O
:	O
#CODE	O

Are	O
you	O
trying	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
by	O
taking	O
arguments	O
from	O
different	O
columns	O
?	O

This	O
has	O
already	O
been	O
[	O
answered	O
here	O
]	O
(	O
#URL	O
)	O
.	O

EDIT	O
:	O
I	O
originally	O
start	O
with	O
a	O
dataframe	B-API
that	O
hase	O
one	O
column	O
.	O

I	O
add	O
4	O
columns	O
in	O
4	O
difference	O
apply	O
steps	O
,	O
and	O
then	O
when	O
I	O
try	O
to	O
add	O
another	O
column	O
I	O
get	O
this	O
error	O
.	O

what	O
are	O
you	O
actually	O
trying	O
to	O
do	O
?	O

using	O
apply	O
with	O
a	O
function	O
that	O
returns	O
a	O
list	O
will	O
try	O
to	O
coerce	O
this	O
to	O
a	O
Series	O
,	O
thus	O
it	O
needs	O
the	O
same	O
length	O
as	O
the	O
original	O
lenght	O
,	O
OR	O
a	O
scalar	O
(	O
including	O
None	O
)	O
.	O

Output	O
in	O
your	O
question	O
is	O
not	O
the	O
one	O
you	O
get	O
from	O
apply	O
.	O

Your	O
output	O
in	O
first	O
case	O
is	O
DataFrame	B-API
with	O
4	O
columns	O
,	O
as	O
@USER	O
said	O
,	O
it's	O
coersed	O
list	O
into	O
rows	O
.	O

@USER	O
I	O
think	O
that	O
the	O
output	O
is	O
the	O
output	O
from	O
apply	O
because	O
apply	O
will	O
run	O
each	O
row	O
through	O
func=random	O
,	O
and	O
that	O
func	O
will	O
print	O
out	O
[	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
]	O
.	O

I	O
am	O
not	O
sure	O
what	O
you	O
are	O
pointing	O
out	O
.	O

I	O
had	O
this	O
issue	O
,	O
and	O
my	O
solution	O
was	O
just	O
to	O
join	O
my	O
list	O
into	O
a	O
string	O
...	O
then	O
split	O
it	O
after	O
the	O
apply	O
.	O

and	O
then	O
use	O
apply	O
:	O
#CODE	O

This	O
doesn't	O
work	O
on	O
my	O
example	O
because	O
there	O
is	O
one	O
line	O
of	O
code	O
that	O
is	O
different	O
.	O

It	O
is	O
missing	O
df	O
[	O
'	O
E	O
']	O
=	O
1	O
.	O

I	O
add	O
the	O
column	O
'	O
E	O
'	O
and	O
then	O
I	O
do	O
apply	O
.	O

I	O
think	O
that	O
that	O
is	O
throwing	O
it	O
all	O
off	O
.	O

The	O
problem	O
that	O
I	O
am	O
working	O
on	O
starts	O
with	O
a	O
dataframe	B-API
with	O
one	O
column	O
and	O
then	O
I	O
keep	O
doing	O
apply	O
to	O
the	O
dataframe	B-API
to	O
add	O
columns	O
.	O

I	O
add	O
4	O
columns	O
and	O
then	O
when	O
I	O
try	O
to	O
add	O
a	O
fifth	O
column	O
,	O
I	O
get	O
that	O
error	O
.	O

EDIT	O
:	O
To	O
clarify	O
,	O
I'm	O
not	O
just	O
doing	O
this	O
for	O
subtracting	O
the	O
mean	O
,	O
it	O
was	O
just	O
a	O
simple	O
example	O
.	O

A	O
more	O
realistic	O
example	O
would	O
be	O
linearly	O
filtering	O
the	O
array	O
along	O
axis	O
0	O
.	O

I'd	O
like	O
to	O
use	O
the	O
scipy.signal	O
filtfilt	O
function	O
to	O
filter	O
my	O
array	O
.	O

This	O
is	O
quite	O
easy	O
if	O
I	O
can	O
just	O
pass	O
it	O
a	O
tpts	O
x	O
feats	O
matrix	O
,	O
but	O
right	O
now	O
it	O
seems	O
that	O
the	O
only	O
way	O
to	O
do	O
it	O
is	O
column-wise	O
using	O
"	O
apply	O
"	O

apply	O
also	O
works	O
on	O
entire	O
dataframes	O
.	O

If	O
you	O
want	O
to	O
subtract	O
5	O
(	O
or	O
an	O
avg	O
number	O
)	O
from	O
every	O
item	O
in	O
the	O
data	O
frame	O
,	O
you	O
can	O
do	O
that	O
as	O
well	O
by	O
excluding	O
the	O
axis	O
argument	O
.	O

So	O
,	O
it's	O
not	O
that	O
I	O
want	O
to	O
apply	O
a	O
function	O
to	O
every	O
item	O
in	O
the	O
dataframe	B-API
,	O
it's	O
that	O
I	O
want	O
to	O
pass	O
the	O
entire	O
contents	O
of	O
a	O
dataframe	B-API
to	O
a	O
function	O
.	O

For	O
example	O
,	O
the	O
hilbert	O
transform	O
in	O
scipy	O
takes	O
a	O
timepoints	O
x	O
features	O
array	O
,	O
and	O
computes	O
the	O
transform	O
along	O
the	O
first	O
axis	O
.	O

It	O
is	O
faster	O
to	O
pass	O
a	O
10,000	O
by	O
100	O
matrix	O
to	O
this	O
function	O
than	O
it	O
is	O
to	O
pass	O
100	O
separate	O
10,000	O
length	O
columns	O
to	O
this	O
function	O
,	O
which	O
is	O
what	O
would	O
happen	O
if	O
I	O
used	O
"	O
apply	O
"	O
.	O

I'm	O
trying	O
to	O
get	O
around	O
this	O
.	O

Am	O
I	O
stuck	O
with	O
using	O
a	O
for	O
loop	O
to	O
apply	O
the	O
boolean	O
'	O
and	O
'	O
operation	O
on	O
all	O
columns	O
(	O
i.e.	O
from	O
column	O
A	O
to	O
column	O
Z	O
)	O
?	O

To	O
reiterate	O
my	O
question	O
in	O
another	O
manner	O
is	O
there	O
an	O
efficient	O
way	O
or	O
built-in	O
pandas	O
function	O
to	O
'	O
AND	O
'	O
a	O
pandas	O
Series	O
on	O
all	O
the	O
columns	O
of	O
a	O
pandas	O
dataframe	B-API
?	O

Hi	O
@USER	O
,	O
I	O
am	O
getting	O
`	O
OverflowError	O
:	O
Python	O
int	O
too	O
large	O
to	O
convert	O
to	O
C	O
long	O
`	O
when	O
I	O
apply	O
your	O
solution	O
.	O

Any	O
suggestion	O
about	O
the	O
reason	O
?	O

My	O
question	O
,	O
then	O
,	O
is	O
how	O
I	O
can	O
accomplish	O
this	O
while	O
reducing	O
my	O
memory	O
overhead	O
.	O

I	O
think	O
the	O
problem	O
is	O
trying	O
to	O
perform	O
the	O
reindexing	O
with	O
the	O
groupby	B-API
/	O
apply	O
method	O
,	O
but	O
I	O
don't	O
kow	O
what	O
the	O
alternative	O
is	O
.	O

It	O
seems	O
like	O
there	O
should	O
be	O
way	O
I	O
could	O
do	O
something	O
similar	O
iteratively	O
that	O
would	O
require	O
less	O
memory	O
,	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
go	O
about	O
it	O
.	O

Or	O
you	O
can	O
use	O
apply	O
:	O
#CODE	O

I	O
now	O
want	O
to	O
apply	O
some	O
aggregate	O
functions	O
to	O
the	O
records	O
in	O
each	O
of	O
my	O
bin	O
groups	O
(	O
An	O
aggregate	O
funcitn	O
is	O
something	O
like	O
sum	O
,	O
mean	O
or	O
count	O
)	O
.	O

Now	O
I	O
want	O
to	O
apply	O
three	O
aggregate	O
functions	O
to	O
the	O
records	O
in	O
each	O
of	O
my	O
bins	O
:	O
the	O
mean	O
of	O
'	O
col11	O
'	O
,	O
the	O
number	O
of	O
records	O
in	O
each	O
bin	O
,	O
and	O
the	O
number	O
of	O
records	O
in	O
each	O
bin	O
that	O
have	O
'	O
col7	O
'	O
equal	O
to	O
one	O
.	O

The	O
mean	O
is	O
easy	O
;	O
numpy	O
already	O
has	O
a	O
function	O
to	O
calculate	O
the	O
mean	O
.	O

If	O
I	O
was	O
just	O
doing	O
the	O
mean	O
of	O
'	O
col11	O
'	O
I	O
would	O
write	O
:	O
`	O
dfg	O
=	O
df	O
[[	O
'	O
bin	O
'	O
,	O
'	O
col7	O
'	O
,	O
'	O
col11	O
']]	O
.groupby	B-API
(	O
'	O
bin	O
')	O
.agg	B-API
(	O
{	O
'	O
col11	O
'	O
:	O
[	O
np.mean	B-API
]	O
}	O
)`	O
.	O

The	O
number	O
of	O
records	O
is	O
also	O
easy	O
;	O
python's	O
`	O
len	O
`	O
function	O
(	O
It's	O
not	O
really	O
a	O
function	O
but	O
a	O
property	O
of	O
lists	O
etc	O
.	O
)	O
will	O
give	O
us	O
the	O
number	O
of	O
items	O
in	O
list	O
.	O

So	O
I	O
now	O
have	O
`	O
dfg	O
=	O
df	O
[[	O
'	O
bin	O
'	O
,	O
'	O
col7	O
'	O
,	O
'	O
col11	O
']]	O
.groupby	B-API
(	O
'	O
bin	O
')	O
.agg	B-API
(	O
{	O
'	O
col11	O
'	O
:	O
[	O
np.mean	B-API
]	O
,	O
'	O
col7	O
'	O
:	O
[	O
len	O
]	O
}	O
)`	O
.	O

Now	O
I	O
can't	O
think	O
of	O
an	O
existing	O
function	O
that	O
counts	O
the	O
number	O
of	O
ones	O
in	O
a	O
numpy	O
array	O
(	O
it	O
has	O
to	O
work	O
on	O
a	O
numpy	O
array	O
)	O
.	O

I	O
can	O
define	O
my	O
own	O
functions	O
that	O
work	O
on	O
a	O
numpy	O
array	O
,	O
hence	O
my	O
function	O
`	O
count_ones	O
`	O
.	O

Now	O
I'll	O
deconstruct	O
the	O
`	O
count_ones	O
`	O
function	O
.	O
the	O
varibale	O
`	O
x	O
`	O
passed	O
to	O
the	O
function	O
is	O
always	O
going	O
to	O
be	O
a	O
1d	O
numpy	O
array	O
.	O

In	O
our	O
specific	O
case	O
it	O
will	O
be	O
all	O
the	O
'	O
col7	O
'	O
values	O
that	O
fall	O
in	O
bin	O
#1	O
,	O
all	O
the	O
'	O
col7	O
'	O
values	O
that	O
fall	O
in	O
bin	O
#2	O
etc	O
..	O

The	O
code	O
`	O
x	O
==	O
1	O
`	O
will	O
create	O
a	O
boolean	O
(	O
TRUE	O
/	O
FALSE	O
)	O
array	O
the	O
same	O
size	O
as	O
x	O
.	O

The	O
entries	O
in	O
the	O
boolean	O
array	O
will	O
be	O
True	O
if	O
the	O
corresponding	O
values	O
in	O
x	O
are	O
equal	O
to	O
1	O
and	O
false	O
otherwise	O
.	O

Because	O
python	O
treats	O
True	O
as	O
1	O
if	O
I	O
sum	O
the	O
values	O
of	O
my	O
boolean	O
array	O
I'll	O
get	O
a	O
count	O
of	O
the	O
values	O
that	O
==	O
1	O
.	O

Now	O
that	O
I	O
have	O
my	O
`	O
count_ones	O
`	O
function	O
I	O
apply	O
it	O
to	O
'	O
col7	O
'	O
by	O
:	O
`	O
dfg	O
=	O
df	O
[[	O
'	O
bin	O
'	O
,	O
'	O
col7	O
'	O
,	O
'	O
col11	O
']]	O
.groupby	B-API
(	O
'	O
bin	O
')	O
.agg	B-API
(	O
{	O
'	O
col11	O
'	O
:	O
[	O
np.mean	B-API
]	O
,	O
'	O
col7	O
'	O
:	O
[	O
count_ones	O
,	O
len	O
]	O
}	O
)`	O

I	O
find	O
this	O
helpful	O
to	O
see	O
what	O
is	O
actually	O
passed	O
to	O
the	O
apply	O
,	O
which	O
in	O
this	O
case	O
is	O
a	O
frame	O
#CODE	O

The	O
above	O
works	O
just	O
fine	O
,	O
but	O
I	O
can't	O
understand	O
why	O
I	O
have	O
to	O
wrap	O
the	O
function	O
in	O
a	O
lambda	O
.	O

Based	O
upon	O
the	O
syntax	O
used	O
with	O
transform	O
and	O
apply	O
it	O
seems	O
to	O
me	O
that	O
the	O
following	O
should	O
work	O
just	O
fine	O
:	O
#CODE	O

Passing	O
arguments	O
to	O
`	O
apply	O
`	O
just	O
happens	O
to	O
work	O
,	O
because	O
`	O
apply	O
`	O
passes	O
on	O
all	O
arguments	O
to	O
the	O
target	O
function	O
.	O

and	O
apply	O
this	O
custom	O
converter	O
#CODE	O

and	O
apply	O
this	O
conversion	O
function	O
:	O
#CODE	O

I	O
apply	O
some	O
functions	O
and	O
generate	O
a	O
new	O
column	O
values	O
to	O
a	O
existing	O
column	O
of	O
Pandas	O
dataframe	B-API
.	O

However	O
`	O
df	O
[	O
'	O
col1	O
']	O
=	O
new_list	O
`	O
does	O
not	O
work	O
to	O
assign	O
new	O
list	O
to	O
the	O
column	O
.	O

Is	O
it	O
the	O
wrong	O
way	O
and	O
what	O
is	O
the	O
accurate	O
way	O
to	O
apply	O
such	O
operation	O
?	O

I	O
don't	O
know	O
why	O
the	O
index	O
method	O
has	O
inconsistent	O
behavior	O
while	O
doing	O
column-wise	O
apply	O
function	O
.	O

And	O
I	O
want	O
to	O
apply	O
lambda	O
to	O
the	O
second	O
columns	O
,	O
it	O
it	O
saying	O
the	O
Series	O
object	O
can	O
not	O
be	O
apply	O
?	O

#CODE	O

When	O
you	O
index	O
with	O
`'	O
B	O
'`	O
you	O
get	O
a	O
series	O
.	O

When	O
you	O
index	O
with	O
`	O
1:2	O
`	O
or	O
with	O
`	O
[	O
'	O
B	O
']`	O
,	O
you	O
get	O
a	O
DataFrame	B-API
with	O
one	O
column	O
.	O

When	O
you	O
use	O
`	O
apply	O
`	O
on	O
a	O
series	O
,	O
your	O
function	O
is	O
called	O
on	O
each	O
element	O
.	O

When	O
you	O
use	O
`	O
apply	O
`	O
on	O
a	O
DataFrame	B-API
,	O
your	O
function	O
is	O
called	O
on	O
each	O
column	O
.	O

and	O
then	O
you	O
can	O
use	O
apply	O
(	O
you	O
don't	O
have	O
to	O
use	O
`	O
lambda	O
`	O
,	O
BTW	O
):	O
#CODE	O

If	O
you	O
want	O
to	O
apply	O
`	O
upper	O
`	O
to	O
DataFrame	B-API
,	O
you	O
can	O
use	O
pandas.applymap()	O
:	O
#CODE	O

Here's	O
a	O
groupby	B-API
way	O
(	O
and	O
you	O
could	O
do	O
an	O
arbitrary	O
apply	O
rather	O
than	O
sum	O
)	O
#CODE	O

Difference	O
between	O
map	O
,	O
applymap	B-API
and	O
apply	O
methods	O
in	O
Pandas	O

Can	O
you	O
tell	O
me	O
when	O
to	O
use	O
these	O
vectorization	O
methods	O
with	O
basic	O
examples	O
?	O

I	O
see	O
that	O
`	O
map	O
`	O
is	O
a	O
`	O
Series	O
`	O
method	O
whereas	O
the	O
rest	O
are	O
`	O
DataFrame	B-API
`	O
methods	O
.	O

I	O
got	O
confused	O
about	O
`	O
apply	O
`	O
and	O
`	O
applymap	B-API
`	O
methods	O
though	O
.	O

Why	O
do	O
we	O
have	O
two	O
methods	O
for	O
applying	O
a	O
function	O
to	O
a	O
DataFrame	B-API
?	O

Again	O
,	O
simple	O
examples	O
which	O
illustrate	O
the	O
usage	O
would	O
be	O
great	O
!	O

Another	O
frequent	O
operation	O
is	O
applying	O
a	O
function	O
on	O
1D	O
arrays	O
to	O
each	O
column	O
or	O
row	O
.	O

DataFrame	B-API
s	O
apply	O
method	O
does	O
exactly	O
this	O
:	O

so	O
using	O
apply	O
is	O
not	O
necessary	O
.	O

Summing	O
up	O
,	O
`	O
apply	O
`	O
works	O
on	O
a	O
row	O
/	O
column	O
basis	O
of	O
a	O
DataFrame	B-API
,	O
`	O
applymap	B-API
`	O
works	O
element-wise	O
on	O
a	O
DataFrame	B-API
,	O
and	O
`	O
map	O
`	O
works	O
element-wise	O
on	O
a	O
Series	O
.	O

strictly	O
speaking	O
,	O
applymap	B-API
internally	O
is	O
implemented	O
via	O
apply	O
with	O
a	O
little	O
wrap-up	O
over	O
passed	O
function	O
parameter	O
(	O
rougly	O
speaking	O
replacing	O
`	O
func	O
`	O
to	O
`	O
lambda	O
x	O
:	O
[	O
func	O
(	O
y	O
)	O
for	O
y	O
in	O
x	O
]`	O
,	O
and	O
applying	O
column-wise	O
)	O

@USER	O
mentioned	O
that	O
apply	O
works	O
on	O
row	O
/	O
columns	O
,	O
while	O
applymap	B-API
works	O
element-wise	O
.	O

But	O
it	O
seems	O
you	O
can	O
still	O
use	O
apply	O
for	O
element-wise	O
computation	O
....	O

#CODE	O

Good	O
catch	O
with	O
this	O
.	O

The	O
reason	O
this	O
works	O
in	O
your	O
example	O
is	O
because	O
np.sqrt	B-API
is	O
a	O
ufunc	O
,	O
i.e.	O
if	O
you	O
give	O
it	O
an	O
array	O
,	O
it	O
will	O
broadcast	O
the	O
sqrt	O
function	O
onto	O
each	O
element	O
of	O
the	O
array	O
.	O

So	O
when	O
apply	O
pushes	O
np.sqrt	B-API
on	O
each	O
columns	O
,	O
np.sqrt	B-API
works	O
itself	O
on	O
each	O
of	O
the	O
elements	O
of	O
the	O
columns	O
,	O
so	O
you	O
are	O
essentially	O
getting	O
the	O
same	O
result	O
as	O
applymap	B-API
.	O

Adding	O
to	O
the	O
other	O
answers	O
,	O
in	O
a	O
`	O
Series	O
`	O
there	O
are	O
also	O
map	O
and	O
apply	O
.	O

Apply	O
can	O
make	O
a	O
DataFrame	B-API
out	O
of	O
a	O
series	O
;	O
however	O
,	O
map	O
will	O
just	O
put	O
a	O
series	O
in	O
every	O
cell	O
of	O
another	O
series	O
,	O
which	O
is	O
probably	O
not	O
what	O
you	O
want	O
.	O

#CODE	O

Also	O
if	O
I	O
had	O
a	O
function	O
with	O
side	O
effects	O
,	O
such	O
as	O
"	O
connect	O
to	O
a	O
web	O
server	O
"	O
,	O
I'd	O
probably	O
use	O
`	O
apply	O
`	O
just	O
for	O
the	O
sake	O
of	O
clarity	O
.	O

#CODE	O

In	O
Pandas	O
version	O
0.13	O
and	O
greater	O
the	O
index	O
level	O
names	O
are	O
immutable	O
(	O
type	O
`	O
FrozenList	O
`)	O
and	O
can	O
no	O
longer	O
be	O
set	O
directly	O
.	O

You	O
must	O
first	O
use	O
`	O
Index.rename()	O
`	O
to	O
apply	O
the	O
new	O
index	O
level	O
names	O
to	O
the	O
Index	O
and	O
then	O
use	O
`	O
DataFrame.reindex()	B-API
`	O
to	O
apply	O
the	O
new	O
index	O
to	O
the	O
DataFrame	B-API
.	O

Examples	O
:	O

Good	O
improvement	O
.	O

I	O
think	O
``	O
apply	O
(	O
...	O
)``	O
could	O
be	O
achieved	O
more	O
simply	O
by	O
``	O
replace	O
(	O
dir_dict	O
)``	O
.	O

I	O
haven't	O
tested	O
that	O
,	O
but	O
I	O
think	O
that's	O
how	O
replace	O
works	O
.	O

You	O
can	O
apply	O
a	O
function	O
that	O
tests	O
row-wise	O
your	O
`	O
DataFrame	B-API
`	O
for	O
the	O
presence	O
of	O
strings	O
,	O
e.g.	O
,	O
say	O
that	O
`	O
df	O
`	O
is	O
your	O
`	O
DataFrame	B-API
`	O
#CODE	O

and	O
then	O
you	O
apply	O
it	O
row	O
by	O
row	O
.	O

I	O
was	O
able	O
to	O
do	O
this	O
in	O
the	O
DataFrame	B-API
using	O
a	O
lambda	O
function	O
with	O
map	O
(	O
lambda	O
x	O
:	O
x.lower()	O
)	O
.	O

I	O
tried	O
to	O
use	O
a	O
lambda	O
function	O
with	O
pd.series.apply()	B-API
but	O
that	O
didn't	O
work	O
.	O

Also	O
when	O
I	O
try	O
to	O
isolate	O
the	O
column	O
in	O
series	O
with	O
something	O
like	O
series	O
[	O
'	O
A	O
']	O
should	O
it	O
return	O
the	O
index	O
(	O
although	O
I	O
guess	O
this	O
makes	O
sense	O
)	O
because	O
I	O
get	O
a	O
float	O
error	O
even	O
though	O
the	O
values	O
that	O
I	O
want	O
to	O
apply	O
the	O
lower	O
method	O
to	O
are	O
strings	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
.	O

You	O
can	O
also	O
do	O
`	O
groupby	B-API
(	O
...,	O
as_index=False	O
)`	O
,	O
though	O
buggy	O
with	O
apply	O
in	O
0.12	O
,	O
fixed	O
in	O
0.13	O
.	O

To	O
add	O
multiple	O
columns	O
,	O
you	O
could	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
.	O

Make	O
sure	O
the	O
function	O
you	O
apply	O
returns	O
a	O
DataFrame	B-API
with	O
the	O
same	O
index	O
as	O
its	O
input	O
.	O

For	O
example	O
,	O
#CODE	O

Maybe	O
this	O
is	O
not	O
what	O
agg	O
was	O
intended	O
for	O
.	O

Maybe	O
I	O
should	O
be	O
using	O
apply	O
...	O

Note	O
:	O
to	O
force	O
the	O
dtype	B-API
to	O
object	O
(	O
and	O
have	O
mixed	O
dtypes	B-API
,	O
ints	O
and	O
floats	O
,	O
rather	O
than	O
all	O
floats	O
)	O
you	O
can	O
use	O
an	O
apply	O
.	O

I	O
would	O
recommend	O
against	O
this	O
if	O
you're	O
doing	O
any	O
analysis	O
!	O

#CODE	O

You	O
can	O
apply	O
this	O
per	O
column	O
,	O
but	O
much	O
easier	O
just	O
to	O
check	O
the	O
dtype	B-API
.	O
in	O
any	O
event	O
pandas	O
operations	O
exclude	O
non-numeric	O
when	O
needed	O
.	O
what	O
are	O
you	O
trying	O
to	O
do	O
?	O

`	O
ix	O
`	O
index	O
access	O
and	O
`	O
mean	O
`	O
function	O
handle	O
this	O
for	O
you	O
.	O

Fetch	O
the	O
two	O
tuples	O
from	O
`	O
df.ix	B-API
`	O
and	O
apply	O
the	O
mean	O
function	O
to	O
it	O
:	O
non	O
existing	O
keys	O
are	O
returned	O
as	O
nan	O
values	O
,	O
and	O
mean	O
ignores	O
nan	O
values	O
by	O
default	O
:	O
#CODE	O

This	O
answer	O
solves	O
this	O
toy	O
example	O
and	O
will	O
be	O
enough	O
for	O
me	O
to	O
rewrite	O
my	O
actual	O
function	O
,	O
but	O
it	O
does	O
not	O
address	O
how	O
to	O
apply	O
a	O
previously	O
defined	O
function	O
without	O
rewriting	O
it	O
to	O
reference	O
columns	O
.	O

You	O
can	O
go	O
with	O
@USER	O
example	O
,	O
if	O
it's	O
possible	O
for	O
you	O
to	O
rewrite	O
your	O
function	O
.	O

But	O
if	O
you	O
don't	O
want	O
to	O
rewrite	O
your	O
function	O
,	O
you	O
can	O
wrap	O
it	O
into	O
anonymous	O
function	O
inside	O
apply	O
,	O
like	O
this	O
:	O
#CODE	O

would	O
calling	O
pd.to_datetime	B-API
from	O
apply	O
allow	O
for	O
easier	O
parralelization	O
after	O
import	O
or	O
would	O
you	O
still	O
have	O
to	O
manually	O
split	O
up	O
the	O
data	O
frame	O
into	O
N	O
/	O
M	O
parts	O
(	O
N	O
=	O
num	O
rows	O
,	O
M	O
=	O
num	O
logical	O
procs	O
)	O
and	O
execute	O
afterward	O
?	O

I'm	O
really	O
hoping	O
for	O
some	O
of	O
the	O
straightforward	O
parallelization	O
cases	O
pandas	O
gets	O
n_jobs	O
type	O
support	O
that	O
some	O
scikit-learn	O
functions	O
have	O
(	O
like	O
gridsearch	O
)	O
.	O

Use	O
apply	O
:	O
#CODE	O

How	O
about	O
not	O
calling	O
add_area_column	O
if	O
the	O
DataFrane	O
is	O
emtpy	O
?	O

(	O
e.g.	O
Take	O
the	O
`	O
if	O
`	O
out	O
of	O
the	O
`	O
add_area_column	O
`	O
and	O
put	O
it	O
where	O
you	O
would	O
call	O
`	O
apply	O
`)	O

these	O
edge	O
cases	O
for	O
apply	O
are	O
pretty	O
tricky	O
...	O
to	O
fix	O
your	O
issue	O
,	O
don't	O
use	O
apply	O
:	O
df	O
[	O
'	O
width	O
']	O
*	O
df	O
[	O
'	O
height	O
']	O

Use	O
ternary	O
operator	O
in	O
apply	O
function	O
in	O
pandas	O
dataframe	B-API
,	O
without	O
grouping	O
columns	O

How	O
can	O
I	O
use	O
ternary	O
operator	O
in	O
the	O
lambda	O
function	O
within	O
`	O
apply	O
`	O
function	O
of	O
`	O
pandas	O
`	O
dataframe	B-API
?	O

select	O
from	O
hdf5	O
apply	O
function	O
(	O
e.g.	O
mean	O
)	O

I	O
want	O
to	O
combine	O
`	O
MEETING	O
DATE	O
`	O
and	O
`	O
MEETING	O
TIME	O
`	O
into	O
one	O
column	O
.	O
datetime.combine	O
seems	O
to	O
do	O
what	O
I	O
want	O
,	O
however	O
,	O
I	O
need	O
to	O
apply	O
this	O
function	O
column-wise	O
somehow	O
.	O

How	O
can	O
I	O
achieve	O
this	O
?	O

perhaps	O
you	O
could	O
`	O
apply	O
`	O
the	O
function	O
(	O
or	O
anyfunction	O
you	O
want	O
)	O
to	O
MEETING	O
DATE	O
and	O
MEETING	O
TIME	O
#URL	O

You	O
can	O
use	O
apply	O
method	O
,	O
and	O
apply	O
combine	O
like	O
this	O
:	O
#CODE	O

call	O
groupby	B-API
and	O
apply	O
to	O
get	O
the	O
begin	O
and	O
end	O
datetime	O
for	O
every	O
group	O
.	O

Apply	O
Function	O
Along	O
DataFrame	B-API
Index	O

What	O
is	O
the	O
best	O
way	O
to	O
apply	O
a	O
function	O
over	O
the	O
index	O
of	O
a	O
Pandas	O
`	O
DataFrame	B-API
`	O
?	O

And	O
after	O
that	O
you	O
can	O
use	O
pandas.DataFrame.apply	B-API
function	O
,	O
with	O
axis=1	O
(	O
means	O
apply	O
function	O
to	O
each	O
row	O
):	O
#CODE	O

Thanks	O
but	O
its	O
not	O
working	O
,	O
Its	O
throwing	O
a	O
traceback	O
and	O
which	O
says	O
:	O
AttributeError	O
:	O
DictReader	O
instance	O
has	O
no	O
attribute	O
'	O
apply	O
'	O
,	O
is	O
it	O
because	O
i	O
am	O
reading	O
this	O
as	O
a	O
dictonary	O
?	O

@USER	O
oh	O
,	O
it	O
will	O
in	O
0.13	O
-	O
there	O
was	O
a	O
bug	O
in	O
apply	O
maybe	O
.	O

This	O
will	O
be	O
significantly	O
more	O
efficient	O
than	O
an	O
apply	O
or	O
using	O
lists	O
...	O

If	O
you	O
use	O
`	O
apply	O
`	O
on	O
the	O
groupby	B-API
,	O
the	O
function	O
you	O
pass	O
is	O
called	O
on	O
each	O
group	O
,	O
passed	O
as	O
a	O
DataFrame	B-API
.	O

So	O
you	O
can	O
do	O
:	O
#CODE	O

However	O
,	O
this	O
will	O
raise	O
an	O
error	O
if	O
the	O
group	O
doesn't	O
have	O
at	O
least	O
two	O
rows	O
.	O

If	O
you	O
want	O
to	O
exclude	O
groups	O
with	O
fewer	O
than	O
two	O
rows	O
,	O
that	O
could	O
be	O
trickier	O
.	O

I'm	O
not	O
aware	O
of	O
a	O
way	O
to	O
exclude	O
the	O
result	O
of	O
`	O
apply	O
`	O
only	O
for	O
certain	O
groups	O
.	O

You	O
could	O
try	O
filtering	O
the	O
group	O
list	O
first	O
by	O
removing	O
small	O
groups	O
,	O
or	O
return	O
a	O
one-row	O
`	O
nan	O
`	O
-filled	O
DataFrame	B-API
and	O
do	O
`	O
dropna	B-API
`	O
on	O
the	O
result	O
.	O

pandas	O
group	O
by	O
n	O
seconds	O
and	O
apply	O
arbitrary	O
rolling	O
function	O

The	O
accelerometer	O
data	O
is	O
not	O
uniformly	O
sampled	O
,	O
and	O
I	O
want	O
to	O
group	O
data	O
by	O
every	O
10	O
or	O
20	O
or	O
30	O
seconds	O
and	O
apply	O
a	O
custom	O
function	O
to	O
the	O
data	O
group	O
.	O

If	O
the	O
data	O
was	O
uniformly	O
sampled	O
,	O
it	O
would	O
have	O
been	O
easy	O
to	O
apply	O
a	O
rolling	O
function	O
.	O

However	O
,	O
since	O
it	O
is	O
not	O
,	O
I	O
want	O
to	O
apply	O
groupby	B-API
using	O
timestamp	O
interval	O
.	O

However	O
,	O
I	O
cannot	O
figure	O
out	O
how	O
to	O
group	O
by	O
an	O
arbitary	O
number	O
of	O
seconds	O
and	O
then	O
apply	O
a	O
function	O
to	O
it	O
.	O

Or	O
have	O
a	O
look	O
at	O
the	O
resampling-functions	O
here	O
.	O

Maybe	O
you	O
could	O
apply	O
a	O
custom	O
resampling-function	O
instead	O
of	O
using	O
the	O
groupby-method	O
.	O

#CODE	O

yes	O
,	O
this	O
isn't	O
working	O
`	O
df.ix	B-API
[	O
'	O
bar	O
'	O
,	O
'	O
two	O
']`	O
.	O

Or	O
wasn't	O
actually	O
,	O
apparently	O
your	O
code	O
would	O
not	O
work	O
if	O
[	O
'	O
Trial	O
']	O
was	O
already	O
set	O
as	O
an	O
indey	O
when	O
it	O
was	O
run	O
.	O

Strangely	O
enough	O
,	O
after	O
I	O
run	O
you	O
code	O
,	O
df	O
[	O
'	O
Trial	O
']	O
no	O
longer	O
works	O
:(	O
which	O
is	O
a	O
pity	O
because	O
I	O
wanted	O
to	O
do	O
this	O
in	O
order	O
to	O
better	O
apply	O
the	O
same	O
function	O
to	O
multiple	O
trials	O
(	O
I	O
want	O
to	O
downsample	O
all	O
of	O
the	O
measurements	O
in	O
every	O
trial	O
to	O
two	O
-	O
just	O
two	O
)	O
.	O

I	O
know	O
pandas	O
has	O
a	O
resample	O
function	O
,	O
but	O
I	O
have	O
no	O
idea	O
how	O
to	O
apply	O
it	O
to	O
my	O
second-level	O
index	O
while	O
keeping	O
the	O
data	O
in	O
discrete	O
categories	O
based	O
on	O
the	O
first-level	O
index	O
:(	O

if	O
it's	O
relevant	O
that	O
you	O
have	O
Timestamp	O
columns	O
,	O
e.g.	O
you're	O
resampling	O
or	O
something	O
,	O
then	O
be	O
explicit	O
and	O
apply	O
`	O
pd.to_datetime	B-API
`	O
to	O
them	O
for	O
good	O
measure**	O
.	O

#CODE	O

Now	O
just	O
apply	O
usual	O
pandas	O
transformations	O
and	O
delete	O
unneseccary	O
columns	O
:	O
#CODE	O

You	O
can	O
apply	O
a	O
specific	O
function	O
to	O
a	O
specific	O
column	O
by	O
passing	O
in	O
a	O
dict	O
.	O

#CODE	O

you	O
can	O
use	O
apply	O
:	O
#CODE	O

brilliant	O
!	O

I'm	O
still	O
looking	O
at	O
what	O
the	O
combination	O
of	O
apply	O
,	O
lambda	O
,	O
pd.Series	B-API
and	O
stack	O
does	O
,	O
but	O
it	O
works	O
exactly	O
as	O
intended	O
.	O
thanks	O
!	O

Pandas	O
groupby	B-API
apply	O
function	O
that	O
combines	O
some	O
groups	O
but	O
not	O
others	O

I'm	O
using	O
pandas	O
`	O
groupby	B-API
`	O
on	O
my	O
DataFrame	B-API
`	O
df	O
`	O
which	O
has	O
columns	O
`	O
type	O
`	O
,	O
`	O
subtype	O
`	O
,	O
and	O
11	O
others	O
.	O

I'm	O
then	O
calling	O
an	O
`	O
apply	O
`	O
with	O
my	O
`	O
combine_function	O
`	O
(	O
needs	O
a	O
better	O
name	O
)	O
on	O
the	O
groups	O
like	O
:	O
#CODE	O

Have	O
you	O
tried	O
just	O
using	O
an	O
apply	O
?	O

So	O
we	O
can	O
use	O
helper	O
function	O
like	O
this	O
and	O
apply	O
it	O
to	O
each	O
group	O
to	O
get	O
desired	O
results	O
.	O

#CODE	O

When	O
apply	O
a	O
function	O
to	O
a	O
list	O
,	O
it	O
occurs	O
"	O
TypeError	O
:	O
'	O
Int64Index	O
'	O
object	O
is	O
not	O
callable	O
"	O

I	O
have	O
tried	O
on	O
some	O
simple	O
list	O
like	O
:	O
`	O
x	O
=[	O
0	O
,	O
1	O
,	O
2	O
]	O
,	O
titleNot0	O
(	O
x	O
)`	O
.	O

It	O
works	O
.	O

But	O
if	O
I	O
apply	O
the	O
function	O
to	O
the	O
groupby	B-API
,	O
it	O
returns	O
"	O
TypeError	O
"	O
.	O

Please	O
help	O
me	O
to	O
fix	O
it	O
.	O

Thank	O
you	O
!	O

maybe	O
it's	O
because	O
when	O
you	O
apply	O
this	O
to	O
a	O
list	O
`	O
ls	O
[	O
x	O
]`	O
returns	O
an	O
integer	O
,	O
when	O
you	O
apply	O
this	O
to	O
a	O
DataFrame	B-API
,	O
`	O
ls	O
[	O
x	O
]`	O
returns	O
a	O
Series	O
.	O

Use	O
this	O
with	O
a	O
groupby	B-API
apply	O
:	O
#CODE	O

apply	O
a	O
function	O
to	O
a	O
groupby	B-API
function	O

I	O
want	O
to	O
count	O
how	O
many	O
consistent	O
increase	O
,	O
and	O
the	O
difference	O
between	O
the	O
first	O
element	O
and	O
the	O
last	O
element	O
,	O
on	O
a	O
groupby	B-API
.	O

But	O
I	O
can't	O
apply	O
the	O
function	O
on	O
the	O
groupby	B-API
.	O

After	O
groupby	B-API
,	O
is	O
it	O
a	O
list	O
?	O

And	O
also	O
what's	O
the	O
difference	O
between	O
"	O
apply	O
"	O
and	O
"	O
agg	O
"	O
?	O

Sorry	O
,	O
I	O
just	O
touched	O
the	O
python	O
for	O
a	O
few	O
days	O
.	O

#CODE	O

The	O
`	O
apply	O
`	O
method	O
calls	O
`	O
foo	O
`	O
once	O
for	O
every	O
group	O
.	O

It	O
can	O
return	O
a	O
Series	O
or	O
a	O
DataFrame	B-API
with	O
the	O
resulting	O
chunks	O
glued	O
together	O
.	O

It	O
is	O
possible	O
to	O
use	O
`	O
apply	O
`	O
when	O
`	O
foo	O
`	O
returns	O
an	O
object	O
such	O
as	O
a	O
numerical	O
value	O
or	O
string	O
,	O
but	O
in	O
such	O
cases	O
I	O
think	O
using	O
`	O
agg	O
`	O
is	O
preferred	O
.	O

A	O
typical	O
use	O
case	O
for	O
using	O
`	O
apply	O
`	O
is	O
when	O
you	O
want	O
to	O
,	O
say	O
,	O
square	O
every	O
value	O
in	O
a	O
group	O
and	O
thus	O
need	O
to	O
return	O
a	O
new	O
group	O
of	O
the	O
same	O
shape	O
.	O

The	O
`	O
transform	O
`	O
method	O
is	O
also	O
useful	O
in	O
this	O
situation	O
--	O
when	O
you	O
want	O
to	O
transform	O
every	O
value	O
in	O
the	O
group	O
and	O
thus	O
need	O
to	O
return	O
something	O
of	O
the	O
same	O
shape	O
--	O
but	O
the	O
result	O
can	O
be	O
different	O
than	O
that	O
with	O
`	O
apply	O
`	O
since	O
a	O
different	O
object	O
may	O
be	O
passed	O
to	O
`	O
foo	O
`	O
(	O
for	O
example	O
,	O
each	O
column	O
of	O
a	O
grouped	O
dataframe	B-API
would	O
be	O
passed	O
to	O
`	O
foo	O
`	O
when	O
using	O
`	O
transform	O
`	O
,	O
while	O
the	O
entire	O
group	O
would	O
be	O
passed	O
to	O
`	O
foo	O
`	O
when	O
using	O
`	O
apply	O
`	O
.	O
The	O
easiest	O
way	O
to	O
understand	O
this	O
is	O
to	O
experiment	O
with	O
a	O
simple	O
dataframe	B-API
and	O
the	O
generic	O
`	O
foo	O
`	O
.	O
)	O

The	O
`	O
agg	O
`	O
method	O
calls	O
`	O
foo	O
`	O
once	O
for	O
every	O
group	O
,	O
but	O
unlike	O
`	O
apply	O
`	O
it	O
should	O
return	O
a	O
single	O
number	O
per	O
group	O
.	O

The	O
group	O
is	O
aggregated	O
into	O
a	O
value	O
.	O

A	O
typical	O
use	O
case	O
for	O
using	O
`	O
agg	O
`	O
is	O
when	O
you	O
want	O
to	O
count	O
the	O
number	O
of	O
items	O
in	O
the	O
group	O
.	O

you	O
could	O
jus	O
use	O
lambda	O
in	O
apply	O
like	O
that	O
:	O

if	O
you	O
subtract	O
values	O
of	O
a	O
particular	O
cells	O
,	O
there's	O
no	O
difference	O
between	O
agg	O
and	O
apply	O
,	O
they	O
both	O
create	O
a	O
one	O
value	O
for	O
each	O
group	O
#CODE	O

SQL	O
(	O
actually	O
,	O
SQL	O
Server	O
)	O
way	O
would	O
be	O
to	O
use	O
`	O
outer	O
apply	O
`	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
apply	O
it	O
to	O
the	O
"	O
col1	O
"	O
column	O
of	O
a	O
dataframe	B-API
similar	O
to	O
:	O
#CODE	O

@USER	O
:	O
Stay	O
away	O
from	O
`	O
apply	O
`	O
(	O
especially	O
with	O
`	O
lambda	O
`)	O
if	O
you	O
can	O
help	O
it	O
.	O

It	O
is	O
likely	O
to	O
be	O
the	O
slowest	O
solution	O
available	O
.	O

Does	O
this	O
apply	O
it	O
to	O
the	O
columns	O
or	O
rows	O
?	O

I	O
tried	O
df	O
=d	O
f.apply	O
(	O
lambda	O
col	O
:	O
col.interpolate	O
(	O
'	O
linear	O
')	O
,	O
axis=1	O
)	O
,	O
yet	O
it's	O
still	O
not	O
interpolating	O
all	O
the	O
columns	O
.	O

Normally	O
different	O
columns	O
in	O
a	O
pandas	O
DataFrame	B-API
contain	O
different	O
type	O
of	O
information	O
,	O
so	O
an	O
interpolation	O
method	O
may	O
not	O
apply	O
or	O
you	O
may	O
need	O
different	O
methods	O
depending	O
on	O
the	O
data	O
.	O

You	O
can	O
use	O
a	O
combination	O
of	O
groupby	B-API
and	O
apply	O
:	O
#CODE	O

Python	O
Pandas	O
:	O
Using	O
Aggregate	O
vs	O
Apply	O
to	O
define	O
new	O
columns	O

But	O
switching	O
aggregate	O
for	O
apply	O
seems	O
to	O
work	O
.	O

Why	O
does	O
apply	O
work	O
and	O
not	O
aggregte	O
?	O

Good	O
question	O
.	O

Actually	O
,	O
if	O
you	O
define	O
some	O
test	O
function	O
like	O
`	O
def	O
test	O
(	O
x	O
):	O
print	O
x	O
;	O
return	O
x.sum()	O
`	O
and	O
call	O
`	O
aggregate	O
`	O
in	O
both	O
cases	O
,	O
you'll	O
see	O
that	O
in	O
first	O
case	O
`	O
x	O
`	O
is	O
a	O
DataFrame	B-API
and	O
in	O
second	O
case	O
`	O
x	O
`	O
is	O
a	O
Series	O
(	O
and	O
when	O
you	O
call	O
`	O
apply	O
`	O
,	O
it's	O
always	O
DataFrame	B-API
)	O
.	O

I	O
don't	O
have	O
time	O
to	O
dig	O
into	O
the	O
code	O
at	O
the	O
moment	O
,	O
and	O
I'm	O
sure	O
some	O
pandas	O
developers	O
will	O
show	O
up	O
and	O
explain	O
this	O
behaviour	O
:)	O

I	O
have	O
struggled	O
to	O
work	O
out	O
what	O
is	O
going	O
on	O
exactly	O
with	O
these	O
groupby	B-API
operations	O
.	O

As	O
Roman	O
points	O
out	O
,	O
the	O
first	O
argument	O
passed	O
to	O
agg	O
is	O
a	O
series	O
,	O
therefore	O
if	O
you	O
want	O
to	O
agg	O
based	O
on	O
values	O
in	O
multiple	O
columns	O
you	O
have	O
to	O
call	O
the	O
second	O
column	O
in	O
the	O
function	O
based	O
upon	O
the	O
index	O
values	O
of	O
the	O
series	O
that	O
is	O
passed	O
automatically	O
.	O
apply	O
always	O
passes	O
as	O
data	O
frame	O
as	O
he	O
points	O
out	O
.	O

If	O
you	O
want	O
to	O
see	O
some	O
really	O
strange	O
behaviour	O
check	O
out	O
transform	O
,	O
it	O
seems	O
to	O
pass	O
series	O
and	O
dataframes	O
as	O
the	O
first	O
argument	O
to	O
the	O
function	O
.	O

Quite	O
confusing	O
IMO	O

@USER	O
Hayden	O
it	O
sounds	O
like	O
the	O
best	O
approach	O
is	O
just	O
to	O
switch	O
to	O
apply	O
or	O
attempt	O
to	O
use	O
cythonized	O
functions	O
when	O
aggregate()	B-API
fails	O
?	O

Also	O
,	O
I	O
imagine	O
the	O
groupby	B-API
code	O
being	O
'	O
hairy	O
'	O
doesn't	O
mean	O
you	O
think	O
its	O
unreliable	O
?	O

Seems	O
to	O
consistently	O
match	O
results	O
I	O
get	O
in	O
SQL	O
.	O

Thanks	O
.	O

Hm	O
,	O
I	O
can't	O
see	O
other	O
problems	O
in	O
your	O
data	O
besides	O
the	O
lat	O
/	O
long	O
at	O
the	O
moment	O
.	O

You	O
could	O
read	O
the	O
header	O
line	O
and	O
replace	O
lat	O
/	O
long	O
with	O
your	O
approach	O
above	O
,	O
`'	O
LatD	O
'	O
,	O
'	O
LatM	O
'	O
,	O
'	O
LatS	O
'	O
,	O
'	O
LonD	O
'	O
,	O
'	O
LonM	O
'	O
,	O
'	O
LonS	O
'`	O
,	O
read	O
the	O
file	O
from	O
just	O
below	O
the	O
header	O
,	O
using	O
whitespace	O
as	O
a	O
delimiter	O
and	O
apply	O
the	O
previously	O
read	O
and	O
amended	O
header	O
line	O
as	O
an	O
index	O
to	O
the	O
new	O
dataframe	B-API
.	O

Pandas	O
clean	O
column	O
and	O
apply	O
optional	O
multiplier	O

So	O
,	O
you	O
can	O
apply	O
a	O
function	O
to	O
your	O
data	O
frame	O
to	O
do	O
this	O
...	O

#CODE	O

As	O
far	O
as	O
it	O
goes	O
,	O
it	O
looks	O
like	O
`	O
std()	B-API
`	O
is	O
calling	O
`	O
aggregation()	O
`	O
on	O
the	O
`	O
groupby	B-API
`	O
result	O
,	O
and	O
a	O
subtle	O
bug	O
(	O
see	O
here	O
-	O
Python	O
Pandas	O
:	O
Using	O
Aggregate	O
vs	O
Apply	O
to	O
define	O
new	O
columns	O
)	O
.	O

To	O
avoid	O
this	O
,	O
you	O
can	O
use	O
`	O
apply()	B-API
`	O
:	O
#CODE	O

Why	O
does	O
function	O
behavior	O
used	O
within	O
pandas	O
apply	O
change	O
?	O

Now	O
,	O
using	O
`	O
apply	O
`	O
and	O
`	O
to_integer	O
`	O
with	O
`	O
df1	O
`	O
:	O
#CODE	O

But	O
if	O
I	O
apply	O
it	O
to	O
this	O
`	O
df2	O
`	O
:	O
#CODE	O

make	O
dict	O
to	O
apply	O
same	O
function	O
to	O
all	O
columns	O
#CODE	O

@USER	O
yeah	O
,	O
mean	O
`	O
apply	O
`	O
with	O
`	O
count	O
`	O
but	O
you've	O
already	O
added	O
that	O
.	O

Apply	O
SequenceMatcher	O
to	O
DataFrame	B-API

You	O
have	O
to	O
apply	O
a	O
function	O
,	O
not	O
a	O
float	O
which	O
expression	O
`	O
SequenceMatcher	O
(	O
None	O
,	O
str	O
(	O
m.ITEM_NAME_x	O
)	O
,	O
str	O
(	O
m.ITEM_NAME_y	O
))	O
.ratio()	O
`	O
is	O
.	O

Update	O
:	O
I	O
realised	O
what	O
you	O
were	O
actually	O
asking	O
,	O
and	O
I	O
think	O
this	O
ought	O
to	O
be	O
an	O
option	O
in	O
sortlevels	O
,	O
but	O
for	O
now	O
I	O
think	O
you	O
have	O
to	O
reset_index	B-API
,	O
groupby	B-API
and	O
apply	O
:	O
#CODE	O

but	O
it	O
tells	O
me	O
there	O
is	O
no	O
attribute	O
'	O
first	O
'	O
when	O
I	O
apply	O
the	O
same	O
thing	O
to	O
the	O
index	O
.	O

#CODE	O

You	O
could	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
:	O
#CODE	O

The	O
exact	O
usage	O
depends	O
on	O
how	O
you	O
wrote	O
your	O
function	O
`	O
myfun	O
`	O
.	O

Where	O
the	O
column	O
used	O
is	O
static	O
(	O
e.g.	O
always	O
`	O
x	O
`)	O
I	O
write	O
`	O
myfun	O
`	O
to	O
take	O
the	O
full	O
`	O
DataFrame	B-API
`	O
and	O
subset	O
inside	O
the	O
function	O
.	O

However	O
if	O
your	O
function	O
is	O
written	O
to	O
accept	O
a	O
vector	O
(	O
or	O
a	O
pandas	O
`	O
Series	O
`)	O
,	O
you	O
can	O
also	O
select	O
the	O
column	O
and	O
`	O
apply	O
`	O
your	O
function	O
to	O
it	O
:	O
#CODE	O

the	O
way	O
you	O
are	O
making	O
the	O
dataframe	B-API
,	O
the	O
other	O
column	O
is	O
index	O
,	O
pandas	O
apply	O
the	O
functions	O
to	O
columns	O
not	O
the	O
index	O

Your	O
operation	O
doesn't	O
make	O
sense	O
as	O
a	O
DataFrame	B-API
.	O

The	O
index	O
labels	O
in	O
your	O
expected	O
result	O
don't	O
match	O
up	O
with	O
the	O
labels	O
in	O
the	O
original	O
`	O
data	O
`	O
.	O

You'll	O
want	O
to	O
take	O
the	O
Series	O
method	O
and	O
`	O
apply	O
`	O
it	O
to	O
each	O
column	O
in	O
`	O
data	O
`	O
.	O

Apply	O
it	O
to	O
your	O
data	O
set	O
:	O
#CODE	O

I	O
thought	O
apply	O
treated	O
each	O
group	O
as	O
a	O
sub-dataframe	O
,	O
which	O
i	O
can	O
then	O
manipulate	O
and	O
then	O
return	O
.	O

I	O
believe	O
my	O
understanding	O
of	O
the	O
structure	O
is	O
flawed	O
,	O
and	O
I've	O
had	O
trouble	O
finding	O
anything	O
to	O
help	O
correct	O
myself	O
.	O

After	O
running	O
this	O
function	O
,	O
I	O
was	O
hoping	O
to	O
be	O
able	O
to	O
reaccess	O
each	O
subgroup	O
and	O
perform	O
further	O
analysis	O
on	O
it	O
.	O

But	O
I'm	O
curious	O
about	O
the	O
resulting	O
format	O
.	O

After	O
I	O
perform	O
my	O
groupby	B-API
function	O
,	O
I	O
can	O
use	O
the	O
describe()	B-API
function	O
,	O
and	O
it	O
will	O
return	O
a	O
table	O
subindexed	O
by	O
each	O
grouped	O
name	O
,	O
with	O
the	O
statistics	O
.	O

After	O
my	O
apply	O
function	O
,	O
I	O
want	O
to	O
look	O
at	O
the	O
same	O
type	O
of	O
table	O
,	O
but	O
it	O
congests	O
it	O
down	O
to	O
one	O
,	O
with	O
the	O
rows	O
being	O
describe	O
parameters	O
,	O
without	O
the	O
level	O
of	O
group	O
indexing	O

I	O
think	O
there's	O
some	O
alignment	O
magic	O
that	O
happens	O
at	O
the	O
end	O
(	O
rather	O
than	O
just	O
a	O
concat	O
)	O
,	O
often	O
I	O
find	O
groupby	B-API
apply	O
a	O
dark	O
art	O
.	O

@USER	O
:	O
I	O
still	O
don't	O
really	O
understand	O
what	O
you're	O
trying	O
to	O
do	O
,	O
but	O
if	O
you	O
want	O
to	O
"	O
perform	O
further	O
analysis	O
"	O
on	O
each	O
group	O
,	O
why	O
don't	O
you	O
just	O
do	O
*	O
that	O
*	O
analysis	O
in	O
the	O
groupby	B-API
function	O
?	O

That	O
is	O
,	O
make	O
a	O
function	O
that	O
actually	O
does	O
the	O
analysis	O
you	O
want	O
done	O
,	O
and	O
apply	O
that	O
with	O
`	O
groupby	B-API
(	O
...	O
)	O
.apply	B-API
(	O
...	O
)`	O
,	O
so	O
it	O
just	O
returns	O
the	O
results	O
of	O
your	O
analysis	O
.	O

@USER	O
its	O
answered	O
my	O
question	O
about	O
how	O
to	O
add	O
the	O
data	O
I	O
wanted	O
to	O
my	O
DataFrame	B-API
without	O
copying	O
it	O
and	O
possibly	O
messing	O
up	O
the	O
order	O
.	O

I'm	O
still	O
not	O
sure	O
why	O
the	O
`	O
groupby	B-API
`	O
/	O
`	O
apply	O
`	O
is	O
failing	O
when	O
I	O
do	O
it	O
one	O
way	O
and	O
not	O
the	O
other	O
,	O
but	O
it	O
seemed	O
easier	O
to	O
go	O
after	O
the	O
more	O
general	O
question	O
.	O

How	O
do	O
we	O
apply	O
a	O
function	O
to	O
an	O
entire	O
group	O
in	O
pandas	O
and	O
python	O
?	O

How	O
can	O
we	O
apply	O
a	O
function	O
to	O
an	O
entire	O
group	O
in	O
pandas	O
dataframe	B-API
in	O
python	O
?	O

This	O
is	O
the	O
code	O
that	O
I	O
have	O
so	O
far	O
:	O
#CODE	O

Could	O
you	O
be	O
more	O
specific	O
about	O
how	O
`	O
magic_apply	O
`	O
will	O
differ	O
from	O
`	O
apply	O
`	O
?	O

Maybe	O
give	O
an	O
example	O
of	O
`	O
myfunc	O
`	O
?	O

As	O
@USER	O
points	O
out	O
the	O
"	O
magic	O
apply	O
"	O
is	O
simply	O
called	O
...	O
apply	O
.	O

It's	O
a	O
groupby	B-API
method	O
:	O
#CODE	O

Beautiful	O
..	O

I	O
thought	O
something	O
like	O
ix	O
index	O
quarter	O
existed	O
just	O
could	O
not	O
apply	O
it	O
!....	O

Thanks	O
.	O

But	O
how	O
do	O
i	O
apply	O
that	O
formatting	O
to	O
a	O
dataframe	B-API
?	O

like	O
---	O
print	O
dfTotalv3.format	O
(	O
{0	O
}	O
{	O
1	O
}	O
{	O
2	O
:	O
,.	O
2f	O
}	O
{	O
3	O
:	O
,.	O
2f	O
}	O
{	O
4	O
:	O
,.	O
2f	O
}	O
)	O
or	O
how	O
could	O
i	O
just	O
format	O
one	O
column	O
by	O
referencing	O
its	O
field	O
name	O
and	O
the	O
format	O
i	O
want	O

see	O
here	O
:	O
#URL	O
you	O
need	O
to	O
set	O
using	O
:	O
``	O
df.loc	B-API
[	O
row	O
,	O
column	O
]	O
=	O
value	O
``	O
,	O
and	O
not	O
chained	O
assignment	O
.	O

In	O
addition	O
,	O
you	O
are	O
better	O
off	O
using	O
a	O
vectorized	O
method	O
or	O
apply	O
if	O
you	O
cannot	O
vectorize	B-API
.	O

Use	O
apply	O
:	O
#CODE	O

Now	O
I	O
apply	O
the	O
cut	O
:	O
`	O
up3	O
=	O
up2	O
[:	O
cut_loc-1	O
]`	O
,	O
which	O
should	O
just	O
shorten	O
the	O
`	O
DataFrame	B-API
`	O
.	O

However	O
,	O
when	O
I	O
go	O
to	O
plot	O
it	O
`	O
up3.plot	O
(	O
x=	O
'	O
Field	O
'	O
,	O
y=	O
'	O
Moment	O
'	O
,	O
color=	O
'	O
red	O
'	O
,	O
label=	O
'	O
Up	O
'`	O
I	O
get	O
the	O
error	O
`'	O
numpy.ndarray	B-API
'	O
object	O
has	O
no	O
attribute	O
'	O
find	O
'`	O

Perhaps	O
not	O
the	O
most	O
fancy	O
way	O
,	O
but	O
you	O
can	O
always	O
`	O
groupby	B-API
`	O
your	O
time	O
frequency	O
and	O
apply	O
a	O
custom	O
function	O
returning	O
what	O
you	O
want	O
.	O

Then	O
groupby	B-API
the	O
month	O
frequency	O
and	O
apply	O
the	O
function	O
:	O
#CODE	O

For	O
example	O
,	O
let's	O
say	O
I'm	O
looking	O
to	O
find	O
and	O
categorize	O
transients	O
using	O
some	O
moving	O
window	O
process	O
(	O
e.g.	O
wavelet	O
analysis	O
)	O
or	O
apply	O
a	O
FIR	O
filter	O
.	O

How	O
do	O
I	O
handle	O
the	O
boundaries	O
,	O
either	O
at	O
the	O
end	O
or	O
beginning	O
of	O
a	O
file	O
or	O
at	O
chunk	O
boundaries	O
?	O

I	O
would	O
like	O
the	O
data	O
to	O
appear	O
as	O
one	O
continuous	O
data	O
set	O
.	O

Based	O
upon	O
the	O
helpful	O
hints	O
I	O
built	O
a	O
iterator	O
that	O
steps	O
over	O
files	O
and	O
returns	O
chunks	O
of	O
arbitrary	O
size	O
---	O
a	O
moving	O
window	O
that	O
hopefully	O
handles	O
file	O
boundaries	O
with	O
grace	O
.	O

I've	O
added	O
the	O
option	O
of	O
padding	O
the	O
front	O
and	O
back	O
of	O
each	O
of	O
the	O
windows	O
with	O
data	O
(	O
overlapping	O
windows	O
)	O
.	O

I	O
can	O
then	O
apply	O
a	O
succession	O
of	O
filters	O
to	O
the	O
overlapping	O
windows	O
and	O
then	O
remove	O
the	O
overlaps	O
at	O
the	O
end	O
.	O

This	O
,	O
I	O
hope	O
,	O
gives	O
me	O
continuity	O
.	O

This	O
can	O
very	O
easily	O
get	O
quite	O
complicated	O
.	O

For	O
instance	O
,	O
if	O
you	O
apply	O
an	O
operation	O
that	O
does	O
a	O
reduction	O
that	O
you	O
can	O
fit	O
in	O
memory	O
,	O
Results	O
can	O
simpley	O
be	O
a	O
pandas.Series	B-API
(	O
or	O
Frame	O
)	O
.	O

Hoever	O
,	O

Thanks	O
for	O
your	O
insight	O
.	O

I	O
looked	O
at	O
your	O
ENH	O
module	O
.	O

I	O
built	O
a	O
iterator	O
that	O
steps	O
over	O
the	O
files	O
but	O
that	O
allows	O
for	O
data	O
padding	O
on	O
either	O
end	O
.	O

By	O
overlapping	O
the	O
data	O
chunks	O
,	O
I	O
can	O
apply	O
a	O
filter	O
and	O
then	O
cast	O
aside	O
the	O
padding	O
at	O
the	O
end	O
,	O
thus	O
preserving	O
continuity	O
.	O

You	O
can	O
do	O
this	O
directly	O
with	O
an	O
apply	O
instead	O
of	O
last	O
(	O
and	O
get	O
the	O
-1th	O
row	O
of	O
each	O
group	O
):	O
#CODE	O

But	O
most	O
likely	O
you	O
can	O
do	O
a	O
transform	O
or	O
apply	O
(	O
depending	O
on	O
what	O
something	O
is	O
):	O
#CODE	O

Thanks	O
-	O
the	O
refactor	O
makes	O
sense	O
.	O

Couldn't	O
figure	O
out	O
the	O
transform	O
apply	O
approach	O
when	O
I	O
looked	O
into	O
it	O
at	O
first	O
.	O

I	O
was	O
hoping	O
there	O
was	O
some	O
nice	O
syntactic	O
sugar	O
.	O

@USER	O
you	O
need	O
something	O
to	O
be	O
a	O
function	O
for	O
transform	O
/	O
apply	O
,	O
worth	O
checking	O
out	O
the	O
docs	O
:	O
#URL	O

@USER	O
completely	O
depends	O
on	O
the	O
something	O
whether	O
or	O
not	O
you	O
can	O
do	O
apply	O
/	O
transform	O
!	O

:)	O

I'll	O
give	O
this	O
the	O
check	O
mark	O
because	O
it's	O
taught	O
me	O
quite	O
a	O
bit	O
.	O

But	O
it	O
still	O
seems	O
odd	O
to	O
me	O
that	O
there	O
isn't	O
a	O
more	O
natural	O
way	O
to	O
do	O
this	O
with	O
groupby	B-API
.	O

For	O
example	O
,	O
I	O
get	O
weird	O
behavior	O
if	O
I	O
take	O
the	O
original	O
dataframe	B-API
and	O
try	O
:	O
`	O
df.sort	O
([	O
'	O
date	O
'])	O
.groupby	B-API
([	O
'	O
ticker	O
'])	O
.transform	B-API
(	O
lambda	O
x	O
:	O
x.diff()	O
)`	O
I	O
would	O
have	O
hoped	O
pandas	O
would	O
be	O
able	O
to	O
figure	O
out	O
that	O
it	O
should	O
ignore	O
text	O
columns	O
and	O
then	O
apply	O
the	O
diff	O
function	O
to	O
the	O
numerical	O
columns	O
.	O

In	O
general	O
,	O
is	O
there	O
a	O
way	O
to	O
use	O
a	O
different	O
function	O
per	O
column	O
in	O
`	O
transform	O
`	O
(	O
like	O
you	O
can	O
with	O
`	O
agg	O
`)	O
?	O

This	O
will	O
accomplish	O
everything	O
I	O
want	O
.	O

And	O
what	O
I	O
really	O
like	O
is	O
that	O
it	O
can	O
be	O
generalized	O
to	O
cases	O
where	O
you	O
want	O
to	O
apply	O
a	O
function	O
more	O
intricate	O
than	O
`	O
diff	O
`	O
.	O

In	O
particular	O
,	O
you	O
could	O
do	O
things	O
like	O
`	O
lambda	O
x	O
:	O
pd.rolling_mean	B-API
(	O
x	O
,	O
20	O
,	O
20	O
)`	O
to	O
make	O
a	O
column	O
of	O
rolling	O
means	O
where	O
you	O
don't	O
need	O
to	O
worry	O
about	O
each	O
ticker's	O
data	O
being	O
corrupted	O
by	O
that	O
of	O
any	O
other	O
ticker	O
(	O
`	O
groupby	B-API
`	O
takes	O
care	O
of	O
that	O
for	O
you	O
...	O
)	O
.	O

Then	O
how	O
do	O
I	O
apply	O
clustering	O
to	O
this	O
to	O
determine	O
a	O
cut-off	O
threshold	O
?	O

I	O
think	O
methods	O
with	O
apply	O
are	O
going	O
to	O
need	O
some	O
annoying	O
sorting	O
at	O
the	O
end	O
...	O

:	O
s	O

Say	O
my	O
dataframe	B-API
had	O
two	O
values	O
columns	O
:	O
value_1	O
and	O
value_2	O
.	O

I	O
can	O
do	O
:	O
`	O
diffs_df	O
=	O
data3.groupby	O
([	O
'	O
ticker	O
'])	O
[[	O
'	O
value_1	O
'	O
,	O
'	O
value_2	O
']]	O
.transform	B-API
(	O
lambda	O
x	O
:	O
x.diff()	O
)`	O
and	O
that	O
works	O
fine	O
.	O

But	O
`	O
diffs_df	O
=	O
data3.groupby	O
([	O
'	O
ticker	O
'])	O
[[	O
'	O
value_1	O
'	O
,	O
'	O
value_2	O
']]	O
.transform	B-API
(	O
pd.DataFrame.diff	B-API
)`	O
blows	O
chunks	O
.	O

So	O
is	O
it	O
correct	O
to	O
say	O
that	O
`	O
transform	O
`	O
always	O
operates	O
on	O
a	O
series	O
(	O
even	O
if	O
it	O
means	O
it	O
has	O
to	O
work	O
on	O
multiple	O
series	O
in	O
succession	O
)	O
,	O
while	O
`	O
apply	O
`	O
works	O
on	O
multiple	O
series	O
all	O
at	O
once	O
as	O
a	O
DataFrame	B-API
?	O

What	O
determines	O
the	O
type	O
of	O
object	O
passed	O
to	O
the	O
function	O
...	O

is	O
it	O
the	O
#	O
of	O
columns	O
,	O
or	O
is	O
it	O
`	O
transform	O
`	O
vs	O
`	O
apply	O
`	O
,	O
or	O
is	O
it	O
`	O
[	O
'	O
colname	O
']`	O
vs	O
`	O
[[	O
'	O
colname	O
']]`	O
?	O

What	O
Pandas	O
data	O
type	O
is	O
passed	O
to	O
transform	O
or	O
apply	O
in	O
a	O
groupby	B-API

Is	O
there	O
any	O
way	O
to	O
force	O
transform	O
to	O
pass	O
the	O
multi-column	O
dataframe	B-API
(	O
i.e.	O
not	O
the	O
individual	O
series	O
from	O
the	O
columns	O
)	O
to	O
the	O
function	O
?	O

I	O
basically	O
want	O
the	O
same	O
behavior	O
of	O
`	O
apply	O
(	O
my_func	O
,	O
axis	O
=1	O
)`	O
but	O
forcing	O
it	O
to	O
return	O
a	O
result	O
with	O
the	O
same	O
index	O
(	O
i.e.	O
what	O
transform	O
is	O
supposed	O
to	O
do	O
,	O
but	O
rather	O
than	O
working	O
column	O
by	O
column	O
,	O
I	O
want	O
to	O
be	O
able	O
to	O
access	O
multiple	O
columns	O
at	O
the	O
same	O
time	O
)	O
.	O

On	O
the	O
Left	O
Hand	O
Side	O
,	O
we	O
get	O
the	O
new	O
column	O
names	O
from	O
the	O
keys	O
of	O
the	O
element	O
of	O
the	O
stats	O
column	O
.	O

Each	O
element	O
in	O
the	O
stats	O
column	O
is	O
a	O
dictionary	O
.	O

So	O
we	O
are	O
doing	O
a	O
bulk	O
assign	O
.	O

On	O
the	O
Right	O
Hand	O
Side	O
,	O
we	O
break	O
up	O
the	O
'	O
stats	O
'	O
column	O
using	O
apply	O
to	O
make	O
a	O
data	O
frame	O
out	O
of	O
each	O
key	O
/	O
value	O
pair	O
.	O

Does	O
such	O
a	O
function	O
exist	O
?	O

If	O
I	O
build	O
my	O
own	O
function	O
,	O
how	O
can	O
I	O
apply	O
it	O
to	O
the	O
DataFrame	B-API
columns	O
?	O

Pandas	O
apply	O
to	O
data	O
frame	O
groupby	B-API

If	O
I	O
groupby	B-API
(	O
g	O
object	O
below	O
)	O
and	O
then	O
apply	O
following	O
function	O
to	O
first	O
1000	O
rows	O
of	O
df	O
,	O
it	O
works	O
.	O

But	O
if	O
I	O
apply	O
it	O
to	O
entire	O
df	O
,	O
I	O
get	O
this	O
exception	O
:	O
#CODE	O

First	O
reset	O
the	O
index	O
,	O
then	O
group	O
and	O
apply	O
.	O

You	O
can	O
recover	O
your	O
original	O
index	O
by	O
then	O
setting	O
the	O
index	O
at	O
the	O
end	O
.	O

The	O
reset	O
index	O
is	O
turned	O
into	O
a	O
column	O
called	O
'	O
index	O
'	O
(	O
which	O
set_index	B-API
then	O
drops	O
)	O
.	O

And	O
there's	O
always	O
`	O
apply	O
`	O
:	O
#CODE	O

In	O
pandas	O
0.13	O
(	O
in	O
development	O
)	O
this	O
is	O
fixed	O
(	O
#URL	O
)	O
.	O

It	O
is	O
for	O
this	O
reason	O
the	O
`	O
as_index=False	O
`	O
is	O
used	O
in	O
the	O
groupby	B-API
call	O
,	O
so	O
the	O
column	O
`	O
L1	O
`	O
(	O
fow	O
which	O
you	O
group	O
)	O
is	O
not	O
added	O
to	O
the	O
index	O
(	O
creating	O
a	O
MultiIndex	O
)	O
,	O
so	O
the	O
original	O
index	O
is	O
retained	O
and	O
the	O
result	O
can	O
be	O
appended	O
to	O
the	O
original	O
frame	O
.	O

But	O
it	O
seems	O
the	O
`	O
as_index	O
`	O
keyword	O
is	O
ignored	O
in	O
0.12	O
when	O
using	O
`	O
apply	O
`	O
.	O

@USER	O
Ah	O
,	O
yes	O
,	O
indeed	O
this	O
does	O
also	O
work	O
.	O

But	O
with	O
`	O
apply	O
`	O
it	O
doesn't	O
.	O

Do	O
you	O
know	O
what	O
is	O
the	O
difference	O
in	O
this	O
case	O
between	O
both	O
?	O

The	O
answer	O
of	O
@USER	O
is	O
indeed	O
the	O
solution	O
to	O
your	O
question	O
,	O
although	O
I	O
think	O
you	O
misunderstand	O
the	O
groupby	B-API
.	O

You	O
still	O
need	O
to	O
apply	O
a	O
function	O
or	O
aggregation	O
on	O
the	O
`	O
groupby()	B-API
`	O
call	O
,	O
in	O
your	O
case	O
to	O
sum	O
all	O
items	O
in	O
a	O
group	O
`	O
data.groupby	O
(	O
..	O
)	O
.sum()	B-API
`	O
.	O

I	O
have	O
a	O
dataframe	B-API
which	O
I	O
want	O
to	O
split	O
into	O
5	O
chunks	O
(	O
more	O
generally	O
n	O
chunks	O
)	O
,	O
so	O
that	O
I	O
can	O
apply	O
a	O
groupby	B-API
on	O
the	O
chunks	O
.	O

then	O
in	O
the	O
apply	O
,	O
do	O
your	O
calculation	O
,	O
which	O
in	O
this	O
case	O
is	O
another	O
groupby	B-API
.	O

#CODE	O

For	O
filling	O
the	O
NaNs	O
,	O
you	O
can	O
apply	O
this	O
on	O
all	O
columns	O
in	O
one	O
line	O
as	O
follows	O
:	O
#CODE	O

Glad	O
I	O
could	O
help	O
!	O

Most	O
functions	O
on	O
Serieses	O
you	O
can	O
also	O
apply	O
on	O
a	O
DataFrame	B-API
,	O
and	O
if	O
you	O
can't	O
,	O
you	O
can	O
always	O
apply	O
a	O
Series	O
functions	O
on	O
all	O
columns	O
at	O
once	O
like	O
this	O
:	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
x.seriesmethod()	O
)`	O

However	O
I	O
wish	O
to	O
plot	O
create	O
a	O
facet-wrapped	O
histogram	O
,	O
and	O
have	O
each	O
facet	O
share	O
the	O
same	O
xlim	O
.	O

The	O
command	O
I	O
use	O
seems	O
to	O
apply	O
the	O
xlim	O
only	O
to	O
the	O
last	O
of	O
the	O
facets	O
.	O

(	O
Also	O
you	O
can	O
see	O
that	O
the	O
labels	O
are	O
applied	O
to	O
the	O
last	O
of	O
the	O
facets	O
only	O
)	O
.	O

Is	O
there	O
a	O
way	O
to	O
specificy	O
a	O
global	O
xlim	O
?	O

(	O
And	O
global	O
labels	O
)	O
?	O

@USER	O
apply	O
answer	O
from	O
question	O
then	O
"	O
1	O
"	O
the	O
found	O
rectangle	O
and	O
recurse	O
.	O

If	O
you	O
do	O
not	O
want	O
to	O
add	O
a	O
column	O
to	O
your	O
original	O
DataFrame	B-API
,	O
you	O
could	O
create	O
an	O
independent	O
`	O
Series	O
`	O
and	O
apply	O
the	O
`	O
groupby	B-API
`	O
method	O
to	O
the	O
`	O
Series	O
`	O
instead	O
:	O
#CODE	O

Apply	O
function	O
to	O
sets	O
of	O
columns	O
in	O
pandas	O
,	O
'	O
looping	O
'	O
over	O
entire	O
data	O
frame	O
column-wise	O

I	O
have	O
tried	O
using	O
`	O
df.groupby	B-API
`	O
and	O
`	O
df.filter	B-API
`	O
to	O
loop-over	O
the	O
columns	O
but	O
I	O
cannot	O
really	O
get	O
it	O
to	O
work	O
,	O
because	O
I	O
am	O
not	O
at	O
all	O
sure	O
how	O
I	O
apply	O
effectively	O
the	O
same	O
function	O
to	O
chunks	O
of	O
the	O
data-frame	O
,	O
all	O
in	O
one	O
go	O
(	O
as	O
apparently	O
one	O
is	O
to	O
avoid	O
looping	O
over	O
rows	O
)	O
.	O

I	O
have	O
tried	O
doing	O
#CODE	O

Note	O
:	O
I	O
am	O
a	O
bit	O
frustrated	O
that	O
I	O
needed	O
to	O
thrown	O
in	O
the	O
two	O
transposes	O
.	O

I	O
just	O
couldn't	O
get	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
to	O
play	O
nicely	O
with	O
`	O
axis=1	O
`	O
.	O

If	O
someone	O
could	O
show	O
me	O
how	O
to	O
do	O
that	O
,	O
I'd	O
be	O
very	O
grateful	O
.	O

The	O
trick	O
here	O
was	O
knowing	O
that	O
when	O
you	O
call	O
`	O
groupby	B-API
(	O
lambda	O
x	O
:	O
f	O
(	O
x	O
))`	O
that	O
`	O
x	O
`	O
is	O
the	O
value	O
of	O
the	O
index	O
for	O
each	O
row	O
.	O

So	O
`	O
groupby	B-API
(	O
lambda	O
x	O
:	O
x	O
[	O
0	O
])`	O
groups	O
by	O
the	O
first	O
letter	O
of	O
the	O
row	O
index	O
.	O

After	O
doing	O
the	O
transposition	O
,	O
this	O
was	O
`	O
A	O
`	O
or	O
`	O
B	O
`	O
.	O

Thanks	O
@USER	O
yeah	O
i	O
kind	O
of	O
got	O
your	O
logic	O
to	O
work	O
in	O
my	O
dataset	O
.	O

I	O
am	O
having	O
a	O
couple	O
of	O
problems	O
though	O
.	O

One	O
is	O
I	O
only	O
wanted	O
to	O
get	O
the	O
mean	O
of	O
the	O
next	O
rows	O
that	O
relate	O
to	O
the	O
same	O
group	O
.	O

i.e.	O
i	O
need	O
to	O
apply	O
a	O
groupby	B-API
to	O
your	O
example	O
in	O
my	O
case	O
it	O
would	O
be	O
by	O
'	O
Country	O
'	O

However	O
,	O
when	O
I	O
do	O
`	O
apply	O
`	O
,	O
I'm	O
getting	O
dataframes	O
only	O
:	O
#CODE	O

Internally	O
,	O
`	O
apply	O
`	O
and	O
`	O
filter	O
`	O
try	O
different	O
ways	O
of	O
looping	O
through	O
the	O
data	O
:	O
a	O
"	O
slow	O
path	O
"	O
that	O
is	O
sure	O
to	O
work	O
for	O
any	O
function	O
,	O
and	O
a	O
"	O
fast	O
path	O
"	O
that	O
only	O
works	O
for	O
some	O
functions	O
.	O

These	O
paths	O
can	O
operate	O
on	O
whole	O
chucks	O
of	O
the	O
data	O
(	O
as	O
a	O
DataFrame	B-API
)	O
or	O
one	O
row	O
at	O
a	O
time	O
(	O
as	O
Series	O
)	O
.	O

Thanks	O
@USER	O
.	O

The	O
problem	O
is	O
,	O
after	O
the	O
`	O
apply	O
(	O
f	O
)`	O
,	O
I	O
cannot	O
do	O
something	O
like	O
`	O
nth	O
(	O
1	O
)`	O
to	O
return	O
the	O
2nd	O
value	O
of	O
each	O
group	O
.	O

Any	O
ideas	O
?	O

In	O
other	O
words	O
,	O
the	O
following	O
fails	O
:	O
`	O
dd.groupby	O
(	O
'	O
user_id	O
')	O
.apply	B-API
(	O
f	O
)	O
.nth	B-API
(	O
1	O
)	O
.dropna	B-API
(	O
how=	O
'	O
all	O
')`	O

in	O
``	O
f	O
``	O
you	O
could	O
do	O
``	O
x.head	O
(	O
2	O
)	O
.tail	B-API
(	O
1	O
)``	O
to	O
do	O
that	O
(	O
you	O
could	O
also	O
do	O
``	O
x.iloc	O
[	O
1	O
]``	O
,	O
but	O
if	O
you	O
have	O
a	O
groupsize	O
<	O
2	O
that	O
will	O
fail	O
.	O
alternatively	O
,	O
you	O
can	O
do	O
a	O
second	O
group	O
/	O
apply	O
(	O
``	O
nth	O
``	O
is	O
a	O
groupby	B-API
operation	O
)	O
,	O
e.g.	O
``	O
dd.gropuby	O
(	O
'	O
user_id	O
')	O
.apply	B-API
(	O
f	O
)	O
.gropuby	O
(	O
'	O
user_id	O
')	O
.nth	B-API
(	O
1	O
)``	O

Hence	O
how	O
do	O
I	O
get	O
my	O
function	O
to	O
apply	O
to	O
the	O
data	O
frame	O
in	O
a	O
row-wise	O
fashion	O
?	O

I	O
do	O
step	O
1	O
once	O
,	O
then	O
repeat	O
step	O
2-3	O
many	O
(	O
~100	O
)	O
times	O
.	O

In	O
the	O
future	O
I	O
may	O
need	O
to	O
pre-process	O
`	O
emission	O
`	O
(	O
apply	O
`	O
cumsum	B-API
`	O
or	O
other	O
functions	O
)	O
before	O
computing	O
`	O
counts	O
`	O
.	O

@USER	O
:	O
That's	O
odd	O
.	O

I	O
just	O
tested	O
this	O
on	O
`	O
pd.concat	B-API
([	O
data	O
]	O
*1000	O
)`	O
and	O
found	O
`	O
str.contains	B-API
`	O
to	O
be	O
2x	O
slower	O
than	O
`	O
apply	O
(	O
lambda	O
x	O
:	O
'	O
Fruit	O
'	O
in	O
x	O
)`	O
.	O

Perhaps	O
my	O
version	O
`	O
0.12.0-933-g281dc4e	O
`	O
is	O
too	O
old	O
?	O

And	O
then	O
set	O
it	O
as	O
the	O
index	O
,	O
groupby	B-API
on	O
`	O
[	O
'	O
Code	O
'	O
,	O
'	O
ID	O
']`	O
and	O
then	O
apply	O
a	O
`	O
resample	O
`	O
on	O
each	O
group	O
:	O
#CODE	O

in	O
a	O
pandas	O
dataframe	B-API
how	O
can	O
I	O
apply	O
a	O
sort	O
of	O
excel	O
left	O
(	O
'	O
state	O
'	O
,	O
2	O
)	O
to	O
only	O
take	O
the	O
first	O
two	O
letters	O
.	O

Ideally	O
I	O
want	O
to	O
learn	O
how	O
to	O
use	O
left	O
,	O
right	O
and	O
mid	O
in	O
a	O
dataframe	B-API
too	O
.	O

So	O
need	O
an	O
equivalent	O
and	O
not	O
a	O
"	O
trick	O
"	O
for	O
this	O
specific	O
example	O
.	O

#CODE	O

For	O
last	O
two	O
that	O
would	O
be	O
`	O
df	O
[	O
'	O
state	O
']	O
.str	B-API
[	O
-2	O
:]	O
`	O
.	O

Don't	O
know	O
what	O
exactly	O
you	O
want	O
for	O
middle	O
,	O
but	O
you	O
can	O
apply	O
arbitrary	O
function	O
to	O
a	O
column	O
with	O
`	O
apply	O
`	O
method	O
:	O
#CODE	O

I	O
have	O
another	O
example	O
where	O
i	O
am	O
try	O
to	O
apply	O
the	O
first	O
two	O
digits	O
of	O
an	O
8	O
digit	O
number	O
.	O
then	O
i	O
get	O
the	O
error	O
.	O

'	O
invalid	O
index	O
to	O
scalar	O
variable	O
'	O
how	O
can	O
i	O
apply	O
the	O
above	O
to	O
take	O
the	O
last	O
2	O
numbers	O
in	O
'	O
year	O
'	O
?	O

Basically	O
,	O
there's	O
no	O
need	O
to	O
apply	O
the	O
set	O
of	O
functions	O
to	O
the	O
two	O
groups	O
separately	O
and	O
append	O
the	O
results	O
together	O
.	O

That's	O
essentially	O
what	O
group	O
by	O
is	O
doing	O
:	O
split	O
,	O
apply	O
(	O
separately	O
)	O
and	O
combine	O
.	O

I	O
have	O
tried	O
to	O
look	O
at	O
Pandas	O
`	O
apply	O
`	O
and	O
`	O
groupby	B-API
`	O
methods	O
,	O
but	O
can	O
not	O
come	O
up	O
with	O
something	O
that	O
generates	O
the	O
desired	O
overlapping	O
groups	O
.	O

thanks	O
but	O
how	O
do	O
I	O
apply	O
that	O
to	O
a	O
dataframe	B-API
.	O

when	O
apply	O
this	O
concept	O
to	O
my	O
larger	O
working	O
file	O
I	O
seem	O
to	O
lose	O
the	O
order	O
of	O
my	O
columns	O
.	O

so	O
month	O
comes	O
before	O
product	O
and	O
month10	O
comes	O
before	O
month2	O
etc	O
.	O
why	O
would	O
this	O
happen	O
or	O
rather	O
how	O
can	O
i	O
avoid	O
losing	O
my	O
shape	O
?	O

"	O
Google	O
or	O
learn	O
"	O
is	O
a	O
generic	O
attitude	O
that	O
could	O
apply	O
to	O
all	O
forums	O
,	O
especially	O
Q&	O
A-style	O
forums	O
.	O

However	O
,	O
I'm	O
obviously	O
here	O
for	O
a	O
reason	O
.	O

"	O
Vote	O
Down	O
requires	O
125	O
reputation	O
.	O

"	O

Perfect	O
for	O
what	O
I	O
wanted	O
.	O

I	O
just	O
needed	O
to	O
understand	O
how	O
to	O
apply	O
the	O
string	O
operations	O
to	O
the	O
dataframes	O
/	O
series	O
,	O
but	O
I	O
guess	O
that's	O
as	O
simple	O
as	O
it	O
is	O
for	O
strings	O
.	O

For	O
row	O
[	O
0	O
]	O
-	O
row	O
[	O
0	O
]	O
.capwords()	O
should	O
solve	O
several	O
problems	O
at	O
once	O
,	O
I	O
expect	O
!	O

I	O
have	O
tried	O
`	O
apply	O
(	O
lambda	O
x	O
:	O
set	O
(	O
x	O
))`	O
but	O
it	O
only	O
works	O
on	O
individual	O
lists	O
as	O
opposed	O
to	O
the	O
entire	O
column	O
.	O

this	O
will	O
raise	O
starting	O
in	O
0.13	O
,	O
you	O
need	O
to	O
``	O
apply	O
``	O
to	O
your	O
groupby	B-API
to	O
get	O
back	O
a	O
dataframe	B-API
,	O
see	O
:	O
#URL	O

I	O
would	O
like	O
to	O
use	O
the	O
`	O
pandas.rolling_apply	B-API
`	O
function	O
to	O
apply	O
my	O
own	O
custom	O
function	O
on	O
a	O
rolling	O
window	O
basis	O
.	O

I	O
have	O
run	O
into	O
,	O
what	O
I	O
think	O
,	O
is	O
a	O
fairly	O
simple	O
problem	O
yet	O
again	O
.	O

I	O
would	O
like	O
to	O
apply	O
the	O
following	O
function	O
to	O
a	O
pandas	O
data	O
frame	O
.	O

#CODE	O

In	O
general	O
,	O
it's	O
better	O
to	O
avoid	O
looping	O
over	O
your	O
frame's	O
rows	O
,	O
if	O
you	O
can	O
avoid	O
it	O
.	O

If	O
I	O
understand	O
your	O
problem	O
correctly	O
,	O
you	O
want	O
to	O
look	O
at	O
a	O
single	O
column	O
from	O
your	O
frame	O
,	O
and	O
apply	O
a	O
function	O
on	O
each	O
element	O
of	O
that	O
column	O
.	O

Then	O
you	O
want	O
to	O
put	O
the	O
result	O
of	O
all	O
those	O
function	O
calls	O
into	O
a	O
column	O
of	O
the	O
original	O
frame	O
.	O

Maybe	O
a	O
new	O
column	O
,	O
maybe	O
in	O
place	O
of	O
the	O
old	O
column	O
.	O

This	O
sounds	O
like	O
a	O
job	O
for	O
`	O
pd.Series.map	B-API
`	O
.	O

#CODE	O

And	O
now	O
,	O
instead	O
of	O
`	O
value_counts()	B-API
`	O
,	O
use	O
`	O
apply	O
(	O
f	O
)`	O
.	O

Here	O
is	O
an	O
example	O
:	O
#CODE	O

Furthermore	O
,	O
you	O
normally	O
don't	O
need	O
to	O
'	O
iterate	O
over	O
the	O
df	O
'	O
as	O
you	O
do	O
here	O
.	O

To	O
apply	O
a	O
function	O
to	O
all	O
groups	O
,	O
you	O
can	O
do	O
that	O
directly	O
on	O
the	O
groupby	B-API
result	O
,	O
eg	O
`	O
df.groupby()	B-API
.apply	B-API
(	O
..	O
)`	O
or	O
`	O
df.groupby()	B-API
.aggregate	B-API
(	O
..	O
)`	O
.	O

Can	O
you	O
give	O
a	O
more	O
specific	O
example	O
of	O
what	O
kind	O
of	O
function	O
you	O
want	O
to	O
apply	O
to	O
the	O
ratios	O
?	O

`	O
data	O
[	O
'	O
ID	O
']`	O
will	O
give	O
you	O
the	O
`	O
ID	O
`	O
column	O
,	O
so	O
you	O
cannot	O
use	O
it	O
as	O
a	O
key	O
.	O

You	O
want	O
one	O
specific	O
value	O
of	O
that	O
column	O
.	O

To	O
apply	O
a	O
function	O
on	O
each	O
row	O
of	O
a	O
dataframe	B-API
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

You	O
can	O
apply	O
an	O
`	O
expanding_mean	B-API
`	O
(	O
see	O
docs	O
)	O
to	O
each	O
group	O
:	O
#CODE	O

I	O
tried	O
using	O
"	O
apply	O
"	O
but	O
I	O
can't	O
figure	O
out	O
how	O
to	O
return	O
a	O
correct	O
data	O
frame	O
.	O

For	O
example	O
#CODE	O

Apply	O
that	O
function	O
to	O
the	O
rows	O
:	O
#CODE	O

The	O
problem	O
is	O
that	O
you	O
are	O
concatenating	O
a	O
pandas	O
Series	O
`	O
Fx	O
[	O
'	O
File	O
']`	O
with	O
the	O
string	O
representation	O
of	O
a	O
pandas	O
Series	O
`	O
str	O
(	O
Fx	O
[	O
'	O
Date	O
'])`	O
,	O
what	O
you	O
need	O
to	O
do	O
is	O
apply	O
the	O
`	O
str	O
`	O
cast	O
function	O
to	O
the	O
elements	O
of	O
`	O
Fx	O
[	O
'	O
Date	O
']`	O
like	O
this	O
:	O
#CODE	O

First	O
,	O
groupby	B-API
code	O
and	O
colour	O
and	O
then	O
apply	O
a	O
customized	O
function	O
to	O
format	O
id	O
and	O
amount	O
:	O
#CODE	O

Apply	O
read_csv	B-API
instead	O
of	O
read_clipboard	B-API
to	O
handle	O
your	O
actual	O
data	O
:	O
#CODE	O

I	O
guess	O
you	O
are	O
assuming	O
that	O
you	O
can	O
select	O
stuff	O
within	O
the	O
groupby	B-API
object	O
.	O

As	O
far	O
as	O
I	O
know	O
,	O
you	O
can't	O
.	O

But	O
you	O
can	O
do	O
that	O
in	O
the	O
resulting	O
object	O
,	O
after	O
you	O
apply	O
your	O
aggregation	O
function	O
.	O

I'd	O
like	O
to	O
show	O
the	O
scatter	O
plots	O
with	O
data	O
points	O
for	O
one	O
group	O
of	O
data	O
,	O
let's	O
say	O
,	O
in	O
green	O
and	O
the	O
other	O
group	O
in	O
red	O
in	O
the	O
very	O
same	O
scatter	O
matrix	O
.	O

The	O
same	O
should	O
apply	O
for	O
the	O
density	O
plots	O
on	O
the	O
diagonal	O
.	O

How	O
to	O
apply	O
hierarchy	O
or	O
multi-index	O
to	O
panda	O
columns	O

You	O
never	O
mentioned	O
you	O
had	O
single	O
unpaired	O
Series	O
(	O
es	O
)	O
instead	O
of	O
a	O
DataFrame	B-API
.	O

You	O
need	O
to	O
provide	O
an	O
example	O
that's	O
faithful	O
to	O
your	O
context	O
so	O
that	O
our	O
solutions	O
apply	O
.	O

Can	O
you	O
re-state	O
your	O
problem	O
?	O

Groupby	B-API
`	O
Group	O
`	O
first	O
and	O
then	O
apply	O
your	O
customized	O
function	O
:	O
#CODE	O

@USER	O
Not	O
sure	O
I	O
understand	O
your	O
point	O
.	O

Do	O
you	O
mean	O
that	O
when	O
you	O
use	O
an	O
apply	O
on	O
a	O
groupby	B-API
mapping	O
,	O
you	O
can	O
treat	O
the	O
object	O
received	O
by	O
apply	O
as	O
a	O
portion	O
of	O
the	O
original	O
df	O
?	O

@USER	O
,	O
yes	O
.	O

Series.apply()	B-API
will	O
apply	O
a	O
function	O
to	O
every	O
element	O
of	O
the	O
Series	O
.	O

Every	O
object	O
is	O
a	O
portion	O
of	O
the	O
entire	O
Series	O
.	O

Groupby	B-API
will	O
apply	O
a	O
function	O
to	O
every	O
portion	O
of	O
the	O
DataFrame	B-API
that	O
matches	O
a	O
value	O
in	O
the	O
grouping	O
Series	O
(	O
es	O
)	O
.	O

Together	O
all	O
groups	O
make	O
the	O
whole	O
DataFrame	B-API
.	O

If	O
you	O
wanted	O
this	O
as	O
columns	O
as	O
days	O
of	O
each	O
week	O
,	O
you	O
could	O
do	O
the	O
groupby	B-API
within	O
the	O
apply	O
:	O
#CODE	O

You	O
could	O
use	O
a	O
groupby	B-API
apply	O
for	O
this	O
:	O
#CODE	O

Also	O
using	O
python	O
2.7.5	O
and	O
pandas	O
0.12.0	O
.	O

Also	O
worth	O
mentioning	O
I	O
would	O
like	O
to	O
apply	O
this	O
to	O
datasets	O
of	O
up	O
to	O
1	O
million	O
rows	O
.	O

Forgot	O
to	O
mention	O
this	O
!	O

@USER	O
:	O
Using	O
`	O
apply	O
`	O
to	O
do	O
this	O
with	O
a	O
`	O
lambda	O
`	O
expression	O
is	O
a	O
worse	O
solution	O
than	O
using	O
the	O
builtin	O
`	O
idxmin	B-API
`	O
directly	O
on	O
the	O
transposed	O
data	O
.	O

For	O
one	O
,	O
`	O
idxmin	B-API
`	O
automatically	O
skips	O
NaN	O
.	O

For	O
two	O
,	O
`	O
idxmin	B-API
`	O
is	O
already	O
optimized	O
to	O
function	O
as	O
an	O
array	O
operation	O
,	O
whereas	O
your	O
`	O
lambda	O
`	O
incurs	O
the	O
cost	O
of	O
a	O
function	O
call	O
across	O
the	O
rows	O
,	O
needlessly	O
.	O

For	O
three	O
,	O
relying	O
on	O
the	O
Pandas	O
API	O
preserves	O
the	O
modularity	O
and	O
readability	O
of	O
the	O
code	O
.	O

Reading	O
that	O
`	O
lambda	O
`	O
is	O
needless	O
extra	O
work	O
for	O
anyone	O
using	O
your	O
code	O
.	O

For	O
four	O
,	O
`	O
idxmin	B-API
`	O
is	O
already	O
tested	O
and	O
documented	O
,	O
whereas	O
the	O
`	O
lambda	O
`	O
isn't	O
.	O

python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O
.	O

Update	O

I	O
would	O
like	O
to	O
apply	O
a	O
function	O
with	O
argument	O
to	O
a	O
pandas	O
series	O
:	O
I	O
have	O
found	O
two	O
different	O
solution	O
of	O
SO	O
:	O

python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O

Passing	O
multiple	O
arguments	O
to	O
apply	O
(	O
Python	O
)	O

if	O
you're	O
using	O
pandas	O
and	O
assuming	O
the	O
date	O
are	O
in	O
datetime	O
format	O
,	O
you	O
can	O
group	O
by	O
on	O
'	O
code	O
'	O
and	O
then	O
apply	O
a	O
min	O
,	O
max	O
function	O
to	O
that	O
.	O

@USER	O
thanks	O
!	O

So	O
`	O
apply	O
`	O
gets	O
called	O
once	O
for	O
the	O
column	O
or	O
once	O
per	O
element	O
?	O

`	O
x.astype	O
(	O
float	O
)`	O
is	O
the	O
whole	O
column	O
or	O
just	O
one	O
element	O
?	O
and	O
`	O
x.sum()	O
`	O
is	O
the	O
group	O
by	O
group	O
sum	O
?	O

How	O
do	O
these	O
rules	O
work	O
?	O

:)	O

I	O
just	O
can't	O
make	O
it	O
,	O
no	O
matter	O
what	O
I	O
try	O
(	O
I	O
tried	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
and	O
have	O
it	O
return	O
a	O
tuple	O
,	O
a	O
list	O
,	O
a	O
Series	O
object	O
..	O
neither	O
worked	O
)	O
.	O

I	O
saw	O
that	O
I	O
can	O
create	O
a	O
DataFrame	B-API
and	O
set	O
the	O
dtype	B-API
to	O
'	O
object	O
'	O
and	O
then	O
I	O
can	O
put	O
tuples	O
in	O
a	O
cell	O
.	O

How	O
do	O
I	O
do	O
it	O
with	O
`	O
apply	O
`	O
?	O

@USER	O
you	O
could	O
do	O
a	O
groupy	O
apply	O
to	O
return	O
just	O
those	O
rows	O
...	O

One	O
way	O
to	O
get	O
the	O
desired	O
result	O
is	O
to	O
use	O
an	O
apply	O
e.g.	O
via	O
the	O
following	O
function	O
:	O
#CODE	O

Basically	O
you	O
just	O
have	O
the	O
function	O
that	O
does	O
`	O
row	O
/	O
row.sum()	O
`	O
,	O
and	O
you	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
to	O
apply	O
it	O
by	O
row	O
.	O

Another	O
option	O
is	O
to	O
use	O
div	O
rather	O
than	O
apply	O
:	O
#CODE	O

The	O
problem	O
with	O
the	O
first	O
approach	O
is	O
that	O
I	O
have	O
no	O
way	O
of	O
accessing	O
my	O
categorical	B-API
data	O
(	O
i.e.	O
the	O
`	O
subject	O
`	O
,	O
`	O
stimuli	O
`	O
,	O
and	O
`	O
resp	O
`	O
columns	O
,	O
amongst	O
others	O
I've	O
left	O
out	O
here	O
)	O
,	O
while	O
the	O
problem	O
with	O
the	O
second	O
is	O
that	O
I	O
end	O
up	O
with	O
a	O
`	O
DataFrame	B-API
`	O
thousands	O
of	O
columns	O
wide	O
(	O
and	O
wider	O
again	O
for	O
each	O
transformation	O
I	O
apply	O
:	O
velocity	O
at	O
each	O
step	O
,	O
angle	O
at	O
each	O
step	O
,	O
etc	O
)	O
,	O
and	O
no	O
useful	O
way	O
of	O
accessing	O
specific	O
time	O
serieses	O
(	O
i.e.	O
what	O
I've	O
been	O
currently	O
calling	O
as	O
`	O
data.rx.mean()	O
.plot()	B-API
`	O
.	O

Apply	O
numpy	O
functions	O
to	O
pandas	O
DataFrame	B-API

I	O
have	O
a	O
DataFrame	B-API
where	O
each	O
element	O
is	O
a	O
numpy	O
array	O
and	O
I	O
would	O
like	O
to	O
apply	O
to	O
them	O
numpy	O
functions	O
.	O

now	O
let's	O
try	O
to	O
apply	O
`	O
np.dot	B-API
`	O
along	O
`	O
axis=1	O
`	O

Why	O
doesn't	O
my	O
apply	O
function	O
return	O
the	O
length	O
of	O
the	O
string	O
?	O

Just	O
for	O
the	O
sake	O
of	O
trying	O
something	O
,	O
does	O
the	O
same	O
error	O
happen	O
if	O
you	O
replace	O
your	O
use	O
of	O
`	O
apply	O
`	O
with	O
`	O
map	O
`	O
since	O
you're	O
looking	O
to	O
spray	O
the	O
operation	O
onto	O
a	O
single	O
`	O
Series	O
`	O
object	O
?	O

and	O
you	O
can	O
also	O
use	O
`	O
map	O
`	O
instead	O
of	O
`	O
apply	O
`	O
since	O
you're	O
operating	O
along	O
the	O
values	O
of	O
a	O
`	O
Series	O
`	O
.	O

Is	O
the	O
issue	O
that	O
result	O
of	O
[	O
11	O
]	O
is	O
set	O
not	O
a	O
list	O
(	O
just	O
apply	O
set	O
to	O
it	O
)	O
.	O

Atm	O
this	O
feels	O
like	O
the	O
[	O
XY	O
Problem	O
]	O
(	O
#URL	O
)	O
...	O

Now	O
,	O
I	O
`	O
apply	O
`	O
it	O
to	O
the	O
dataframe	B-API
:	O
#CODE	O

The	O
thing	O
you	O
have	O
to	O
realize	O
about	O
apply	O
is	O
you	O
need	O
to	O
write	O
functions	O
that	O
operate	O
on	O
scalar	O
values	O
and	O
return	O
the	O
result	O
that	O
you	O
want	O
.	O

With	O
that	O
in	O
mind	O
:	O
#CODE	O

Just	O
want	O
to	O
clarify	O
that	O
when	O
using	O
`	O
apply	O
`	O
on	O
a	O
series	O
,	O
you	O
should	O
write	O
function	O
that	O
accept	O
scalar	O
values	O
.	O

When	O
using	O
`	O
apply	O
`	O
on	O
a	O
DataFrame	B-API
,	O
however	O
,	O
the	O
functions	O
should	O
accept	O
either	O
full	O
columns	O
(	O
when	O
`	O
axis=0	O
`	O
--	O
the	O
default	O
)	O
or	O
full	O
rows	O
(	O
when	O
`	O
axis=1	O
`)	O
.	O

OK	O
-	O
I	O
think	O
I	O
just	O
figured	O
it	O
out	O
-	O
to	O
use	O
functions	O
on	O
a	O
dataframe	B-API
,	O
you	O
have	O
to	O
use	O
(	O
should	O
use	O
)	O
apply	O
.	O

So	O
,	O
I	O
can	O
chain	O
together	O
functions	O
by	O
using	O
apply	O
inside	O
of	O
the	O
main	O
function	O
.	O

Is	O
that	O
right	O
(	O
does	O
that	O
make	O
sense	O
)	O
?	O

It's	O
worth	O
noting	O
that	O
you	O
can	O
do	O
this	O
(	O
without	O
using	O
apply	O
,	O
so	O
more	O
efficiently	O
)	O
using	O
`	O
str.contains	B-API
`	O
:	O
#CODE	O

I	O
also	O
have	O
some	O
states	O
which	O
are	O
not	O
present	O
in	O
the	O
dictionary	O
.	O

If	O
I	O
apply	O
map()	B-API
,	O
the	O
corresponding	O
values	O
in	O
the	O
new	O
series	O
are	O
missing	O
.	O

Can	O
I	O
somehow	O
specify	O
that	O
I	O
want	O
to	O
apply	O
identity	O
function	O
for	O
the	O
values	O
not	O
present	O
in	O
the	O
dictionary	O
,	O
i.e.	O
leave	O
them	O
as	O
is	O
?	O

If	O
you	O
can	O
have	O
a	O
NaN	O
in	O
the	O
FK	O
column	O
,	O
then	O
could	O
you	O
replace	O
the	O
NaN's	O
with	O
some	O
other	O
random	O
number	O
,	O
let's	O
say	O
if	O
all	O
current	O
FK's	O
are	O
positive	O
integers	O
,	O
then	O
use	O
a	O
negative	O
int	O
like	O
-999	O
to	O
distinguish	O
empty	O
values	O
.	O

Another	O
option	O
is	O
to	O
only	O
include	O
the	O
rows	O
that	O
have	O
a	O
value	O
:	O
"	O
df	O
[	O
df	O
[	O
'	O
FK_COL	O
']	O
.notnull()	B-API
]"	O
.	O

Then	O
apply	O
the	O
filling	O
on	O
NaN	O
values	O
,	O
and	O
save	O
this	O
dataframe	B-API
to	O
a	O
new	O
variable	O
for	O
loading	O
into	O
the	O
database	O
.	O

using	O
apply	O
you	O
can	O
make	O
new	O
value	O
and	O
assign	O
it	O
to	O
new	O
column	O

E.g.	O
you	O
could	O
use	O
groupby	B-API
apply	O
with	O
`	O
def	O
f	O
(	O
x	O
):	O
return	O
(	O
1	O
.	O
*	O
x	O
[	O
'	O
weight	O
']	O
*	O
x	O
[	O
'	O
jobs	O
'])	O
.sum()	B-API
/	O
x	O
[	O
'	O
jobs	O
']	O
.sum()	B-API
`	O
but	O
it	O
will	O
probably	O
be	O
less	O
efficient	O
than	O
the	O
above	O
.	O

You	O
could	O
do	O
this	O
as	O
a	O
one	O
line	O
apply	O
(	O
the	O
first	O
column	O
being	O
negative	O
,	O
the	O
second	O
positive	O
):	O
#CODE	O

then	O
use	O
apply	O
to	O
get	O
your	O
"	O
Type	O
"	O
#CODE	O

original	O
Apply	O
:	O
#CODE	O

revised	O
Apply	O
:	O
#CODE	O

This	O
will	O
be	O
faster	O
than	O
the	O
apply	O
soln	O
(	O
and	O
the	O
looping	O
soln	O
)	O

Apply	O
#CODE	O

An	O
easier	O
way	O
to	O
describe	O
your	O
function	O
is	O
as	O
x	O
->	O
1	O
-	O
x	O
,	O
this	O
will	O
be	O
more	O
efficient	O
that	O
apply	O
/	O
map	O
.	O

#CODE	O

I	O
am	O
looking	O
to	O
'	O
smooth	O
'	O
regularly-sampled	O
30-sec	O
time	O
series	O
data	O
using	O
the	O
pandas	O
`	O
rolling_window	B-API
`	O
function	O
,	O
with	O
a	O
window	O
type	O
other	O
than	O
`	O
boxcar	O
`	O
-	O
ideally	O
`	O
hamming	O
`	O
.	O

However	O
,	O
so	O
far	O
all	O
windows	O
which	O
I	O
have	O
tried	O
to	O
apply	O
,	O
over	O
varying	O
window	O
lengths	O
from	O
2	O
to	O
100	O
,	O
appear	O
to	O
offset	O
the	O
smoothed	O
data	O
to	O
lower	O
values	O
,	O
e.g.	O
:	O

To	O
verify	O
correctness	O
apply	O
the	O
rolling	O
window	O
on	O
a	O
step	O
function	O
.	O

If	O
there	O
were	O
an	O
offset	O
,	O
it	O
would	O
show	O
up	O

However	O
their	O
IS	O
a	O
way	O
to	O
do	O
this	O
.	O

Here	O
is	O
the	O
sketch	O
.	O

Use	O
`	O
select_as_coordinates	O
`	O
to	O
actually	O
execute	O
your	O
query	O
;	O
this	O
returns	O
an	O
`	O
Int64Index	O
`	O
of	O
the	O
row	O
number	O
(	O
the	O
coordinates	O
)	O
.	O

Then	O
apply	O
an	O
iterator	O
to	O
that	O
where	O
you	O
select	O
based	O
on	O
those	O
rows	O
.	O

This	O
is	O
the	O
function	O
you'll	O
apply	O
to	O
each	O
of	O
the	O
lists	O
in	O
`	O
groups	O
`	O
.	O

Just	O
like	O
before	O
we	O
hand	O
of	O
the	O
pair	O
to	O
`	O
SequenceMatcher	O
`	O
to	O
get	O
the	O
ratio	O
.	O

Only	O
now	O
we	O
need	O
to	O
keep	O
the	O
name	O
around	O
.	O

So	O
in	O
that	O
function	O
`	O
x	O
`	O
is	O
a	O
tuple	O
like	O
`	O
(	O
'	O
maria	O
'	O
,	O
'	O
mary	O
')`	O
.	O

We	O
need	O
to	O
know	O
the	O
name	O
in	O
the	O
best	O
match	O
and	O
the	O
ratio	O
of	O
the	O
best	O
match	O
,	O
so	O
I	O
threw	O
them	O
in	O
a	O
dict	O
with	O
`	O
{name	O
:	O
ratio}	O
`	O
.	O

The	O
other	O
thing	O
here	O
is	O
that	O
`	O
max	O
`	O
takes	O
a	O
second	O
argument	O
.	O

This	O
time	O
it's	O
just	O
saying	O
the	O
thing	O
to	O
maximize	O
is	O
`	O
x	O
[	O
1	O
]`	O
,	O
the	O
ratio	O
.	O

You	O
don't	O
need	O
to	O
if	O
you	O
simply	O
pass	O
a	O
``	O
min_itemsize=40	O
``	O
(	O
or	O
whatever	O
number	O
is	O
'	O
big	O
enough	O
')	O
,	O
this	O
will	O
apply	O
to	O
all	O
object	O
columns	O
,	O
alternatively	O
,	O
you	O
can	O
use	O
:	O
``	O
df.dtypes	B-API
``	O
to	O
see	O
which	O
are	O
object	O
(	O
the	O
values	O
are	O
the	O
dtype	B-API
)	O

Why	O
do	O
pyplot	B-API
methods	O
apply	O
instantly	O
and	O
subplot	O
axes	O
methods	O
do	O
not	O
?	O

I'm	O
editing	O
my	O
graphs	O
step	O
by	O
step	O
.	O

Doing	O
so	O
,	O
`	O
plt	O
`	O
functions	O
from	O
`	O
matplotlib.pyplot	B-API
`	O
apply	O
instantly	O
to	O
my	O
graphical	O
output	O
of	O
pylab	O
.	O

That's	O
great	O
.	O

Apply	O
function	O
to	O
a	O
specific	O
number	O
of	O
rows	O
in	O
a	O
DataFrame	B-API

I	O
have	O
a	O
weather	O
data	O
and	O
I	O
would	O
need	O
to	O
apply	O
a	O
function	O
to	O
a	O
specific	O
number	O
of	O
rows	O
.	O

For	O
example	O
,	O
to	O
calculate	O
mean	O
values	O
of	O
every	O
10	O
or	O
15	O
rows	O
.	O

The	O
number	O
of	O
rows	O
is	O
important	O
because	O
there	O
are	O
quite	O
many	O
missing	O
values	O
in	O
dates	O
and	O
I	O
don't	O
want	O
to	O
rely	O
on	O
it	O
.	O

I	O
tried	O
`	O
groupby	B-API
`	O
but	O
there	O
I	O
can	O
only	O
specify	O
hours	O
or	O
minutes	O
.	O

Anyway	O
I	O
would	O
like	O
to	O
apply	O
any	O
function	O
independent	O
from	O
`	O
DateTime	O
index	O
`	O
.	O

I	O
think	O
slicing	O
`	O
DF	O
`	O
would	O
be	O
an	O
option	O
`	O
df	O
[:	O
9	O
]`	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
this	O
to	O
all	O
rows	O
?	O

Also	O
what	O
is	O
the	O
function	O
you	O
want	O
to	O
apply	O
?	O

Does	O
`	O
df.resample	B-API
(	O
'	O
10min	O
'	O
,	O
how=	O
)`	O
work	O
?	O

4	O
:	O
I	O
apply	O
the	O
transaction	O
level	O
criteria	O
to	O
the	O
datafarme	O

I	O
want	O
to	O
apply	O
the	O
expanding	O
mean	O
,	O
such	O
that	O
`	O
ptsA	O
`	O
and	O
`	O
ptsB	O
`	O
for	O
each	O
player	O
get	O
counted	O
in	O
(	O
and	O
are	O
not	O
left	O
)	O
to	O
the	O
net	O
result	O
.	O

Final	O
output	O
should	O
make	O
it	O
more	O
clear	O
:	O
#CODE	O

Python	O
pandas	O
groupby	B-API
object	O
apply	O
method	O
duplicates	O
first	O
group	O

I	O
am	O
confused	O
about	O
this	O
behavior	O
of	O
apply	O
method	O
of	O
groupby	B-API
in	O
pandas	O
(	O
0.12.0-4	O
)	O
,	O
it	O
appears	O
to	O
apply	O
the	O
function	O
TWICE	O
to	O
the	O
first	O
row	O
of	O
a	O
data	O
frame	O
.	O

For	O
example	O
:	O
#CODE	O

Then	O
I	O
try	O
to	O
do	O
something	O
similar	O
using	O
apply	O
on	O
the	O
groupby	B-API
object	O
and	O
I	O
get	O
the	O
first	O
row	O
output	O
twice	O
:	O
#CODE	O

Edit	O
:	O
@USER	O
provides	O
the	O
answer	O
below	O
.	O

I	O
am	O
dense	O
and	O
did	O
not	O
understand	O
it	O
immediately	O
,	O
so	O
here	O
is	O
a	O
simple	O
example	O
to	O
show	O
that	O
despite	O
the	O
double	O
printout	O
of	O
the	O
first	O
group	O
in	O
the	O
example	O
above	O
,	O
the	O
apply	O
method	O
operates	O
only	O
once	O
on	O
the	O
first	O
group	O
and	O
does	O
not	O
mutate	O
the	O
original	O
data	O
frame	O
:	O
#CODE	O

This	O
is	O
checking	O
whether	O
you	O
are	O
mutating	O
the	O
data	O
in	O
the	O
apply	O
.	O

If	O
you	O
are	O
then	O
it	O
has	O
to	O
take	O
a	O
slower	O
path	O
than	O
otherwise	O
.	O

It	O
doesn't	O
change	O
the	O
results	O
.	O

@USER	O
:	O
Could	O
the	O
result	O
of	O
the	O
first	O
call	O
be	O
saved	O
so	O
it	O
is	O
not	O
called	O
again	O
?	O

This	O
might	O
help	O
if	O
the	O
function	O
called	O
by	O
apply	O
takes	O
a	O
long	O
time	O
...	O

(	O
along	O
with	O
being	O
more	O
intuitive	O
,	O
since	O
this	O
question	O
comes	O
up	O
a	O
lot	O
.	O
)	O

The	O
`	O
apply	O
`	O
function	O
needs	O
to	O
know	O
the	O
shape	O
of	O
the	O
returned	O
data	O
to	O
intelligently	O
figure	O
out	O
how	O
it	O
will	O
be	O
combined	O
.	O

To	O
do	O
this	O
it	O
calls	O
the	O
function	O
(	O
`	O
checkit	O
`	O
in	O
your	O
case	O
)	O
twice	O
to	O
achieve	O
this	O
.	O

Depending	O
on	O
your	O
actual	O
use	O
case	O
,	O
you	O
can	O
replace	O
the	O
call	O
to	O
`	O
apply	O
`	O
with	O
`	O
aggregate	O
`	O
,	O
`	O
transform	O
`	O
or	O
`	O
filter	O
`	O
,	O
as	O
described	O
in	O
detail	O
here	O
.	O

These	O
functions	O
require	O
the	O
return	O
value	O
to	O
be	O
a	O
particular	O
shape	O
,	O
and	O
so	O
don't	O
call	O
the	O
function	O
twice	O
.	O

What	O
can	O
I	O
do	O
if	O
I	O
have	O
several	O
DataFrames	O
and	O
I	O
want	O
to	O
apply	O
the	O
same	O
set	O
of	O
operations	O
to	O
each	O
with	O
operations	O
that	O
do	O
not	O
support	O
`	O
inplace=True	O
`	O
?	O

Is	O
there	O
a	O
way	O
to	O
change	O
the	O
original	O
DataFrame	B-API
in	O
a	O
for-loop	O
?	O

For	O
example	O
,	O
instead	O
of	O
`	O
df_train	O
[	O
df_train	O
>	O
1	O
]	O
=	O
1	O
`	O
and	O
`	O
df_test	O
[	O
df_test	O
>	O
1	O
]	O
=	O
1	O
`	O
iterating	O
over	O
the	O
two	O
frames	O
and	O
changing	O
the	O
content	O
of	O
the	O
DataFrames	O
in	O
the	O
for-loop	O
.	O

I	O
think	O
a	O
nicer	O
way	O
to	O
do	O
this	O
,	O
assuming	O
you	O
were	O
planning	O
on	O
apply	O
it	O
to	O
an	O
entire	O
column	O
,	O
is	O
to	O
use	O
one	O
of	O
the	O
vectorised	O
string	O
methods	O
:	O
`	O
str.split	B-API
`	O
:	O
#CODE	O

You	O
can	O
group	O
and	O
apply	O
an	O
user-defined	O
function	O
:	O
#CODE	O

Are	O
you	O
trying	O
to	O
apply	O
two	O
different	O
types	O
of	O
equations	O
based	O
on	O
the	O
value	O
in	O
serialNumber	O
?	O

After	O
the	O
merge	O
between	O
the	O
object_list	O
and	O
percentages	O
,	O
you	O
could	O
"	O
query	O
"	O
the	O
dataframe	B-API
based	O
on	O
the	O
value	O
in	O
serialNumber	O
and	O
apply	O
the	O
correct	O
formula	O
;	O
#CODE	O

The	O
apply	O
function	O
is	O
similar	O
to	O
pythons	O
builtin	O
"	O
map	O
"	O
.	O

You	O
can	O
'	O
apply	O
'	O
the	O
same	O
function	O
over	O
the	O
rows	O
or	O
columns	O
(	O
where	O
axis=1	O
is	O
for	O
row-wise	O
[	O
top	O
to	O
bottom	O
]	O
where	O
the	O
indexes	O
will	O
be	O
the	O
column	O
names	O
,	O
and	O
axis=0	O
is	O
column-wise	O
[	O
left	O
to	O
right	O
]	O
where	O
the	O
row	O
indexes	O
are	O
the	O
indexes	O
)	O

Apply	O
function	O
to	O
pandas	O
Series	O
with	O
argument	O
(	O
which	O
varies	O
for	O
every	O
element	O
)	O

I	O
have	O
a	O
pandas	O
Series	O
and	O
a	O
function	O
that	O
I	O
want	O
to	O
apply	O
to	O
each	O
element	O
of	O
the	O
Series	O
.	O

The	O
function	O
have	O
an	O
additional	O
argument	O
too	O
.	O

So	O
far	O
so	O
good	O
:	O
for	O
example	O

python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O
.	O

Update	O

I	O
had	O
to	O
face	O
this	O
problem	O
in	O
my	O
code	O
and	O
I	O
have	O
found	O
a	O
straightforward	O
solution	O
but	O
it	O
is	O
quite	O
specific	O
and	O
(	O
even	O
worse	O
)	O
do	O
not	O
use	O
the	O
apply	O
method	O
.	O

That's	O
an	O
unusual	O
broadcast	O
rule	O
,	O
and	O
not	O
one	O
that	O
will	O
be	O
widely	O
desired	O
.	O

So	O
the	O
Pandas	O
API	O
doesn't	O
directly	O
handle	O
it	O
for	O
you	O
.	O

Your	O
best	O
bet	O
would	O
be	O
to	O
write	O
a	O
function	O
that	O
maps	O
the	O
`	O
t	B-API
`	O
vector	O
into	O
a	O
correctly-sized	O
column	O
in	O
the	O
data	O
frame	O
,	O
using	O
whatever	O
mapping	O
convention	O
you'd	O
like	O
,	O
and	O
after	O
that	O
is	O
created	O
,	O
*	O
then	O
*	O
you	O
can	O
just	O
use	O
a	O
simple	O
`	O
apply	O
`	O
or	O
`	O
map	O
`	O
or	O
basic	O
array	O
function	O
to	O
operate	O
on	O
them	O
.	O

But	O
you	O
shouldn't	O
want	O
Pandas	O
to	O
support	O
arbitrary	O
ways	O
of	O
broadcasting	O
elements	O
.	O

That	O
interface	O
would	O
be	O
so	O
wide	O
open	O
it	O
would	O
necessitate	O
that	O
the	O
data	O
structure	O
was	O
meaningless	O
.	O

can	O
you	O
show	O
``	O
data.info()``	O
before	O
this	O
?	O

you	O
should	O
have	O
``	O
float64	O
``	O
dtypes	B-API
already	O
.	O
secondarily	O
,	O
you	O
don't	O
need	O
the	O
apply	O
,	O
you	O
can	O
do	O
something	O
like	O
:	O
``	O
data	O
[	O
data	O
[	O
'	O
currency	O
']	O
!	O
=	O
'	O
A	O
'	O
,	O
'	O
amount	O
']	O
=d	O
ata	O
[	O
'	O
qty	O
']	O
*data	O
[	O
'	O
rate	B-API
']``	O

Apply	O
function	O
then	O
Filter	O
DataFrame	B-API

You	O
can	O
[	O
groupby	B-API
an	O
index	O
level	O
]	O
(	O
#URL	O
):	O
`	O
site.groupby	O
(	O
level=	O
'	O
DK	O
'	O
,	O
axis=1	O
)`	O
,	O
and	O
then	O
iterate	O
through	O
that	O
like	O
a	O
normal	O
groupby	B-API
object	O
.	O

It	O
may	O
be	O
cleaner	O
to	O
use	O
and	O
`	O
apply	O
`	O
after	O
grouping	O
,	O
instead	O
of	O
iterating	O
over	O
the	O
groups	O
.	O

I	O
am	O
struggling	O
with	O
indexing	O
and	O
bools	O
but	O
i	O
can't	O
solve	O
this	O
.	O

I	O
strongly	O
suspect	O
that	O
i	O
need	O
to	O
use	O
a	O
lambda	O
function	O
,	O
but	O
i	O
don't	O
know	O
how	O
to	O
apply	O
it	O
.	O

So	O
please	O
have	O
mercy	O
it's	O
too	O
long	O
that	O
i'm	O
trying	O
on	O
this	O
.	O

Hope	O
i've	O
been	O
clear	O
enough	O
.	O

You	O
would	O
need	O
to	O
use	O
`	O
applymap	B-API
`	O
instead	O
of	O
`	O
apply	O
`	O
to	O
do	O
it	O
that	O
way	O
.	O

But	O
more	O
generally	O
,	O
working	O
with	O
lists	O
inside	O
DataFrames	O
can	O
be	O
somewhat	O
awkward	O
,	O
and	O
working	O
with	O
columns	O
where	O
some	O
values	O
are	O
lists	O
and	O
some	O
are	O
numbers	O
is	O
also	O
likely	O
to	O
be	O
awkward	O
.	O

You	O
can	O
apply	O
your	O
values	O
to	O
your	O
matrice	O
by	O
looping	O
through	O
the	O
list	O
with	O
values	O
that	O
you	O

want	O
to	O
apply	O
and	O
append	O
them	O
to	O
the	O
matrice	O
in	O
the	O
loop	O
.	O

#CODE	O

how	O
to	O
apply	O
a	O
function	O
which	O
takes	O
the	O
caller	O
as	O
its	O
arugment	O

When	O
calling	O
apply	O
,	O
add	O
group	O
keys	O
to	O
index	O
to	O
identify	O
pieces	O
`	O
.	O

Reindexing	O
error	O
makes	O
no	O
sense	O
does	O
not	O
seem	O
to	O
apply	O
as	O
my	O
old	O
index	O
is	O
unique	O
.	O

Probably	O
better	O
to	O
split	O
your	O
data	O
using	O
regexp	O
and	O
then	O
apply	O
some	O
date	O
parsing	O
using	O
strptime	O
IMO	O
,	O
I	O
can't	O
think	O
of	O
an	O
easier	O
method	O

Use	O
`	O
apply	O
`	O
for	O
row-wise	O
methods	O
:	O
#CODE	O

Well	O
,	O
it	O
does	O
select	O
the	O
number	O
of	O
rows	O
I	O
want	O
but	O
I	O
can't	O
apply	O
`	O
size()	B-API
`	O
method	O
on	O
this	O
new	O
object	O
.	O

#CODE	O

I	O
don't	O
want	O
to	O
redefine	O
each	O
and	O
every	O
method	O
of	O
a	O
class	O
to	O
pass	O
through	O
.	O

This	O
is	O
just	O
one	O
example	O
.	O

I'd	O
like	O
to	O
apply	O
this	O
elsewhere	O
.	O

``	O
df	O
==	O
DataFrame	B-API
(	O
np.tile	B-API
(	O
rowmax	O
,	O
len	O
(	O
df	O
))	O
.reshape	B-API
(	O
df.shape	B-API
)	O
.T	B-API
,	O
index	O
=d	O
f.index	O
,	O
columns	O
=d	O
f.columns	O
)``	O
will	O
get	O
your	O
boolean	O
frame	O
(	O
kind	O
of	O
like	O
a	O
broadcasted	O
comparison	O
operator	O
);	O
faster	O
,	O
but	O
prob	O
not	O
more	O
clear	O
than	O
the	O
``	O
apply	O
``	O

This	O
means	O
we	O
don't	O
easily	O
know	O
how	O
to	O
build	O
our	O
grouping	O
.	O

It	O
would	O
be	O
much	O
better	O
to	O
just	O
operate	O
on	O
the	O
first	O
level	O
,	O
but	O
then	O
I'm	O
stuck	O
on	O
how	O
to	O
then	O
apply	O
the	O
grouping	O
I	O
actually	O
want	O
.	O

#CODE	O

I	O
think	O
you	O
are	O
doing	O
a	O
row	O
/	O
column-wise	O
operation	O
so	O
can	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

@USER	O
Thank	O
you	O
,	O
I	O
understand	O
the	O
difference	O
and	O
see	O
that	O
both	O
selections	O
are	O
not	O
the	O
same	O
;	O
this	O
can	O
be	O
confirmed	O
using	O
the	O
`	O
is	O
`	O
operator	O
for	O
comparison	O
.	O

But	O
is	O
there	O
a	O
simple	O
rule	O
?	O

The	O
documentation	O
looks	O
rather	O
complicated	O
in	O
this	O
point	O
.	O

How	O
far	O
does	O
the	O
following	O
statement	O
apply	O
to	O
one	O
but	O
not	O
the	O
other	O
select	O
?	O

"	O
Whenever	O
an	O
array	O
of	O
labels	O
or	O
a	O
boolean	O
vector	O
are	O
involved	O
in	O
the	O
indexing	O
operation	O
,	O
the	O
result	O
will	O
be	O
a	O
copy	O
.	O

"	O
In	O
both	O
versions	O
`	O
df	O
[	O
"	O
col	O
"]	O
==	O
3	O
`	O
is	O
a	O
boolean	O
vector	O
for	O
selection	O
,	O
but	O
in	O
the	O
former	O
version	O
the	O
condition	O
is	O
used	O
first	O
;	O
in	O
the	O
latter	O
the	O
Series	O
is	O
selected	O
first	O
.	O

Why	O
does	O
pandas	O
apply	O
calculate	O
twice	O

I'm	O
using	O
the	O
apply	O
method	O
on	O
a	O
panda's	O
DataFrame	B-API
object	O
.	O

When	O
my	O
DataFrame	B-API
has	O
a	O
single	O
column	O
,	O
it	O
appears	O
that	O
the	O
applied	O
function	O
is	O
being	O
called	O
twice	O
.	O

The	O
questions	O
are	O
why	O
?	O

And	O
,	O
can	O
I	O
stop	O
that	O
behavior	O
?	O

Also	O
,	O
calling	O
it	O
four	O
times	O
when	O
you	O
apply	O
on	O
the	O
column	O
is	O
normal	O
.	O

When	O
you	O
get	O
one	O
columnm	O
you	O
get	O
a	O
Series	O
,	O
not	O
a	O
DataFrame	B-API
.	O

`	O
apply	O
`	O
on	O
a	O
Series	O
applies	O
the	O
function	O
to	O
each	O
element	O
.	O

Since	O
your	O
column	O
has	O
four	O
elements	O
in	O
it	O
,	O
the	O
function	O
is	O
called	O
four	O
times	O
.	O

doing	O
a	O
nested	O
a	O
nested	O
apply	O
/	O
grouping	O
like	O
this	O
is	O
not	O
the	O
answer	O
.	O

This	O
is	O
almost	O
pure	O
python	O
code	O
,	O
you	O
are	O
not	O
leveraging	O
any	O
of	O
pandas	O
strengths	O
.	O

You	O
prob	O
want	O
to	O
groupby	B-API
at	O
the	O
top	O
level	O
(	O
or	O
construct	O
a	O
multi-index	O
)	O
,	O
select	O
the	O
values	O
that	O
you	O
want	O
to	O
include	O
,	O
then	O
use	O
a	O
cythonized	O
function	O
to	O
apply	O
it	O
.	O

You	O
only	O
want	O
to	O
do	O
1	O
level	O
of	O
groupby	B-API
and	O
apply	O
(	O
except	O
in	O
some	O
very	O
very	O
rare	O
cases	O
)	O
.	O

You	O
are	O
ultimately	O
are	O
doing	O
some	O
vectorized	O
operations	O
,	O
but	O
you	O
are	O
doing	O
them	O
backwards	O
at	O
the	O
lowest	O
level	O
.	O

You	O
can	O
do	O
the	O
apply	O
and	O
groupby	B-API
by	O
one	O
multilevel	O
groupby	B-API
,	O
here	O
is	O
the	O
code	O
:	O
#CODE	O

Pandas	O
:	O
how	O
to	O
apply	O
function	O
to	O
only	O
part	O
of	O
a	O
dataframe	B-API
and	O
append	O
result	O
back	O
to	O
dataframe	B-API
?	O

I	O
could	O
then	O
figure	O
out	O
how	O
to	O
append	O
these	O
lists	O
back	O
to	O
the	O
original	O
list	O
(	O
though	O
I	O
have	O
no	O
idea	O
how	O
to	O
go	O
from	O
a	O
dataframe	B-API
to	O
a	O
list	O
again	O
to	O
do	O
this	O
)	O
.	O

Is	O
there	O
more	O
of	O
a	O
direct	O
way	O
to	O
only	O
apply	O
the	O
function	O
to	O
the	O
numeric	O
variables	O
?	O

Also	O
,	O
how	O
would	O
you	O
change	O
the	O
pandas	O
dataframe	B-API
back	O
to	O
its	O
original	O
list	O
form	O
anyway	O
?	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
use	O
a	O
lambda	O
to	O
subtract	O
the	O
list	O
values	O
column-wise	O
:	O
#CODE	O

I	O
was	O
trying	O
to	O
remember	O
what	O
the	O
correct	O
/	O
better	O
method	O
was	O
and	O
couldn't	O
remember	O
this	O
one	O
so	O
i	O
posted	O
`	O
apply	O
`	O
as	O
an	O
answer	O
.	O

Ed	O
,	O
in	O
this	O
case	O
,	O
'	O
sub	O
'	O
was	O
what	O
I	O
was	O
looking	O
for	O
,	O
but	O
I'm	O
certainly	O
keeping	O
the	O
'	O
apply	O
lambda	O
'	O
method	O
in	O
my	O
back	O
pocket	O
--	O
the	O
next	O
problem	O
in	O
queue	O
isn't	O
a	O
straight	O
subtraction	O
.	O

Thanks	O
!	O

I	O
want	O
to	O
apply	O
filters	O
based	O
on	O
the	O
following	O
pattern	O
from	O
'	O
CAT1	O
'	O
'	O
CAT2	O
'	O
;	O

You	O
could	O
just	O
define	O
a	O
function	O
and	O
pass	O
this	O
to	O
`	O
apply	O
`	O
and	O
set	O
`	O
axis=1	O
`	O
would	O
work	O
,	O
not	O
sure	O
I	O
can	O
think	O
of	O
an	O
operation	O
that	O
would	O
give	O
you	O
what	O
you	O
want	O

Then	O
apply	O
it	O
to	O
your	O
dataframe	B-API
passing	O
in	O
the	O
`	O
axis=1	O
`	O
option	O
:	O
#CODE	O

Trying	O
other	O
user-defined	O
functions	O
produces	O
similar	O
errors	O
.	O

In	O
all	O
these	O
cases	O
,	O
it's	O
pretty	O
clearly	O
trying	O
to	O
apply	O
peak_to_peak()	O
or	O
np.mean()	B-API
(	O
or	O
whatever	O
)	O
to	O
the	O
(	O
subsets	O
of	O
the	O
)	O
'	O
key2	O
'	O
column	O
from	O
df	O
,	O
whereas	O
for	O
the	O
built-in	O
methods	O
and	O
predefined	O
functions	O
,	O
it	O
(	O
correctly	O
)	O
ignores	O
the	O
'	O
key2	O
'	O
column	O
subsets	O
.	O

Also	O
check	O
out	O
#URL	O
which	O
covers	O
`	O
apply	O
`	O
,	O
`	O
map	O
`	O
as	O
well	O
as	O
`	O
applymap	B-API
`	O
.	O

I	O
would	O
like	O
to	O
maintain	O
the	O
data	O
types	O
from	O
the	O
original	O
data	O
frame	O
as	O
I	O
need	O
to	O
apply	O
other	O
operations	O
to	O
the	O
total	O
row	O
,	O
something	O
like	O
:	O
#CODE	O

That's	O
a	O
little	O
too	O
complex	O
to	O
discuss	O
without	O
something	O
concrete	O
to	O
work	O
with	O
.	O

I	O
suggest	O
you	O
make	O
some	O
short	O
toy	O
examples	O
and	O
open	O
a	O
new	O
question	O
.	O

Or	O
see	O
if	O
[	O
this	O
old	O
answer	O
of	O
mine	O
]	O
(	O
#URL	O
)	O
gets	O
you	O
close	O
enough	O
.	O

You'll	O
have	O
to	O
split	O
your	O
sentences	O
into	O
columns	O
of	O
words	O
and	O
then	O
apply	O
.	O

That	O
article	O
used	O
`	O
id	O
`	O
s	O
to	O
achieve	O
different	O
formatting	O
for	O
each	O
table	O
but	O
you	O
could	O
just	O
apply	O
the	O
desired	O
CSS	O
styles	O
directly	O
to	O
the	O
appropriate	O
HTML	O
tags	O
.	O

For	O
instance	O
,	O
your	O
image	O
is	O
from	O
their	O
"	O
Box	O
3	O
"	O
example	O
,	O
which	O
used	O
the	O
ids	O
`	O
box-table-a	O
`	O
and	O
`	O
box-table-b	O
`	O
and	O
the	O
corresponding	O
formatting	O
is	O

Some	O
of	O
these	O
are	O
documented	O
[	O
here	O
]	O
(	O
#URL	O
)	O
,	O
but	O
some	O
are	O
missing	O
.	O

However	O
,	O
it	O
looks	O
like	O
many	O
of	O
the	O
missing	O
ones	O
are	O
fairly	O
clear	O
because	O
they	O
just	O
apply	O
a	O
mathematical	O
function	O
of	O
the	O
same	O
name	O
to	O
each	O
group	O
(	O
e.g.	O
,	O
`	O
cummin	B-API
`)	O
.	O

these	O
ultimately	O
just	O
call	O
the	O
same	O
named	O
DataFrame	B-API
method	O
(	O
or	O
an	O
optimized	O
for	O
groupby	B-API
version	O
)	O
(	O
asside	O
from	O
the	O
specific	O
methods	O
``	O
transform	O
/	O
apply	O
/	O
agg	O
/	O
groups	O
``)	O

You'll	O
need	O
to	O
mess	O
with	O
the	O
`	O
b	O
`	O
column	O
to	O
get	O
things	O
flipped	O
.	O

I'd	O
say	O
multiply	O
by	O
-1	O
,	O
apply	O
the	O
sub	O
and	O
div	O
,	O
then	O
multiply	O
by	O
-1	O
again	O
.	O

If	O
I	O
find	O
a	O
more	O
elegant	O
way	O
(	O
for	O
example	O
,	O
using	O
the	O
column	O
index	O
:	O
(	O
0	O
or	O
1	O
)	O
mod	O
2	O
-	O
1	O
to	O
select	O
the	O
sign	O
in	O
the	O
apply	O
operation	O
so	O
it	O
can	O
be	O
done	O
with	O
just	O
one	O
apply	O
command	O
,	O
I'll	O
let	O
you	O
know	O
.	O

Using	O
the	O
apply	O
function	O
,	O
we	O
can	O
compare	O
entire	O
columns	O
to	O
the	O
empty	O
string	O
and	O
then	O
aggregate	O
down	O
with	O
the	O
`	O
.all()	B-API
`	O
method	O
.	O

#CODE	O

Can't	O
figure	O
out	O
how	O
to	O
apply	O
the	O
solution	O
to	O
my	O
code	O
,,	O
when	O
I	O
try	O
to	O
just	O
run	O
the	O
code	O
as	O
provided	O
I	O
get	O
module	O
not	O
callable	O
and	O
when	O
I	O
try	O
to	O
place	O
the	O
code	O
in	O
the	O
"	O
with	O
"	O
clause	O
it	O
blows	O
up	O
..	O

(	O
so	O
I	O
have	O
not	O
translated	O
that	O
correctly	O
.	O
)	O
I	O
tried	O
to	O
just	O
use	O
the	O
Family=clause	O
inside	O
the	O
"	O
with	O
"	O
gives	O
KeyError	O
:	O
0	O

The	O
`	O
converters	O
`	O
parameter	O
tells	O
`	O
read_csv	B-API
`	O
to	O
apply	O
the	O
given	O

Appreciate	O
the	O
quick	O
answer	O
@USER	O
.	O

However	O
,	O
I	O
seem	O
to	O
get	O
conversion	O
error	O
when	O
trying	O
to	O
apply	O
the	O
.loc	B-API
.	O

Moreover	O
,	O
as	O
this	O
is	O
just	O
an	O
example	O
,	O
do	O
you	O
think	O
there	O
is	O
a	O
way	O
to	O
apply	O
the	O
"	O
*=	O
-1	O
"	O
to	O
all	O
columns	O
,	O
as	O
'	O
1Y	O
'	O
:	O
'	O
1Y4M	O
'	O
?	O

What	O
is	O
the	O
difference	O
between	O
pandas	O
agg	O
and	O
apply	O
function	O
?	O

Using	O
`	O
apply	O
`	O
:	O
#CODE	O

`	O
apply	O
`	O
applies	O
the	O
function	O
to	O
each	O
group	O
(	O
your	O
`	O
Species	O
`)	O
.	O

Your	O
function	O
returns	O
1	O
,	O
so	O
you	O
end	O
up	O
with	O
3	O
groups	O
.	O

So	O
for	O
all	O
4.000	O
locations	O
you	O
apply	O
the	O
distance	O
function	O
to	O
all	O
11.000	O
towers	O
?	O

That	O
seems	O
rather	O
wasteful	O
,	O
as	O
most	O
towers	O
are	O
*	O
not	O
*	O
near	O
.	O

You	O
could	O
already	O
greatly	O
reduce	O
the	O
work	O
by	O
binning	O
all	O
the	O
towers	O
on	O
certain	O
lat	O
/	O
long	O
combinations	O
,	O
such	O
that	O
you	O
only	O
have	O
to	O
iterate	O
over	O
a	O
small	O
subset	O
of	O
all	O
the	O
towers	O
to	O
find	O
your	O
best	O
match	O
.	O

Does	O
this	O
mean	O
that	O
it	O
recognizes	O
each	O
string	O
as	O
a	O
word	O
?	O

so	O
when	O
I	O
apply	O
the	O
filter	O
it	O
will	O
filter	O
against	O
each	O
of	O
the	O
words	O
in	O
my	O
List2	O
?	O

#CODE	O

I	O
usually	O
read	O
everything	O
as	O
string	O
,	O
then	O
apply	O
a	O
helper	O
function	O
that	O
includes	O
try	O
/	O
except	O
to	O
convert	O
each	O
individual	O
string	O
.	O

Or	O
you	O
can	O
validate	O
your	O
strings	O
with	O
regex	O
,	O
and	O
substitute	O
all	O
the	O
values	O
that	O
aren't	O
a	O
date	O
with	O
''	O
.	O

I	O
have	O
the	O
following	O
problem	O
,	O
I	O
have	O
a	O
Panda	O
data	O
frame	O
and	O
I	O
want	O
to	O
process	O
each	O
row	O
ny	O
using	O
the	O
apply	O
method	O
.	O

Each	O
row	O
should	O
be	O
processed	O
by	O
using	O
a	O
function	O
(	O
static	O
method	O
)	O
within	O
the	O
same	O
class	O
..	O

#CODE	O

You	O
can	O
group	O
by	O
`'	O
Currency	O
'`	O
and	O
apply	O
`	O
diff	O
`	O
but	O
first	O
you	O
need	O
to	O
convert	O
the	O
data	O
to	O
`	O
float	O
`	O
,	O
try	O
this	O
:	O
#CODE	O

Hi	O
again	O
@USER	O
.	O

Your	O
code-update	O
is	O
very	O
much	O
appreciated	O
.	O

However	O
,	O
when	O
applying	O
"	O
diff	O
"	O
to	O
my	O
groupby-function	O
,	O
it	O
seems	O
that	O
Python	O
mess	O
up	O
the	O
original	O
order	O
of	O
the	O
currencys	O
.	O

What's	O
probably	O
happening	O
is	O
that	O
when	O
I	O
apply	O
groupby	B-API
currencies	O
,	O
Python	O
also	O
SORTS	O
the	O
data	O
accordingly	O
->	O
so	O
e.g.	O
if	O
my	O
original	O
data	O
is	O
stored	O
in	O
order	O
"	O
EUR	O
,	O
CHF	O
,	O
DKK	O
"	O
the	O
diff-command	O
makes	O
the	O
data	O
"	O
CHF	O
,	O
DKK	O
,	O
EUR	O
"	O
,	O
i.e.	O
when	O
putting	O
back	O
the	O
currency-labels	O
,	O
they	O
obviously	O
will	O
be	O
mis-labeled	O
.	O

Is	O
there	O
a	O
way	O
to	O
maybe	O
tell	O
Python	O
,	O
*	O
not	O
*	O
to	O
order	O
by	O
currency	O
,	O
but	O
leave	O
the	O
order	O
as	O
is	O
?	O

Thanks	O
.	O

It	O
could	O
be	O
an	O
groupby's	O
apply	O
will	O
do	O
it	O
,	O
like	O
I	O
say	O
in	O
other	O
question	O
,	O
depends	O
what	O
you're	O
doing	O
!	O

Note	O
:	O
most	O
of	O
the	O
time	O
you	O
don't	O
need	O
to	O
do	O
this	O
,	O
apply	O
,	O
aggregate	O
and	O
transform	O
are	O
your	O
friends	O
!	O

I	O
think	O
it	O
may	O
be	O
simpler	O
to	O
use	O
an	O
apply	O
here	O
:	O
#CODE	O

@USER	O
this	O
seems	O
to	O
work	O
with	O
apply	O
:	O
s	O
(	O
Thanks	O
for	O
editing	O
,	O
makes	O
it	O
much	O
easier	O
,	O
if	O
I	O
hadn't	O
already	O
+1d	O
,	O
I	O
would	O
again	O
!	O
)	O
:)	O

When	O
you	O
do	O
an	O
apply	O
each	O
column	O
is	O
realigned	O
with	O
the	O
other	O
results	O
,	O
since	O
every	O
value	O
between	O
1	O
and	O
5	O
is	O
seen	O
it's	O
aligned	O
with	O
`	O
range	O
(	O
1	O
,	O
6	O
)`	O
:	O
#CODE	O

When	O
you	O
do	O
the	O
apply	O
,	O
it	O
concats	O
the	O
result	O
of	O
doing	O
this	O
for	O
each	O
column	O
:	O
#CODE	O

I	O
would	O
then	O
like	O
to	O
apply	O
some	O
vba	O
formatting	O
to	O
the	O
results	O
-	O
but	O
i'm	O
not	O
sure	O
which	O
dll	O
or	O
addon	O
or	O
something	O
I	O
would	O
need	O
to	O
call	O
excel	O
vba	O
using	O
python	O
to	O
format	O
headings	O
as	O
bold	O
and	O
add	O
color	O
etc	O
.	O

Doesn't	O
`	O
apply	O
`	O
call	O
my	O
lambda	O
function	O
,	O
once	O
for	O
each	O
column	O
?	O

Use	O
`	O
where	O
`	O
instead	O
of	O
`	O
apply	O
`	O
and	O
add	O
days	O
with	O
`	O
np.timedelta64	O
`	O
#CODE	O

Just	O
put	O
your	O
code	O
in	O
a	O
function	O
an	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

If	O
I	O
just	O
group	O
the	O
object	O
and	O
apply	O
the	O
interval	O
function	O
,	O
it	O
looks	O
like	O
this	O
:	O
#CODE	O

Apply	O
custom	O
function	O
to	O
the	O
temporary	O
column	O

But	O
I	O
cannot	O
work	O
out	O
how	O
to	O
use	O
the	O
group	O
by	O
functions	O
(	O
transform	O
,	O
apply	O
,	O
etc	O
)	O
to	O
achieve	O
the	O
same	O
result	O
.	O

How	O
can	O
I	O
do	O
this	O
in	O
a	O
concise	O
way	O
using	O
pandas	O
?	O

@USER	O
it's	O
the	O
for	O
loop	O
which	O
is	O
slow	O
,	O
as	O
is	O
apply	O
(	O
to	O
a	O
lesser	O
extent	O
)	O
.	O

Although	O
it's	O
possible	O
this	O
could	O
be	O
made	O
faster	O
!	O

Apply	O
then	O
calls	O
the	O
function	O
on	O
each	O
group	O
and	O
assimilates	O
the	O
results	O

The	O
result	O
of	O
apply	O
is	O
a	O
list	O
of	O
index	O
values	O
that	O
represent	O
rows	O
with	O
B	O
==	O
1	O
if	O
more	O
than	O
one	O
row	O
in	O
the	O
group	O
else	O
the	O
default	O
row	O
for	O
given	O
A	O

The	O
data	O
is	O
sparse	O
but	O
I	O
do	O
need	O
them	O
.	O

I	O
am	O
gonna	O
try	O
to	O
apply	O
on	O
a	O
small	O
set	O
of	O
data	O
first	O
.	O

Thanks	O
a	O
lot	O
!	O

Is	O
there	O
a	O
vectorized	O
way	O
to	O
apply	O
that	O
formatting	O
command	O
in	O
either	O
context	O
?	O

Ok	O
,	O
then	O
how	O
would	O
I	O
apply	O
that	O
in	O
my	O
case	O
?	O

You	O
can	O
just	O
apply	O
this	O
to	O
each	O
case	O
/	O
group	O
:	O
#CODE	O

how	O
to	O
apply	O
a	O
function	O
to	O
multiple	O
columns	O
in	O
a	O
pandas	O
dataframe	B-API
at	O
one	O
time	O

Question	O
:	O
1	O
-	O
what	O
if	O
I	O
have	O
a	O
dataframe	B-API
with	O
50	O
columns	O
,	O
and	O
want	O
to	O
apply	O
that	O
formatting	O
to	O
multiple	O
columns	O
,	O
etc	O
column	O
1	O
,	O
3	O
,	O
5	O
,	O
7	O
,	O
9	O
,	O

Is	O
there	O
also	O
any	O
way	O
to	O
programatically	O
create	O
that	O
string	O
(	O
which	O
would	O
change	O
depending	O
on	O
the	O
number	O
of	O
columns	O
you	O
had	O
)	O
and	O
apply	O
the	O
format_number	O
function	O
?	O

I.e.	O
the	O
above	O
would	O
work	O
fine	O
if	O
I	O
knew	O
exactly	O
how	O
many	O
columns	O
were	O
in	O
the	O
sheet	O
every	O
time	O
,	O
but	O
If	O
I	O
didn't	O
know	O
the	O
number	O
of	O
columns	O
,	O
and	O
wanted	O
to	O
apply	O
the	O
same	O
function	O
to	O
every	O
column	O
,	O
is	O
there	O
a	O
better	O
way	O
of	O
doing	O
it	O
?	O

@USER	O
:	O
If	O
you	O
just	O
want	O
to	O
apply	O
it	O
to	O
all	O
the	O
columns	O
,	O
just	O
do	O
`	O
df.applymap	B-API
(	O
format_number	O
)`	O
.	O

You	O
could	O
use	O
`	O
apply	O
`	O
like	O
this	O
:	O
#CODE	O

@USER	O
ignoring	O
my	O
code	O
example	O
,	O
if	O
you	O
perform	O
`	O
apply	O
`	O
to	O
a	O
dataframe	B-API
then	O
the	O
dataframe	B-API
itself	O
is	O
modified	O
by	O
any	O
changes	O
in	O
your	O
function	O
so	O
you	O
would	O
not	O
need	O
to	O
assign	O
to	O
the	O
column	O
,	O
you	O
may	O
still	O
need	O
to	O
depending	O
on	O
what	O
your	O
function	O
is	O
doing	O
.	O

The	O
point	O
being	O
that	O
you	O
just	O
need	O
to	O
call	O
`	O
df.apply	B-API
`	O
and	O
not	O
need	O
to	O
say	O
do	O
`	O
df	O
[[	O
'	O
col1	O
'	O
,	O
'	O
col2	O
'	O
,	O
'	O
col3	O
']]	O
=d	O
f.apply	O
(	O
lambda	O
row	O
:	O
format_number	O
(	O
row	O
)	O
,	O
axis=1	O
))`	O
,	O
in	O
my	O
code	O
the	O
assignment	O
is	O
done	O
by	O
the	O
`	O
format_number	O
`	O
function	O
so	O
I	O
guess	O
the	O
assignment	O
is	O
implicit	O
rather	O
than	O
explicit	O
like	O
BrenBarn's	O
answer	O

Alternatively	O
you	O
could	O
simply	O
use	O
the	O
apply	O
function	O
on	O
all	O
rows	O
of	O
df	O
.	O

#CODE	O

and	O
hence	O
I	O
can	O
apply	O
`	O
timedelta64	O
`	O
conversions	O
.	O

For	O
microseconds	O
#CODE	O

You	O
can	O
go	O
by	O
using	O
the	O
power	O
of	O
apply	O
function	O
:	O
#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
test	O
your	O
column	O
like	O
so	O
:	O
#CODE	O

what	O
would	O
be	O
the	O
most	O
efficient	O
way	O
to	O
use	O
groupby	B-API
and	O
in	O
parallel	O
apply	O
a	O
filter	O
in	O
pandas	O
?	O

Python	O
--	O
Pandas	O
:	O
How	O
to	O
apply	O
aggfunc	O
to	O
data	O
in	O
currency	O
format	O
?	O

I	O
have	O
a	O
table	O
above	O
.	O

Want	O
to	O
apply	O
groupby	B-API
function	O
to	O
the	O
data	O
and	O
apply	O
sum	O
(	O
over	O
revenue_total	O
)	O
.	O

Pandas	O
gives	O
an	O
NA	O
value	O
since	O
revenue_total	O
is	O
an	O
object	O
data	O
type	O
.	O

Any	O
help	O
#CODE	O

Apply	O
Different	O
Resampling	O
Method	O
to	O
the	O
Same	O
Column	O
(	O
pandas	O
)	O

I	O
have	O
a	O
time	O
series	O
and	O
I	O
want	O
to	O
apply	O
different	O
functions	O
to	O
the	O
same	O
column	O
.	O

I	O
have	O
2	O
pandas	O
data	O
frames	O
`	O
df	O
`	O
and	O
`	O
df_min	O
`	O
.	O

I	O
apply	O
some	O
filters	O
to	O
`	O
df	O
`	O
,	O
which	O
results	O
in	O
a	O
single	O
row	O
of	O
data	O
,	O
and	O
I'd	O
like	O
to	O
append	O
that	O
row	O
to	O
`	O
df_min	O
`	O
.	O

I	O
tried	O
using	O
a	O
loop	O
to	O
traverse	O
`	O
df	O
`	O
,	O
and	O
tried	O
using	O
`	O
loc	O
`	O
to	O
append	O
the	O
row	O
to	O
`	O
df_min	O
`	O
.	O

I	O
keep	O
getting	O
a	O
`	O
Incompatible	O
indexer	O
with	O
DataFrame	B-API
`	O
ValueError	O
for	O
the	O
line	O
where	O
I	O
use	O
`	O
loc	O
`	O
.	O

I	O
guess	O
I	O
am	O
not	O
using	O
`	O
loc	O
`	O
correctly	O
.	O

What	O
would	O
be	O
the	O
best	O
way	O
to	O
accomplish	O
what	O
I	O
am	O
trying	O
to	O
do	O
?	O

#CODE	O

Pandas	O
how	O
to	O
apply	O
multiple	O
functions	O
to	O
dataframe	B-API

Is	O
there	O
a	O
way	O
to	O
apply	O
a	O
list	O
of	O
functions	O
to	O
each	O
column	O
in	O
a	O
DataFrame	B-API
like	O
the	O
DataFrameGroupBy.agg	O
function	O
does	O
?	O

I	O
found	O
an	O
ugly	O
way	O
to	O
do	O
it	O
like	O
this	O
:	O
#CODE	O

Assuming	O
these	O
were	O
datetime	O
columns	O
(	O
if	O
they're	O
not	O
apply	O
`	O
to_datetime	B-API
`)	O
you	O
can	O
just	O
subtract	O
them	O
:	O
#CODE	O

But	O
when	O
I	O
apply	O
it	O
to	O
the	O
DataFrame	B-API
,	O
I	O
get	O
an	O
error	O
.	O

#CODE	O

Thanks	O
to	O
@USER	O
for	O
pointing	O
out	O
the	O
sweet	O
apply	O
syntax	O
to	O
avoid	O
the	O
lambda	O
.	O

Thanks	O
,	O
Andy	O
.	O

Apply	O
actually	O
passes	O
the	O
values	O
correctly	O
,	O
so	O
you	O
don't	O
need	O
the	O
lambda	O
.	O

I	O
edited	O
the	O
answer	O
to	O
use	O
the	O
simpler	O
syntax	O
,	O
and	O
avoid	O
the	O
lambda	O
.	O

Then	O
apply	O
a	O
lookup	O
from	O
`	O
df2	O
`	O
to	O
each	O
element	O
of	O
the	O
lists	O
in	O
`	O
vals	O
`	O
:	O
#CODE	O

Note	O
:	O
that's	O
a	O
really	O
bad	O
way	O
to	O
iterate	O
over	O
the	O
rows	O
,	O
either	O
use	O
iterrows	B-API
or	O
apply	O
.	O

Using	O
range	O
like	O
that	O
creates	O
a	O
huge	O
python	O
list	O
(	O
in	O
python	O
2	O
)	O
,	O
xrange	O
is	O
slightly	O
better	O
.	O

I	O
believe	O
that	O
you	O
are	O
operating	O
on	O
copies	O
of	O
the	O
dataframe	B-API
.	O

I	O
think	O
you	O
should	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

I	O
don't	O
think	O
so	O
map	O
operates	O
on	O
each	O
element	O
in	O
a	O
series	O
,	O
if	O
you	O
want	O
to	O
pass	O
do	O
something	O
with	O
multiple	O
arguments	O
on	O
a	O
row-wise	O
basis	O
then	O
you	O
could	O
use	O
`	O
apply	O
`	O
and	O
set	O
`	O
axis=1	O
`	O
like	O
so	O
`	O
mn.apply	O
(	O
lambda	O
row	O
:	O
getTag	O
(	O
row	O
)	O
,	O
axis=1	O
)`	O
in	O
`	O
getTag	O
`	O
you	O
can	O
select	O
the	O
columns	O
like	O
so	O
:	O
`	O
row	O
[	O
'	O
fld1	O
']`	O
and	O
`	O
row	O
[	O
'	O
fld2	O
']`	O
.	O

This	O
should	O
achieve	O
what	O
you	O
want	O

And	O
to	O
answer	O
the	O
general	O
question	O
:	O
Yes	O
,	O
there	O
is	O
a	O
way	O
to	O
pass	O
extra	O
arguments	O
--	O
use	O
apply	O
instead	O
of	O
map	O
(	O
Thanks	O
to	O
Andy	O
Hayden	O
for	O
pointing	O
this	O
out	O
):	O
#CODE	O

Still	O
,	O
I	O
don't	O
recommend	O
using	O
`	O
apply	O
`	O
for	O
this	O
particular	O
problem	O
since	O
`	O
pd.cut	B-API
`	O
is	O
be	O
faster	O
,	O
easier	O
to	O
use	O
,	O
and	O
avoids	O
the	O
non-deterministic	O
order	O
of	O
dict	O
keys	O
problem	O
.	O

But	O
knowing	O
that	O
`	O
apply	O
`	O
can	O
take	O
additional	O
positional	O
arguments	O
may	O
help	O
you	O
in	O
the	O
future	O
.	O

How	O
to	O
apply	O
a	O
long	O
set	O
of	O
conditions	O
on	O
a	O
pandas	O
dataframe	B-API
efficiently	O
-	O
stock	O
backtesting	O

I'm	O
attempting	O
to	O
apply	O
a	O
long	O
set	O
of	O
conditions	O
and	O
operations	O
onto	O
a	O
pandas	O
dataframe	B-API
(	O
see	O
the	O
dataframe	B-API
below	O
with	O
VTI	O
,	O
upper	O
,	O
lower	O
,	O
etc	O
)	O
.	O

I	O
attempted	O
to	O
use	O
apply	O
,	O
but	O
I	O
was	O
having	O
a	O
lot	O
of	O
trouble	O
doing	O
so	O
.	O

)	O
.	O

My	O
current	O
solution	O
(	O
which	O
works	O
perfectly	O
)	O
relies	O
on	O
a	O
for	O
loop	O
iterating	O
through	O
the	O
dataframe	B-API
.	O

But	O
my	O
sense	O
is	O
that	O
this	O
is	O
an	O
inefficient	O
way	O
to	O
complete	O
my	O
simulation	O
.	O

I'd	O
appreciate	O
help	O
on	O
the	O
design	O
of	O
my	O
code	O
.	O

#CODE	O

Generally	O
speaking	O
,	O
you	O
need	O
to	O
assess	O
the	O
way	O
in	O
which	O
the	O
desired	O
result	O
for	O
a	O
given	O
row	O
depends	O
on	O
the	O
data	O
that	O
is	O
"	O
higher	O
up	O
"	O
in	O
your	O
set	O
.	O

If	O
a	O
given	O
row's	O
output	O
can	O
be	O
created	O
based	O
on	O
*	O
input	O
*	O
data	O
in	O
higher	O
rows	O
,	O
you	O
can	O
save	O
yourself	O
some	O
time	O
and	O
effort	O
using	O
something	O
like	O
`	O
apply	O
`	O
.	O

But	O
if	O
your	O
desired	O
output	O
for	O
a	O
given	O
row	O
depends	O
on	O
the	O
*	O
output	O
*	O
from	O
earlier	O
rows	O
,	O
then	O
your	O
problem	O
is	O
inherently	O
ordered	O
and	O
as	O
a	O
result	O
,	O
you're	O
unlikely	O
to	O
be	O
able	O
to	O
do	O
much	O
better	O
than	O
a	O
`	O
for	O
`	O
loop	O
even	O
if	O
you	O
wind	O
up	O
with	O
cleaner	O
code	O
.	O

How	O
do	O
I	O
apply	O
a	O
count	O
function	O
?	O

like	O
how=	O
???	O

)	O
Hmmm	O
,	O
I	O
figured	O
out	O
,	O
it's	O
np.size	O

You	O
can	O
[	O
set	O
up	O
a	O
progress	O
meter	O
for	O
apply	O
]	O
(	O
#URL	O
)	O
,	O
but	O
this	O
obviously	O
slows	O
down	O
whatever	O
it	O
is	O
you're	O
doing	O
.	O

Generally	O
a	O
bad	O
idea	O
to	O
return	O
different	O
types	O
of	O
data	O
in	O
an	O
apply	O
(	O
here	O
a	O
string	O
or	O
a	O
Series	O
)	O
,	O
it's	O
unclear	O
what	O
you	O
want	O
the	O
apply	O
to	O
return	O
...	O

@USER	O
Your	O
comment	O
suggests	O
to	O
me	O
that	O
I	O
may	O
not	O
understand	O
`	O
apply	O
`	O
properly	O
.	O

My	O
understanding	O
was	O
that	O
my	O
function	O
would	O
return	O
the	O
string	O
'	O
RARE_VALUE	O
'	O
if	O
the	O
condition	O
were	O
met	O
but	O
keep	O
the	O
existing	O
string	O
/	O
null	O
if	O
it	O
weren't	O
.	O

Is	O
this	O
incorrect	O
?	O

Ah	O
wait	O
,	O
I	O
see	O
what	O
you're	O
saying	O
,	O
I	O
mistook	O
this	O
for	O
a	O
DataFrame	B-API
apply	O
.	O

No	O
you're	O
correct	O
,	O
but	O
boolean	O
masking	O
at	O
each	O
step	O
is	O
**	O
slow**	O
!!	O

Or	O
,	O
if	O
these	O
are	O
numpy	O
arrays	O
you	O
need	O
to	O
apply	O
tolist	B-API
to	O
each	O
item	O
first	O
:	O
#CODE	O

I	O
have	O
a	O
DataFrame	B-API
with	O
multi-index	O
[	O
'	O
timestamp	O
'	O
,	O
'	O
symbol	O
']	O
that	O
contains	O
timeseries	O
data	O
.	O

I	O
merging	O
this	O
data	O
with	O
other	O
samples	O
and	O
my	O
apply	O
function	O
that	O
uses	O
asof	O
is	O
similar	O
to	O
:	O
#CODE	O

pandas	O
groupby	B-API
apply	O
function	O
that	O
take	O
N-column	O
frame	O
and	O
returns	O
object	O

Is	O
there	O
a	O
'	O
transform	O
'	O
method	O
of	O
something	O
like	O
that	O
to	O
apply	O
a	O
function	O
to	O
groups	O
(	O
all	O
columns	O
at	O
once	O
)	O
and	O
return	O
an	O
object	O
?	O

Anything	O
I	O
try	O
seems	O
to	O
return	O
one	O
object	O
per	O
column	O
in	O
the	O
group	O
.	O

and	O
suppose	O
I	O
do	O
a	O
groupby	B-API
on	O
Date	O
and	O
apply	O
some	O
function	O
to	O
the	O
groups	O
labeled	O
by	O
(	O
Term	O
,	O
Month	O
,	O
s	O
)	O
.	O

The	O
result	O
should	O
be	O
something	O
like	O
#CODE	O

You	O
could	O
apply	O
the	O
function	O
and	O
then	O
aggregate	O
each	O
group	O
manually	O
.	O

For	O
example	O
,	O
assuming	O
the	O
aggregation	O
is	O
a	O
mean	O
and	O
the	O
function	O
is	O
the	O
sum	O
of	O
the	O
column	O
,	O
you	O
could	O
:	O
#CODE	O

Then	O
we	O
can	O
apply	O
the	O
fit()	O
on	O
all	O
the	O
columns	O
at	O
once	O
for	O
each	O
group	O
of	O
rows	O
:	O
#CODE	O

I	O
should	O
have	O
mentioned	O
that	O
I	O
can	O
use	O
the	O
'	O
apply	O
'	O
or	O
'	O
agg	O
'	O
function	O
but	O
it	O
returns	O
the	O
same	O
(	O
redundant	O
)	O
object	O
for	O
each	O
column	O
.	O

So	O
it	O
appears	O
that	O
my	O
function	O
is	O
receiving	O
access	O
to	O
the	O
full	O
group	O
each	O
time	O
(	O
which	O
is	O
what	O
I	O
want	O
)	O
but	O
that	O
it	O
is	O
being	O
called	O
once	O
for	O
each	O
column	O
in	O
the	O
group	O
(	O
or	O
at	O
least	O
that's	O
how	O
the	O
result	O
is	O
populated	O
)	O
.	O

Hmmm	O
,	O
I	O
think	O
you	O
are	O
correct	O
for	O
the	O
usage	O
of	O
`	O
agg	O
`	O
,	O
but	O
the	O
`	O
apply	O
`	O
method	O
should	O
normally	O
receive	O
all	O
the	O
columns	O
at	O
once	O
for	O
each	O
group	O
.	O

I	O
edited	O
my	O
answer	O
above	O
to	O
illustrate	O
that	O
.	O

You	O
can	O
convert	O
all	O
elements	O
of	O
id	O
to	O
`	O
str	O
`	O
using	O
`	O
apply	O
`	O
#CODE	O

You	O
really	O
want	O
to	O
return	O
a	O
bool	O
to	O
indicate	O
rather	O
than	O
a	O
string	O
.	O

Also	O
avoiding	O
apply	O
where	O
possible	O
.	O

The	O
data	O
is	O
a	O
bit	O
distorted	O
that	O
is	O
why	O
when	O
I	O
initially	O
read	O
with	O
pd.read_csv	B-API
,	O
the	O
column	O
is	O
mixed	O
with	O
string	O
and	O
int	O
.	O

It	O
is	O
my	O
wish	O
to	O
remove	O
the	O
string	O
part	O
to	O
apply	O
aggregation	O
functions	O
on	O
that	O
columns	O
.	O

My	O
basic	O
question	O
is	O
can	O
I	O
efficiently	O
apply	O
this	O
structure	O
to	O
HDF	O
?	O

Specifically	O
:	O

apply	O
hierarchy	O
or	O
multi-index	O
to	O
panda	O
columns	O

Honestly	O
I'm	O
lost	O
as	O
to	O
how	O
to	O
do	O
it	O
.	O

Do	O
I	O
need	O
to	O
append	O
data	O
from	O
the	O
original	O
reviews	O
back	O
onto	O
my	O
sorted	O
dataframe	B-API
?	O

Do	O
I	O
need	O
to	O
make	O
a	O
function	O
to	O
apply	O
onto	O
the	O
groupby	B-API
function	O
?	O

Tips	O
or	O
suggestions	O
would	O
be	O
very	O
helpful	O
!	O

As	O
DanB	O
says	O
,	O
groupby()	B-API
just	O
splits	O
your	O
DataFrame	B-API
into	O
groups	O
.	O

Then	O
,	O
you	O
apply	O
some	O
number	O
of	O
functions	O
to	O
each	O
group	O
and	O
pandas	O
will	O
stitch	O
the	O
results	O
together	O
as	O
best	O
it	O
can	O
--	O
indexed	O
by	O
the	O
original	O
group	O
identifiers	O
.	O

Other	O
than	O
that	O
,	O
as	O
far	O
as	O
I	O
understand	O
,	O
there's	O
no	O
"	O
memory	O
"	O
for	O
what	O
the	O
original	O
group	O
looked	O
like	O
.	O

Instead	O
,	O
you	O
have	O
to	O
specify	O
what	O
you	O
want	O
to	O
output	O
to	O
contain	O
.	O

There	O
are	O
a	O
few	O
ways	O
to	O
do	O
this	O
--	O
I'd	O
look	O
into	O
'	O
agg	O
'	O
and	O
'	O
apply	O
'	O
.	O

'	O
Agg	O
'	O
is	O
for	O
functions	O
that	O
return	O
a	O
single	O
value	O
for	O
the	O
whole	O
group	O
,	O
whereas	O
apply	O
is	O
much	O
more	O
flexible	O
.	O

Suppose	O
you	O
want	O
to	O
return	O
a	O
dataframe	B-API
of	O
the	O
first	O
and	O
last	O
review	O
by	O
each	O
reviewer	O
.	O

We	O
can	O
use	O
'	O
apply	O
'	O
,	O
which	O
works	O
with	O
any	O
function	O
that	O
outputs	O
a	O
pandas	O
object	O
.	O

So	O
we'll	O
write	O
a	O
function	O
that	O
takes	O
each	O
group	O
and	O
a	O
dataframe	B-API
of	O
just	O
the	O
first	O
and	O
last	O
row	O
:	O

Pandas	O
has	O
a	O
lot	O
of	O
built-in	O
functionality	O
to	O
apply	O
functions	O
in	O
a	O
vectorized	O
way	O
over	O
Series	O
and	O
DataFrames	O
.	O

When	O
that	O
fails	O
,	O
you	O
can	O
use	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
.	O

Here	O
`	O
map	O
`	O
will	O
applies	O
a	O
function	O
element-wise	O
on	O
a	O
Series	O
.	O

For	O
more	O
on	O
map	O
and	O
apply	O
,	O
see	O
this	O
answer	O
.	O

This	O
is	O
better	O
than	O
having	O
multiple	O
DataFrames	O
,	O
because	O
you	O
can	O
apply	O
fast	O
numpy	O
/	O
pandas	O
operations	O
to	O
the	O
entire	O
DataFrame	B-API
whereas	O
,	O
if	O
you	O
had	O
a	O
list	O
of	O
DataFrames	O
you	O
would	O
be	O
forced	O
to	O
use	O
a	O
Python	O
loop	O
to	O
operate	O
on	O
the	O
sub-DataFrames	O
individually	O
(	O
assuming	O
you	O
want	O
to	O
perform	O
the	O
same	O
operation	O
on	O
each	O
sub-DataFrame	O
)	O
.	O

Doing	O
so	O
is	O
generally	O
always	O
slower	O
.	O

I	O
know	O
I	O
can	O
do	O
it	O
by	O
converting	O
the	O
DataFrame	B-API
to	O
a	O
list	O
of	O
lists	O
,	O
or	O
by	O
using	O
a	O
row-wise	O
`	O
apply	O
`	O
to	O
grab	O
each	O
item	O
one	O
by	O
one	O
,	O
but	O
isn't	O
there	O
any	O
way	O
to	O
do	O
it	O
without	O
that	O
amount	O
of	O
overhead	O
?	O

How	O
can	O
I	O
do	O
the	O
equivalent	O
of	O
`	O
Series.map	B-API
`	O
on	O
multiple	O
columns	O
at	O
once	O
?	O

My	O
timing	O
results	O
are	O
somewhat	O
different	O
from	O
yours	O
.	O

I	O
get	O
900us	O
for	O
the	O
MultiIndex	O
solution	O
and	O
only	O
90us	O
for	O
your	O
`	O
apply	O
`	O
.	O

But	O
that	O
`	O
apply	O
`	O
doesn't	O
actually	O
do	O
the	O
indexing	O
;	O
timing	O
`	O
d.apply	O
(	O
lambda	O
r	O
:	O
s.ix	O
[	O
r	O
]	O
,	O
axis=1	O
)`	O
gives	O
a	O
much	O
slower	O
result	O
of	O
about	O
5.5ms	O
.	O

However	O
,	O
I	O
thought	O
of	O
another	O
way	O
:	O
`	O
d.apply	O
(	O
tuple	O
,	O
axis=1	O
)	O
.map	B-API
(	O
s	O
)`	O
.	O

This	O
seems	O
to	O
be	O
even	O
faster	O
at	O
about	O
580us	O
.	O

Even	O
so	O
,	O
doesn't	O
it	O
seem	O
like	O
there	O
should	O
be	O
a	O
built-in	O
way	O
to	O
do	O
this	O
without	O
creating	O
a	O
new	O
data	O
structure	O
?	O

The	O
values	O
I	O
want	O
to	O
index	O
with	O
are	O
already	O
sitting	O
right	O
there	O
.	O

If	O
it	O
is	O
a	O
DatetimeIndex	B-API
the	O
apply	O
won't	O
work	O
.	O

the	O
date_format	O
argument	O
does	O
not	O
apply	O
to	O
timedelta	O
dtypes	B-API
.	O

Easist	O
to	O
simply	O
convert	O
them	O
to	O
strings	O
first	O
,	O
e.g.	O
``	O
df	O
[	O
timedelta_field	O
']	O
=	O
df	O
[	O
'	O
timedelta_fields	O
']	O
.apply	B-API
(	O
str	O
)``	O

You	O
can	O
do	O
an	O
apply	O
on	O
the	O
LgRnk	O
column	O
:	O
#CODE	O

I	O
found	O
this	O
presentation	O
,	O
which	O
is	O
going	O
about	O
SQLALchemy	O
and	O
GeoAlchemy2	O
.	O

And	O
where	O
it	O
is	O
mentioned	O
that	O
it	O
support	O
PostGIS	O
Raster	O
as	O
well	O
.	O

It	O
seems	O
to	O
be	O
very	O
interesting	O
!	O

But	O
using	O
the	O
documentation	O
I	O
don't	O
see	O
how	O
I	O
can	O
apply	O
this	O
to	O
Raster	O
data	O

Using	O
apply	O
,	O
as	O
in	O
`	O
df.x.apply	O
(	O
tuple	O
,	O
axis=1	O
)`	O
will	O
work	O
,	O
but	O
then	O
I'd	O
somehow	O
need	O
to	O
iterate	O
over	O
the	O
first	O
level	O
of	O
the	O
index	O
.	O

`	O
df.x	O
=	O
df.x.apply	O
(	O
tuple	O
,	O
axis=1	O
)`	O
sort-of	O
works	O
,	O
but	O
the	O
index	O
is	O
still	O
unchanged	O
(	O
i.e.	O
still	O
has	O
two	O
levels	O
)	O
.	O

Now	O
I	O
also	O
have	O
a	O
function	O
`	O
func	O
`	O
that	O
takes	O
`	O
id	O
,	O
group	O
`	O
as	O
input	O
.	O

I	O
would	O
like	O
to	O
apply	O
`	O
func	O
`	O
to	O
each	O
`	O
id	O
,	O
group	O
`	O
in	O
the	O
groupby	B-API
object	O
.	O

Currently	O
I	O
use	O
a	O
loop	O
:	O
#CODE	O

Is	O
there	O
any	O
better	O
(	O
faster	O
)	O
way	O
of	O
doing	O
this	O
using	O
an	O
apply	O
or	O
similar	O
?	O

You	O
can	O
use	O
`	O
apply	O
`	O
on	O
the	O
groupby	B-API
object	O
to	O
apply	O
a	O
function	O
to	O
each	O
group	O
.	O

Since	O
the	O
function	O
will	O
need	O
to	O
accept	O
the	O
group	O
as	O
its	O
argument	O
,	O
you	O
can	O
use	O
the	O
following	O
:	O
#CODE	O

Using	O
pandas	O
built	O
in	O
functions	O
you	O
would	O
have	O
to	O
apply	O
`	O
notnull()	B-API
`	O
over	O
all	O
series	O
and	O
then	O
call	O
a	O
numpy	O
function	O
to	O
the	O
DataFrame	B-API
anyway	O
.	O

And	O
can	O
you	O
apply	O
it	O
to	O
selected	O
columns	O
,	O
instead	O
of	O
the	O
whole	O
dataframe	B-API
?	O

-	O
because	O
If	O
I	O
have	O
a	O
text	O
column	O
like	O
someones	O
name	O
,	O
I	O
can	O
foresee	O
it	O
throwing	O
an	O
error	O
?	O

no	O
you	O
cannot	O
just	O
group	O
,	O
you	O
have	O
to	O
apply	O
/	O
transform	O
.	O

Otherwise	O
you	O
could	O
just	O
filter	O
the	O
NaN	O
(	O
I'm	O
assuming	O
that	O
is	O
what	O
you	O
want	O
to	O
do	O
,	O
difficult	O
to	O
tell	O
without	O
sample	O
data	O
and	O
code	O
)	O
and	O
apply	O
the	O
map	O
:	O
`	O
df	O
[	O
'	O
flag	O
']	O
=	O
filtered.notnull()	O
.map	B-API
(	O
'	O
N	O
')`	O

One	O
way	O
is	O
to	O
use	O
an	O
apply	O
:	O
#CODE	O

I	O
need	O
to	O
combine	O
different	O
functions	O
into	O
one	O
and	O
use	O
the	O
apply	O
function	O
(	O
of	O
those	O
individual	O
functions	O
)	O
within	O
the	O
main	O
function	O
itself	O
.	O

My	O
case	O
is	O
something	O
more	O
complex	O
so	O
i'll	O
use	O
a	O
basic	O
example	O
for	O
this	O
.	O

The	O
above	O
function	O
would	O
give	O
me	O
all	O
values	O
in	O
a	O
single	O
column	O
separated	O
by	O
commas	O
.	O

is	O
there	O
a	O
way	O
to	O
apply	O
each	O
one	O
in	O
such	O
a	O
way	O
that	O
they	O
come	O
under	O
different	O
columns	O
??	O

The	O
`	O
apply	O
`	O
returns	O
a	O
dataframe	B-API
with	O
True	O
/	O
False	O
values	O
(	O
the	O
`	O
`	O
expression	O
is	O
evaluated	O
for	O
each	O
column	O
where	O
`	O
x.name	O
[	O
2	O
]`	O
selects	O
the	O
third	O
level	O
of	O
that	O
column	O
name	O
)	O
,	O
and	O
the	O
where	O
replaces	O
the	O
False	O
values	O
with	O
NaN	O
.	O

Apply	O
to	O
each	O
element	O
in	O
a	O
Pandas	O
dataframe	B-API

Is	O
there	O
anyway	O
to	O
apply	O
this	O
simple	O
function	O
to	O
each	O
element	O
in	O
the	O
data	O
frame	O
?	O

I	O
use	O
0.12.0	O
(	O
added	O
to	O
the	O
question	O
as	O
well	O
)	O
.	O

(	O
I	O
am	O
trying	O
to	O
apply	O
your	O
solution	O
and	O
compare	O
times	O
.	O
)	O

python	O
pandas	O
strange	O
error	O
when	O
concat	O
the	O
return	O
values	O
of	O
'	O
apply	O
'	O

The	O
apply	O
function	O
is	O
trying	O
to	O
return	O
a	O
whole	O
dataframe	B-API
in	O
your	O
case	O
.	O

You	O
can't	O
really	O
do	O
that	O
.	O

You	O
can	O
use	O
apply	O
to	O
map	O
a	O
column	O
or	O
a	O
row	O
of	O
a	O
frame	O
to	O
a	O
row	O
/	O
column	O
or	O
scalar	O
.	O

Printing	O
is	O
fine	O
,	O
but	O
that's	O
no	O
surprise	O
...	O

In	O
pandas	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
to	O
do	O
similar	O
thing	O
#CODE	O

The	O
reason	O
the	O
rolling	O
apply	O
does	O
not	O
work	O
is	O
because	O
1	O
)	O
you	O
provided	O
it	O
a	O
GroupBy	B-API
object	O
and	O
not	O
a	O
series	O
,	O
and	O
2	O
)	O
it	O
only	O
works	O
with	O
numerical	O
values	O
.	O

@USER	O
Yes	O
,	O
thinking	O
of	O
the	O
combine	O
was	O
the	O
hard	O
part	O
:-)	O
.	O

For	O
set	O
difference	O
,	O
`	O
s	O
-	O
s2	O
`	O
does	O
work	O
,	O
but	O
intersection	O
as	O
`	O
s	O
&	O
s2	O
`	O
seems	O
not	O
to	O
work	O
for	O
pandas	O
serieses	O
.	O

I	O
was	O
looking	O
for	O
a	O
way	O
to	O
apply	O
a	O
function	O
on	O
the	O
elements	O
of	O
two	O
serieses	O
,	O
but	O
didn't	O
find	O
an	O
obvious	O
one	O
.	O

There	O
hopefully	O
will	O
be	O
some	O
support	O
for	O
parallel	O
`	O
apply	O
`	O
in	O
0.14	O
,	O
see	O
here	O
:	O
#URL	O

also	O
,	O
there's	O
no	O
reason	O
to	O
use	O
apply	O
in	O
this	O
case	O
.	O

Apply	O
upper	O
and	O
lower	O
bounds	O
to	O
Pandas	O
Dataframe	B-API

You	O
could	O
iterate	O
over	O
each	O
column	O
/	O
bounds-list	O
and	O
apply	O
the	O
same	O
filter	O
.	O

#CODE	O

I	O
apply	O
a	O
custom	O
function	O
on	O
the	O
DataFrame	B-API
column	O
(	O
convert_time	O
)	O
#CODE	O

I	O
encounterd	O
the	O
same	O
question	O
and	O
I	O
used	O
a	O
same	O
way	O
like	O
you	O
to	O
solve	O
it	O
.	O

(	O
apply	O
a	O
function	O
to	O
remove	O
the	O
unnecessary	O
data	O
)	O

Only	O
better	O
in	O
terms	O
of	O
simpler	O
syntax	O
:	O
`	O
df.rain_column.map	O
(	O
d	O
)`	O
,	O
and	O
perhaps	O
faster	O
performance-wise	O
,	O
it	O
depends	O
on	O
data	O
size	O
and	O
type	O
for	O
a	O
dataframe	B-API
with	O
100	O
rows	O
then	O
`	O
apply	O
`	O
is	O
marginally	O
faster	O
(	O
apply	O
228	O
us	O
vs	O
map	O
287us	O
)	O
,	O
for	O
one	O
with	O
10000	O
rows	O
then	O
map	O
is	O
26	O
times	O
faster	O
(	O
map	O
is	O
512	O
us	O
vs	O
apply	O
13	O
ms	O
)	O

Alright	O
,	O
this	O
makes	O
a	O
lot	O
of	O
sense	O
,	O
since	O
apply	O
is	O
more	O
general	O
purpose	O
than	O
map	O
.	O

How	O
can	O
I	O
use	O
apply	O
with	O
pandas	O
rolling_corr()	B-API

Also	O
how	O
do	O
we	O
do	O
the	O
same	O
using	O
some	O
applymap	B-API
or	O
apply	O
/	O
map	O
method	O
of	O
df	O
?	O

Ok	O
.	O

I	O
understand	O
this	O
is	O
not	O
how	O
Pandas	O
works	O
.	O

I	O
was	O
trying	O
to	O
relate	O
it's	O
functionality	O
with	O
other	O
data	O
analysis	O
tools	O
.	O

But	O
in	O
R	O
,	O
I	O
could	O
do	O
a	O
similar	O
thing	O
using	O
apply	O
method	O
and	O
then	O
using	O
the	O
same	O
if-else	O
statement	O
.	O

It	O
creates	O
the	O
right	O
flag	O
.	O

Isn't	O
pandas	O
an	O
add	O
on	O
of	O
R	O
dataframe	B-API
with	O
more	O
better	O
features	O
?	O

Or	O
do	O
you	O
think	O
we	O
also	O
have	O
a	O
similar	O
way	O
to	O
do	O
this	O
in	O
pandas	O
using	O
some	O
applymap	B-API
or	O
apply	O
method	O
and	O
if-else	O
construct	O
?	O

This	O
is	O
the	O
R	O
code	O
which	O
creates	O
the	O
flag	O
properly	O
:	O

c$Flag	O
->	O
apply	O
(	O
c	O
,	O
1	O
,	O
function	O
(	O
X	O
)	O
{	O

Why	O
not	O
just	O
use	O
apply	O
with	O
these	O
functions	O
.	O

@USER	O
obviously	O
you	O
have	O
to	O
elaborate	O
.	O

Anyway	O
,	O
like	O
I	O
commented	O
usually	O
it's	O
better	O
to	O
use	O
groupby	B-API
methods	O
e.g	O
apply	O
.	O

Thanks	O
DSM	O
!	O

@USER	O
that	O
would	O
be	O
a	O
sign	O
that	O
the	O
apply	O
did	O
not	O
create	O
a	O
dataframe	B-API
.	O

Are	O
you	O
sure	O
there	O
are	O
lists	O
in	O
your	O
series	O
?	O

Now	O
comes	O
the	O
third	O
part	O
-	O
Let's	O
apply	O
same	O
reasoning	O
.	O

`	O
reindex	O
`	O
is	O
not	O
defined	O
in	O
`	O
MyDataFrame	O
`	O
.	O

Where	O
should	O
we	O
look	O
next	O
?	O

Class	O
hierarchy	O
,	O
that	O
means	O
`	O
pandas.DataFrame	B-API
`	O
.	O

Now	O
`	O
reindex	O
`	O
is	O
indeed	O
defined	O
by	O
this	O
class	O
and	O
it	O
returns	O
a	O
pandas.DataFrame	B-API
object	O
!	O

.	O
(	O
See	O
this	O
:	O
#URL	O
)	O
So	O
,	O
no	O
wonder	O
`	O
y	O
`	O
is	O
a	O
`	O
pandas	O
DataFrame	B-API
`	O
.	O

Apply	O
method	O
of	O
DataFrame	B-API
vs	O
List	O
Comprehension	O

I	O
can	O
do	O
it	O
with	O
list	O
comprehension	O
but	O
I	O
would	O
like	O
to	O
understand	O
if	O
I	O
can	O
do	O
that	O
with	O
the	O
apply	O
method	O
of	O
DataFrame	B-API
.	O

Here	O
is	O
a	O
toy	O
model	O
:	O
#CODE	O

Probably	O
it	O
is	O
just	O
because	O
of	O
my	O
shallow	O
knowledge	O
of	O
pandas	O
,	O
but	O
when	O
I	O
use	O
the	O
apply	O
method	O
I	O
imagine	O
the	O
serie	O
as	O
a	O
list	O
or	O
so	O
end	O
hence	O
I	O
do	O
not	O
have	O
any	O
idea	O
on	O
how	O
to	O
"	O
put	O
"	O
the	O
index	O
attribute	O
.	O

The	O
`	O
(	O
df1-df2	O
)	O
.dropna()	B-API
`	O
call	O
creates	O
a	O
slice	O
of	O
the	O
dataframe	B-API
.	O

When	O
you	O
apply	O
a	O
new	O
operation	O
,	O
this	O
triggers	O
a	O
`	O
SettingWithCopy	O
`	O
check	O
because	O
it	O
could	O
be	O
a	O
copy	O
(	O
but	O
often	O
is	O
not	O
)	O
.	O

slices	O
aren't	O
conditional	O
,	O
you'll	O
have	O
to	O
apply	O
a	O
filter	O
.	O

You	O
could	O
use	O
`	O
apply	O
`	O
,	O
there	O
is	O
probably	O
a	O
better	O
way	O
than	O
this	O
:	O
#CODE	O

One	O
way	O
is	O
to	O
merge	O
index	O
values	O
as	O
well	O
-	O
pd.merge	B-API
(	O
df1.reset_index()	O
,	O
df2.reset_index()	O
,	O
...	O
)	O
.	O

Then	O
run	O
apply	O
twice	O
to	O
return	O
indices	O
of	O
df1	O
and	O
df2	O
as	O
appropriate	O
.	O

You	O
could	O
then	O
select	O
appropriate	O
rows	O
from	O
the	O
two	O
and	O
concatenate	O
pd.concat	B-API
([	O
df1.ix	O
[	O
ix1	O
]	O
,	O
df2.ix	O
[	O
ix2	O
]]	O
,	O
ignore_index=True	O
)	O
.	O

This	O
might	O
make	O
it	O
faster	O

I	O
have	O
a	O
dataframe	B-API
to	O
start	O
with	O
,	O
with	O
that	O
dataframe	B-API
I	O
want	O
to	O
apply	O
some	O
function	O
.	O

I	O
want	O
to	O
repeat	O
this	O
many	O
times	O
and	O
build	O
/	O
stack	O
the	O
reults	O
from	O
the	O
operations	O
in	O
a	O
new	O
larger	O
dataframe	B-API
.	O

I	O
was	O
thinking	O
of	O
doing	O
this	O
with	O
a	O
for	O
loop	O
.	O

Here	O
is	O
a	O
simplified	O
example	O
that	O
I	O
can	O
not	O
get	O
to	O
work	O
:	O
#CODE	O

Clearly	O
the	O
`	O
apply	O
`	O
method	O
isn't	O
a	O
disaster	O
.	O

But	O
just	O
seems	O
weird	O
that	O
I	O
couldn't	O
figure	O
out	O
the	O
syntax	O
for	O
doing	O
this	O
directly	O
across	O
all	O
the	O
columns	O
with	O
`	O
mul	O
`	O
.	O

Is	O
there	O
a	O
more	O
direct	O
way	O
to	O
handle	O
this	O
?	O

If	O
not	O
,	O
is	O
there	O
an	O
intuitive	O
reason	O
the	O
`	O
mul	O
`	O
syntax	O
shouldn't	O
be	O
enhanced	O
to	O
work	O
this	O
way	O
?	O

Jeff	O
,	O
thanks	O
for	O
the	O
reply	O
.	O

And	O
sorry	O
for	O
highlighting	O
something	O
that's	O
already	O
been	O
flagged	O
as	O
an	O
issue	O
.	O

For	O
what	O
it's	O
worth	O
,	O
I	O
think	O
my	O
`	O
apply	O
`	O
column-wise	O
solution	O
,	O
above	O
,	O
is	O
easier	O
to	O
read	O
than	O
the	O
`	O
pd.concat	B-API
...	O

`	O
method	O
in	O
your	O
`	O
[	O
129	O
]`	O
.	O

What	O
do	O
you	O
think	O
?	O

using	O
``	O
apply	O
``	O
will	O
be	O
much	O
slower	O
.	O

Both	O
options	O
works	O
very	O
nice	O
:)	O
Do	O
you	O
know	O
hot	O
to	O
apply	O
your	O
method	O
to	O
use	O
secondary	O
`	O
y_axis	O
`	O
[	O
example	O
]	O
(	O
#URL	O
)	O
?	O

I	O
know	O
I	O
can	O
loop	O
through	O
and	O
apply	O
regex	O
#CODE	O

whats	O
the	O
best	O
way	O
to	O
apply	O
it	O
to	O
the	O
column	O
in	O
the	O
dataframe	B-API
?	O

so	O
I	O
have	O
df	O
[	O
'	O
pricing	O
']	O
do	O
I	O
just	O
loop	O
row	O
by	O
row	O
?	O

It	O
is	O
like	O
a	O
dataframe	B-API
,	O
but	O
requires	O
`	O
apply	O
`	O
to	O
generate	O
a	O
new	O
structure	O
(	O
either	O
reduced	O
or	O
an	O
actual	O
DataFrame	B-API
)	O
.	O

Doing	O
something	O
like	O
:	O
`	O
df.groupby	B-API
(	O
...	O
)	O
.sum()	B-API
`	O
is	O
syntactic	O
sugar	O
for	O
using	O
`	O
apply	O
`	O
.	O

Functions	O
which	O
are	O
naturally	O
applicable	O
to	O
using	O
this	O
kind	O
of	O
sugar	O
are	O
enabled	O
;	O
otherwise	O
they	O
will	O
raise	O
an	O
error	O
.	O

Their	O
are	O
ways	O
to	O
apply	O
some	O
operations	O
to	O
multiple	O
slabs	O
of	O
a	O
n-dim	O
(	O
esp	O
.	O
via	O
new	O
`	O
apply	O
`	O
in	O
0.13.1	O
,	O
see	O
here	O
.	O

Using	O
partial	O
with	O
groupby	B-API
and	O
apply	O
in	O
Pandas	O

I	O
am	O
having	O
trouble	O
using	O
partial	O
with	O
groupby	B-API
and	O
apply	O
in	O
Pandas	O
.	O

Perhaps	O
I	O
am	O
not	O
using	O
this	O
right	O
?	O

#CODE	O

There	O
is	O
no	O
need	O
to	O
use	O
`	O
functools.partial	O
`	O
here	O
,	O
as	O
you	O
can	O
provide	O
arguments	O
to	O
the	O
function	O
inside	O
the	O
`	O
apply	O
`	O
call	O
.	O

If	O
your	O
function	O
has	O
as	O
first	O
argument	O
the	O
group	O
(	O
so	O
switch	O
the	O
order	O
of	O
the	O
arguments	O
)	O
,	O
then	O
the	O
other	O
arguments	O
in	O
`	O
apply	O
`	O
are	O
passed	O
to	O
the	O
function	O
and	O
in	O
this	O
way	O
you	O
can	O
specify	O
the	O
`	O
columnName	O
`	O
in	O
the	O
apply	O
:	O
#CODE	O

The	O
reason	O
it	O
does	O
not	O
work	O
with	O
partial	O
,	O
is	O
that	O
`	O
functools.wraps	O
`	O
does	O
not	O
seem	O
to	O
work	O
together	O
with	O
`	O
functools.partial	O
`	O
(	O
`	O
wraps	O
`	O
is	O
used	O
inside	O
the	O
apply	O
)	O
.	O

except	O
that	O
the	O
top	O
n	O
logic	O
should	O
be	O
embedded	O
(	O
head	O
(	O
n	O
)	O
does	O
not	O
work	O
with	O
n	O
depends	O
on	O
my	O
data-set	O
-	O
I	O
guess	O
I	O
need	O
to	O
use	O
"	O
apply	O
"	O
?	O

-	O
and	O
post	O
this	O
the	O
Object	O
,	O
which	O
is	O
a	O
""	O
object	O
needs	O
to	O
be	O
identified	O
by	O
matplotlib	O
with	O
its	O
own	O
labels	O
(	O
top	O
n	O
"	O
name	O
"	O
here	O
)	O

Still	O
not	O
following	O
how	O
the	O
cluster	O
name	O
is	O
chosen	O
.	O

Also	O
,	O
you	O
don't	O
need	O
to	O
apply	O
list	O
in	O
definition	O
of	O
cn1	O
since	O
you're	O
iterating	O
through	O
it	O
.	O

Thanks	O
to	O
user1827356	O
,	O
I	O
sped	O
it	O
up	O
by	O
a	O
factor	O
of	O
100	O
by	O
taking	O
the	O
operation	O
out	O
of	O
the	O
apply	O
.	O

For	O
some	O
reason	O
first	O
was	O
dropping	O
by	O
Group	O
column	O
,	O
so	O
I	O
used	O
idxmax	B-API
instead	O
.	O

#CODE	O

Then	O
using	O
the	O
built-in	O
apply	O
function	O
in	O
pandas	O
.	O

But	O
then	O
,	O
I	O
realize	O
none	O
of	O
my	O
dates	O
are	O
in	O
fact	O
strings	O
,	O
so	O
that	O
does	O
not	O
really	O
solve	O
the	O
problem	O
.	O

#CODE	O

no	O
,	O
you	O
need	O
to	O
do	O
this	O
on	O
the	O
entire	O
frame	O
,	O
selecting	O
out	O
individual	O
elements	O
is	O
general	O
VERY	O
slow	O
.	O

Try	O
doing	O
what	O
I	O
suggegted	O
AFTER	O
a	O
groupby	B-API
(	O
e.g.	O
in	O
the	O
apply	O
function	O
itself	O
,	O
which	O
only	O
has	O
a	O
time-index	O
and	O
only	O
has	O
the	O
elements	O
for	O
which	O
group	O
you	O
need	O
)	O

You	O
could	O
also	O
use	O
`	O
shift	O
`	O
to	O
accomplish	O
this	O
within	O
a	O
`	O
groupby	B-API
`	O
/	O
`	O
apply	O
`	O
:	O
#CODE	O

this	O
is	O
pretty	O
awesome	O
,	O
never	O
thought	O
about	O
shift	O
.	O

I	O
did	O
try	O
to	O
use	O
groupby	B-API
and	O
apply	O
with	O
a	O
vlookup	O
and	O
couldn't	O
quite	O
crack	O
it	O
.	O
this	O
works	O
perfectly	O
,	O
but	O
just	O
for	O
my	O
own	O
educational	O
use	O
,	O
if	O
there	O
were	O
some	O
years	O
skipped	O
and	O
a	O
vlookup	O
was	O
needed	O
,	O
would	O
you	O
know	O
what	O
to	O
do	O
?	O

Why	O
is	O
this	O
printing	O
the	O
print	O
statement	O
in	O
the	O
function	O
4	O
times	O
?	O

The	O
way	O
I	O
would	O
have	O
thought	O
it	O
works	O
is	O
to	O
group	O
`	O
df	O
`	O
into	O
3	O
dataframes	O
(	O
for	O
each	O
machine	O
)	O
and	O
apply	O
`	O
func	O
`	O
on	O
each	O
of	O
those	O
grouped	O
dataframes	O
.	O

But	O
this	O
is	O
not	O
what	O
I	O
observe	O
...	O

For	O
example	O
if	O
three	O
values	O
in	O
a	O
row	O
are	O
all	O
higher	O
than	O
the	O
previous	O
,	O
and	O
the	O
fourth	O
is	O
lower	O
,	O
then	O
I	O
want	O
to	O
add	O
the	O
first	O
three	O
.	O

Does	O
that	O
make	O
sense	O
.	O

I	O
want	O
the	O
capability	O
that	O
excels	O
cell.offset	O
property	O
or	O
array	O
element	O
provides	O
.	O

I	O
need	O
to	O
be	O
able	O
to	O
apply	O
calculations	O
on	O
multiple	O
values	O
from	O
a	O
dataframe	B-API
column	O
,	O
rather	O
than	O
a	O
single	O
value	O
.	O

I	O
want	O
to	O
apply	O
my_func	O
(	O
a	O
custom	O
created	O
function	O
)	O
to	O
each	O
row	O
of	O
a	O
dataframe	B-API
.	O

#CODE	O

You	O
need	O
to	O
set	O
`	O
axis=1	O
`	O
in	O
`	O
apply	O
`	O
:	O
#CODE	O

If	O
you're	O
only	O
passing	O
in	O
the	O
row	O
,	O
you	O
can	O
just	O
do	O
`	O
df.apply	B-API
(	O
my_func	O
,	O
axis=1	O
)`	O
.	O

Atlernatively	O
,	O
you	O
can	O
use	O
the	O
`	O
args	O
`	O
kwarg	O
or	O
a	O
`	O
lambda	O
`	O
to	O
pass	O
in	O
more	O
arguments	O
.	O

`	O
apply	O
(	O
my_funx	O
,	O
axis=1	O
,	O
args	O
=(	O
par1	O
,	O
par2	O
))`	O
or	O
`	O
apply	O
(	O
lambda	O
row	O
:	O
my_func	O
(	O
row	O
,	O
par1	O
,	O
par2	O
)	O
,	O
axis=1	O
)`	O

However	O
,	O
it	O
is	O
really	O
slow	O
.	O

I	O
looked	O
around	O
and	O
found	O
`	O
apply	O
`	O
can	O
do	O
the	O
work	O
too	O
:	O
#CODE	O

It's	O
even	O
faster	O
.	O

With	O
my	O
larger	O
dataset	O
(	O
about	O
90k	O
rows	O
)	O
,	O
the	O
`	O
transform	O
`	O
method	O
takes	O
about	O
44	O
secs	O
on	O
my	O
computer	O
,	O
`	O
apply	O
`	O
takes	O
~2	O
secs	O
and	O
the	O
`	O
for	O
loop	O
`	O
takes	O
only	O
~1	O
secs	O
.	O

I	O
need	O
to	O
work	O
on	O
much	O
larger	O
dataset	O
so	O
even	O
the	O
time	O
difference	O
between	O
the	O
`	O
apply	O
`	O
and	O
`	O
for	O
loop	O
`	O
makes	O
a	O
difference	O
to	O
me	O
.	O

However	O
,	O
the	O
`	O
for	O
loop	O
`	O
looks	O
ugly	O
and	O
may	O
not	O
be	O
easily	O
applied	O
if	O
I	O
need	O
to	O
create	O
other	O
group-based	O
variables	O
.	O

Above	O
"	O
apply_by_multiprocessing	O
"	O
can	O
execute	O
Pandas	O
Dataframe	B-API
apply	O
in	O
parallel	O
.	O

But	O
when	O
I	O
make	O
it	O
to	O
Celery	O
task	O
,	O
It	O
raised	O
AssertionError	O
:	O
'	O
Worker	O
'	O
object	O
has	O
no	O
attribute	O
'	O
_config	O
'	O
.	O

#CODE	O

You	O
can	O
apply	O
`	O
strip	O
`	O
to	O
each	O
element	O
in	O
a	O
column	O
this	O
way	O
:	O
#CODE	O

But	O
a	O
groupby	B-API
operation	O
doesn't	O
actually	O
return	O
a	O
DataFrame	B-API
sorted	O
by	O
group	O
.	O

The	O
`	O
.head()	B-API
`	O
method	O
is	O
a	O
little	O
misleading	O
here	O
--	O
it's	O
just	O
a	O
convenience	O
feature	O
to	O
let	O
you	O
re-examine	O
the	O
object	O
(	O
in	O
this	O
case	O
,	O
`	O
df	O
`)	O
that	O
you	O
grouped	O
.	O

The	O
result	O
of	O
`	O
groupby	B-API
`	O
is	O
separate	O
kind	O
of	O
object	O
,	O
a	O
`	O
GroupBy	B-API
`	O
object	O
.	O

You	O
must	O
`	O
apply	O
`	O
,	O
`	O
transform	O
`	O
,	O
or	O
`	O
filter	O
`	O
to	O
get	O
back	O
to	O
a	O
DataFrame	B-API
or	O
Series	O
.	O

Why	O
am	O
I	O
getting	O
an	O
empty	O
row	O
in	O
my	O
dataframe	B-API
after	O
using	O
pandas	O
apply	O
?	O

I'm	O
fairly	O
new	O
to	O
Python	O
and	O
Pandas	O
and	O
trying	O
to	O
figure	O
out	O
how	O
to	O
do	O
a	O
simple	O
split-join-apply	O
.	O

The	O
problem	O
I	O
am	O
having	O
is	O
that	O
I	O
am	O
getting	O
an	O
blank	O
row	O
at	O
the	O
top	O
of	O
all	O
the	O
dataframes	O
I'm	O
getting	O
back	O
from	O
Pandas	O
'	O
apply	O
function	O
and	O
I'm	O
not	O
sure	O
why	O
.	O

Can	O
anyone	O
explain	O
?	O

The	O
groupby	B-API
/	O
apply	O
operation	O
returns	O
is	O
a	O
new	O
DataFrame	B-API
,	O
with	O
a	O
named	O
index	O
.	O

The	O
name	O
corresponds	O
to	O
the	O
column	O
name	O
by	O
which	O
the	O
original	O
DataFrame	B-API
was	O
grouped	O
.	O

Ah	O
,	O
okay	O
,	O
so	O
the	O
reason	O
it	O
is	O
there	O
is	O
that	O
the	O
groupby	B-API
/	O
apply	O
operation	O
_replaces_	O
the	O
usual	O
indexing	O
with	O
indexing	O
by	O
the	O
grouping	O
value	O
?	O

Is	O
that	O
correct	O
?	O

Yes	O
,	O
the	O
result	O
of	O
the	O
groupby	B-API
/	O
apply	O
is	O
a	O
new	O
DataFrame	B-API
,	O
with	O
a	O
named	O
index	O
,	O
and	O
the	O
name	O
corresponds	O
to	O
the	O
column	O
name	O
by	O
which	O
the	O
original	O
DataFrame	B-API
was	O
grouped	O
.	O

This	O
way	O
reduce	O
the	O
timings	O
by	O
half	O
on	O
my	O
side	O
.	O

By	O
problem	O
is	O
I	O
have	O
values	O
for	O
hours	O
initialy	O
in	O
24	O
columns	O
and	O
date	O
in	O
first	O
one	O
.	O

So	O
I	O
have	O
to	O
be	O
more	O
efficient	O
as	O
I	O
can	O
because	O
after	O
,	O
I	O
have	O
to	O
stach	O
columns	O
and	O
do	O
an	O
apply	O
to	O
do	O
a	O
relativedelta	B-API
on	O
the	O
datetime	O
(	O
which	O
is	O
take	O
actually	O
2	O
min	O
more	O
)	O
...	O

I	O
have	O
done	O
one	O
for	O
this	O
typical	O
problem	O
{	O
too	O
long	O
dataframe	B-API
apply	O
row	O
functions}	O
.	O

I	O
am	O
very	O
suprising	O
if	O
I	O
am	O
the	O
first	O
person	O
to	O
deal	O
with	O
this	O
problem	O
.	O

too	O
long	O
dataframe	B-API
apply	O
row	O
functions	O

Rather	O
than	O
do	O
a	O
apply	O
here	O
,	O
I	O
would	O
probably	O
check	O
each	O
column	O
for	O
whether	O
it's	O
numeric	O
with	O
a	O
simple	O
list	O
comprehension	O
and	O
separate	O
these	O
paths	O
and	O
then	O
concat	O
them	O
back	O
.	O

This	O
will	O
be	O
more	O
efficient	O
for	O
larger	O
frames	O
.	O

#CODE	O

Ah	O
,	O
I	O
was	O
talking	O
about	O
calling	O
a	O
method	O
(	O
`	O
fillna	B-API
`)	O
on	O
an	O
object	O
wrapped	O
by	O
a	O
curly	O
bracket	O
,	O
which	O
I	O
am	O
usually	O
not	O
a	O
fan	O
of	O
.	O

I	O
prefer	O
using	O
`	O
apply	O
`	O
as	O
suggested	O
by	O
Karl	O
.	O

Or	O
you	O
could	O
use	O
shift	O
within	O
a	O
`	O
groupby	B-API
`	O
/	O
`	O
apply	O
`	O
:	O
#CODE	O

Thanks	O
.	O

I	O
like	O
the	O
`	O
apply	O
`	O
solution	O
!	O

Pandas	O
Groupby	B-API
apply	O
function	O
to	O
count	O
values	O
greater	O
than	O
zero	O

Pandas	O
Groupby	B-API
apply	O
function	O
to	O
count	O
values	O
greater	O
than	O
zero	O

You	O
might	O
want	O
consider	O
using	O
apply	O
:	O
#CODE	O

Groupem	O
(	O
can	O
also	O
use	O
an	O
apply	O
here	O
)	O
#CODE	O

Apply	O
is	O
only	O
useful	O
when	O
you	O
cannot	O
vectorize	B-API
.	O

Before	O
even	O
stored	O
would	O
be	O
great	O
.	O

Would	O
an	O
apply	O
be	O
the	O
fastest	O
way	O
for	O
after	O
the	O
fact	O
?	O

Writing	O
an	O
apply	O
right	O
now	O
.	O

Is	O
there	O
a	O
way	O
to	O
get	O
the	O
width	O
of	O
a	O
column	O
of	O
type	O
object	O
?	O

Just	O
apply	O
`	O
to_datetime	B-API
`	O
:	O
#CODE	O

Presumably	O
you	O
want	O
to	O
real	O
part	O
of	O
the	O
complex	O
numbers	O
(	O
numpy.real	B-API
)	O
,	O
unfortunately	O
this	O
doesn't	O
play	O
super	O
nicely	O
with	O
pandas	O
Series	O
/	O
DataFrame	B-API
,	O
so	O
you	O
need	O
to	O
apply	O
back	O
the	O
indexes	O
:	O
#CODE	O

I	O
have	O
messed	O
around	O
with	O
groupby	B-API
,	O
and	O
calculated	O
actual	O
epoch	O
values	O
at	O
the	O
start	O
and	O
end	O
of	O
5	O
minute	O
time	O
blocks	O
for	O
each	O
of	O
the	O
observation	O
periods	O
,	O
in	O
a	O
separate	O
dataframe	B-API
.	O

But	O
I	O
can't	O
see	O
how	O
to	O
bring	O
these	O
to	O
bear	O
in	O
a	O
function	O
that	O
applies	O
per	O
observation	O
period	O
in	O
the	O
original	O
dataframe	B-API
above	O
,	O
where	O
there	O
are	O
multiple	O
values	O
for	O
each	O
observational	O
period	O
.	O

I	O
suspect	O
the	O
answer	O
lies	O
in	O
a	O
better	O
comprehension	O
of	O
groupby	B-API
and	O
the	O
apply	O
method	O
,	O
but	O
I'm	O
having	O
trouble	O
getting	O
this	O
off	O
the	O
ground	O
.	O

(	O
Also	O
,	O
maybe	O
I	O
am	O
not	O
using	O
the	O
right	O
search	O
terms	O
,	O
but	O
I'm	O
not	O
finding	O
much	O
on	O
this	O
posted	O
to	O
the	O
forum	O
already	O
.	O
I'm	O
only	O
able	O
to	O
find	O
info	O
on	O
working	O
with	O
timeseries	O
)	O
.	O

Two	O
options	O
I've	O
considered	O
but	O
can't	O
figure	O
out	O
how	O
to	O
program	O
:	O

[	O
Edit	O
]	O
Update	O
-	O
I	O
think	O
you	O
can	O
use	O
the	O
apply	O
function	O
to	O
subtract	O
the	O
right	O
min	O
time	O
#CODE	O

Okay	O
,	O
this	O
is	O
making	O
some	O
progress	O
.	O

But	O
each	O
of	O
my	O
observation	O
periods	O
starts	O
at	O
a	O
different	O
time	O
(	O
the	O
dates	O
&	O
times	O
are	O
spread	O
out	O
over	O
3	O
months	O
)	O
.	O

So	O
,	O
I	O
can't	O
just	O
do	O
step	O
1	O
across	O
all	O
my	O
'	O
epoch	O
'	O
data	O
-	O
I	O
need	O
to	O
apply	O
it	O
separately	O
for	O
each	O
'	O
observation	O
'	O
group	O
.	O

Similarly	O
,	O
I'd	O
need	O
to	O
do	O
step	O
2	O
by	O
'	O
observation	O
'	O
group	O
.	O

So	O
I	O
think	O
the	O
plan	O
of	O
action	O
will	O
be	O
to	O
use	O
the	O
sort	O
of	O
approach	O
you've	O
provided	O
,	O
but	O
apply	O
it	O
via	O
groupby	B-API
?	O

I've	O
updated	O
the	O
answer	O
.	O

Based	O
on	O
the	O
dataframe	B-API
you	O
created	O
you	O
can	O
get	O
the	O
right	O
min	O
value	O
and	O
apply	O
to	O
the	O
epoch	O
column	O

A	O
few	O
caveats	O
apply	O
:	O

Given	O
that	O
the	O
time	O
periods	O
in	O
the	O
data	O
are	O
non-uniform	O
and	O
contain	O
overlap	O
,	O
there	O
are	O
a	O
few	O
approaches	O
possible	O
.	O

If	O
you're	O
alright	O
with	O
linearly	O
averaging	O
entries	O
and	O
exits	O
,	O
you	O
can	O
take	O
each	O
time	O
period	O
and	O
calculate	O
how	O
many	O
entries	O
and	O
exits	O
occur	O
per	O
hour	O
on	O
average	O
,	O
then	O
,	O
given	O
an	O
hour	O
,	O
you	O
could	O
iterate	O
through	O
all	O
data	O
points	O
,	O
find	O
how	O
much	O
a	O
data	O
point	O
overlaps	O
with	O
that	O
hour	O
(	O
i.e.	O
15	O
minutes	O
or	O
the	O
whole	O
hour	O
)	O
,	O
and	O
apply	O
the	O
data	O
point's	O
average	O
entries	O
/	O
exits	O
per	O
hour	O
modified	O
by	O
the	O
percentage	O
of	O
overlap	O
to	O
an	O
accumulator	O
.	O

Struggling	O
with	O
pandas	O
'	O
rolling	O
and	O
shifting	O
concept	O
.	O

There	O
are	O
many	O
good	O
suggestions	O
including	O
in	O
this	O
forum	O
but	O
I	O
failed	O
miserably	O
to	O
apply	O
these	O
to	O
my	O
scenario	O
.	O

If	O
you	O
manage	O
to	O
get	O
the	O
data	O
in	O
ine	O
single	O
Dataframe	B-API
it	O
should	O
be	O
possible	O
using	O
'	O
apply	O
'	O
.	O

and	O
then	O
you	O
can	O
group	O
by	O
the	O
'	O
i	O
'	O
column	O
and	O
apply	O
an	O
arbitrary	O
function	O
to	O
the	O
subgroup	O
.	O

#CODE	O

or	O
`	O
apply	O
`	O
:	O
#CODE	O

I	O
have	O
a	O
MultiIndex	O
pandas	O
DataFrame	B-API
in	O
which	O
I	O
want	O
to	O
apply	O
a	O
function	O
to	O
one	O
of	O
its	O
columns	O
and	O
assign	O
the	O
result	O
to	O
that	O
same	O
column	O
.	O

#CODE	O

I	O
managed	O
to	O
apply	O
the	O
function	O
slicing	O
the	O
dataframe	B-API
with	O
`	O
.loc	B-API
`	O
as	O
the	O
warning	O
recommended	O
:	O
#CODE	O

Thank	O
you	O
,	O
removing	O
the	O
indexing	O
is	O
speeding	O
up	O
the	O
process	O
substantially	O
.	O

However	O
,	O
I	O
still	O
get	O
very	O
large	O
file	O
sizes	O
:	O
for	O
every	O
300Mb	O
table	O
that	O
I	O
append	O
to	O
the	O
merged	O
store	O
,	O
I	O
get	O
an	O
increase	O
in	O
size	O
of	O
1Gb	O
which	O
eventually	O
is	O
going	O
to	O
fill	O
in	O
my	O
disk	O
.	O

This	O
should	O
not	O
be	O
due	O
to	O
compression	O
,	O
as	O
I	O
did	O
not	O
apply	O
compression	O
to	O
the	O
300Mb	O
files	O
.	O

But	O
I'm	O
looking	O
for	O
generalization	O
for	O
arbitrary	O
number	O
of	O
columns	O
.	O

I	O
tried	O
to	O
apply	O
these	O
methods	O
as	O
reduction	O
function	O
,	O
but	O
couldn't	O
make	O
it	O
work	O
.	O

Third	O
question	O
:	O
I	O
think	O
that	O
the	O
code	O
is	O
quite	O
pythonic	O
,	O
but	O
I	O
am	O
not	O
proud	O
of	O
that	O
because	O
of	O
the	O
last	O
list	O
comprehension	O
which	O
is	O
running	O
over	O
the	O
series	O
of	O
the	O
dataframe	B-API
:	O
using	O
the	O
method	O
apply	O
would	O
look	O
better	O
to	O
my	O
eyes	O
(	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
do	O
it	O
)	O
.	O

Nontheless	O
is	O
there	O
any	O
real	O
reason	O
(	O
apart	O
from	O
elegance	O
)	O
I	O
should	O
work	O
to	O
do	O
the	O
changes	O
?	O

I'm	O
not	O
sure	O
there	O
is	O
a	O
better	O
method	O
than	O
using	O
apply	O
in	O
this	O
case	O

Unfortunately	O
it	O
isn't	O
currently	O
possible	O
to	O
apply	O
Excel	O
formatting	O
when	O
writing	O
data	O
with	O
Pandas	O
`	O
to_excel()	B-API
`	O
.	O

You	O
can	O
apply	O
column	O
formatting	O
when	O
using	O
XlsxWriter	O
as	O
the	O
Excel	O
writer	O
engine	O
.	O

See	O
Working	O
with	O
Python	O
Pandas	O
and	O
XlsxWriter	O
.	O

Use	O
a	O
function	O
and	O
apply	O
to	O
whole	O
column	O
:	O
#CODE	O

pandas	O
apply	O
filter	O
for	O
boolean	O
type	O

`	O
pd.tools.plotting.scatter_matrix	O
`	O
returns	O
an	O
array	O
of	O
the	O
axes	O
it	O
draws	O
;	O
The	O
lower	O
left	O
boundary	O
axes	O
corresponds	O
to	O
indices	O
`	O
[:	O
,	O
0	O
]`	O
and	O
`	O
[	O
-1	O
,	O
:]	O
`	O
.	O

One	O
can	O
loop	O
over	O
these	O
elements	O
and	O
apply	O
any	O
sort	O
of	O
modifications	O
.	O

For	O
example	O
:	O
#CODE	O

You	O
can	O
apply	O
a	O
multiindex	O
to	O
a	O
dataframe	B-API
with	O
#CODE	O

Once	O
you	O
tested	O
`	O
flatten	O
`	O
on	O
one	O
OrderedDict	O
,	O
it	O
is	O
straight-forward	O
to	O
apply	O
it	O
to	O
a	O
list	O
of	O
OrderedDict	O

Yeah	O
,	O
thanks	O
a	O
lot	O
@USER	O
Zhu	O
.	O

Quick	O
follow-up	O
:	O
I	O
have	O
a	O
couple	O
hundred	O
columns	O
,	O
so	O
I	O
can't	O
call	O
a	O
column	O
the	O
way	O
you	O
called	O
the	O
column	O
Val	O
.	O

How	O
would	O
I	O
apply	O
the	O
method	O
you	O
suggested	O
on	O
across	O
every	O
column	O
?	O

Inconsistent	O
behavior	O
of	O
apply	O
with	O
operator.itemgetter	O
v.s.	O
applymap	B-API
operator.itemgetter	O

`	O
apply	O
`	O
gives	O
wrong	O
result	O
#CODE	O

apply	O
is	O
being	O
passed	O
an	O
entire	O
row	O
which	O
is	O
a	O
series	O
of	O
2	O
elements	O
which	O
are	O
lists	O
;	O
the	O
last	O
list	O
is	O
returned	O
and	O
coerced	O
to	O
a	O
series	O
.	O
embedded	O
lists	O
as	O
elements	O
are	O
not	O
a	O
good	O
idea	O
in	O
general	O
.	O

apply	O
custom	O
function	O
/	O
method	O
to	O
the	O
groups	O
(	O
sort	O
within	O
group	O
on	O
col	O
'	O
A	O
'	O
,	O
filter	O
elements	O
)	O
.	O

#CODE	O

If	O
you	O
wish	O
to	O
select	O
many	O
rows	O
per	O
group	O
,	O
you	O
could	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
with	O
a	O
function	O
that	O
returns	O
sub-DataFrames	O
for	O

each	O
group	O
.	O

`	O
apply	O
`	O
will	O
then	O
try	O
to	O
merge	O
these	O
sub-DataFrames	O
for	O
you	O
.	O

Another	O
way	O
is	O
to	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
to	O
return	O
a	O
Series	O
of	O
index	O
values	O
.	O

Again	O
`	O
apply	O
`	O
will	O
try	O
to	O
join	O
the	O
Series	O
into	O
one	O
Series	O
.	O

You	O
could	O
then	O
use	O
`	O
df.loc	B-API
`	O
to	O
select	O
rows	O
by	O
index	O
value	O
:	O
#CODE	O

Also	O
,	O
the	O
reason	O
is	O
because	O
the	O
entire	O
data	O
frame	O
is	O
read	O
in	O
externally	O
but	O
that	O
one	O
column	O
happens	O
to	O
be	O
all	O
JSON	O
.	O

I	O
apply	O
pd.io.json.read_json()	O
to	O
the	O
column	O
but	O
that	O
leaves	O
me	O
with	O
a	O
column	O
of	O
DataFrames	O
that	O
I	O
need	O
to	O
expand	O
out	O
.	O

But	O
when	O
I	O
apply	O
the	O
conditions	O
to	O
obtain	O
the	O
final	O
dataframe	B-API
:	O
#CODE	O

I'm	O
using	O
Ubuntu	O
,	O
so	O
this	O
might	O
not	O
apply	O
that	O
accurately	O
,	O
but	O
here's	O
how	O
I'll	O
do	O
it	O
.	O

#CODE	O

However	O
,	O
also	O
note	O
that	O
Pandas	O
has	O
string	O
operators	O
builtin	O
.	O

Using	O
them	O
will	O
be	O
far	O
faster	O
than	O
using	O
`	O
apply	O
`	O
to	O
call	O
a	O
custom	O
Python	O
function	O
for	O
each	O
item	O
in	O
the	O
Series	O
.	O

#CODE	O

No	O
need	O
to	O
go	O
via	O
`	O
apply	O
`	O
;	O
`	O
100	O
*	O
df2	O
/	O
df2.sum()	O
`	O
should	O
work	O
.	O

For	O
looping	O
over	O
a	O
groupby	B-API
object	O
,	O
you	O
can	O
try	O
`	O
apply	O
`	O
.	O

For	O
example	O
,	O
#CODE	O

Pandas	O
:	O
Timing	O
difference	O
between	O
Function	O
and	O
Apply	O
to	O
Series	O

Why	O
is	O
the	O
apply	O
(	O
lambda	O
)	O
method	O
~	O
3.5	O
x	O
slower	O
.	O

In	O
more	O
complex	O
dataframes	O
,	O
I	O
have	O
noticed	O
a	O
larger	O
difference	O
(	O
~10	O
x	O
)	O
.	O

So	O
in	O
this	O
case	O
it	O
looks	O
like	O
most	O
of	O
the	O
performance	O
difference	O
is	O
related	O
apply	O
converting	O
each	O
column	O
to	O
a	O
`	O
Series	O
`	O
and	O
passing	O
each	O
series	O
separately	O
to	O
rolling_mean	B-API
.	O

Having	O
it	O
use	O
`	O
Raw=True	O
`	O
has	O
it	O
just	O
pass	O
ndarrays	O
.	O

Aftermath	O
:	O
I	O
ended	O
up	O
being	O
a	O
coward	O
and	O
preprocessing	O
the	O
data	O
before	O
importing	O
into	O
pandas	O
.	O

But	O
I'm	O
still	O
curious	O
if	O
there's	O
a	O
general	O
solution	O
,	O
using	O
something	O
like	O
apply	O
or	O
map	O
.	O

@USER	O
.	O

Yes	O
I	O
am	O
sure	O
.	O

`	O
sweep	O
`	O
is	O
based	O
on	O
`	O
apply	O
`	O
.	O

if	O
you	O
read	O
the	O
documentation	O
for	O
apply	O
,	O
the	O
definition	O
is	O
amply	O
clear	O
IMHO	O
.	O

Before	O
you	O
ask	O
,	O
yes	O
apply	O
is	O
mentioned	O
on	O
the	O
docs	O
page	O
for	O
sweep	O
(	O
look	O
under	O
see	O
also	O
)	O
.	O

Pandas	O
has	O
an	O
apply	O
method	O
too	O
,	O
apply	O
being	O
what	O
R's	O
sweep	O
uses	O
under	O
the	O
hood	O
.	O

(	O
Note	O
that	O
the	O
MARGIN	O
argument	O
is	O
"	O
equivalent	O
"	O
to	O
the	O
axis	O
argument	O
in	O
many	O
pandas	O
functions	O
,	O
except	O
that	O
it	O
takes	O
values	O
0	O
and	O
1	O
rather	O
than	O
1	O
and	O
2	O
)	O
.	O

#CODE	O

You	O
can	O
use	O
an	O
apply	O
with	O
a	O
function	O
which	O
is	O
called	O
against	O
each	O
row	O
:	O
#CODE	O

Note	O
:	O
that	O
axis=0	O
would	O
apply	O
against	O
each	O
column	O
,	O
this	O
is	O
the	O
default	O
as	O
data	O
is	O
stored	O
column-wise	O
and	O
so	O
column-wise	O
operations	O
are	O
more	O
efficient	O
.	O

You	O
can	O
do	O
the	O
same	O
in	O
numpy	O
(	O
ie	O
`	O
data.values	O
`	O
here	O
)	O
,	O
either	O
multiplying	O
directly	O
,	O
this	O
will	O
be	O
faster	O
as	O
it	O
doesn't	O
worry	O
about	O
data-alignment	O
,	O
or	O
using	O
vectorize	B-API
rather	O
than	O
apply	O
.	O

Great	O
answer	O
.	O

I	O
am	O
playing	O
around	O
with	O
this	O
approach	O
now	O
and	O
had	O
a	O
question	O
.	O

Can	O
you	O
please	O
comment	O
on	O
the	O
use	O
of	O
`	O
lambda	O
`	O
in	O
`	O
apply	O
`	O
?	O

Any	O
reason	O
to	O
prefer	O
it	O
over	O
a	O
function	O
declared	O
using	O
`	O
def	O
`	O
?	O

Thanks	O
much	O
.	O

Obviously	O
I	O
could	O
write	O
plain	O
Python	O
that	O
,	O
given	O
the	O
period	O
I	O
re-sampled	O
to	O
in	O
Pandas	O
,	O
could	O
give	O
me	O
the	O
Series	O
I	O
need	O
,	O
but	O
I'd	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
trick	O
within	O
Pandas	O
that	O
helps	O
me	O
with	O
this	O
,	O
or	O
something	O
I	O
could	O
do	O
in	O
Numpy	O
,	O
as	O
I	O
want	O
to	O
apply	O
this	O
to	O
largish	O
datasets	O
(	O
hundreds	O
of	O
users	O
,	O
thousands	O
of	O
days	O
,	O
multiple	O
login	O
/	O
logouts	O
a	O
day	O
per	O
user	O
)	O
.	O

How	O
to	O
apply	O
a	O
function	O
to	O
a	O
mixed	O
type	O
Pandas	O
DataFrame	B-API
in	O
place	O
?	O

This	O
is	O
how	O
I	O
apply	O
a	O
function	O
to	O
Pandas	O
dataframe	B-API
,	O
it	O
works	O
in	O
place	O
and	O
modifies	O
the	O
original	O
data	O
frame	O
.	O

#CODE	O

But	O
if	O
I	O
try	O
the	O
same	O
on	O
this	O
data	O
frame	O
(	O
it	O
has	O
ints	O
and	O
floats	O
instead	O
of	O
just	O
ints	O
)	O
,	O
then	O
it	O
fails	O
to	O
apply	O
inplace	O
and	O
always	O
returns	O
a	O
dataframe	B-API
.	O

But	O
I	O
have	O
a	O
huge	O
dataframe	B-API
,	O
so	O
I	O
want	O
to	O
do	O
it	O
inplace	O
.	O

#CODE	O

So	O
no	O
way	O
to	O
apply	O
a	O
function	O
in-place	O
to	O
a	O
DataFrame	B-API
in	O
pandas	O
?	O

But	O
of	O
course	O
it'll	O
return	O
a	O
frame	O
,	O
apply	O
returns	O
a	O
frame	O
,	O
this	O
seems	O
to	O
work	O
inplace	O
for	O
me	O
in	O
0.13.1	O
(	O
even	O
with	O
floats	O
)	O
.	O

Generally	O
you'll	O
want	O
to	O
vectorize	B-API
rather	O
than	O
use	O
apply	O
,	O
obviously	O
here	O
,	O
as	O
mentioned	O
above	O
,	O
you'd	O
use	O
`	O
x	O
[	O
'	O
b	O
']	O
+=1	O
`	O
.	O

Also	O
,	O
I	O
think	O
using	O
iterrows	B-API
is	O
preferable	O
to	O
using	O
apply	O
like	O
this	O
.	O

I	O
realise	O
this	O
does	O
answer	O
the	O
question	O
(	O
well	O
)	O
,	O
but	O
using	O
apply	O
with	O
side-effects	O
seems	O
hacky	O
/	O
wrong	O
/	O
I	O
really	O
dislike	O
it	O
!	O

If	O
you	O
want	O
to	O
iterate	O
across	O
your	O
database	O
and	O
apply	O
a	O
function	O
to	O
each	O
row	O
,	O
you	O
might	O
also	O
want	O
to	O
consider	O
the	O
apply	O
function	O
#CODE	O

If	O
a	O
column	O
contains	O
only	O
strings	O
,	O
we	O
can	O
apply	O
`	O
len	O
`	O
on	O
it	O
like	O
what	O
you	O
did	O
should	O
work	O
fine	O
:	O
#CODE	O

Continuing	O
the	O
above	O
example	O
,	O
let	O
us	O
convert	O
`	O
strange	O
`	O
to	O
strings	O
and	O
check	O
if	O
`	O
apply	O
`	O
works	O
:	O
#CODE	O

Then	O
I	O
tried	O
to	O
apply	O
the	O
same	O
solution	O
to	O
`	O
pandas	O
`	O
:	O
#CODE	O

Use	O
`	O
groupby-shift	O
`	O
to	O
apply	O
the	O
shift	O
to	O
each	O
group	O
individually	O
:	O
(	O
Thanks	O
to	O
Jeff	O
for	O
pointing	O
out	O
this	O
simplification	O
.	O
)	O
#CODE	O

datetime	O
won't	O
operate	O
on	O
a	O
pandas	O
Series	O
(	O
column	O
of	O
a	O
dataframe	B-API
)	O
.	O

You	O
can	O
use	O
`	O
to_datetime	B-API
`	O
or	O
you	O
could	O
use	O
`	O
datetime	O
`	O
within	O
`	O
apply	O
`	O
.	O

Something	O
like	O
the	O
following	O
should	O
work	O
:	O
#CODE	O

Or	O
use	O
apply	O
:	O
#CODE	O

Yeah	O
,	O
I	O
did	O
the	O
`	O
to_datetime	B-API
`	O
answer	O
a	O
while	O
ago	O
and	O
the	O
came	O
back	O
and	O
added	O
the	O
`	O
apply	O
`	O
answer	O
at	O
about	O
the	O
same	O
time	O
as	O
you	O
.	O

not	O
a	O
speedfreak	O
myself	O
,	O
but	O
i	O
tested	O
yours	O
and	O
my	O
apply	O
method	O
.	O

Youe	O
is	O
about	O
50%	O
faster	O
as	O
mine	O
has	O
the	O
overhead	O
of	O
creating	O
a	O
new	O
dataframe	B-API
before	O
doing	O
the	O
apply	O
.	O

All	O
in	O
all	O
your	O
is	O
probably	O
better	O
.	O

Also	O
handles	O
the	O
1	O
for	O
day	O
better	O
than	O
mine	O
.	O

Because	O
questions	O
describing	O
your	O
requirements	O
and	O
asking	O
someone	O
to	O
write	O
the	O
code	O
for	O
you	O
or	O
explain	O
how	O
to	O
write	O
the	O
code	O
are	O
considered	O
off-topic	O
for	O
Stack	O
Overflow	O
,	O
but	O
none	O
of	O
the	O
standard	O
close	O
reasons	O
apply	O
.	O

Some	O
people	O
seem	O
to	O
think	O
that	O
"	O
too	O
broad	O
"	O
,	O
"	O
unclear	O
what	O
you're	O
asking	O
"	O
,	O
or	O
"	O
lacks	O
sufficient	O
information	O
to	O
diagnose	O
the	O
problem	O
"	O
are	O
always	O
sufficient	O
to	O
cover	O
these	O
kinds	O
of	O
questions	O
,	O
but	O
this	O
case	O
illustrates	O
why	O
they	O
often	O
don't	O
get	O
the	O
right	O
message	O
across	O
.	O

I've	O
already	O
searched	O
posts	O
on	O
stackoverflow	O
,	O
and	O
looked	O
at	O
the	O
documentation	O
for	O
convert_objects	B-API
,	O
but	O
it	O
is	O
unfortunately	O
pretty	O
sparse	O
.	O

I	O
wouldn't	O
have	O
known	O
to	O
even	O
attempt	O
to	O
apply	O
it	O
this	O
way	O
if	O
not	O
for	O
the	O
previous	O
post	O
(	O
linked	O
above	O
)	O
.	O

In	O
order	O
to	O
apply	O
a	O
method	O
on	O
a	O
DataFrame	B-API
that	O
is	O
grouped	O
;	O
your	O
need	O
to	O
use	O
a	O
loop	O
as	O
follows	O
:	O
#CODE	O

I	O
have	O
checked	O
and	O
the	O
`	O
apply	O
lambda	O
`	O
part	O
gives	O
the	O
expected	O
results	O
if	O
I	O
`	O
debug	O
print	O
`	O
it	O
.	O

The	O
problem	O
seems	O
to	O
be	O
assigning	O
the	O
apply	O
lambda	O
construct	O
back	O
to	O
the	O
DataFrame	B-API
.	O

Note	O
:	O
it	O
could	O
be	O
there	O
are	O
some	O
NaNs	O
causing	O
this	O
float	O
upcasting	O
,	O
in	O
which	O
case	O
you	O
may	O
have	O
to	O
reconsider	O
your	O
approach	O
(	O
since	O
you	O
won't	O
be	O
able	O
to	O
convert	O
to	O
int	O
!	O
)	O
,	O
one	O
option	O
might	O
be	O
to	O
do	O
the	O
string	O
formatting	O
and	O
then	O
apply	O
`	O
to_datetime	B-API
`	O
:	O
#CODE	O

I	O
am	O
not	O
sure	O
that	O
I	O
understand	O
your	O
question	O
,	O
but	O
in	O
the	O
last	O
part	O
you	O
say	O
that	O
you	O
want	O
to	O
make	O
sure	O
that	O
your	O
data	O
is	O
not	O
correlated	O
.	O

You	O
apply	O
Principal	O
Component	O
Analysis	O
(	O
PCA	B-API
)	O
to	O
any	O
dataset	O
,	O
the	O
resulting	O
principal	O
components	O
are	O
not	O
correlated	O
by	O
definition	O
.	O

I	O
don't	O
fully	O
understand	O
how	O
to	O
get	O
my	O
apply	O
function	O
to	O
actually	O
apply	O
to	O
the	O
row	O
to	O
change	O
it	O
.	O

In	O
that	O
case	O
merge	O
them	O
and	O
then	O
depending	O
on	O
the	O
complexity	O
of	O
your	O
function	O
either	O
use	O
a	O
lambda	O
or	O
define	O
your	O
function	O
and	O
just	O
apply	O
it	O
row-wise	O
so	O
`	O
merged	O
=	O
df.merge	B-API
(	O
df1	O
,	O
on=	O
'	O
Date	O
')`	O
then	O
`	O
merged.apply	O
(	O
myfunc	O
,	O
axis=1	O
)`	O
or	O
`	O
merged.apply	O
(	O
lambda	O
row	O
:	O
myfunc	O
(	O
row	O
)	O
,	O
axis=1	O
)`	O
I'd	O
need	O
to	O
see	O
your	O
function	O
first	O
though	O
before	O
deciding	O
the	O
best	O
approach	O
,	O
also	O
it's	O
getting	O
late	O
here	O
in	O
blighty	O
so	O
I	O
may	O
not	O
answer	O

Yes	O
that	O
is	O
correct	O
,	O
then	O
apply	O
a	O
function	O
row	O
wise	O
or	O
if	O
you're	O
just	O
looking	O
for	O
values	O
larger	O
than	O
some	O
threshold	O
then	O
do	O
boolean	O
masking	O
using	O
max()	B-API
that	O
will	O
be	O
very	O
quick	O
.	O

Sorry	O
love	O
to	O
help	O
further	O
but	O
it's	O
getting	O
late	O
here	O
.	O

Note	O
:	O
This	O
is	O
not	O
the	O
same	O
as	O
this	O
question	O
;	O
and	O
I	O
have	O
read	O
the	O
documentation	O
,	O
but	O
am	O
not	O
enlightened	O
by	O
it	O
.	O

I've	O
also	O
read	O
through	O
the	O
"	O
Related	O
"	O
questions	O
on	O
this	O
topic	O
,	O
but	O
I'm	O
still	O
missing	O
the	O
simple	O
rule	O
Pandas	O
is	O
using	O
,	O
and	O
how	O
I'd	O
apply	O
it	O
to	O
for	O
example	O
modify	O
the	O
values	O
(	O
or	O
a	O
subset	O
of	O
values	O
)	O
in	O
a	O
dataframe	B-API
that	O
satisfy	O
a	O
particular	O
query	O
.	O

Then	O
I	O
used	O
the	O
pandas	O
`	O
apply	O
`	O
method	O
(	O
as	O
was	O
suggested	O
here	O
)	O
to	O
implement	O
the	O
`	O
pyproj.Geod.inv	O
`	O
calculation	O
,	O
looping	O
through	O
slices	O
of	O
the	O
`	O
pandas	O
`	O
`	O
DataFrame	B-API
`	O
for	O
each	O
individual	O
in	O
the	O
population	O
.	O

#CODE	O

Now	O
use	O
`	O
apply	O
`	O
and	O
`	O
cut	O
`	O
to	O
create	O
a	O
new	O
dataframe	B-API
that	O
replaces	O
the	O
percentile	O
with	O
the	O
decile	O
bin	O
it	O
is	O
in	O
(	O
apply	O
is	O
iterating	O
over	O
each	O
column	O
):	O
#CODE	O

Use	O
apply	O
once	O
again	O
to	O
get	O
a	O
frequency	O
count	O
:	O
#CODE	O

You	O
should	O
use	O
the	O
apply	O
function	O
which	O
applies	O
a	O
function	O
on	O
either	O
each	O
column	O
(	O
default	O
)	O
or	O
each	O
row	O
efficiently	O
:	O
#CODE	O

and	O
then	O
call	O
apply	O
like	O
this	O
:	O
#CODE	O

linear	O
fit	O
by	O
group	O
in	O
apply	O
takes	O
too	O
long	O
using	O
pandas	O

Normally	O
,	O
we	O
can	O
use	O
either	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
,	O
but	O
it	O
seems	O
that	O
neither	O
of	O
them	O
allows	O
the	O
access	O
to	O
values	O
in	O
the	O
previous	O
row	O
.	O

Thanks	O
for	O
your	O
suggestions	O
!	O

I	O
used	O
a	O
combination	O
of	O
the	O
two	O
responses	O
to	O
change	O
the	O
original	O
text	O
into	O
a	O
list	O
,	O
saved	O
matches	O
to	O
a	O
list	O
,	O
then	O
joined	O
the	O
list	O
and	O
saved	O
it	O
to	O
a	O
new	O
variable	O
using	O
the	O
format	O
@USER	O
stated	O
.	O

Now	O
to	O
format	O
,	O
scale	O
,	O
and	O
apply	O
to	O
the	O
actual	O
data	O
set	O
.	O

It's	O
significantly	O
less	O
verbose	O
as	O
well	O
.	O

you're	O
right	O
,	O
but	O
how	O
does	O
that	O
apply	O
here	O
?	O

This	O
is	O
a	O
bug	O
,	O
slated	O
to	O
be	O
fixed	O
for	O
0.14	O
(	O
releasing	O
soon	O
)	O
,	O
see	O
here	O
.	O

The	O
bug	O
is	O
that	O
non-cythonized	O
routines	O
are	O
calling	O
`	O
apply	O
`	O
rather	O
than	O
``	O
agg	O
`	O
effectively	O
.	O

As	O
expected	O
this	O
apply	O
works	O
over	O
the	O
groupby	B-API
object	O
:	O
#CODE	O

However	O
,	O
when	O
specifying	O
options	O
for	O
apply	O
it	O
throws	O
up	O
an	O
error	O
:	O
#CODE	O

Pandas	O
:	O
Timing	O
difference	O
between	O
Function	O
and	O
Apply	O
to	O
Series	O

There	O
are	O
different	O
`	O
apply	O
`	O
methods	O
for	O
`	O
DataFrame	B-API
`	O
s	O
and	O
`	O
GroupBy	B-API
`	O
objects	O
.	O

Only	O
`	O
DataFrame.apply	B-API
`	O
has	O
a	O
`	O
raw	O
`	O
argument	O
:	O
#CODE	O

My	O
mistake	O
you	O
can	O
pass	O
that	O
param	O
on	O
a	O
groupby	B-API
apply	O
,	O
could	O
you	O
post	O
some	O
sample	O
data	O
so	O
I	O
can	O
see	O
what	O
your	O
df	O
looks	O
like	O
prior	O
to	O
the	O
groupby	B-API

@USER	O
So	O
if	O
you	O
reset_index	B-API
and	O
then	O
do	O
groupby	B-API
and	O
apply	O
does	O
it	O
work	O
?	O

Suppose	O
I	O
want	O
to	O
calculate	O
how	O
many	O
days	O
ago	O
each	O
observation	O
occurred	O
,	O
and	O
return	O
that	O
as	O
a	O
simple	O
integer	O
.	O

I	O
know	O
I	O
can	O
just	O
use	O
`	O
apply	O
`	O
twice	O
,	O
but	O
is	O
there	O
a	O
vectorized	O
/	O
cleaner	O
way	O
to	O
do	O
it	O
?	O

#CODE	O

I	O
think	O
you	O
want	O
to	O
use	O
the	O
`	O
apply	O
`	O
method	O
of	O
the	O
**	O
DataFrame**	O
,	O
using	O
axis	O
=	O
1	O
,	O
e.g.	O
df.apply	B-API
(	O
lambda	O
row	O
:	O
print	O
row	O
,	O
axis=1	O
)	O
.	O

This	O
method	O
will	O
generate	O
a	O
series	O
,	O
which	O
you	O
could	O
add	O
to	O
your	O
**	O
DataFrame**	O
.	O

I'll	O
write	O
this	O
up	O
into	O
an	O
answer	O
for	O
you	O
.	O

You	O
can	O
use	O
the	O
`	O
apply	O
`	O
method	O
of	O
the	O
DataFrame	B-API
,	O
using	O
`	O
axis	O
=	O
1	O
`	O
to	O
work	O
on	O
each	O
row	O
of	O
the	O
DataFrame	B-API
to	O
build	O
a	O
Series	O
with	O
the	O
same	O
Index	O
.	O

pandas	O
groupby	B-API
add	O
column	O
from	O
apply	O
operation	O

Awesome	O
,	O
a	O
`	O
transform()	B-API
`	O
was	O
exactly	O
what	O
I	O
needed	O
!	O

But	O
do	O
you	O
mind	O
explaining	O
what's	O
the	O
difference	O
between	O
`	O
transform	O
`	O
and	O
`	O
apply	O
`	O
?	O

`	O
apply	O
`	O
we	O
will	O
work	O
just	O
fine	O
too	O
.	O

If	O
you	O
replace	O
`	O
transform	O
`	O
with	O
`	O
apply	O
`	O
,	O
you	O
should	O
get	O
the	O
same	O
output	O
.	O

`	O
apply	O
`	O
is	O
the	O
more	O
general	O
method	O
;	O
`	O
transform	O
`	O
is	O
appropriate	O
when	O
you	O
want	O
to	O
return	O
something	O
like	O
indexed	O
.	O

I	O
tried	O
creating	O
a	O
function	O
that	O
would	O
filter	O
on	O
table	O
B	O
and	O
then	O
using	O
apply	O
like	O
below	O
.	O

#CODE	O

For	O
comparison	O
,	O
here's	O
the	O
timeit	O
of	O
`	O
apply	O
`	O
on	O
the	O
same	O
frames	O
:	O
#CODE	O

I	O
know	O
how	O
to	O
create	O
a	O
new	O
column	O
with	O
`	O
apply	O
`	O
or	O
`	O
np.where	B-API
`	O
based	O
on	O
the	O
values	O
of	O
another	O
column	O
,	O
but	O
a	O
way	O
of	O
selectively	O
changing	O
the	O
values	O
of	O
an	O
existing	O
column	O
is	O
escaping	O
me	O
;	O
I	O
suspect	O
`	O
df.ix	B-API
`	O
is	O
involved	O
?	O

Am	O
I	O
close	O
?	O

When	O
I	O
apply	O
a	O
numeric	O
function	O
to	O
the	O
group	O
,	O
such	O
as	O
max()	B-API
or	O
mean()	B-API
,	O
I	O
get	O
a	O
DataFrame	B-API
with	O
type	O
`	O
object	O
`	O
returned	O
#CODE	O

When	O
I	O
select	O
only	O
numeric	O
columns	O
first	O
and	O
then	O
apply	O
a	O
numeric	O
function	O
to	O
the	O
group	O
,	O
such	O
as	O
max()	B-API
or	O
mean()	B-API
,	O
I	O
get	O
a	O
DataFrame	B-API
with	O
a	O
numeric	O
type	O
#CODE	O

More	O
generally	O
,	O
if	O
you	O
want	O
to	O
transform	O
the	O
groups	O
of	O
a	O
`	O
GroupBy	B-API
`	O
object	O
with	O
any	O
arbitrary	O
function	O
,	O
use	O
the	O
methods	O
apply	O
,	O
transform	O
,	O
or	O
filter	O
.	O

See	O
the	O
docs	O
linked	O
by	O
Jeff	O
above	O
to	O
understand	O
the	O
distinctions	O
between	O
these	O
three	O
.	O

i've	O
had	O
no	O
success	O
using	O
transform	O
,	O
apply	O
,	O
or	O
aggregate	O
to	O
accomplish	O
my	O
goal	O
.	O

:-/	O

@USER	O
or	O
maybe	O
a	O
nested	O
`	O
apply	O
`	O
0_o	O

Though	O
some	O
locations	O
has	O
4	O
non	O
nan	O
values	O
,	O
the	O
whole	O
process	O
is	O
stopped	O
,	O
saying	O
the	O
'	O
cubic	O
'	O
method	O
requires	O
at	O
least	O
4	O
non	O
nan	O
values	O
.	O

How	O
can	O
I	O
make	O
it	O
conditional	O
to	O
apply	O
the	O
'	O
cubic	O
'	O
method	O
to	O
change	O
values	O
for	O
those	O
locations	O
which	O
can	O
run	O
'	O
cubic	O
'	O
method	O
?	O

But	O
it	O
is	O
extremely	O
slow	O
.	O

Would	O
it	O
be	O
quicker	O
to	O
do	O
this	O
in	O
list	O
comprehension	O
,	O
or	O
with	O
an	O
apply	O
function	O
?	O

What	O
is	O
best	O
practice	O
for	O
this	O
kind	O
of	O
operation	O
?	O

For	O
the	O
aggregation	O
methods	O
,	O
the	O
list	O
is	O
fairly	O
short	O
so	O
I	O
can	O
easily	O
make	O
a	O
list	O
of	O
`	O
if	O
`	O
statements	O
.	O

However	O
,	O
by	O
definition	O
the	O
`	O
apply	O
`	O
`	O
lambda	O
`	O
functions	O
are	O
bespoke	O
for	O
each	O
definition	O
.	O

Here's	O
an	O
example	O
which	O
takes	O
a	O
couple	O
of	O
columns	O
to	O
derive	O
a	O
percentage	O
:	O
#CODE	O

While	O
this	O
works	O
,	O
iterating	O
over	O
columns	O
feels	O
like	O
it	O
goes	O
against	O
the	O
spirit	O
of	O
python	O
and	O
`	O
numpy	O
`	O
.	O

Is	O
there	O
a	O
more	O
natural	O
way	O
I'm	O
not	O
seeing	O
?	O

I	O
would	O
normally	O
use	O
`	O
apply	O
`	O
,	O
but	O
I	O
don't	O
know	O
how	O
to	O
use	O
`	O
apply	O
`	O
and	O
still	O
get	O
the	O
unique	O
population	O
value	O
for	O
each	O
row	O
.	O

What's	O
the	O
correct	O
way	O
to	O
apply	O
`	O
zscore	O
`	O
(	O
or	O
an	O
equivalent	O
function	O
not	O
from	O
scipy	O
)	O
to	O
a	O
column	O
of	O
a	O
pandas	O
dataframe	B-API
and	O
have	O
it	O
ignore	O
the	O
`	O
nan	O
`	O
values	O
?	O

I'd	O
like	O
it	O
to	O
be	O
same	O
dimension	O
as	O
original	O
column	O
with	O
`	O
np.nan	O
`	O
for	O
values	O
that	O
can't	O
be	O
normalized	O

Iterate	O
and	O
apply	O
function	O
over	O
level	O
(	O
s	O
)	O
of	O
MultiIndex	O
dropping	O
the	O
iteration	O
level	O

Can't	O
you	O
just	O
apply	O
a	O
lambda	O
that	O
strips	O
out	O
the	O
first	O
index	O
level	O
?	O

Agree	O
that	O
A	O
and	O
B	O
are	O
all	O
in	O
memory	O
.	O

I	O
am	O
reading	O
a	O
file	O
(	O
.csv	O
)	O
into	O
memory	O
performing	O
the	O
rename	O
and	O
only	O
then	O
saving	O
it	O
to	O
HDF5	O
.	O

As	O
soon	O
as	O
I	O
apply	O
the	O
rename	O
method	O
to	O
the	O
frame	O
,	O
it	O
doubles	O
the	O
output	O
size	O
.	O

If	O
I	O
omit	O
the	O
rename	O
method	O
the	O
file	O
size	O
is	O
half	O
.	O

Since	O
all	O
operations	O
are	O
performed	O
in	O
memory	O
with	O
the	O
writing	O
to	O
HDF	O
only	O
happening	O
at	O
the	O
end	O
,	O
I	O
can't	O
seem	O
to	O
understand	O
why	O
the	O
rename	O
method	O
would	O
seem	O
to	O
cause	O
the	O
frame	O
to	O
double	O
in	O
size	O
and	O
thus	O
create	O
a	O
double-sized	O
HDF	O
file	O
.	O

Is	O
there	O
a	O
way	O
to	O
do	O
this	O
without	O
the	O
for	O
loop	O
or	O
using	O
where	O
(	O
)	O
or	O
apply	O
(	O
)	O
functions	O
.	O

`	O
apply	O
`	O
should	O
work	O
well	O
for	O
you	O
:	O
#CODE	O

It	O
just	O
depends	O
on	O
how	O
you	O
want	O
to	O
treat	O
NaNs	O
.	O

If	O
you	O
return	O
`	O
NaN	O
`	O
when	O
`	O
row	O
[	O
'	O
C	O
']`	O
is	O
`	O
NaN	O
`	O
,	O
then	O
you	O
won't	O
even	O
need	O
this	O
case	O
,	O
since	O
`	O
x	O
*	O
NaN	O
`	O
is	O
`	O
NaN	O
`	O
.	O

If	O
you	O
want	O
to	O
return	O
0	O
,	O
you	O
can	O
do	O
a	O
`	O
fillna	B-API
(	O
0	O
)`	O
after	O
`	O
apply	O
`	O
ing	O
`	O
fund	O
`	O
.	O

Also	O
,	O
for	O
various	O
reasons	O
`	O
np.nan	O
==	O
np.nan	O
`	O
is	O
*	O
always	O
*	O
False	O
,	O
so	O
your	O
way	O
wouldn't	O
quite	O
work	O
.	O

Pandas	O
gives	O
the	O
`	O
pd.isnull	B-API
`	O
function	O
to	O
check	O
for	O
NaNs	O
.	O

Thanks	O
.	O

I	O
actually	O
have	O
two	O
indices	O
(	O
one	O
is	O
`	O
datetime	O
`	O
,	O
the	O
other	O
one	O
is	O
a	O
string	O
)	O
.	O

Is	O
`	O
to_datetime()	B-API
`	O
an	O
`	O
Index	O
`	O
method	O
??	O

If	O
so	O
,	O
how	O
can	O
I	O
apply	O
it	O
to	O
only	O
one	O
of	O
the	O
index	O
levels	O
?	O

Apply	O
resampling	O
to	O
each	O
group	O
in	O
a	O
groupby	B-API
object	O

And	O
I	O
would	O
like	O
to	O
apply	O
this	O
function	O
to	O
every	O
dataframe	B-API
in	O
a	O
groupby	B-API
object	O
with	O
something	O
like	O
the	O
following	O
:	O
#CODE	O

How	O
do	O
I	O
create	O
functions	O
like	O
the	O
above	O
and	O
have	O
them	O
properly	O
apply	O
to	O
a	O
groupby	B-API
object	O
?	O

am	O
i	O
just	O
using	O
pandas	O
incredibly	O
badly	O
?	O

i	O
am	O
used	O
to	O
being	O
able	O
to	O
groupby	B-API
and	O
apply	O
a	O
transformation	O
without	O
difficulty	O
.	O

am	O
i	O
supposed	O
to	O
do	O
things	O
differently	O
for	O
this	O
application	O
for	O
some	O
reason	O
?	O

Now	O
,	O
you	O
can	O
apply	O
interpolation	O
methods	O
on	O
the	O
`	O
NaN	O
`	O
values	O
as	O
described	O
in	O
the	O
docs	O
.	O

To	O
apply	O
to	O
a	O
groupby	B-API
then	O
you	O
can	O
do	O
this	O
:	O
#CODE	O

Thanks	O
.	O

What	O
if	O
want	O
to	O
apply	O
the	O
result	O
within	O
a	O
group	O
,	O
respecting	O
the	O
boundaries	O
of	O
the	O
group	O
?	O

Sorry	O
for	O
the	O
last	O
minute	O
twist	O
,	O
but	O
it	O
turns	O
out	O
that	O
I	O
need	O
to	O
make	O
sure	O
this	O
happens	O
.	O

Problem	O
is	O
I	O
cannot	O
specify	O
the	O
index	O
position	O
inside	O
the	O
ix	O
function	O
as	O
I	O
plan	O
to	O
iterate	O
by	O
row	O
using	O
apply	O
function	O
.	O

Any	O
suggestion	O
?	O

#CODE	O

Thanks	O
Jeff	O
,	O
it	O
sounds	O
like	O
this	O
is	O
a	O
question	O
for	O
Enthought	O
.	O

I've	O
been	O
able	O
to	O
work	O
around	O
the	O
problem	O
for	O
now	O
by	O
using	O
`	O
apply	O
`	O
,	O
but	O
am	O
still	O
concerned	O
.	O

Try	O
"	O
Apply	O
completion	O
on	O
.	O

"	O
or	O
try	O
to	O
play	O
with	O
"	O
AutoCompletion	O
delay	O
"	O
.	O

I	O
need	O
a	O
method	O
to	O
get	O
the	O
selected	O
features	O
,	O
(	O
and	O
preferably	O
something	O
to	O
drop	O
the	O
unselected	O
ones	O
,	O
for	O
when	O
I	O
apply	O
the	O
models	O
and	O
selected	O
features	O
on	O
new	O
"	O
test	O
"	O
data	O
)	O
.	O

Hi	O
Gank	O
.	O

The	O
"	O
field	O
"	O
was	O
supposed	O
to	O
show	O
you	O
can	O
apply	O
the	O
"	O
.values	B-API
"	O
method	O
to	O
various	O
fields	O
of	O
the	O
dataframe	B-API
such	O
as	O
columns	O
or	O
a	O
selected	O
column	O
.	O

"	O
.index	B-API
"	O
is	O
an	O
example	O
of	O
replacing	O
"	O
field	O
"	O
with	O
an	O
actual	O
field	O
that	O
is	O
available	O
:)	O
I	O
guess	O
that	O
could	O
be	O
clearer	O
...	O

Well	O
,	O
you	O
can	O
avoid	O
the	O
apply	O
and	O
do	O
it	O
vectorized	O
(	O
I	O
think	O
that	O
makes	O
it	O
a	O
bit	O
nicer	O
):	O
#CODE	O

Actually	O
it's	O
not	O
a	O
complete	O
duplicate	O
...	O
the	O
question	O
is	O
asking	O
specifically	O
for	O
Pandas	O
.	O

The	O
response	O
below	O
shows	O
how	O
to	O
assign	O
an	O
axis	O
to	O
a	O
plot	O
function	O
call	O
from	O
`	O
pandas.DataFrame.plot	B-API
`	O
which	O
makes	O
it	O
possible	O
to	O
apply	O
the	O
`	O
matplotlib.pyplot	B-API
`	O
refinements	O
.	O

Figured	O
it	O
out	O
.	O

Selecting	O
out	O
the	O
Series	O
in	O
the	O
Dataframe	B-API
effectively	O
allows	O
me	O
to	O
assign	O
to	O
it	O
and	O
the	O
original	O
dataframe	B-API
.	O
this	O
allows	O
me	O
to	O
use	O
the	O
slicing	O
syntac	O
to	O
apply	O
logic	O
influencing	O
the	O
results	O
:	O
#CODE	O

Return	O
multiple	O
columns	O
from	O
apply	O
pandas	O

Is	O
there	O
anyway	O
I	O
can	O
make	O
this	O
faster	O
?	O

For	O
example	O
,	O
can	O
I	O
instead	O
of	O
returning	O
one	O
column	O
at	O
a	O
time	O
from	O
apply	O
and	O
running	O
it	O
3	O
times	O
,	O
can	O
I	O
return	O
all	O
three	O
columns	O
in	O
one	O
pass	O
to	O
insert	O
back	O
into	O
the	O
original	O
dataframe	B-API
?	O

You	O
could	O
try	O
using	O
DataFrame's	O
`	O
apply	O
`	O
.	O

Write	O
a	O
function	O
that	O
includes	O
an	O
exception	O
handler	O
and	O
apply	O
it	O
to	O
the	O
DataFrame	B-API
.	O

#CODE	O

you	O
should	O
avoid	O
``	O
apply	O
``	O
if	O
you	O
can	O
vectorize	B-API
,	O
e.g	O
``	O
df	O
[	O
'	O
diff	O
']	O
.where	B-API
(	O
df	O
[	O
'	O
diff	O
']	O
.abs()	B-API
>	O
=	O
0.3	O
)``	O
will	O
be	O
much	O
faster	O

The	O
basic	O
idea	O
is	O
to	O
group	O
data	O
based	O
on	O
`'	O
Localization	O
'`	O
and	O
to	O
apply	O
a	O
function	O
on	O
group	O
.	O

#CODE	O

I	O
would	O
like	O
to	O
group	O
a	O
`	O
DataFrame	B-API
`	O
then	O
apply	O
`	O
myfunc	O
`	O
along	O
columns	O
of	O
each	O
individual	O
frame	O
(	O
in	O
each	O
group	O
)	O
and	O
then	O
paste	O
together	O
the	O
results	O
.	O

There	O
are	O
hacky	O
ways	O
to	O
do	O
it	O
,	O
but	O
I	O
wonder	O
it	O
seems	O
like	O
there	O
is	O
some	O
simple	O
kwarg	O
I'm	O
missing	O
.	O

ok	O
,	O
revised	O
the	O
answer	O
;	O
you	O
can	O
do	O
almost	O
anything	O
inside	O
the	O
apply	O
FYI	O

As	O
far	O
as	O
the	O
unpacking	O
goes	O
,	O
maybe	O
you	O
could	O
let	O
the	O
function	O
take	O
an	O
argument	O
for	O
whether	O
to	O
add	O
or	O
subtract	O
,	O
and	O
then	O
apply	O
it	O
twice	O
.	O

You	O
could	O
perform	O
a	O
groupby	B-API
/	O
apply	O
(	O
shift	O
)	O
operation	O
:	O
#CODE	O

The	O
obvious	O
way	O
to	O
find	O
all	O
such	O
matches	O
is	O
to	O
iterate	O
over	O
each	O
row	O
and	O
apply	O
a	O
filter	O
to	O
the	O
data	O
frame	O
:	O
#CODE	O

In	O
Pandas	O
,	O
is	O
there	O
an	O
easy	O
way	O
to	O
apply	O
a	O
function	O
only	O
on	O
columns	O
of	O
a	O
specific	O
type	O
?	O

What	O
is	O
an	O
easy	O
way	O
to	O
apply	O
a	O
function	O
only	O
on	O
columns	O
of	O
a	O
certain	O
type	O
?	O

And	O
now	O
you	O
can	O
use	O
that	O
list	O
with	O
an	O
apply	O
or	O
whatever	O
.	O

I'm	O
trying	O
to	O
drop	O
rows	O
of	O
a	O
dataframe	B-API
based	O
on	O
whether	O
they	O
are	O
duplicates	O
,	O
and	O
always	O
keep	O
the	O
more	O
recent	O
of	O
the	O
rows	O
.	O

This	O
would	O
be	O
simple	O
using	O
`	O
df.drop_duplicates()	B-API
`	O
,	O
however	O
I	O
also	O
need	O
to	O
apply	O
a	O
`	O
timedelta	O
`	O
.	O

The	O
row	O
is	O
to	O
be	O
considered	O
a	O
duplicate	O
if	O
the	O
`	O
EndDate	O
`	O
column	O
is	O
less	O
than	O
182	O
days	O
earlier	O
than	O
that	O
of	O
another	O
row	O
with	O
the	O
same	O
ID	O
.	O

Groupby	B-API
the	O
'	O
level	O
'	O
on	O
the	O
columns	O
and	O
apply	O
f	O
;	O
don't	O
use	O
apply	O
directly	O
,	O
but	O
just	O
concat	O
the	O
results	O
as	O
rows	O
(	O
this	O
is	O
the	O
'	O
unstacking	O
'	O
part	O
)	O
.	O

(	O
3	O
)	O
Or	O
you	O
could	O
do	O
it	O
all	O
in	O
a	O
function	O
that	O
was	O
called	O
by	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
:	O
#CODE	O

When	O
using	O
`	O
count	O
`	O
,	O
state	O
isn't	O
a	O
nuisance	O
column	O
(	O
it	O
can	O
count	O
strings	O
)	O
so	O
the	O
`	O
resample	O
`	O
is	O
going	O
to	O
apply	O
count	O
to	O
it	O
(	O
although	O
the	O
output	O
is	O
not	O
what	O
I	O
would	O
expect	O
)	O
.	O

You	O
could	O
do	O
something	O
like	O
(	O
tell	O
it	O
only	O
to	O
apply	O
`	O
count	O
`	O
to	O
`	O
value_a	O
`)	O
,	O
#CODE	O

Or	O
more	O
generally	O
,	O
you	O
can	O
apply	O
different	O
kinds	O
of	O
`	O
how	O
`	O
to	O
different	O
columns	O
:	O
#CODE	O

pandas	O
apply	O
function	O
that	O
returns	O
multiple	O
values	O
to	O
rows	O
in	O
pandas	O
dataframe	B-API

I	O
would	O
like	O
to	O
apply	O
a	O
transformation	O
to	O
each	O
row	O
that	O
also	O
returns	O
a	O
vector	O
#CODE	O

I	O
end	O
up	O
with	O
a	O
Pandas	O
series	O
whose	O
elements	O
are	O
tuples	O
.	O

This	O
is	O
beacause	O
apply	O
will	O
take	O
the	O
result	O
of	O
myfunc	O
without	O
unpacking	O
it	O
.	O

How	O
can	O
I	O
change	O
myfunc	O
so	O
that	O
I	O
obtain	O
a	O
new	O
df	O
with	O
3	O
columns	O
?	O

pandas	O
,	O
apply	O
string	O
operation	O
to	O
column	O
should	O
be	O
string	O
type	O
,	O
but	O
has	O
missing	O
values	O
(	O
np.nan	O
)	O

groupby	B-API
the	O
'	O
c	O
'	O
column	O
,	O
and	O
consider	O
all	O
the	O
columns	O
that	O
you	O
want	O
passed	O
to	O
the	O
`	O
apply	O
`	O
EXCEPT	O
for	O
c	O
(	O
this	O
is	O
what	O
`	O
df.columns	O
-	O
[	O
'	O
c	O
']`	O
does	O
,	O
as	O
normally	O
the	O
grouping	O
column	O
IS	O
passed	O
to	O
the	O
apply	O
.	O

Try	O
using	O
apply	O
with	O
a	O
custom	O
function	O
over	O
axis=1	O
:	O
#CODE	O

@USER	O
Actually	O
,	O
it	O
does	O
.	O

Just	O
specify	O
the	O
columns	O
when	O
you	O
apply	O
the	O
function	O
,	O
like	O
this	O
:	O
`	O
df	O
[[	O
'	O
col1	O
'	O
,	O
'	O
col2	O
']]	O
.apply	B-API
(	O
...	O
)`	O

This	O
should	O
still	O
be	O
pretty	O
fast	O
because	O
it	O
uses	O
`	O
pandas	O
`'	O
vectorized	O
string	O
methods	O
for	O
each	O
of	O
the	O
columns	O
(	O
the	O
apply	O
is	O
across	O
the	O
columns	O
,	O
not	O
an	O
iteration	O
over	O
the	O
rows	O
)	O
.	O

Well	O
it	O
looks	O
like	O
within	O
groups	O
,	O
there	O
is	O
one	O
observation	O
per	O
month	O
and	O
you	O
want	O
the	O
percent	O
change	O
from	O
one	O
month	O
to	O
the	O
next	O
.	O

You	O
can	O
do	O
that	O
with	O
a	O
`	O
groupby	B-API
/	O
apply	O
`	O
by	O
grouping	O
on	O
'	O
product_desc	O
'	O
and	O
then	O
using	O
the	O
built	O
in	O
`	O
pct_change()	B-API
`	O
method	O
:	O
#CODE	O

Thanks	O
for	O
your	O
help	O
on	O
this	O
.	O

The	O
pct_change	B-API
function	O
was	O
exactly	O
what	O
I	O
needed	O
.	O

However	O
,	O
when	O
I	O
apply	O
the	O
sort	O
they	O
don't	O
sort	O
the	O
same	O
way	O
.	O

Did	O
you	O
convert	O
the	O
activity_month	O
into	O
dates	O
with	O
strptime	O
first	O
?	O

My	O
results	O
are	O
sorted	O
by	O
product_desc	O
but	O
have	O
the	O
activity_month	O
out	O
of	O
order	O
.	O

Now	O
I	O
find	O
that	O
the	O
class	O
of	O
`	O
a	O
`	O
and	O
the	O
class	O
of	O
`	O
b	O
`	O
are	O
different	O
;	O
`	O
b	O
`	O
is	O
a	O
`	O
pandas.core.series.Series	O
`	O
object	O
and	O
therefore	O
you	O
can	O
not	O
apply	O
the	O
method	O
`	O
append2	O
`	O
to	O
it	O
.	O

but	O
still	O
can't	O
quite	O
get	O
the	O
output	O
to	O
the	O
formats	O
I	O
need	O
.	O

I'm	O
not	O
quite	O
sure	O
how	O
to	O
apply	O
the	O
df.groupby	B-API
syntax	O
or	O
the	O
df.apply	B-API
syntax	O
to	O
what	O
I'm	O
working	O
with	O
.	O

Here	O
is	O
a	O
neat	O
apply	O
trick	O
.	O

I'll	O
create	O
a	O
function	O
and	O
print	O
out	O
what	O
is	O
incoming	O
(	O
and	O
maybe	O
even	O
debug	O
in	O
their	O
)	O
.	O

Then	O
easy	O
to	O
see	O
what's	O
happening	O
.	O

#CODE	O

Perfect	O
!	O

This	O
is	O
exactly	O
what	O
I	O
was	O
looking	O
for	O
.	O

I	O
guess	O
my	O
confusion	O
stems	O
from	O
the	O
fact	O
that	O
the	O
Series.value_counts	B-API
doesn't	O
seem	O
to	O
fit	O
into	O
the	O
arguments	O
required	O
by	O
the	O
df.apply	B-API
method	O
.	O

How	O
does	O
it	O
know	O
which	O
axis	O
to	O
apply	O
the	O
value_counts	B-API
to	O
?	O

You	O
can	O
reformat	O
the	O
values	O
by	O
passing	O
a	O
reformatting	O
function	O
into	O
the	O
`	O
apply	O
`	O
method	O
as	O
follows	O
:	O
#CODE	O

Apply	O
an	O
operation	O
to	O
the	O
value	O
of	O
a	O
series	O
(	O
2	O
and	O
3	O
)	O
#CODE	O

Then	O
apply	O
:	O
#CODE	O

what	O
does	O
the	O
function	O
in	O
df.groupby	B-API
(	O
...	O
)	O
.apply	B-API
(	O
lambda	O
x	O
:	O
...	O
)	O
apply	O
to	O
?	O

what	O
is	O
the	O
form	O
of	O
x	O
?	O

list	O
?	O

groupby	B-API
,	O
apply	O
,	O
and	O
set	O
not	O
behaving	O
as	O
expected	O
...	O

is	O
this	O
a	O
bug	O
?	O

[	O
@USER	O
]	O
(	O
#URL	O
)	O
,	O
why	O
does	O
`	O
dat.groupby	O
([	O
'	O
names	O
'])	O
[[	O
'	O
letters	O
']]`	O
pass	O
all	O
the	O
columns	O
through	O
to	O
apply	O
(	O
letters	O
,	O
numbers	O
,	O
names	O
)	O
?	O

Why	O
not	O
just	O
the	O
'	O
letters	O
'	O
column	O
as	O
a	O
dataframe	B-API
instead	O
of	O
a	O
series	O
?	O

Is	O
it	O
ignoring	O
`	O
[[	O
'	O
letters	O
']]`	O
(	O
syntatic	O
sugar	O
that's	O
not	O
allowed	O
)	O
?	O

You	O
don't	O
need	O
the	O
final	O
apply	O
,	O
see	O
here	O
:	O
#URL	O
you	O
can	O
simply	O
``	O
astype	B-API
(	O
'	O
timedelta64	O
[	O
D	O
]')``	O
or	O
divide	O
by	O
``	O
np.timedelta64	O
(	O
1	O
,	O
'	O
D	O
')``	O
(	O
they	O
are	O
sligthly	O
different	O
in	O
how	O
they	O
round	O
.	O

Based	O
your	O
code	O
(	O
your	O
`	O
groupby	B-API
/	O
apply	O
`)	O
,	O
it	O
looks	O
like	O
(	O
despite	O
your	O
example	O
...	O
but	O
maybe	O
I	O
misunderstand	O
what	O
you	O
want	O
and	O
then	O
what	O
Andy	O
did	O
would	O
be	O
the	O
best	O
idea	O
)	O
that	O
you're	O
working	O
with	O
a	O
'	O
date	O
'	O
column	O
that	O
is	O
a	O
`	O
datetime64	O
`	O
dtype	B-API
and	O
not	O
an	O
`	O
integer	O
`	O
dtype	B-API
in	O
your	O
actual	O
data	O
.	O

Also	O
it	O
looks	O
like	O
you	O
want	O
compute	O
the	O
change	O
in	O
days	O
as	O
measured	O
from	O
the	O
first	O
observation	O
of	O
a	O
given	O
`	O
group	O
/	O
stage	O
`	O
.	O

I	O
think	O
this	O
is	O
a	O
better	O
set	O
of	O
example	O
data	O
(	O
if	O
I	O
understand	O
your	O
goal	O
correctly	O
):	O
#CODE	O

Given	O
that	O
you	O
should	O
get	O
some	O
speed-up	O
from	O
just	O
modifying	O
your	O
apply	O
(	O
as	O
Jeff	O
suggests	O
in	O
his	O
comment	O
)	O
by	O
dividing	O
through	O
by	O
the	O
`	O
timedelta64	O
`	O
in	O
a	O
vectorized	O
way	O
after	O
the	O
apply	O
(	O
or	O
you	O
could	O
do	O
it	O
in	O
the	O
apply	O
):	O
#CODE	O

But	O
you	O
can	O
also	O
avoid	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
given	O
your	O
data	O
is	O
in	O
group	O
,	O
stage	O
,	O
date	O
order	O
.	O

The	O
first	O
date	O
for	O
every	O
`	O
[	O
'	O
group	O
'	O
,	O
'	O
stage	O
']`	O
grouping	O
happens	O
when	O
either	O
the	O
group	O
changes	O
or	O
the	O
stage	O
changes	O
.	O

So	O
I	O
think	O
you	O
can	O
do	O
something	O
like	O
the	O
following	O
:	O
#CODE	O

Apply	O
method	O
:	O
#CODE	O

So	O
I	O
think	O
avoiding	O
the	O
apply	O
could	O
give	O
some	O
significant	O
speed-ups	O

Yeah	O
@USER	O
,	O
I	O
thought	O
about	O
`	O
transform	O
`	O
but	O
at	O
least	O
for	O
0.13.1	O
I	O
usually	O
find	O
transform	O
no	O
faster	O
than	O
a	O
generic	O
`	O
apply	O
`	O
so	O
I	O
didn't	O
include	O
it	O
.	O

But	O
I	O
will	O
update	O
the	O
answer	O
with	O
that	O
as	O
an	O
alternative	O
.	O

Of	O
course	O
you	O
don't	O
show	O
your	O
data	O
so	O
this	O
may	O
or	O
may	O
not	O
apply	O
and	O
I	O
apologize	O
if	O
not	O
,	O
but	O
for	O
a	O
large	O
dataframe	B-API
I'm	O
dealing	O
with	O
I	O
see	O
a	O
speedup	O
of	O
,	O
well	O
,	O
24	O
million	O
times	O
!	O

Thanks	O
.	O

Is	O
this	O
technically	O
a	O
`	O
transform	O
`	O
or	O
`	O
apply	O
`	O
operation	O
?	O

I	O
never	O
quite	O
understood	O
the	O
difference	O
.	O

`	O
apply	O
`	O
is	O
the	O
most	O
general	O
category	O
of	O
operation	O
on	O
a	O
group	O
,	O
so	O
lots	O
of	O
things	O
fall	O
under	O
its	O
umbrella	O
.	O

What	O
distinguishes	O
transform	O
operations	O
is	O
that	O
they	O
produce	O
something	O
indexed	O
like	O
the	O
input	O
,	O
and	O
that	O
happens	O
here	O
,	O
so	O
I	O
guess	O
you	O
could	O
think	O
of	O
it	O
as	O
a	O
transform	O
.	O

Well	O
,	O
one	O
approach	O
is	O
the	O
following	O
:	O
(	O
1	O
)	O
do	O
a	O
`	O
groupby	B-API
/	O
apply	O
`	O
with	O
'	O
id	O
'	O
as	O
grouping	O
variable	O
.	O

(	O
2	O
)	O
Within	O
the	O
apply	O
,	O
`	O
resample	O
`	O
the	O
group	O
to	O
a	O
daily	O
time	O
series	O
.	O

(	O
3	O
)	O
Then	O
just	O
using	O
`	O
rolling_sum	B-API
`	O
(	O
and	O
shift	O
so	O
you	O
don't	O
include	O
the	O
current	O
rows	O
'	O
x	O
'	O
value	O
)	O
to	O
compute	O
the	O
sum	O
of	O
your	O
70	O
day	O
lookback	O
periods	O
.	O

(	O
4	O
)	O
Reduce	O
the	O
group	O
back	O
to	O
only	O
the	O
original	O
observations	O
:	O
#CODE	O

You	O
are	O
going	O
to	O
need	O
your	O
data	O
sorted	O
by	O
`	O
[	O
'	O
id	O
'	O
,	O
'	O
dates	O
']`	O
.	O

Now	O
we	O
can	O
do	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
:	O
#CODE	O

It	O
just	O
becomes	O
the	O
next	O
parameter	O
in	O
the	O
`	O
apply	O
`	O
.	O

See	O
me	O
edit	O
for	O
details	O
.	O

No	O
need	O
for	O
the	O
`	O
lambda	O
`	O
on	O
the	O
first	O
one	O
:	O
`	O
apply	O
(	O
'	O
{	O
:	O
0	O
>	O
15}	O
'	O
.format	B-API
)`	O
should	O
work	O
too	O
.	O

as	O
the	O
apply	O
function	O
creates	O
only	O
one	O
column	O
with	O
tuples	O
in	O
it	O
.	O

You	O
can	O
put	O
the	O
two	O
values	O
in	O
a	O
Series	O
,	O
and	O
then	O
it	O
will	O
be	O
returned	O
as	O
a	O
dataframe	B-API
from	O
the	O
apply	O
(	O
where	O
each	O
series	O
is	O
a	O
row	O
in	O
that	O
dataframe	B-API
)	O
.	O

With	O
a	O
dummy	O
example	O
:	O
#CODE	O

Use	O
`	O
to_datetime	B-API
`	O
to	O
convert	O
to	O
a	O
string	O
to	O
a	O
datetime	O
,	O
you	O
can	O
pass	O
a	O
formatting	O
string	O
but	O
in	O
this	O
case	O
it	O
seems	O
to	O
handle	O
it	O
fine	O
,	O
then	O
if	O
you	O
wanted	O
a	O
date	O
then	O
call	O
`	O
apply	O
`	O
and	O
use	O
a	O
lambda	O
to	O
call	O
`	O
.date()	B-API
`	O
on	O
each	O
datetime	O
entry	O
:	O
#CODE	O

It	O
is	O
.	O

Thanks	O
.	O

In	O
R	O
,	O
we	O
could	O
write	O
something	O
such	O
as	O
grepl	O
(	O
"	O
date	O
"	O
,	O
colnames	O
(	O
df	O
))	O
,	O
which	O
creates	O
a	O
logical	O
index	O
by	O
which	O
we	O
subset	O
.	O

Maybe	O
that	O
same	O
logic	O
does	O
not	O
apply	O
here	O
,	O
although	O
I	O
have	O
seen	O
people	O
do	O
that	O
for	O
selecting	O
rows	O
.	O

Using	O
'	O
apply	O
'	O
in	O
Pandas	O
(	O
externally	O
defined	O
function	O
)	O

What	O
am	O
I	O
doing	O
wrong	O
?	O

I	O
think	O
I'm	O
not	O
really	O
understanding	O
how	O
apply	O
(	O
and	O
its	O
cousins	O
,	O
aggregate	O
and	O
agg	O
)	O
works	O
.	O

If	O
someone	O
could	O
explain	O
,	O
I'd	O
be	O
ever	O
so	O
grateful	O
!	O

You	O
could	O
group	O
by	O
year	O
,	O
isolate	O
the	O
prop	O
column	O
,	O
apply	O
`	O
argmax	B-API
`	O
,	O
and	O
use	O
`	O
loc	O
`	O
to	O
select	O
desired	O
rows	O
:	O
#CODE	O

AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
info	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

No	O
worries	O
,	O
the	O
given	O
solution	O
still	O
applies	O
,	O
you	O
just	O
have	O
to	O
call	O
it	O
inside	O
of	O
an	O
apply	O
of	O
your	O
groupby	B-API
:	O
`	O
df.groupby	B-API
(	O
bla	O
)	O
.apply	B-API
(	O
lambda	O
df_grouped	O
:	O
df_grouped.groupby	O
(	O
level	O
=[	O
0	O
,	O
1	O
,	O
2	O
])	O
.apply	B-API
(	O
fancy_func	O
))`	O

how	O
to	O
apply	O
Functions	O
on	O
numpy	O
arrays	O
using	O
pandas	O
groupby	B-API
function	O

@USER	O
I	O
get	O
this	O
error	O
when	O
trying	O
to	O
apply	O
.	O
why	O
might	O
this	O
be	O
?	O

I	O
want	O
to	O
apply	O
a	O
weighted	O
sum	O
to	O
a	O
DataFrame	B-API
.	O

In	O
the	O
past	O
I	O
have	O
used	O
#CODE	O

I	O
want	O
to	O
apply	O
a	O
weighted	O
average	O
to	O
the	O
sum	O
where	O
the	O
most	O
recent	O
is	O
multiplied	O
by	O
0.6	O
,	O
2nd	O
by	O
0.2	O
,	O
3rd	O
and	O
4th	O
by	O
0.1	O
.	O

I	O
think	O
you	O
can	O
do	O
it	O
will	O
a	O
`	O
rolling_apply	B-API
`	O
within	O
a	O
function	O
called	O
by	O
a	O
normal	O
`	O
groupby	B-API
/	O
apply	O
`	O
.	O

So	O
something	O
like	O
the	O
following	O
:	O
#CODE	O

@USER	O
Thanks	O
.	O

I'm	O
new	O
to	O
Python	O
Is	O
this	O
documented	O
somewhere	O
?	O

I	O
could	O
not	O
find	O
it	O
in	O
the	O
Pandas	O
documentation	O
.	O

I	O
did	O
find	O
something	O
about	O
loglog	O
plots	O
in	O
the	O
matplotlib	O
documentation	O
,	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
this	O
to	O
a	O
Pandas	O
dataframe	B-API
.	O

It	O
is	O
not	O
updating	O
+1	O
count	O
as	O
I	O
wanted	O
.	O

I	O
believe	O
it	O
is	O
some	O
kind	O
of	O
type	O
issue	O
,	O
but	O
not	O
sure	O
how	O
to	O
force	O
the	O
type	O
.	O

I	O
am	O
using	O
DataFrame	B-API
for	O
my	O
data	O
as	O
I	O
want	O
to	O
use	O
group	O
function	O
to	O
split	O
the	O
data	O
and	O
apply	O
the	O
above	O
function	O
.	O

Any	O
suggestions	O
?	O

Use	O
indexing	O
instead	O
of	O
apply	O
,	O
it's	O
much	O
faster	O
:	O
#CODE	O

Since	O
you've	O
got	O
to	O
do	O
the	O
`	O
apply	O
`	O
anyway	O
,	O
I	O
think	O
it	O
is	O
cleaner	O
to	O
move	O
the	O
`	O
json.loads	O
`	O
and	O
column	O
creation	O
all	O
into	O
the	O
apply	O
(	O
don't	O
use	O
the	O
`	O
converters	O
`	O
for	O
`	O
read_csv	B-API
`)	O
:	O
`	O
df	O
[	O
'	O
field3	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
pd.Series	B-API
(	O
json.loads	O
(	O
x	O
)))`	O

By	O
searching	O
this	O
subject	O
,	O
I've	O
known	O
basic	O
syntax	O
of	O
replace()	B-API
.	O

But	O
I	O
couldn't	O
apply	O
to	O
my	O
specific	O
problem	O
.	O

Although	O
unwieldy	O
using	O
`	O
loc	O
`	O
will	O
scale	O
better	O
with	O
larger	O
dataframes	O
as	O
the	O
apply	O
here	O
is	O
called	O
for	O
every	O
row	O
whilst	O
using	O
boolean	O
indexing	O
will	O
be	O
vectorised	O
.	O

That	O
is	O
only	O
true	O
if	O
the	O
column	O
already	O
exists	O
I	O
think	O
as	O
I	O
get	O
no	O
warning	O
unless	O
the	O
column	O
exists	O
,	O
I	O
did	O
some	O
timings	O
and	O
using	O
`	O
loc	O
`	O
method	O
is	O
1.66ms	O
for	O
a	O
data	O
frame	O
size	O
of	O
3000	O
rows	O
versus	O
the	O
apply	O
method	O
which	O
takes	O
60.2	O
ms	O

How	O
do	O
I	O
apply	O
a	O
function	O
to	O
a	O
pandas	O
dataframe	B-API
?	O

I	O
have	O
tried	O
to	O
apply	O
a	O
function	O
to	O
a	O
pandas	O
dataframe	B-API
like	O
this	O
#CODE	O

So	O
the	O
first	O
problem	O
in	O
your	O
code	O
is	O
that	O
you	O
are	O
calling	O
apply	O
and	O
setting	O
param	O
`	O
axis=1	O
`	O
this	O
applies	O
your	O
function	O
row-wise	O
which	O
is	O
fine	O
.	O

Currently	O
,	O
I	O
am	O
using	O
`	O
df_sub	O
=d	O
f	O
[	O
df.ID.isin	O
(	O
ID_list	O
)]`	O
to	O
do	O
it	O
.	O

But	O
it	O
takes	O
a	O
lot	O
time	O
.	O

`	O
ID	O
`	O
s	O
contained	O
in	O
`	O
ID_list	O
`	O
doesn't	O
have	O
any	O
pattern	O
,	O
so	O
it's	O
not	O
within	O
certain	O
range	O
.	O

(	O
And	O
I	O
need	O
to	O
apply	O
the	O
same	O
operation	O
to	O
many	O
similar	O
dataframes	O
.	O

I	O
was	O
wondering	O
if	O
there	O
is	O
any	O
faster	O
way	O
to	O
do	O
this	O
.	O

Will	O
it	O
help	O
a	O
lot	O
if	O
make	O
`	O
ID	O
`	O
as	O
the	O
index	O
?	O

If	O
you're	O
working	O
with	O
small	O
datasets	O
,	O
you	O
get	O
different	O
behaviors	O
and	O
it	O
actually	O
becomes	O
faster	O
to	O
use	O
a	O
list	O
comprehension	O
or	O
apply	O
against	O
a	O
dictionary	O
than	O
using	O
`	O
isin	B-API
`	O
.	O

Thank	O
you	O
all	O
for	O
help	O
.	O

I've	O
try	O
out	O
these	O
different	O
methods	O
and	O
get	O
back	O
with	O
results	O
.	O

But	O
can	O
how	O
can	O
I	O
apply	O
Cython	O
to	O
pandas	O
?	O

It's	O
hard	O
to	O
declare	O
type	O
.	O

Summarizing	O
the	O
comments	O
,	O
for	O
a	O
dataframe	B-API
of	O
this	O
size	O
,	O
using	O
`	O
apply	O
`	O
will	O
not	O
differ	O
much	O
in	O
performance	O
compared	O
to	O
using	O
vectorized	O
functions	O
(	O
working	O
on	O
the	O
full	O
column	O
)	O
,	O
but	O
when	O
your	O
real	O
dataframe	B-API
becomes	O
larger	O
,	O
it	O
will	O
.	O

Indeed	O
,	O
I	O
get	O
201us	O
(	O
np	O
)	O
vs	O
208us	O
(	O
math	O
)	O
,	O
so	O
almost	O
the	O
same	O
for	O
this	O
dataframe	B-API
,	O
but	O
for	O
a	O
larger	O
one	O
(	O
this	O
one	O
100	O
times	O
repeated	O
)	O
,	O
numpy	O
is	O
clearly	O
faster	O
than	O
using	O
apply	O
.	O

Also	O
for	O
the	O
concatenation	O
,	O
for	O
this	O
dataframe	B-API
,	O
using	O
apply	O
is	O
not	O
slower	O
(	O
even	O
a	O
bit	O
faster	O
500	O
vs	O
700	O
us	O
)	O
,	O
but	O
for	O
larger	O
dataframes	O
(	O
7000	O
rows	O
)	O
it	O
is	O
again	O
clearly	O
slower	O
(	O
200	O
vs	O
80	O
ms	O
)	O
.	O

Regarding	O
to	O
the	O
performance	O
,	O
I	O
just	O
notice	O
if	O
I	O
use	O
the	O
vectorized	O
functions	O
,	O
I	O
may	O
cause	O
a	O
memoryError	O
(	O
I	O
have	O
3G	O
ram	O
)	O
but	O
apply	O
does	O
not	O
have	O
such	O
a	O
problem	O
.	O

So	O
I	O
think	O
the	O
vectorized	O
functions	O
are	O
reading	O
everything	O
in	O
memory	O
right	O
?	O

The	O
original	O
file	O
is	O
about	O
12M	O
in	O
size	O
,	O
above	O
is	O
just	O
a	O
sample	O
section	O
of	O
the	O
file	O

When	O
using	O
`	O
apply	O
`	O
the	O
id	O
generation	O
is	O
performed	O
per	O
row	O
resulting	O
in	O
minimal	O
overhead	O
in	O
memory	O
allocation	O
.	O

yeah	O
,	O
this	O
way	O
works	O
,	O
but	O
in	O
this	O
thread	O
,	O
#URL	O
it	O
is	O
said	O
the	O
vectorized	O
function	O
is	O
faster	O
than	O
using	O
apply	O
call	O
,	O
and	O
from	O
my	O
experiments	O
it	O
seems	O
true	O
.	O

The	O
vectorized	O
functions	O
tend	O
to	O
use	O
more	O
memory	O
than	O
apply	O
call	O
,	O
but	O
the	O
confusion	O
is	O
that	O
I	O
still	O
have	O
lots	O
of	O
memory	O
left	O
when	O
the	O
memory	O
error	O
occurs	O

I	O
can	O
reproduce	O
the	O
memory	O
problem	O
.	O

Still	O
investigating	O
further	O
but	O
no	O
luck	O
on	O
faster	O
approaches	O
.	O

Also	O
timed	O
the	O
apply	O
solution	O
and	O
it	O
takes	O
about	O
5	O
minutes	O
with	O
500k	O
rows	O

Sorry	O
,	O
I	O
can	O
also	O
reproduce	O
it	O
on	O
0.13.1	O
,	O
but	O
the	O
issue	O
does	O
not	O
occur	O
in	O
0.12	O
or	O
in	O
0.14	O
(	O
released	O
yesterday	O
)	O
,	O
so	O
it	O
seems	O
a	O
bug	O
in	O
0.13	O
.	O

So	O
,	O
maybe	O
try	O
to	O
upgrade	O
your	O
pandas	O
version	O
,	O
as	O
the	O
vectorized	O
way	O
is	O
much	O
faster	O
as	O
the	O
apply	O
(	O
5s	O
vs	O
>	O
1min	O
on	O
my	O
machine	O
)	O
,	O
*	O
and	O
*	O
using	O
less	O
peak	O
memory	O
(	O
200Mb	O
vs	O
980Mb	O
,	O
with	O
`	O
%memit	O
`)	O
on	O
0.14	O
.	O

So	O
,	O
maybe	O
try	O
to	O
upgrade	O
your	O
pandas	O
version	O
,	O
as	O
the	O
vectorized	O
way	O
is	O
much	O
faster	O
as	O
the	O
apply	O
(	O
5s	O
vs	O
>	O
1min	O
on	O
my	O
machine	O
)	O
,	O
and	O
using	O
less	O
peak	O
memory	O
(	O
200Mb	O
vs	O
980Mb	O
,	O
with	O
%memit	O
)	O
on	O
0.14	O

Can	O
I	O
apply	O
a	O
function	O
that	O
uses	O
'	O
shift	O
'	O
on	O
a	O
grouped	O
data	O
frame	O
,	O
and	O
return	O
a	O
simple	O
data	O
frame	O
from	O
pandas	O
?	O

You	O
can	O
use	O
the	O
`	O
TimeGrouper	O
`	O
function	O
in	O
a	O
`	O
groupy	O
/	O
apply	O
`	O
.	O

With	O
a	O
`	O
TimeGrouper	O
`	O
you	O
don't	O
need	O
to	O
create	O
your	O
period	O
column	O
.	O

I	O
know	O
you're	O
not	O
trying	O
to	O
compute	O
the	O
mean	O
but	O
I	O
will	O
use	O
it	O
as	O
an	O
example	O
:	O
#CODE	O

Or	O
an	O
example	O
with	O
an	O
explicit	O
`	O
apply	O
`	O
:	O
#CODE	O

It	O
works	O
because	O
the	O
groupby	B-API
here	O
with	O
as_index=False	O
actually	O
returns	O
the	O
period	O
column	O
you	O
want	O
as	O
the	O
part	O
of	O
the	O
multiindex	O
and	O
I	O
just	O
grab	O
that	O
part	O
of	O
the	O
multiindex	O
and	O
assign	O
to	O
a	O
new	O
column	O
in	O
the	O
orginal	O
dataframe	B-API
.	O

You	O
could	O
do	O
anything	O
in	O
the	O
apply	O
,	O
I	O
just	O
want	O
the	O
index	O
:	O
#CODE	O

Yes	O
,	O
you	O
can	O
do	O
it	O
in	O
an	O
apply	O
.	O

Just	O
do	O
a	O
groupby	B-API
in	O
a	O
function	O
that	O
the	O
first	O
groupby	B-API
/	O
apply	O
calls	O

@USER	O
you	O
could	O
use	O
a	O
function	O
and	O
apply	O
it	O
to	O
the	O
dataframe	B-API
but	O
I'm	O
not	O
sure	O
you	O
would	O
save	O
much	O
time	O
,	O
it	O
would	O
depend	O
on	O
how	O
many	O
unique	O
ids	O
there	O
were	O
,	O
once	O
you	O
have	O
created	O
the	O
dicts	O
then	O
using	O
`	O
map	O
`	O
is	O
really	O
fast	O

It's	O
a	O
reasonable	O
way	O
to	O
do	O
it	O
.	O

You	O
could	O
change	O
the	O
apply	O
a	O
little	O
to	O
only	O
return	O
a	O
`	O
ranks	O
`	O
Series	O
.	O

That	O
would	O
allow	O
you	O
to	O
just	O
assign	O
a	O
new	O
`	O
ranks	O
`	O
column	O
to	O
the	O
original	O
dataframe	B-API
as	O
the	O
result	O
of	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
.	O

But	O
your	O
way	O
works	O
just	O
fine	O
.	O

I	O
am	O
struggling	O
to	O
set	O
xlim	O
for	O
each	O
histogram	O
and	O
create	O
1	O
column	O
of	O
graphs	O
so	O
the	O
x-axis	O
ticks	O
are	O
aligned	O
.	O

Being	O
new	O
pandas	O
,	O
I	O
am	O
unsure	O
of	O
how	O
to	O
apply	O
answer	O
applies	O
:	O
Overlaying	O
multiple	O
histograms	O
using	O
pandas	O
.	O

#CODE	O

The	O
layout	O
option	O
is	O
very	O
helpful	O
.	O

However	O
,	O
the	O
bin	O
setting	O
seems	O
to	O
only	O
apply	O
to	O
the	O
range	O
of	O
data	O
not	O
the	O
entire	O
interval	O
that	O
we	O
display	O
using	O
xlim	O
.	O

For	O
example	O
,	O
say	O
that	O
I'd	O
like	O
to	O
bucket	O
the	O
counts	O
over	O
[	O
-1	O
,	O
1	O
]	O
with	O
a	O
total	O
of	O
10	O
buckets	O
;	O
then	O
the	O
values	O
from	O
0	O
to	O
0.2	O
should	O
be	O
in	O
a	O
single	O
bucket	O
,	O
but	O
that's	O
not	O
the	O
case	O
with	O
bins=10	O
.	O

Any	O
idea	O
why	O
not	O
?	O

jeff	O
,	O
i	O
getting	O
the	O
output	O
i	O
want	O
.	O

I	O
just	O
want	O
to	O
see	O
if	O
another	O
way	O
exist	O
with	O
pandas	O
,	O
like	O
apply	O
or	O
shift	O
.	O

I	O
tried	O
but	O
i	O
couldn't	O
figure	O
out	O

Once	O
you	O
understood	O
what	O
happened	O
here	O
,	O
I'm	O
sure	O
you	O
can	O
apply	O
this	O
to	O
find	O
the	O
maximum	O
of	O
'	O
t1	O
'	O
.	O

Udate	O
:	O
If	O
you	O
don't	O
want	O
to	O
depend	O
on	O
the	O
column	O
order	O
,	O
you	O
can	O
also	O
specify	O
the	O
values	O
to	O
use	O
to	O
fill	O
for	O
each	O
row	O
(	O
like	O
`	O
.fillna	B-API
(	O
value	O
=d	O
f	O
[	O
'	O
D	O
']`)	O
.	O

The	O
only	O
problem	O
is	O
that	O
this	O
only	O
works	O
for	O
Series	O
(	O
when	O
it	O
is	O
a	O
dataframe	B-API
,	O
it	O
tries	O
to	O
map	O
the	O
different	O
values	O
to	O
fill	O
to	O
the	O
different	O
columns	O
,	O
not	O
the	O
rows	O
)	O
.	O

So	O
with	O
an	O
apply	O
to	O
do	O
it	O
column	O
by	O
column	O
,	O
it	O
works	O
:	O
#CODE	O

`	O
Cannot	O
access	O
callable	O
attribute	O
'	O
reset_index	B-API
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
`	O

Thanks	O
a	O
lot	O
!	O

My	O
fault	O
was	O
,	O
that	O
I	O
did	O
not	O
realize	O
,	O
that	O
I	O
have	O
to	O
apply	O
some	O
function	O
to	O
the	O
groupby	B-API
dataframe	B-API
,	O
like	O
`	O
.size()	B-API
`	O
,	O
to	O
work	O
with	O
it	O
...	O

#CODE	O

Then	O
you	O
can	O
select	O
the	O
rows	O
you	O
want	O
in	O
an	O
apply	O
call	O
on	O
the	O
grouped	O
object	O
:	O
#CODE	O

If	O
you	O
have	O
one	O
large	O
dataframe	B-API
and	O
only	O
a	O
few	O
update	O
values	O
I	O
would	O
use	O
apply	O
like	O
this	O
:	O
#CODE	O

OK	O
,	O
first	O
problem	O
is	O
you	O
have	O
embedded	O
spaces	O
causing	O
the	O
function	O
to	O
incorrectly	O
apply	O
:	O

So	O
you	O
can	O
call	O
`	O
replace	O
`	O
instead	O
of	O
calling	O
`	O
apply	O
`	O
:	O
#CODE	O

@USER	O
so	O
is	O
`	O
replace	O
`	O
faster	O
than	O
calling	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
and	O
passing	O
a	O
dict	O
now	O
?	O

Wasn't	O
aware	O
of	O
`	O
factorize	O
`	O
also	O
,	O
when	O
was	O
this	O
introduced	O
?	O

My	O
tentative	O
solution	O
is	O
to	O
apply	O
this	O
function	O
after	O
reading	O
:	O
#CODE	O

Now	O
you	O
can	O
use	O
an	O
apply	O
with	O
zip	O
:	O
#CODE	O

I	O
have	O
applied	O
dropna	B-API
(	O
how=	O
'	O
all	O
')	O
,	O
which	O
makes	O
my	O
example	O
misleading	O
.	O

However	O
,	O
I	O
am	O
not	O
willing	O
to	O
apply	O
dropna	B-API
(	O
how=	O
'	O
any	O
')	O
,	O
since	O
I	O
do	O
not	O
want	O
to	O
lose	O
valid	O
data	O
just	O
because	O
a	O
NaN	O
sits	O
in	O
the	O
next	O
column	O
over	O
.	O

Your	O
suggestion	O
is	O
good	O
.	O

That	O
being	O
said	O
,	O
there	O
still	O
seems	O
to	O
be	O
a	O
fundamental	O
problem	O
with	O
quantile	O
(	O
or	O
so	O
I	O
think	O
!	O
)	O
.	O

the	O
order	O
within	O
group	O
apply	O
function	O

order	O
is	O
preserved	O
within	O
a	O
group	O
and	O
to	O
the	O
subframe	O
that	O
is	O
passed	O
to	O
apply	O
or	O
a	O
reduction	O
function	O
.	O
you	O
should	O
show	O
what	O
you	O
are	O
doing	O
and	O
why	O
this	O
matters	O
.	O

@USER	O
it	O
matters	O
for	O
apply	O
functions	O
like	O
x	O
-	O
x.shift	O
(	O
1	O
)	O
.	O

If	O
order	O
is	O
not	O
preserved	O
I	O
may	O
get	O
wrong	O
answer	O
.	O

If	O
you	O
are	O
using	O
apply	O
not	O
only	O
is	O
the	O
order	O
not	O
guaranteed	O
,	O
but	O
as	O
you've	O
found	O
it	O
can	O
trigger	O
the	O
function	O
for	O
the	O
same	O
group	O
a	O
couple	O
of	O
times	O
(	O
to	O
decide	O
which	O
"	O
path	O
"	O
to	O
take	O
/	O
what	O
type	O
of	O
result	O
to	O
return	O
)	O
.	O

So	O
if	O
your	O
function	O
has	O
side-effects	O
don't	O
do	O
this	O
!	O

Apply	O
styles	O
while	O
exporting	O
to	O
'	O
xlsx	O
'	O
in	O
pandas	O
with	O
XlsxWriter	O

When	O
using	O
the	O
pure	O
XlsxWriter	O
I	O
can	O
apply	O
formats	O
to	O
cells	O
what	O
also	O
works	O
nice	O
.	O

Based	O
on	O
this	O
new	O
dataframe	B-API
,	O
I	O
can	O
group	O
it	O
by	O
`	O
ticker	O
`	O
and	O
`	O
row	O
`	O
,	O
and	O
apply	O
a	O
daily	O
`	O
resample	O
`	O
on	O
each	O
of	O
these	O
groups	O
and	O
`	O
fillna	B-API
`	O
(	O
with	O
method	O
'	O
pad	O
'	O
to	O
forward	O
fill	O
)	O
#CODE	O

@USER	O
:	O
Happy001	O
asked	O
to	O
see	O
the	O
dtype	B-API
of	O
`	O
realtime	O
`	O
.	O

You	O
showed	O
the	O
*	O
type	O
*	O
of	O
what	O
you	O
get	O
when	O
you	O
select	O
a	O
column	O
from	O
a	O
groupby	B-API
object	O
(	O
`	O
SeriesGroupBy	B-API
`)	O
,	O
and	O
the	O
*	O
type	O
*	O
of	O
an	O
unrelated	O
Series	O
after	O
you	O
apply	O
`	O
pd.to_datetime	B-API
`	O
to	O
its	O
elements	O
,	O
which	O
by	O
construction	O
is	O
`	O
Series	O
`	O
.	O

So	O
far	O
,	O
nothing	O
you've	O
shown	O
is	O
incompatible	O
with	O
the	O
error	O
message	O
`	O
pandas	O
`	O
gave	O
,	O
which	O
says	O
that	O
you're	O
trying	O
to	O
subtract	O
a	O
`	O
timedelta	O
`	O
from	O
a	O
`	O
unicode	O
`	O
string	O
.	O

Instead	O
,	O
look	O
at	O
`	O
df	O
[	O
'	O
realtime	O
']	O
.dtype	B-API
`	O
,	O
and	O
`	O
df	O
[	O
"	O
realtime	O
"]	O
.apply	B-API
(	O
type	O
)`	O
.	O

How	O
to	O
apply	O
OLS	O
from	O
statsmodels	O
to	O
groupby	B-API

So	O
how	O
can	O
I	O
go	O
through	O
my	O
dataframe	B-API
and	O
apply	O
sm.OLS()	O
for	O
each	O
product_desc	O
?	O

If	O
I	O
understand	O
you	O
correctly	O
,	O
I	O
think	O
you	O
can	O
do	O
it	O
with	O
a	O
`	O
groupby	B-API
/	O
apply	O
`	O
.	O

It's	O
a	O
bit	O
tricky	O
.	O

So	O
I	O
think	O
you	O
have	O
data	O
like	O
the	O
following	O
:	O
#CODE	O

bypass	O
read_csv	B-API
and	O
apply	O
to_datetime	B-API
after	O
:	O

I	O
think	O
the	O
problem	O
is	O
`	O
apply	O
`	O
expects	O
to	O
return	O
the	O
same	O
number	O
of	O
rows	O
as	O
the	O
input	O
.	O

You	O
could	O
also	O
do	O
it	O
with	O
a	O
`	O
groupby	B-API
/	O
apply	O
`	O
since	O
it	O
is	O
more	O
flexible	O
.	O

So	O
something	O
like	O
the	O
following	O
:	O
#CODE	O

You	O
can	O
use	O
the	O
pandas	O
groupby-apply	O
combo	O
.	O

Group	O
the	O
dataframe	B-API
by	O
"	O
Item	O
"	O
and	O
apply	O
a	O
function	O
that	O
calculates	O
the	O
process	O
time	O
.	O

Something	O
like	O
:	O
#CODE	O

@USER	O
still	O
I	O
think	O
BrenBarn	O
is	O
correct	O
.	O

If	O
you	O
are	O
just	O
updating	O
existing	O
data	O
then	O
the	O
performance	O
hit	O
may	O
not	O
be	O
an	O
issue	O
,	O
it	O
sounds	O
like	O
all	O
you'd	O
be	O
doing	O
would	O
some	O
stats	O
on	O
the	O
updated	O
values	O
,	O
note	O
that	O
groupby	B-API
itself	O
does	O
nothing	O
only	O
when	O
you	O
apply	O
a	O
function	O
does	O
it	O
do	O
something	O
.	O

If	O
you	O
know	O
which	O
group	O
is	O
to	O
be	O
updated	O
then	O
you	O
can	O
call	O
`	O
get_group	B-API
(	O
'	O
updated_item	O
)`	O
can	O
call	O
apply	O
on	O
just	O
that	O
group	O
see	O
:	O
#URL	O

You	O
could	O
use	O
the	O
`	O
apply	O
`	O
method	O
:	O
#CODE	O

Thanks	O
!!	O

I	O
found	O
my	O
stupid	O
mistake	O
while	O
using	O
apply()	B-API
.	O

I	O
did	O
apply	O
(	O
wordnet.synsets()	O
)	O

For	O
example	O
,	O
say	O
that	O
I	O
know	O
what	O
slices	O
I	O
want	O
to	O
apply	O
on	O
each	O
level	O
name	O
,	O
e.g.	O
as	O
a	O
dictionary	O
:	O
#CODE	O

you	O
could	O
use	O
an	O
`	O
apply	O
`	O
statement	O
to	O
select	O
the	O
values	O
from	O
the	O
correct	O
columns	O
.	O

I	O
now	O
would	O
like	O
to	O
combine	O
the	O
'	O
Day	O
'	O
and	O
'	O
Hour	O
'	O
columns	O
into	O
one	O
'	O
Date	O
'	O
index	O
column	O
.	O

I	O
did	O
a	O
lot	O
of	O
searching	O
and	O
so	O
far	O
I	O
have	O
only	O
seen	O
solutions	O
that	O
are	O
based	O
on	O
pd.read_csv	B-API
and	O
pd.read_table	B-API
.	O

However	O
,	O
as	O
this	O
is	O
a	O
series	O
(	O
not	O
a	O
dataframe	B-API
/	O
csv	O
/	O
excel	O
)	O
,	O
these	O
solutions	O
do	O
not	O
seem	O
to	O
apply	O
.	O

use	O
``	O
apply	O
``	O
ONLY	O
as	O
a	O
last	O
resort	O
(	O
e.g.	O
you	O
can't	O
do	O
vectorized	O
things	O
)	O
.	O
even	O
if	O
you	O
have	O
a	O
very	O
complicated	O
function	O
to	O
do	O
,	O
you	O
can	O
often	O
do	O
vectorized	O
calculations	O
on	O
most	O
of	O
it	O
,	O
saving	O
the	O
last	O
for	O
``	O
apply	O
``	O
,	O
which	O
is	O
essentially	O
a	O
loop	O
.	O

Using	O
apply	O
took	O
172ms	O
versus	O
39ms	O
using	O
Jeff's	O
method	O
,	O
I	O
can	O
also	O
confirm	O
that	O
it	O
made	O
negligle	O
difference	O
whether	O
the	O
apply	O
was	O
called	O
inside	O
or	O
outside	O
the	O
function	O
but	O
it	O
does	O
modify	O
the	O
df	O
so	O
you	O
didn't	O
need	O
to	O
return	O
the	O
df	O
as	O
it	O
was	O
being	O
modified	O
inside	O
the	O
function	O

@USER	O
:	O
thanks	O
for	O
your	O
clarifications	O
once	O
again	O
,	O
very	O
glad	O
you	O
helped	O
me	O
with	O
it	O
.	O

As	O
a	O
new	O
user	O
like	O
me	O
to	O
python	O
/	O
pandas	O
,	O
the	O
problem	O
mostly	O
is	O
,	O
that	O
I	O
can	O
only	O
search	O
/	O
google	O
for	O
solutions	O
as	O
the	O
libraries	O
contain	O
so	O
many	O
classes	O
and	O
functions	O
that	O
I	O
don't	O
know	O
what	O
to	O
look	O
for	O
(	O
in	O
this	O
case	O
the	O
`	O
DatetimeIndex	B-API
`	O
class	O
)	O
.	O

And	O
then	O
sometimes	O
different	O
solutions	O
(	O
in	O
this	O
case	O
using	O
`	O
apply	O
`)	O
come	O
up	O
on	O
google	O
/	O
stackoverflow	O
and	O
yet	O
again	O
I	O
can	O
NOT	O
verify	O
that	O
there	O
is	O
no	O
better	O
solution	O
as	O
I	O
dont	O
have	O
the	O
insight	O
into	O
the	O
library	O
.	O

But	O
I	O
keep	O
learning	O
heavily	O
each	O
day	O
,	O
thanks	O
:)	O

Pandas	O
:	O
apply	O
a	O
function	O
to	O
a	O
multiindexed	O
series	O

Now	O
I	O
want	O
to	O
apply	O
any	O
function	O
to	O
each	O
series	O
indexed	O
by	O
numbers.hash	O
only	O
,	O
e.g.	O
summing	O
the	O
values	O
in	O
each	O
time	O
series	O
that	O
is	O
made	O
up	O
of	O
local_time	O
and	O
the	O
value	O
.	O

I	O
guess	O
I	O
can	O
get	O
the	O
number.hash	O
indices	O
and	O
iterate	O
over	O
them	O
,	O
but	O
there	O
must	O
be	O
a	O
more	O
efficient	O
and	O
clean	O
way	O
to	O
do	O
it	O
.	O

Or	O
groupby	B-API
and	O
apply	O
an	O
arbitrary	O
function	O
#CODE	O

gives	O
"	O
AttributeError	O
:	O
rint	B-API
"	O
if	O
I	O
insert	O
values	O
and	O
then	O
apply	O
np.round()	O
.	O

If	O
I	O
copy	O
df.describe()	B-API
,	O
change	O
some	O
values	O
and	O
then	O
do	O
np.round()	O
it	O
works	O
fine	O
.	O

Both	O
are	O
DataFrames	O
so	O
I	O
don't	O
see	O
why	O
the	O
behaviour	O
could	O
be	O
different	O
.	O

Thanks	O
.	O

For	O
some	O
weird	O
reason	O
that	O
didn't	O
work	O
.	O

I	O
keep	O
checking	O
that	O
I	O
have	O
dupes	O
by	O
using	O
df.duplicated()	B-API
.value_counts()	B-API
and	O
it	O
does	O
show	O
as	O
many	O
rows	O
as	O
True	O
but	O
then	O
when	O
I	O
apply	O
`	O
df.sort	O
(	O
df.columns.tolist()	O
)`	O
as	O
you	O
suggest	O
,	O
it	O
still	O
is	O
not	O
sorting	O
all	O
of	O
the	O
duplicated	O
rows	O
.	O

No	O
,	O
I	O
have	O
tried	O
that	O
and	O
received	O
this	O
:	O
AttributeError	O
:	O
Cannot	O
access	O
attribute	O
'	O
values	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

You	O
need	O
to	O
apply	O
some	O
kind	O
of	O
aggregation	O
to	O
the	O
GroupBy	B-API
object	O
to	O
return	O
a	O
DataFrame	B-API
.	O

Once	O
you	O
have	O
that	O
,	O
you	O
can	O
use	O
`	O
.values	B-API
`	O
to	O
extract	O
the	O
numpy	O
arrary	O
.	O

In	O
DF1	O
are	O
a	O
few	O
hundred	O
thousand	O
records	O
with	O
columns	O
lat1	O
and	O
lon1	O
and	O
there	O
are	O
50,000	O
records	O
in	O
DF2	O
with	O
columns	O
lat2	O
,	O
lon2	O
and	O
zip	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
f	O
(	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
which	O
calculates	O
the	O
distance	O
between	O
two	O
points	O
(	O
defined	O
using	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
.	O

I	O
ultimately	O
want	O
to	O
add	O
zip	O
from	O
DF2	O
into	O
Df1	O
corresponding	O
to	O
the	O
record	O
in	O
D2	O
corresponding	O
to	O
the	O
smallest	O
distance	O
between	O
that	O
row	O
in	O
Df1	O
and	O
all	O
rows	O
in	O
D2	O
.	O

For	O
all	O
110k+	O
records	O
in	O
`	O
df1	O
`	O
do	O
you	O
want	O
to	O
apply	O
your	O
distance	O
function	O
for	O
every	O
record	O
in	O
`	O
df2	O
`	O
?	O

pandas	O
apply	O
function	O
to	O
multiple	O
columns	O
and	O
multiple	O
rows	O

I	O
have	O
a	O
dataframe	B-API
with	O
consecutive	O
pixel	O
coordinates	O
in	O
rows	O
and	O
columns	O
'	O
xpos	O
'	O
,	O
'	O
ypos	O
'	O
,	O
and	O
I	O
want	O
to	O
calculate	O
the	O
angle	O
in	O
degrees	O
of	O
each	O
path	O
between	O
consecutive	O
pixels	O
.	O

Currently	O
I	O
have	O
the	O
solution	O
presented	O
below	O
,	O
which	O
works	O
fine	O
and	O
for	O
teh	O
size	O
of	O
my	O
file	O
is	O
speedy	O
enough	O
,	O
but	O
iterating	O
through	O
all	O
the	O
rows	O
seems	O
not	O
to	O
be	O
the	O
pandas	O
way	O
to	O
do	O
it	O
.	O

I	O
know	O
how	O
to	O
apply	O
a	O
function	O
to	O
different	O
columns	O
,	O
and	O
how	O
to	O
apply	O
functions	O
to	O
different	O
rows	O
of	O
columns	O
,	O
but	O
can't	O
figure	O
out	O
how	O
to	O
combine	O
both	O
.	O

I	O
compared	O
the	O
time	O
of	O
three	O
solutions	O
for	O
my	O
df	O
(	O
the	O
size	O
of	O
the	O
df	O
is	O
about	O
6k	O
rows	O
)	O
,	O
the	O
iteration	O
is	O
almost	O
9	O
times	O
slower	O
than	O
apply	O
,	O
and	O
about	O
1500	O
times	O
slower	O
then	O
doing	O
it	O
without	O
apply	O
:	O

execution	O
time	O
of	O
the	O
solution	O
without	O
iteration	O
,	O
with	O
apply	O
:	O
0.17s	O

execution	O
time	O
of	O
accepted	O
answer	O
by	O
EdChum	O
using	O
diff()	B-API
,	O
without	O
iteration	O
and	O
without	O
apply	O
:	O
0.001s	O

Suggestion	O
:	O
do	O
not	O
use	O
iteration	O
or	O
apply	O
and	O
always	O
try	O
to	O
use	O
vectorized	O
calculation	O
;)	O
it	O
is	O
not	O
only	O
faster	O
,	O
but	O
also	O
more	O
readable	O
.	O

Also	O
if	O
possible	O
avoid	O
using	O
`	O
apply	O
`	O
,	O
as	O
this	O
operates	O
row-wise	O
,	O
if	O
you	O
can	O
find	O
a	O
vectorised	O
method	O
that	O
can	O
work	O
on	O
the	O
entire	O
series	O
or	O
dataframe	B-API
then	O
always	O
prefer	O
this	O
.	O

NOTE	O
:	O
I	O
selected	O
the	O
'	O
size	O
'	O
column	O
because	O
all	O
the	O
functions	O
apply	O
to	O
that	O
column	O
.	O

If	O
you	O
wanted	O
to	O
do	O
a	O
different	O
set	O
of	O
functions	O
for	O
different	O
columns	O
,	O
you	O
can	O
use	O
`	O
agg	O
`	O
with	O
a	O
dictionary	O
with	O
a	O
list	O
of	O
functions	O
e.g.	O
`	O
agg	O
(	O
{	O
'	O
size	O
'	O
:	O
[	O
np.sum	B-API
,	O
np.average	B-API
]	O
}	O
)`	O
.	O

This	O
results	O
in	O
`	O
MultiIndex	O
`	O
columns	O
,	O
which	O
means	O
that	O
when	O
getting	O
the	O
IDs	O
for	O
the	O
maximum	O
size	O
in	O
each	O
group	O
you	O
need	O
to	O
do	O
:	O
#CODE	O

I've	O
tried	O
using	O
the	O
`	O
apply	O
`	O
function	O
across	O
the	O
column	O
,	O
but	O
to	O
no	O
avail	O
.	O

So	O
,	O
I	O
took	O
a	O
very	O
naive	O
(	O
but	O
not	O
very	O
concise	O
)	O
approach	O
to	O
create	O
these	O
columns	O
:	O
#CODE	O

Rather	O
than	O
fill	O
as	O
an	O
empty	O
column	O
,	O
you	O
can	O
simply	O
populate	O
this	O
with	O
an	O
apply	O
:	O
#CODE	O

Perform	O
a	O
`	O
groupby	B-API
`	O
by	O
'	O
Country	O
'	O
and	O
use	O
`	O
transform	O
`	O
to	O
apply	O
a	O
function	O
to	O
that	O
group	O
which	O
will	O
return	O
an	O
index	O
aligned	O
to	O
the	O
original	O
df	O
#CODE	O

I'm	O
aware	O
of	O
df.where	B-API
function	O
but	O
apparently	O
it's	O
not	O
possible	O
to	O
apply	O
for	O
columns	O
,	O
it	O
works	O
just	O
for	O
all	O
DataFrame	B-API
.	O

Why	O
not	O
use	O
the	O
built	O
in	O
string	O
method	O
,	O
rather	O
than	O
apply	O
.	O

`	O
df	O
[	O
0	O
]	O
.str	B-API
.count	B-API
(	O
'	O
:	O
')`	O

@USER	O
using	O
that	O
function	O
is	O
actually	O
slower	O
than	O
using	O
`	O
apply	O
`	O
(	O
see	O
my	O
answer	O
)	O
.	O

Looking	O
for	O
a	O
better	O
method	O
to	O
achieve	O
desired	O
output	O
as	O
shown	O
.	O

I	O
have	O
messed	O
with	O
lambda	O
,	O
apply	O
,	O
aggregrate	O
commands	O
can't	O
quite	O
get	O
anything	O
to	O
work	O
.	O

#CODE	O

I	O
realize	O
there	O
are	O
different	O
settings	O
one	O
can	O
apply	O
that	O
will	O
change	O
the	O
look	O
and	O
feel	O
of	O
either	O
individually	O
(	O
matplotlib	O
savefig()	B-API
plots	O
different	O
from	O
show()	B-API
)	O
,	O
however	O
I	O
haven't	O
been	O
able	O
to	O
find	O
any	O
easy	O
to	O
follow	O
documentation	O
that	O
shows	O
how	O
to	O
set	O
the	O
default	O
fonts	O
while	O
using	O
matplotlib	O
backend	O
:	O
MacOSX	O
.	O

Can	O
someone	O
show	O
how	O
to	O
make	O
the	O
font	O
that	O
appears	O
in	O
the	O
shown	O
figure	O
also	O
appear	O
in	O
the	O
saved	O
figure	O
?	O

BUT	O
so	O
far	O
we	O
can't	O
apply	O
the	O
right	O
DatetimeIndex	B-API
to	O
ts.resample()	O

I	O
think	O
to	O
use	O
`	O
apply	O
`	O
in	O
this	O
case	O
will	O
be	O
difficult	O
as	O
it	O
is	O
conditional	O
(	O
based	O
on	O
the	O
surrounding	O
cells	O
)	O
.	O

I	O
think	O
you	O
many	O
want	O
to	O
generate	O
separate	O
`	O
DataFrame	B-API
`	O
s	O
for	O
`	O
Around_A	O
,	O
B	O
....	O

`	O
.	O

Once	O
you	O
get	O
those	O
,	O
you	O
can	O
use	O
`	O
dropna()	B-API
`	O
to	O
get	O
rid	O
of	O
the	O
rows	O
containing	O
`	O
nan	O
`	O
s	O
,	O
which	O
will	O
make	O
the	O
dataset	O
much	O
smaller	O
and	O
may	O
avoid	O
the	O
memory	O
issue	O
altogether	O
.	O

Basically	O
I	O
want	O
to	O
create	O
a	O
new	O
column	O
"	O
Ratio	O
"	O
that	O
divides	O
Price	O
/	O
Buy	O
or	O
Price	O
/	O
Sell	O
,	O
depending	O
on	O
which	O
abs	O
(	O
buy	O
)	O
or	O
abs	O
(	O
sell	O
)	O
is	O
greater	O
.	O

I	O
am	O
not	O
really	O
sure	O
how	O
to	O
do	O
this	O
...	O
would	O
I	O
use	O
an	O
apply	O
function	O
?	O

Here	O
is	O
the	O
solution	O
using	O
apply	O
-	O
First	O
define	O
a	O
function	O
operating	O
in	O
rows	O
of	O
the	O
DataFrame	B-API
.	O

#CODE	O

Finally	O
,	O
set	O
the	O
`	O
Ratio	O
`	O
column	O
appropriately	O
using	O
apply	O
.	O

Thanks	O
this	O
works	O
!	O

But	O
is	O
there	O
a	O
way	O
to	O
do	O
it	O
with	O
an	O
apply	O
function	O
or	O
something	O
as	O
well	O
?	O

i	O
am	O
looking	O
to	O
apply	O
multiply	O
masks	O
on	O
each	O
column	O
of	O
a	O
pandas	O
dataset	O
(	O
respectively	O
to	O
it's	O
properties	O
)	O
in	O
python	O
.	O

how	O
can	O
i	O
apply	O
the	O
concat_mask	O
on	O
df	O
,	O
so	O
that	O
i	O
select	O
rows	O
,	O
in	O
which	O
all	O
Boolean	O
criteria	O
are	O
matched	O
(	O
are	O
True	O
)	O
?	O

Thanks	O
for	O
Your	O
answer	O
.	O

In	O
the	O
proper	O
code	O
i	O
actually	O
iterate	O
throw	O
all	O
columns	O
and	O
apply	O
various	O
of	O
diffenrent	O
conditions	O
to	O
mask	O
each	O
column	O
.	O

This	O
is	O
all	O
what	O
the	O
code	O
ment	O
to	O
express	O
.	O

not	O
yet	O
#URL	O
(	O
but	O
you	O
can	O
do	O
it	O
in	O
the	O
apply	O
;	O
this	O
is	O
for	O
using	O
an	O
aggregate	O
function	O
)	O
.	O

Since	O
we're	O
using	O
views	O
here	O
,	O
this	O
should	O
be	O
more	O
efficient	O
/	O
faster	O
than	O
the	O
apply	O
...	O

Pandas	O
rolling	O
apply	O
with	O
variable	O
window	O
length	O

I'm	O
trying	O
to	O
reduce	O
meterological	O
data	O
using	O
`	O
pandas	O
`	O
0.13.1	O
.	O

I	O
have	O
a	O
large	O
dataframe	B-API
of	O
floats	O
.	O

Thanks	O
to	O
this	O
answer	O
I	O
have	O
grouped	O
the	O
data	O
into	O
half-hour	O
intervals	O
most	O
efficiently	O
.	O

I	O
am	O
using	O
`	O
groupby	B-API
`	O
+	O
`	O
apply	O
`	O
instead	O
of	O
`	O
resample	O
`	O
because	O
of	O
the	O
need	O
to	O
examine	O
multiple	O
columns	O
.	O

#CODE	O

I	O
want	O
to	O
use	O
`	O
math.atan2	O
`	O
on	O
the	O
'	O
Ux	O
/	O
Uy	O
'	O
columns	O
and	O
am	O
having	O
trouble	O
successfully	O
`	O
apply	O
`	O
ing	O
any	O
function	O
.	O

I	O
get	O
tracebacks	O
about	O
attribute	O
`	O
ndim	B-API
`	O
:	O
#CODE	O

My	O
original	O
question	O
was	O
:	O
what	O
kind	O
of	O
value	O
should	O
be	O
returned	O
from	O
my	O
`	O
apply	O
`	O
ed	O
function	O
so	O
that	O
a	O
groupby-apply	O
operation	O
results	O
in	O
a	O
1-column	O
DataFrame	B-API
or	O
Series	O
with	O
a	O
length	O
equal	O
to	O
number	O
of	O
groups	O
and	O
group	O
names	O
(	O
e.g.	O
Timestamps	O
)	O
used	O
as	O
index	O
values	O
?	O

this	O
will	O
be	O
much	O
more	O
efficient	O
to	O
not	O
use	O
apply	O
at	O
all	O
,	O
rather	O
compute	O
the	O
mean	O
aggregates	O
first	O
,	O
then	O
use	O
np.atan2	O
.	O

I'll	O
put	O
up	O
an	O
example	O
tomorrow	O

Just	O
looking	O
at	O
your	O
exception	O
,	O
looks	O
like	O
you're	O
trying	O
to	O
apply	O
function	O
to	O
each	O
row	O
but	O
didn't	O
specify	O
axis=1	O
e.g.	O
df.apply	B-API
(	O
f	O
,	O
axis=1	O
)	O
#apply	O
function	O
to	O
each	O
row	O

Pandas	O
uses	O
the	O
index	O
"	O
line	O
up	O
"	O
operations	O
in	O
that	O
the	O
operation	O
will	O
apply	O
only	O
to	O
the	O
common	O
indices	O
.	O

So	O
if	O
you	O
want	O
to	O
subtract	O
one	O
row	O
from	O
all	O
in	O
a	O
DataFrame	B-API
then	O
you	O
need	O
to	O
convert	O
that	O
to	O
a	O
numpy	O
array	O
first	O
as	O
shown	O
in	O
the	O
answer	O
.	O

then	O
apply	O
the	O
filter	O
like	O
so	O
:	O

well	O
you	O
can	O
simply	O
access	O
the	O
subfeatures	O
field	O
in	O
the	O
apply	O
then	O
.	O

It	O
doesn't	O
affect	O
you	O
as	O
its	O
not	O
visible	O
to	O
you	O
.	O

This	O
tests	O
whether	O
you	O
are	O
mutating	O
the	O
input	O
in	O
the	O
apply	O
or	O
not	O
.	O

Just	O
use	O
``	O
apply	O
``	O
or	O
iterate	O
over	O
the	O
groups	O
.	O

Thus	O
in	O
a	O
non-trivial	O
computation	O
it	O
is	O
essential	O
that	O
you	O
use	O
the	O
built	O
in	O
functions	O
.	O

Using	O
(	O
apply	O
/	O
aggregate	O
)	O
is	O
nice	O
for	O
a	O
generalized	O
function	O
evaluation	O
,	O
but	O
pandas	O
cannot	O
make	O
too	O
many	O
assumptions	O
about	O
what	O
is	O
going	O
on	O
in	O
the	O
user	O
function	O
,	O
and	O
these	O
are	O
evaluated	O
in	O
python	O
space	O
.	O

#CODE	O

if	O
you	O
combine	O
this	O
with	O
another	O
apply	O
,	O
you'll	O
get	O
info	O
for	O
the	O
total	O
columns	O
#CODE	O

I've	O
come	O
up	O
with	O
this	O
,	O
using	O
itertools	O
,	O
to	O
find	O
mid-day	O
timestamps	O
and	O
group	O
them	O
by	O
date	O
,	O
and	O
now	O
I'm	O
coming	O
up	O
short	O
trying	O
to	O
apply	O
imap	O
to	O
find	O
the	O
means	O
.	O

#CODE	O

There	O
might	O
be	O
,	O
but	O
AFAIK	O
,	O
there	O
is	O
no	O
way	O
to	O
use	O
bracket	O
indexing	O
`	O
df1	O
[	O
...	O
]`	O
or	O
any	O
of	O
the	O
indexers	O
like	O
`	O
.loc	B-API
[	O
]`	O
,	O
`	O
.at	B-API
[	O
]`	O
,	O
or	O
`	O
.ix	B-API
[	O
]`	O
to	O
accomplish	O
this	O
easily	O
.	O

Each	O
of	O
these	O
returns	O
"	O
rectangular	O
"	O
DataFrames	O
,	O
whereas	O
you	O
want	O
to	O
select	O
a	O
*	O
sequence	O
*	O
of	O
individual	O
values	O
using	O
row	O
and	O
column	O
label	O
coordinates	O
.	O

There	O
is	O
a	O
way	O
to	O
use	O
`	O
df.apply	B-API
`	O
--	O
there	O
almost	O
always	O
is	O
--	O
but	O
I	O
think	O
`	O
apply	O
`	O
should	O
be	O
avoided	O
when	O
possible	O
because	O
it	O
is	O
often	O
a	O
relatively	O
slow	O
alternative	O
.	O

(	O
Under	O
the	O
hood	O
it	O
uses	O
a	O
Python	O
loop	O
which	O
calls	O
a	O
Python	O
function	O
for	O
each	O
row	O
or	O
each	O
column	O
...	O
a	O
recipe	O
for	O
slowness	O
.	O
)	O

and	O
when	O
I	O
try	O
to	O
apply	O
pct_change	B-API
:	O
#CODE	O

So	O
,	O
I	O
have	O
created	O
a	O
Series	O
with	O
C1	O
,	O
C2	O
and	O
C3	O
as	O
the	O
values	O
-	O
one	O
way	O
top	O
count	O
this	O
is	O
to	O
loop	O
over	O
the	O
rows	O
and	O
columns	O
of	O
the	O
DataFrame	B-API
and	O
then	O
over	O
this	O
Series	O
and	O
increment	O
the	O
counter	O
if	O
it	O
matches	O
.	O

But	O
is	O
there	O
an	O
`	O
apply	O
`	O
approach	O
that	O
can	O
achieve	O
this	O
in	O
a	O
compact	O
fashion	O
?	O

You	O
could	O
apply	O
`	O
value_counts	B-API
`	O
:	O
#CODE	O

You	O
can	O
just	O
apply	O
`	O
dropna	B-API
`	O
to	O
`	O
a12	O
`	O
before	O
`	O
merge	O
`	O
:	O
#CODE	O

Pandas	O
:	O
apply	O
tupleize_cols	O
to	O
dataframe	B-API
without	O
to_csv()	B-API
?	O

pandas	O
apply	O
np.histogram	B-API
to	O
reshape	O
dataframe	B-API

`	O
np.histogram	B-API
`	O
is	O
neither	O
a	O
reducer	O
(	O
returns	O
a	O
single	O
value	O
)	O
,	O
nor	O
a	O
transformer	O
(	O
returns	O
the	O
same	O
number	O
as	O
the	O
input	O
)	O
.	O

So	O
`	O
apply	O
`	O
doesn't	O
know	O
how	O
to	O
map	O
the	O
return	O
values	O
.	O

Here	O
is	O
another	O
way	O
(	O
and	O
conceptually	O
how	O
to	O
think	O
about	O
apply	O
)	O
#CODE	O

Perfect	O
,	O
thanks	O
!	O

I	O
knew	O
I	O
was	O
missing	O
something	O
about	O
the	O
internals	O
of	O
`	O
apply	O
`	O

The	O
code	O
above	O
obviously	O
does	O
not	O
work	O
.	O

It	O
is	O
not	O
clear	O
to	O
me	O
how	O
to	O
correctly	O
pass	O
the	O
fixed	O
`	O
y	O
`	O
to	O
the	O
function	O
while	O
having	O
`	O
apply	O
`	O
iterating	O
through	O
the	O
`	O
x	O
`	O
columns	O
(	O
`	O
x1	O
`	O
,	O
`	O
x2	O
`	O
,	O
...	O
)	O
.	O

I	O
suspect	O
there	O
might	O
be	O
a	O
very	O
clever	O
one-line	O
solution	O
to	O
do	O
this	O
.	O

Any	O
idea	O
?	O

The	O
function	O
you	O
pass	O
to	O
`	O
apply	O
`	O
must	O
take	O
a	O
`	O
pandas.DataFrame	B-API
`	O
as	O
a	O
first	O
argument	O
,	O
you	O
can	O
pass	O
additional	O
keyword	O
or	O
positional	O
arguments	O
to	O
`	O
apply	O
`	O
that	O
get	O
passed	O
to	O
the	O
applied	O
function	O
.	O

So	O
,	O
your	O
example	O
would	O
work	O
with	O
a	O
small	O
modification	O
.	O

Change	O
`	O
ols_res	O
`	O
to	O
#CODE	O

Then	O
,	O
you	O
can	O
use	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
like	O
this	O
#CODE	O

Use	O
`	O
groupby	B-API
`	O
and	O
we	O
can	O
pass	O
a	O
dict	O
of	O
functions	O
to	O
apply	O
to	O
each	O
column	O
,	O
for	O
`	O
WL	O
`	O
column	O
we	O
apply	O
`	O
count	O
`	O
from	O
`	O
pandas.Series	B-API
`	O
,	O
the	O
`	O
all	O
`	O
applies	O
a	O
test	O
on	O
all	O
values	O
and	O
returns	O
`	O
True	O
`	O
if	O
all	O
values	O
in	O
the	O
series	O
are	O
`	O
True	O
`	O
and	O
`	O
False	O
`	O
otherwise	O
.	O

#CODE	O

In	O
order	O
to	O
assign	O
these	O
values	O
back	O
to	O
the	O
original	O
dataframe	B-API
you	O
can	O
use	O
`	O
transform	O
`	O
,	O
unfortunately	O
I	O
couldn't	O
figure	O
out	O
how	O
to	O
apply	O
different	O
functions	O
to	O
different	O
columns	O
as	O
transform	O
won't	O
accept	O
`	O
agg	O
`	O
function	O
or	O
a	O
user	O
defined	O
function	O
.	O

Pandas	O
groupby	B-API
apply	O
how	O
to	O
speed	O
up	O

rolling	O
apply	O
for	O
a	O
binary	O
(	O
or	O
n-ary	O
)	O
function	O
in	O
pandas	O

To	O
do	O
this	O
,	O
I	O
have	O
the	O
following	O
function	O
that	O
I	O
would	O
like	O
to	O
use	O
a	O
rolling	O
apply	O
with	O
-	O
all	O
this	O
does	O
is	O
calculate	O
covariance	O
assuming	O
zero	O
mean	O
if	O
not	O
centered	O
and	O
calculate	O
the	O
usual	O
covariance	O
when	O
it	O
is	O
centered	O
.	O

#CODE	O

You	O
can	O
just	O
call	O
`	O
apply	O
`	O
and	O
access	O
the	O
`	O
time	O
`	O
function	O
on	O
the	O
datetime	O
object	O
create	O
the	O
column	O
initially	O
like	O
this	O
without	O
the	O
need	O
for	O
post	O
processing	O
:	O
#CODE	O

it	O
does	O
not	O
apply	O
operator	O
by	O
elements	O
,	O
but	O
returns	O
a	O
2*n	O
DataFrame	B-API
of	O
NaNs	O
:	O
#CODE	O

this	O
uses	O
indexing	O
by	O
column	O
name	O
,	O
and	O
doesn't	O
use	O
logical	O
operators	O
on	O
columns	O
,	O
rather	O
than	O
that	O
it	O
traverses	O
rows	O
with	O
apply	O
function	O
:	O
#CODE	O

thanks	O
for	O
the	O
reference	O
although	O
I	O
haven't	O
been	O
able	O
to	O
apply	O
it	O
to	O
my	O
specific	O
problem	O
.	O

There's	O
also	O
evidence	O
that	O
statsmodels	O
supports	O
timeseries	O
from	O
pandas	O
.	O

You	O
may	O
be	O
able	O
to	O
apply	O
this	O
to	O
linear	O
models	O
as	O
well	O
:	O

It	O
worked	O
fine	O
with	O
the	O
test	O
data	O
(	O
200	O
lines	O
)	O
but	O
gives	O
me	O
the	O
following	O
error	O
when	O
I	O
apply	O
it	O
to	O
the	O
real	O
data	O
(	O
20	O
million	O
lines	O
):	O
#CODE	O

use	O
a	O
lamda	O
apply	O
to	O
pass	O
groups	O
to	O
the	O
function	O

This	O
will	O
work	O
by	O
calling	O
`	O
apply	O
`	O
and	O
passing	O
param	O
`	O
axis=1	O
`	O
to	O
apply	O
it	O
row-wise	O
:	O
#CODE	O

You	O
simply	O
`	O
groupby	B-API
`	O
your	O
`	O
time	O
`	O
column	O
and	O
then	O
apply	O
the	O
`	O
mean	O
`	O
method	O
to	O
each	O
element	O
.	O

See	O
documentation	O
here	O
.	O

#CODE	O

You	O
won't	O
be	O
able	O
to	O
merge	O
using	O
a	O
partial	O
match	O
,	O
you'd	O
have	O
to	O
merge	O
what	O
you	O
can	O
and	O
then	O
perform	O
a	O
lookup	O
for	O
the	O
other	O
rows	O
,	O
I've	O
done	O
this	O
before	O
where	O
there	O
were	O
inexact	O
matches	O
.	O

You	O
have	O
to	O
write	O
some	O
function	O
and	O
then	O
apply	O
it	O
row-wise	O
to	O
your	O
merged	O
dataframe	B-API

and	O
I'm	O
trying	O
to	O
apply	O
a	O
transformation	O
in	O
order	O
to	O
get	O
a	O
dataframe	B-API
that	O
looks	O
like	O
the	O
following	O
#CODE	O

My	O
question	O
is	O
how	O
can	O
I	O
apply	O
this	O
function	O
to	O
several	O
classifiers	O
and	O
append	O
their	O
result	O
as	O
a	O
long	O
data	O
frame	O
like	O
#CODE	O

`	O
d.index	O
=	O
d.index.apply	O
(	O
lambda	O
x	O
:	O
x.time()	O
)`	O
won't	O
work	O
.	O

I	O
finally	O
managed	O
to	O
do	O
it	O
by	O
doing	O
a	O
reset	O
of	O
the	O
index	O
,	O
apply	O
,	O
and	O
set	O
again	O
:	O

A	O
simple	O
method	O
would	O
be	O
`	O
df.loc	B-API
[:	O
((	O
df	O
[	O
'	O
A	O
']	O
==	O
0	O
)	O
&	O
(	O
df	O
[	O
'	O
C	O
']	O
==	O
0	O
))	O
.idxmax()	B-API
]`	O
but	O
this	O
doesn't	O
apply	O
for	O
every	O
id	O

@USER	O
you	O
can	O
just	O
groupby	B-API
id	O
then	O
apply	O
idxmax	B-API
(	O
filter	O
before	O
the	O
groupby	B-API
)	O

I've	O
been	O
trying	O
to	O
apply	O
your	O
code	O
to	O
my	O
dataset	O
but	O
keep	O
running	O
into	O
MemoryErrors	O
.	O

My	O
local	O
machine	O
only	O
runs	O
python	O
32	O
so	O
i	O
switched	O
to	O
an	O
Amazon	O
m3.medium	O
(	O
1	O
VCPU	O
3.75GB	O
Mem	O
64-bit	O
python	O
)	O
but	O
even	O
this	O
instance	O
Kills	O
the	O
job	O
.	O

How	O
can	O
you	O
achieve	O
these	O
kinds	O
of	O
runtimes	O
?	O

I	O
have	O
a	O
pandas	O
dataframe	B-API
with	O
mixed	O
type	O
columns	O
,	O
and	O
I'd	O
like	O
to	O
apply	O
sklearn's	O
min_max_scaler	O
to	O
some	O
of	O
the	O
columns	O
.	O

Ideally	O
,	O
I'd	O
like	O
to	O
do	O
these	O
transformations	O
in	O
place	O
,	O
but	O
haven't	O
figured	O
out	O
a	O
way	O
to	O
do	O
that	O
yet	O
.	O

I've	O
written	O
the	O
following	O
code	O
that	O
works	O
:	O
#CODE	O

I	O
know	O
that	O
I	O
can	O
do	O
it	O
just	O
in	O
pandas	O
,	O
but	O
I	O
may	O
want	O
to	O
eventually	O
apply	O
a	O
different	O
sklearn	O
method	O
that	O
isn't	O
as	O
easy	O
to	O
write	O
myself	O
.	O

I'm	O
more	O
interested	O
in	O
figuring	O
out	O
why	O
applying	O
to	O
a	O
series	O
doesn't	O
work	O
as	O
I	O
expected	O
than	O
I	O
am	O
in	O
coming	O
up	O
with	O
a	O
strictly	O
simpler	O
solution	O
.	O

My	O
next	O
step	O
will	O
be	O
to	O
run	O
a	O
RandomForestRegressor	O
,	O
and	O
I	O
want	O
to	O
make	O
sure	O
I	O
understand	O
how	O
Pandas	O
and	O
sklearn	O
work	O
together	O
.	O

Using	O
apply	O
is	O
always	O
the	O
last	O
operation	O
to	O
try	O
.	O

Vectorized	O
methods	O
are	O
much	O
faster	O
.	O

#CODE	O

@USER	O
That	O
works	O
for	O
the	O
entire	O
dataframe	B-API
easily	O
.	O

How	O
would	O
you	O
apply	O
this	O
to	O
a	O
single	O
column	O
?	O

`	O
df	O
[(	O
'	O
date	O
'	O
,	O
''	O
,	O
'')]	O
.swaplevel	B-API
(	O
0	O
,	O
2	O
)`	O
did	O
not	O
work	O
.	O

How	O
can	O
I	O
apply	O
this	O
process	O
to	O
all	O
the	O
columns	O
I	O
want	O
at	O
once	O
and	O
produce	O
a	O
dataframe	B-API
of	O
it	O
all	O
?	O

Sorry	O
if	O
this	O
is	O
a	O
repeat	O
;	O
the	O
pandas	O
questions	O
I've	O
found	O
that	O
seem	O
to	O
be	O
about	O
related	O
topics	O
are	O
all	O
over	O
my	O
head	O
.	O

I	O
have	O
3,000	O
.dat	O
files	O
that	O
I	O
am	O
reading	O
and	O
concatenating	O
into	O
one	O
pandas	O
dataframe	B-API
.	O

They	O
have	O
the	O
same	O
format	O
(	O
4	O
columns	O
,	O
no	O
header	O
)	O
except	O
that	O
some	O
of	O
them	O
have	O
a	O
description	O
at	O
the	O
beginning	O
of	O
the	O
file	O
while	O
others	O
don't	O
.	O

In	O
order	O
to	O
concatenate	O
those	O
files	O
,	O
I	O
need	O
to	O
get	O
rid	O
of	O
those	O
first	O
rows	O
before	O
I	O
concatenate	O
them	O
.	O

The	O
`	O
skiprows	O
`	O
option	O
of	O
the	O
`	O
pandas.read_csv()	B-API
`	O
doesn't	O
apply	O
here	O
,	O
because	O
the	O
number	O
of	O
rows	O
to	O
skip	O
is	O
very	O
inconsistent	O
from	O
one	O
file	O
to	O
another	O
(	O
btw	O
,	O
I	O
use	O
`	O
pandas.read_csv()	B-API
`	O
and	O
not	O
`	O
pandas.read_table()	B-API
`	O
because	O
the	O
files	O
are	O
separated	O
by	O
a	O
coma	O
)	O
.	O

I	O
thought	O
I	O
could	O
apply	O
a	O
list	O
of	O
strings	O
,	O
but	O
it	O
does	O
not	O
work	O
either	O
,	O
because	O
it	O
is	O
`	O
not	O
in	O
the	O
ColumnDataSource	O
`	O
.	O

If	O
I	O
zoom	O
in	O
deeper	O
,	O
the	O
numbers	O
are	O
getting	O
even	O
less	O
meaningfull	O
.	O

Then	O
it	O
might	O
say	O
`	O
03	O
`	O
,	O
but	O
03	O
of	O
what	O
?	O

At	O
which	O
minute	O
,	O
which	O
hour	O
?	O

Is	O
there	O
a	O
solution	O
for	O
this	O
?	O

python	O
pandas	O
:	O
groupby	B-API
apply	O
function	O
looks	O
at	O
prior	O
rows	O

so	O
I've	O
updated	O
my	O
code	O
below	O
,	O
maybe	O
I'm	O
not	O
understanding	O
how	O
apply	O
works	O
,	O
but	O
I	O
thought	O
this	O
would	O
execute	O
twice	O
(	O
once	O
for	O
each	O
group	O
)	O
.	O

Then	O
,	O
my	O
function	O
would	O
loop	O
over	O
each	O
row	O
within	O
those	O
executions	O
.	O

I'm	O
still	O
puzzled	O
as	O
to	O
why	O
it's	O
going	O
3	O
times	O
...	O

I	O
thought	O
"	O
executed	O
"	O
would	O
print	O
5	O
times	O
.	O

Thoughts	O
on	O
this	O
?	O

its	O
not	O
specific	O
to	O
apply	O
,	O
but	O
more	O
general	O
in	O
groupby	B-API
,	O
nor	O
is	O
ever	O
point	O
mentioned	O
in	O
the	O
doc-string	O
.	O

I	O
tried	O
to	O
apply	O
this	O
method	O
to	O
each	O
subset	O
of	O
data	O
with	O
a	O
nested-loop	O
script	O
:	O
#CODE	O

Grouping	O
data	O
frames	O
and	O
applying	O
a	O
function	O
is	O
essentially	O
done	O
in	O
one	O
statement	O
,	O
using	O
the	O
`	O
apply	O
`	O
-functionality	O
of	O
pandas	O
:	O
#CODE	O

pandas	O
:	O
apply	O
a	O
function	O
to	O
the	O
many	O
columns	O
of	O
a	O
large	O
DataFrame	B-API
to	O
return	O
multiple	O
rows	O

Taking	O
the	O
idea	O
from	O
From	O
this	O
answer	O
:	O
pandas	O
:	O
apply	O
function	O
to	O
DataFrame	B-API
that	O
can	O
return	O
multiple	O
rows	O

If	O
you	O
have	O
"	O
oddly-shaped	O
"	O
json	O
,	O
then	O
you	O
can	O
either	O
`	O
json_normalize	B-API
`	O
when	O
reading	O
,	O
or	O
parse	O
the	O
columns	O
which	O
contain	O
multiple	O
columns	O
after	O
reading	O
in	O
the	O
DataFrame	B-API
(	O
e.g.	O
using	O
a	O
Series	O
string	O
method	O
or	O
apply	O
)	O
.	O

just	O
use	O
an	O
`	O
apply	O
`	O
with	O
a	O
function	O
that	O
creates	O
a	O
dictionary	O
based	O
on	O
the	O
`	O
str.count	B-API
`	O
of	O
the	O
substrings	O

Well	O
,	O
I	O
am	O
creating	O
somewhat	O
of	O
a	O
randomizer	O
for	O
an	O
experiment	O
.	O

In	O
order	O
to	O
counterbalance	O
appropriately	O
,	O
I	O
want	O
to	O
be	O
able	O
to	O
randomize	O
the	O
rows	O
and	O
the	O
columns	O
independently	O
from	O
each	O
other	O
,	O
but	O
the	O
data	O
inside	O
the	O
table	O
isn't	O
all	O
ints	O
,	O
but	O
rather	O
,	O
lists	O
of	O
strings	O
,	O
dictionaries	O
,	O
and	O
such	O
.	O

That	O
said	O
,	O
I	O
am	O
trying	O
to	O
find	O
out	O
if	O
there	O
is	O
a	O
way	O
to	O
basically	O
do	O
what	O
was	O
done	O
in	O
the	O
link	O
I	O
posted	O
(	O
randomize	O
column-wise	O
)	O
and	O
apply	O
that	O
to	O
rows	O
.	O

I	O
was	O
able	O
to	O
make	O
this	O
work	O
,	O
but	O
only	O
if	O
the	O
dataframe	B-API
contains	O
numbers	O
only	O
,	O
though	O
I	O
want	O
to	O
extend	O
the	O
possibility	O
to	O
strings	O
and	O
such	O
.	O

Tried	O
using	O
:	O
apply	O
(	O
pd.Series.interpolate	B-API
(	O
method=	O
'	O
linear	O
'))	O
however	O
I	O
get	O
the	O
following	O
error	O
:	O

My	O
idea	O
was	O
to	O
apply	O
this	O
function	O
(	O
or	O
similar	O
)	O
column	O
wise	O
.	O

Have	O
played	O
with	O
.apply()	B-API
but	O
because	O
its	O
a	O
double	O
(	O
or	O
triple	O
)	O
function	O
call	O
i.e.	O
f1	O
.	O

(	O
)	O
.f2	O
(	O
x	O
,	O
y	O
)	O
or	O
f1	O
.	O

(	O
)	O
.f2	O
(	O
x	O
,	O
y	O
)	O
.f3	O
(	O
x	O
,	O
y	O
)	O
it	O
gives	O
me	O
an	O
error	O
.	O

Any	O
ideas	O
would	O
be	O
greatly	O
appreciated	O
and	O
I	O
think	O
this	O
would	O
be	O
a	O
very	O
useful	O
bit	O
of	O
code	O
to	O
have	O
out	O
there	O
!	O

how	O
to	O
apply	O
preprocessing	O
methods	O
on	O
several	O
columns	O
at	O
one	O
time	O
in	O
sklearn	O

My	O
question	O
is	O
I	O
have	O
so	O
many	O
columns	O
in	O
my	O
pandas	O
data	O
frame	O
and	O
I	O
am	O
trying	O
to	O
apply	O
the	O
sklearn	O
preprocessing	O
using	O
dataframe	B-API
mapper	O
from	O
sklearn-pandas	O
library	O
such	O
as	O
#CODE	O

Typically	O
everything	O
that	O
you	O
do	O
within	O
`	O
groupby	B-API
`	O
should	O
be	O
group	O
independent	O
.	O

So	O
,	O
within	O
any	O
`	O
groupby.apply()	B-API
`	O
,	O
you	O
will	O
only	O
get	O
the	O
group	O
itself	O
,	O
not	O
the	O
context	O
.	O

An	O
alternative	O
is	O
to	O
compute	O
the	O
`	O
index	O
`	O
value	O
for	O
the	O
whole	O
sample	O
(	O
following	O
,	O
`	O
index	O
`)	O
out	O
of	O
the	O
indices	O
for	O
the	O
groups	O
(	O
here	O
,	O
`	O
selected	O
`)	O
.	O

Note	O
that	O
the	O
dataset	O
is	O
sorted	O
by	O
groups	O
,	O
which	O
you	O
need	O
to	O
do	O
if	O
you	O
want	O
to	O
apply	O
the	O
following	O
.	O

Thanks	O
@USER	O
for	O
the	O
quick	O
reply	O
.	O

Unfortunately	O
it	O
does	O
not	O
work	O
for	O
me	O
:	O
I	O
get	O
`	O
ValueError	O
:	O
level	O
>	O
0	O
only	O
valid	O
with	O
MultiIndex	O
`	O
when	O
trying	O
to	O
apply	O
your	O
line	O
`	O
c	O
=	O
test.groupby	O
(	O
level=1	O
)	O
.count()	B-API
`	O
.	O

I	O
think	O
it	O
must	O
be	O
due	O
to	O
the	O
fact	O
that	O
my	O
original	O
data	O
is	O
not	O
indexed	O
as	O
yours	O
(	O
0	O
,	O
1	O
,	O
2	O
,	O
0	O
,	O
1	O
,	O
2	O
)	O
but	O
(	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,...	O
)	O
.	O

Did	O
you	O
already	O
group	O
text	O
by	O
'	O
name	O
'	O
before	O
applying	O
your	O
solution	O
here	O
?	O

Sounds	O
like	O
you	O
are	O
on	O
the	O
right	O
track	O
.	O

Creating	O
two	O
groups	O
is	O
a	O
good	O
approach	O
.	O

Since	O
your	O
precip_avg	O
starts	O
as	O
"	O
the	O
average	O
precip	O
level	O
for	O
all	O
Jan	O
1st	O
2pm	O
across	O
all	O
years	O
"	O
this	O
average	O
will	O
not	O
change	O
when	O
you	O
apply	O
other	O
filters	O
.	O

The	O
average	O
would	O
be	O
the	O
same	O
if	O
you	O
looked	O
at	O
the	O
past	O
50	O
years	O
or	O
the	O
past	O
5	O
years	O
.	O

This	O
may	O
be	O
desirable	O
or	O
it	O
may	O
not	O
be	O
.	O

Previously	O
answered	O
questions	O
don't	O
seem	O
to	O
apply	O
.	O

Someone	O
good	O
with	O
lambda	O
functions	O
or	O
the	O
.asfreq	B-API
method	O
might	O
be	O
able	O
to	O
come	O
up	O
with	O
something	O
.	O

#CODE	O

Using	O
StackOverflow	O
and	O
the	O
documentation	O
I	O
have	O
only	O
been	O
able	O
to	O
find	O
how	O
to	O
apply	O
a	O
function	O
dependent	O
on	O
a	O
single	O
variable	O
to	O
more	O
than	O
one	O
column	O
(	O
using	O
the	O
axis	O
option	O
)	O
.	O

Please	O
help	O
.	O

This	O
will	O
be	O
much	O
faster	O
than	O
performing	O
an	O
apply	O
operation	O
as	O
it	O
is	O
vectorised	O
.	O

@USER	O
you're	O
welcome	O
,	O
you	O
can	O
accept	O
this	O
as	O
answer	O
,	O
there	O
will	O
be	O
a	O
tick	O
mark	O
underneath	O
the	O
voting	O
buttons	O
.	O

Using	O
apply	O
and	O
iterating	O
should	O
always	O
be	O
the	O
last	O
choice	O
,	O
if	O
possible	O
find	O
a	O
method	O
that	O
operates	O
on	O
the	O
whole	O
dataframe	B-API

This	O
means	O
that	O
all	O
you	O
have	O
to	O
do	O
to	O
group	O
by	O
year	O
is	O
leverage	O
the	O
apply	O
function	O
and	O
re-work	O
the	O
syntax	O

Dynamically	O
creating	O
variables	O
,	O
while	O
doing	O
map	O
/	O
apply	O
on	O
a	O
dataframe	B-API
in	O
pandas	O
to	O
get	O
key	O
names	O
for	O
the	O
values	O
in	O
Series	O
object	O
returned	O

It	O
looks	O
like	O
THIS	O
loop	O
is	O
the	O
killer	O
here.Also	O
,	O
intutively	O
,	O
looping	O
on	O
a	O
dataframe	B-API
is	O
a	O
BAD	O
practice	O
.	O

How	O
can	O
I	O
rewrite	O
this	O
,	O
perhaps	O
using	O
Map	O
/	O
Apply	O
?	O

#CODE	O

I	O
also	O
know	O
that	O
`	O
df2.apply	O
(	O
funct1	O
,	O
axis=1	O
)`	O
contains	O
part	O
of	O
mycustom	O
"	O
names	O
"	O
(	O
ie	O
feature	O
values	O
)	O
,	O
how	O
would	O
I	O
then	O
build	O
these	O
names	O
using	O
map	O
/	O
apply	O
?	O

Ie	O
.	O

I	O
will	O
have	O
the	O
values	O
,	O
but	O
how	O
would	O
I	O
create	O
the	O
"	O
key	O
"	O
`'	O
P_	O
'	O
+feature_name+	O
'	O
_	O
'	O
+feature_value+	O
'	O
_C	O
'`	O
,	O
since	O
feature	O
value	O
post	O
apply	O
is	O
returned	O
as	O
a	O
series	O
object	O
.	O

Gregor	O
-	O
+1	O
for	O
making	O
the	O
time	O
&	O
effort	O
.	O

I	O
have	O
to	O
admit	O
that	O
itertuples()	B-API
struck	O
me	O
,	O
omly	O
when	O
I	O
saw	O
the	O
tuples	O
in	O
your	O
code	O
.	O

I	O
am	O
not	O
accepting	O
,	O
since	O
I	O
am	O
still	O
looking	O
at	O
a	O
map	O
/	O
apply	O
way	O
(	O
possibly	O
)	O
to	O
solve	O
this	O
.	O

itertuples()	B-API
is	O
what	O
worked	O
for	O
me	O
(	O
worked	O
at	O
lightspeed	O
)	O
-	O
though	O
It	O
is	O
still	O
not	O
using	O
the	O
map	O
/	O
apply	O
approach	O
that	O
I	O
so	O
much	O
wanted	O
to	O
see	O
.	O

Itertuples	B-API
on	O
a	O
pandas	O
dataframe	B-API
returns	O
the	O
whole	O
row	O
,	O
so	O
I	O
no	O
longer	O
have	O
to	O
do	O
`	O
df2	O
[	O
df2	O
[	O
feature_name	O
]=	O
=feature_value	O
]	O
[	O
'	O
click	O
']`	O
-	O
be	O
aware	O
that	O
this	O
matching	O
by	O
value	O
is	O
not	O
only	O
expensive	O
,	O
but	O
also	O
undesired	O
,	O
since	O
it	O
may	O
return	O
a	O
series	O
,	O
if	O
there	O
were	O
duplicate	O
rows	O
.	O
itertuples	B-API
solves	O
that	O
problem	O
were	O
elegantly	O
,	O
though	O
I	O
need	O
to	O
then	O
access	O
the	O
individual	O
objects	O
/	O
columns	O
by	O
integer	O
indexes	O
,	O
which	O
means	O
less	O
re-usable	O
code	O
.	O

I	O
could	O
abstract	O
this	O
,	O
but	O
It	O
wont	O
be	O
like	O
accessing	O
by	O
column	O
names	O
,	O
the	O
status-quo	O
.	O

#CODE	O

Then	O
,	O
pass	O
that	O
into	O
the	O
`	O
groupby	B-API
`	O
object	O
with	O
apply	O
.	O

#CODE	O

the	O
final	O
line	O
uses	O
the	O
apply	O
method	O
,	O
with	O
the	O
paramater	O
key	O
set	O
to	O
1	O
,	O
which	O
applies	O
the	O
method	O
-first	O
parameter	O
-	O
row	O
wise	O
along	O
the	O
DataFrame	B-API
and	O
Returns	O
a	O
Series	O
which	O
is	O
appended	O
to	O
the	O
DataFrame	B-API
.	O

How	O
can	O
I	O
accomplish	O
this	O
concisely	O
and	O
efficiently	O
?	O

I've	O
tried	O
using	O
combinations	O
of	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
,	O
but	O
I'm	O
new	O
to	O
PANDAS	O
and	O
keep	O
throwing	O
Exceptions	O
.	O

next	O
you	O
just	O
apply	O
a	O
lambda	O
function	O
that	O
finds	O
the	O
union	O
between	O
columns	O
.	O

Had	O
trouble	O
finding	O
a	O
quick	O
method	O
for	O
the	O
union	O
but	O
this	O
works	O
#CODE	O

Pandas	O
apply	O
and	O
lambda	O
function	O
efficiency	O

The	O
`	O
apply	O
`	O
operation	O
of	O
pandas	O
is	O
quite	O
expressive	O
,	O
I	O
could	O
first	O
`	O
group	O
`	O
,	O
and	O
then	O
do	O
the	O
Cartesian	O
product	O
on	O
each	O
group	O
using	O
`	O
apply	O
`	O
,	O
and	O
then	O
aggregate	O
the	O
result	O
using	O
`	O
sum	O
`	O
.	O

The	O
problem	O
with	O
this	O
approach	O
,	O
however	O
,	O
is	O
that	O
`	O
apply	O
`	O
is	O
not	O
lazy	O
,	O
it	O
will	O
compute	O
all	O
the	O
intermediate	O
results	O
before	O
the	O
aggregation	O
,	O
and	O
the	O
intermediate	O
results	O
(	O
Cartesian	O
production	O
on	O
each	O
group	O
)	O
is	O
very	O
large	O
.	O

Intermediate	O
result	O
after	O
the	O
`	O
apply	O
`	O
(	O
can	O
be	O
large	O
)	O
#CODE	O

Could	O
you	O
give	O
a	O
small	O
self-contained	O
example	O
with	O
fake	O
data	O
to	O
show	O
what	O
you	O
want	O
?	O

(	O
E.g.	O
I	O
don't	O
see	O
why	O
you	O
can't	O
move	O
a	O
summation	O
into	O
the	O
apply	O
to	O
avoid	O
expanding	O
more	O
than	O
one	O
group	O
at	O
a	O
time	O
,	O
but	O
maybe	O
that	O
doesn't	O
work	O
in	O
a	O
real	O
case	O
for	O
some	O
reason	O
.	O
)	O

Why	O
are	O
vectorized	O
operations	O
like	O
apply	O
so	O
much	O
quicker	O
?	O

I	O
imagine	O
there	O
must	O
be	O
some	O
row	O
by	O
row	O
iteration	O
going	O
on	O
there	O
too	O
.	O

``	O
apply	O
``	O
is	O
NOT	O
vectorized	O
.	O

``	O
iterrows	B-API
``	O
is	O
even	O
worse	O
as	O
it	O
boxes	O
everything	O
(	O
that	O
'	O
the	O
perf	O
diff	O
with	O
``	O
apply	O
``)	O
.	O

You	O
should	O
only	O
use	O
``	O
iterrows	B-API
``	O
in	O
very	O
very	O
few	O
situations	O
.	O

IMHO	O
never	O
.	O

Show	O
what	O
you	O
are	O
actually	O
doing	O
with	O
``	O
iterrows	B-API
``	O
.	O

3	O
)	O
Apply	O
involves	O
can	O
usually	O
be	O
done	O
by	O
an	O
iterator	O
in	O
cython	O
space	O
(	O
this	O
is	O
done	O
internally	O
in	O
pandas	O
)	O
(	O
this	O
is	O
a	O
)	O
case	O
.	O

This	O
is	O
dependent	O
on	O
what	O
is	O
going	O
on	O
inside	O
the	O
apply	O
expression	O
.	O

e.g.	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
np.sum	B-API
(	O
x	O
))`	O
will	O
be	O
executed	O
pretty	O
swiftly	O
(	O
of	O
course	O
`	O
df.sum	B-API
(	O
1	O
)`	O
is	O
even	O
better	O
)	O
.	O

However	O
something	O
like	O
:	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
[	O
'	O
b	O
']	O
+	O
1	O
)`	O
will	O
be	O
executed	O
in	O
python	O
space	O
,	O
and	O
consequently	O
is	O
slower	O
.	O

The	O
examples	O
I've	O
seen	O
using	O
'	O
map	O
'	O
or	O
'	O
apply	O
'	O
generally	O
show	O
one	O
datatable	O
which	O
seems	O
intuitive	O
enough	O
.	O

However	O
,	O
I	O
am	O
working	O
across	O
two	O
tables	O
and	O
they	O
are	O
large	O
(	O
T1	O
is	O
2.5million	O
rows	O
,	O
T2	O
is	O
96000	O
rows	O
)	O
.	O

Unfortunatley	O
not	O
.	O

I	O
get	O
this	O
message	O
:	O
"	O
ValueError	O
:	O
array	O
is	O
too	O
big	O
.	O

"	O
I'm	O
pretty	O
sure	O
that	O
I	O
will	O
get	O
5	O
billion	O
rows	O
having	O
looked	O
into	O
the	O
data	O
(	O
I	O
agree	O
it	O
is	O
not	O
creating	O
a	O
cartesian	O
product	O
)	O
.	O

I	O
plan	O
on	O
trying	O
itertools	O
with	O
the	O
groupby	B-API
feature	O
.	O

I	O
might	O
make	O
two	O
grouped	O
objects	O
,	O
one	O
for	O
each	O
table	O
,	O
to	O
start	O
.	O

Then	O
iterate	O
to	O
find	O
the	O
"	O
matching	O
"	O
groups	O
.	O

I	O
will	O
then	O
merge	O
and	O
apply	O
on	O
each	O
as	O
you	O
have	O
done	O
,	O
aggregating	O
to	O
a	O
new	O
table	O
.	O

If	O
you	O
know	O
how	O
to	O
do	O
that	O
I'd	O
be	O
grateful	O
to	O
see	O
it	O
on	O
this	O
(	O
tiny	O
)	O
example	O
.	O

If	O
I	O
succeed	O
,	O
I'll	O
post	O
it	O
myself	O
:)	O

I	O
cannot	O
apply	O
a	O
rolling	O
window	O
because	O
this	O
would	O
first	O
be	O
daily	O
and	O
secondly	O
I	O
need	O
to	O
specify	O
the	O
number	O
of	O
values	O
(	O
a	O
rolling	O
window	O
does	O
not	O
aggregate	O
by	O
time	O
frame	O
,	O
some	O
posts	O
addressed	O
this	O
issue	O
but	O
they	O
are	O
not	O
relevant	O
to	O
my	O
problem	O
as	O
the	O
rolling	O
would	O
still	O
be	O
for	O
each	O
new	O
day	O
)	O
.	O

I	O
cannot	O
apply	O
resampling	O
,	O
because	O
then	O
the	O
sample	O
would	O
be	O
every	O
5	O
months	O
,	O
e	O
..	O

g	O
I	O
would	O
only	O
have	O
values	O
for	O
May	O
2012	O
,	O
Oct	O
2012	O
,	O
March	O
2013	O
...	O

Finally	O
,	O
as	O
the	O
function	O
is	O
not	O
linear	O
I	O
cannot	O
reconstruct	O
it	O
by	O
first	O
doing	O
a	O
monthly	O
sample	O
and	O
then	O
applying	O
a	O
5	O
period	O
rolling	O
window	O
on	O
it	O
.	O

To	O
clarify	O
:	O
I	O
am	O
looking	O
for	O
5	O
calendar	O
months	O
(	O
data	O
is	O
not	O
necessarily	O
evenly	O
spaced	O
)	O
,	O
including	O
the	O
current	O
month	O
,	O
so	O
for	O
May	O
2012	O
I	O
go	O
from	O
Jan	O
2012	O
to	O
May	O
2012	O
(	O
the	O
length	O
of	O
the	O
windows	O
is	O
5	O
months	O
,	O
regardless	O
if	O
I	O
have	O
only	O
one	O
day	O
per	O
month	O
or	O
20	O
)	O
.	O

User	O
@USER	O
is	O
correct	O
,	O
in	O
addition	O
I	O
only	O
care	O
of	O
a	O
monthly	O
result	O
,	O
so	O
I	O
need	O
to	O
apply	O
the	O
same	O
for	O
June	O
2012	O
,	O
July	O
2012	O
,	O
etc	O
.	O

If	O
pandas	O
has	O
imported	O
you	O
date	O
and	O
time	O
data	O
,	O
you	O
should	O
be	O
able	O
to	O
get	O
select	O
data	O
from	O
given	O
months	O
using	O
the	O
syntax	O
`	O
dft	O
[	O
datetime	O
(	O
2013	O
,	O
1	O
,	O
1	O
):	O
datetime	O
(	O
2013	O
,	O
6	O
)]`	O
.	O

Just	O
program	O
a	O
loop	O
or	O
equivalent	O
to	O
cycle	O
the	O
start	O
and	O
end	O
month	O
values	O
and	O
apply	O
your	O
function	O
to	O
the	O
values	O
in	O
the	O
resulting	O
dataframes	O
.	O

(	O
Sorry	O
,	O
I	O
don't	O
have	O
a	O
date	O
stamped	O
data	O
set	O
handy	O
to	O
test	O
this	O
myself	O
right	O
now	O
)	O

I	O
would	O
consider	O
yours	O
a	O
dupe	O
of	O
[	O
this	O
]	O
(	O
#URL	O
)	O
question	O
,	O
but	O
the	O
accepted	O
answer	O
there	O
is	O
not	O
what	O
I	O
would	O
use	O
.	O

Still	O
,	O
the	O
[	O
higher	O
voted	O
answers	O
]	O
(	O
#URL	O
)	O
there	O
apply	O
to	O
your	O
situation	O
.	O

Call	O
`	O
apply	O
`	O
on	O
the	O
dataframe	B-API
(	O
note	O
the	O
double	O
square	O
brackets	O
`	O
df	O
[[	O
'	O
A	O
']]`	O
rather	O
than	O
`	O
df	O
[	O
'	O
A	O
']`)	O
and	O
call	O
the	O
string	O
method	O
`	O
isdigit()	B-API
`	O
,	O
we	O
then	O
set	O
param	O
`	O
axis=1	O
`	O
to	O
apply	O
the	O
lambda	O
function	O
row-wise	O
.	O

What	O
happens	O
here	O
is	O
that	O
the	O
index	O
is	O
used	O
to	O
create	O
a	O
boolean	O
mask	O
.	O

#CODE	O

This	O
will	O
be	O
considerably	O
faster	O
that	O
using	O
`	O
apply	O
`	O
on	O
a	O
larger	O
frame	O
as	O
this	O
is	O
all	O
implemented	O
in	O
cython	O
.	O

#CODE	O

Do	O
you	O
want	O
`	O
transform	O
`	O
so	O
that	O
it	O
returns	O
an	O
object	O
with	O
its	O
index	O
aligned	O
to	O
the	O
original	O
dataframe	B-API
?	O

like	O
`	O
b	O
=	O
stock_data_df.groupby	O
(	O
'	O
stock	O
id	O
')	O
.transform	B-API
(	O
apply	O
(	O
lambda	O
x	O
:	O
x	O
[	O
'	O
price	O
']	O
>	O
=	O
pd.rolling_max	B-API
(	O
x	O
[	O
'	O
price	O
']	O
,	O
20	O
)))`	O

Not	O
sure	O
if	O
you	O
so	O
the	O
edit	O
,	O
but	O
I	O
tried	O
`	O
b	O
=	O
stock_data_df.groupby	O
(	O
'	O
stock	O
id	O
')	O
.transform	B-API
(	O
apply	O
(	O
lambda	O
x	O
:	O
x	O
[	O
'	O
price	O
']	O
>	O
=	O
pd.rolling_max	B-API
(	O
x	O
[	O
'	O
price	O
']	O
,	O
20	O
)))`	O
and	O
then	O
I	O
get	O
`	O
TypeError	O
:	O
(	O
)	O
takes	O
exactly	O
1	O
argument	O
(	O
0	O
given	O
)`	O

edit	O
:	O
I	O
shoudl	O
add	O
that	O
I	O
already	O
know	O
what	O
the	O
95%CI	O
values	O
are	O
.	O

This	O
is	O
just	O
a	O
plotting	O
question	O
(	O
how	O
to	O
apply	O
the	O
axvline	B-API
to	O
each	O
of	O
these	O
subplots	O
)	O
.	O

Thx	O
.	O

Note	O
that	O
when	O
setting	O
properties	O
of	O
an	O
axis	O
using	O
its	O
methods	O
,	O
most	O
of	O
the	O
`	O
plt	O
`	O
attributes	O
become	O
`	O
set_X	B-API
`	O
.	O

For	O
example	O
,	O
instead	O
of	O
`	O
plt.ylabel	B-API
(	O
'	O
my_y	O
')`	O
you	O
do	O
`	O
ax1.set_ylabel	O
(	O
'	O
my_y	O
')`	O
.	O

You	O
can	O
still	O
use	O
the	O
`	O
plt	O
`	O
methods	O
,	O
but	O
they	O
will	O
apply	O
to	O
whatever	O
the	O
current	O
plot	O
is	O
.	O

The	O
variables	O
`	O
ax1	O
`	O
and	O
`	O
ax2	O
`	O
give	O
you	O
a	O
little	O
more	O
freedom	O
about	O
when	O
you	O
do	O
things	O
.	O

You	O
have	O
the	O
right	O
idea	O
with	O
groupby	B-API
.	O

It	O
has	O
the	O
ability	O
to	O
split	O
up	O
your	O
data	O
by	O
the	O
day	O
then	O
give	O
you	O
access	O
to	O
those	O
groups	O
.	O

The	O
trick	O
here	O
is	O
using	O
the	O
apply	O
method	O
on	O
the	O
Series	O
df	O
[	O
'	O
date_time	O
']	O
.	O

Apply	O
on	O
a	O
series	O
applies	O
the	O
input	O
method	O
element	O
wise	O
and	O
returns	O
a	O
new	O
Series	O
.	O

You	O
can	O
use	O
this	O
to	O
split	O
up	O
by	O
days	O
and	O
then	O
again	O
to	O
split	O
up	O
by	O
hours	O
.	O

But	O
in	O
the	O
code	O
below	O
,	O
it	O
seems	O
there	O
are	O
just	O
too	O
many	O
lines	O
.	O

That	O
is	O
,	O
the	O
rank()	B-API
function	O
in	O
pandas	O
is	O
super	O
convenient	O
.	O

Seems	O
to	O
me	O
there	O
should	O
be	O
some	O
parameter	O
somewhere	O
that	O
says	O
to	O
the	O
data	O
frame	O
,	O
"	O
Hey	O
,	O
apply	O
this	O
function	O
you	O
already	O
know	O
about	O
,	O
but	O
instead	O
of	O
doing	O
to	O
the	O
original	O
column	O
itself	O
,	O
as	O
you	O
do	O
it	O
,	O
make	O
it	O
a	O
new	O
column	O
at	O
the	O
end	O
of	O
the	O
data	O
frame	O
"	O

Please	O
explain	O
exactly	O
what	O
you	O
want	O
to	O
achieve	O
,	O
in	O
general	O
you	O
want	O
to	O
avoid	O
any	O
form	O
of	O
iteration	O
and	O
using	O
apply	O
if	O
the	O
calculation	O
can	O
be	O
vectorised	O
.	O

It	O
looks	O
like	O
you	O
are	O
just	O
adding	O
a	O
new	O
column	O
,	O
in	O
which	O
case	O
just	O
do	O
df	O
[	O
'	O
new_col	O
']	O
=	O
some_calc_on_df	O
.	O

If	O
you	O
want	O
to	O
append	O
another	O
dataframe	B-API
which	O
has	O
the	O
same	O
index	O
then	O
use	O
append	O
or	O
concat	O
,	O
no	O
need	O
to	O
merge	O
unless	O
the	O
order	O
is	O
different	O
and	O
you	O
want	O
to	O
join	O
on	O
some	O
id	O
column	O

You	O
are	O
getting	O
this	O
error	O
because	O
the	O
function	O
you	O
are	O
passing	O
to	O
apply	O
doesn't	O
return	O
anything	O
.	O

If	O
all	O
you	O
care	O
about	O
is	O
the	O
printed	O
output	O
,	O
you	O
could	O
just	O
return	O
the	O
df	O
back	O
,	O
like	O
this	O
.	O

#CODE	O

Then	O
the	O
apply	O
will	O
run	O
through	O
without	O
error	O
.	O

#CODE	O

For	O
example	O
,	O
if	O
the	O
value	O
in	O
float_col	O
is	O
greater	O
than	O
5	O
,	O
I	O
want	O
to	O
multiply	O
the	O
value	O
in	O
in_col	O
(	O
in	O
the	O
same	O
row	O
)	O
by	O
2	O
.	O

I'm	O
guessing	O
I'm	O
supposed	O
to	O
use	O
one	O
of	O
the	O
`	O
map	O
`	O
`	O
apply	O
`	O
or	O
`	O
applymap	B-API
`	O
functions	O
,	O
but	O
I'm	O
not	O
sure	O
which	O
,	O
or	O
how	O
.	O

Apply	O
regex	O
replace	O
to	O
python	O
pandas	O
data	O
frame	O

For	O
some	O
reason	O
,	O
the	O
function	O
runs	O
properly	O
on	O
strings	O
,	O
but	O
when	O
running	O
it	O
on	O
the	O
data	O
frame	O
with	O
apply	O
it	O
returns	O
empty	O
strings	O
,	O
and	O
not	O
the	O
first	O
three	O
octets	O
.	O

Turns	O
out	O
that	O
the	O
errors	O
raised	O
on	O
version	O
0.12	O
*	O
should	O
*	O
be	O
raised	O
on	O
0.14.1	O
.	O

The	O
bug	O
here	O
is	O
that	O
`	O
Grouby.filter	O
`	O
should	O
apply	O
to	O
the	O
entire	O
subframe	O
,	O
not	O
rows	O
within	O
the	O
subframe	O
.	O

I	O
am	O
calculating	O
a	O
series	O
by	O
multiplying	O
two	O
columns	O
of	O
a	O
dataframe	B-API
.	O

I	O
apply	O
groupby	B-API
on	O
that	O
series	O
.	O

Get	O
`	O
ValueError	O
:	O
Buffer	O
has	O
wrong	O
number	O
of	O
dimensions	O
(	O
expected	O
1	O
,	O
got	O
2	O
)`	O

python	O
pandas	O
apply	O
function	O
group	O
by	O
group	O

My	O
question	O
is	O
:	O
can	O
I	O
avoid	O
to	O
iterate	O
group	O
by	O
group	O
to	O
apply	O
my_stat_function	O
,	O
and	O
is	O
there	O
exist	O
something	O
faster	O
,	O
maybe	O
applying	O
the	O
function	O
apply	O
?	O

I	O
would	O
really	O
like	O
something	O
more	O
"	O
pandas-ish	O
'	O
and	O
faster	O
.	O

You	O
can	O
apply	O
functions	O
to	O
groups	O
:	O
`	O
df.groupby	B-API
(	O
'	O
user_id	O
')	O
.apply	B-API
(	O
my_stat_function	O
)`	O
or	O
similar	O
,	O
have	O
you	O
tried	O
this	O
?	O

Thank	O
you	O
for	O
your	O
help	O
,	O
my	O
problem	O
is	O
that	O
I	O
don't	O
know	O
how	O
to	O
define	O
my_stat_function	O
in	O
order	O
to	O
apply	O
it	O
like	O
this	O
,	O
because	O
I	O
need	O
the	O
full	O
data	O
of	O
each	O
group	O
,	O
It	O
is	O
not	O
a	O
row	O
by	O
row	O
execution	O
.	O

Do	O
you	O
see	O
what	O
I	O
mean	O
?	O

You	O
could	O
groupby	B-API
user	O
and	O
apply	O
the	O
function	O
,	O
you'd	O
have	O
to	O
rewrite	O
your	O
function	O
though	O

generally	O
speaking	O
you	O
don't	O
want	O
to	O
iterate	O
through	O
a	O
dataframe	B-API
.	O
look	O
into	O
the	O
`	O
apply	O
`	O
method	O
:	O
#URL	O
Also	O
,	O
the	O
point	O
of	O
stackoverflow	O
is	O
to	O
be	O
a	O
resource	O
for	O
future	O
readers	O
who	O
might	O
have	O
a	O
similar	O
question	O
.	O

There	O
are	O
currently	O
over	O
7100	O
pandas	O
questions	O
.	O

Your	O
title	O
,	O
as	O
it	O
current	O
reads	O
,	O
will	O
not	O
at	O
all	O
help	O
future	O
readers	O
understand	O
what	O
the	O
topic	O
of	O
this	O
question	O
is	O
.	O

You	O
can	O
then	O
apply	O
some	O
boolean	O
logic	O
to	O
find	O
the	O
count	O
which	O
you're	O
interested	O
in	O
:	O
#CODE	O

Python	O
:	O
Pandas	O
:	O
Speeding	O
up	O
an	O
Apply	O
Function	O

I	O
am	O
trying	O
to	O
do	O
a	O
pandas	O
apply	O
function	O
on	O
a	O
33	O
MB	O
dataframe	B-API
(	O
in	O
CSV	O
form	O
)	O
and	O
it	O
is	O
going	O
incredibly	O
slow	O
.	O

And	O
I	O
am	O
trying	O
out	O
figure	O
out	O
why	O
.	O

I	O
was	O
doing	O
an	O
apply	O
on	O
a	O
much	O
bigger	O
dataframe	B-API
(	O
16	O
GB	O
)	O
and	O
it	O
finished	O
in	O
about	O
6	O
hours	O
.	O

This	O
function	O
is	O
operating	O
on	O
a	O
much	O
,	O
much	O
smaller	O
dataframe	B-API
and	O
I	O
let	O
it	O
run	O
for	O
1.5	O
hours	O
and	O
still	O
nothing	O
.	O

PS-	O
also	O
if	O
someone	O
knows	O
how	O
to	O
add	O
a	O
progress	O
bar	O
on	O
an	O
apply	O
function	O
that	O
would	O
be	O
a	O
great	O
added	O
bonus	O
:)	O
Thanks	O
again	O
!	O

#CODE	O

Then	O
,	O
rather	O
than	O
using	O
apply	O
,	O
you	O
could	O
merge	O
your	O
existing	O
data	O
against	O
the	O
stock	O
df	O
,	O
something	O
like	O
this	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
fill	O
missing	O
values	O
,	O
rather	O
than	O
having	O
custom	O
logic	O
in	O
apply	O
,	O
it's	O
much	O
faster	O
use	O
`	O
fillna	B-API
`	O
#CODE	O

You	O
need	O
to	O
combine	O
the	O
functions	O
that	O
apply	O
to	O
the	O
same	O
column	O
,	O
like	O
this	O
:	O
#CODE	O

Then	O
apply	O
to	O
the	O
columns	O
and	O
assign	O
:	O
#CODE	O

Why	O
?	O

I	O
thought	O
I	O
could	O
pass	O
any	O
function	O
to	O
`	O
apply	O
`	O
on	O
a	O
group	O
.	O

@USER	O
I	O
agree	O
about	O
`	O
transform	O
`	O
,	O
although	O
I	O
thought	O
you	O
can	O
mimic	O
the	O
behavior	O
of	O
`	O
transform	O
`	O
with	O
apply	O
(	O
which	O
is	O
more	O
generic	O
)	O

If	O
you	O
want	O
to	O
compute	O
stats	O
across	O
each	O
set	O
of	O
rows	O
with	O
the	O
same	O
index	O
in	O
the	O
two	O
datasets	O
,	O
you	O
can	O
use	O
`	O
.groupby()	B-API
`	O
to	O
group	O
the	O
data	O
by	O
row	O
index	O
,	O
then	O
apply	O
the	O
mean	O
,	O
median	O
etc	O
.	O

:	O
#CODE	O

much	O
faster	O
than	O
my	O
general	O
function	O
,	O
you	O
can	O
also	O
use	O
apply	O
on	O
this	O
for	O
more	O
general	O
functions	O

Is	O
this	O
something	O
I	O
would	O
use	O
`	O
groupby	B-API
`	O
for	O
and	O
then	O
apply	O
a	O
function	O
to	O
it	O
?	O

I	O
tried	O
doing	O
a	O
`	O
groupby	B-API
`	O
for	O
the	O
cust_id	O
and	O
date	O
columns	O
,	O
but	O
I	O
was	O
given	O
an	O
object	O
so	O
I'm	O
not	O
sure	O
if	O
it	O
is	O
formatted	O
properly	O
.	O

You	O
can	O
just	O
get	O
a	O
list	O
of	O
the	O
columns	O
you	O
want	O
to	O
multiply	O
the	O
scores	O
by	O
and	O
then	O
an	O
apply	O
function	O
...	O

#CODE	O

Both	O
of	O
you	O
have	O
the	O
desired	O
answer	O
.	O

I	O
really	O
appreciated	O
it	O
.	O

In	O
fact	O
I	O
have	O
a	O
more	O
generalised	O
question	O
.	O

I	O
have	O
a	O
function	O
which	O
takes	O
a	O
couple	O
of	O
column	O
values	O
as	O
input	O
and	O
outputs	O
an	O
value	O
and	O
I	O
wanna	O
apply	O
that	O
function	O
to	O
each	O
row	O
in	O
a	O
dataframe	B-API
.	O

Is	O
that	O
possible	O
not	O
to	O
use	O
for	O
loop	O
to	O
achieve	O
that	O
?	O

thanks	O
in	O
advance	O
.	O

This	O
roundabout	O
method	O
of	O
converting	O
my	O
`	O
array	O
`	O
to	O
a	O
nested	O
`	O
list	O
`	O
and	O
then	O
converting	O
it	O
back	O
to	O
an	O
array	O
via	O
`	O
apply	O
`	O
is	O
bothersome	O
.	O

Is	O
there	O
a	O
more	O
straightforward	O
way	O
that	O
I'm	O
just	O
not	O
aware	O
of	O
?	O

I	O
don't	O
think	O
that's	O
a	O
supported	O
use	O
case	O
for	O
DataFrames	O
;	O
while	O
you	O
can	O
cram	O
nonscalar	O
data	O
into	O
a	O
cell	O
,	O
there's	O
not	O
much	O
you	O
can	O
do	O
with	O
it	O
after	O
that	O
.	O

You'll	O
have	O
a	O
column	O
dtype	B-API
of	O
object	O
,	O
which	O
is	O
slow	O
to	O
begin	O
with	O
,	O
and	O
you	O
can't	O
really	O
do	O
any	O
fast	O
aggregation	O
ops	O
,	O
so	O
you'll	O
have	O
to	O
fall	O
back	O
to	O
relatively	O
slow	O
apply	O
ops	O
.	O

Depending	O
on	O
preference	O
you	O
might	O
be	O
more	O
interested	O
in	O
using	O
a	O
MultiIndex	O
or	O
a	O
Panel	O
instead	O
of	O
this	O
approach	O
.	O

You	O
can	O
perform	O
a	O
`	O
groupby	B-API
`	O
on	O
'	O
Product	O
ID	O
'	O
,	O
then	O
apply	O
`	O
idxmax	B-API
`	O
on	O
'	O
Sales	O
'	O
column	O
.	O

And	O
a	O
function	O
,	O
which	O
I	O
want	O
to	O
apply	O
to	O
each	O
row	O
,	O
storing	O
the	O
result	O
into	O
a	O
new	O
column	O
.	O

#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
with	O
the	O
`	O
axis=1	O
`	O
argument	O
to	O
apply	O
by	O
row	O
.	O

The	O
more	O
general	O
apply	O
will	O
be	O
slower	O
.	O

It's	O
better	O
to	O
find	O
a	O
way	O
to	O
vectorize	B-API
the	O
operations	O
.	O

When	O
you	O
have	O
more	O
data	O
a	O
general	O
apply	O
will	O
not	O
scale	O
very	O
well	O
especially	O
the	O
row	O
by	O
row	O
version	O
since	O
each	O
row	O
is	O
converted	O
to	O
a	O
series	O
of	O
uniform	O
type	O
which	O
if	O
you	O
have	O
mixed	O
types	O
will	O
be	O
very	O
annoying	O
to	O
use	O
and	O
inefficient	O
.	O

Actually	O
most	O
of	O
those	O
are	O
implemented	O
in	O
Cython	O
which	O
speeds	O
up	O
loops	O
considerably	O
.	O

By	O
vectorization	O
I	O
simply	O
meant	O
applying	O
operations	O
on	O
whole	O
sequences	O
rather	O
than	O
single	O
elements	O
at	O
a	O
time	O
,	O
which	O
is	O
unrelated	O
to	O
the	O
use	O
of	O
BLAS	O
.	O

What	O
I'm	O
saying	O
is	O
that	O
spending	O
a	O
bit	O
of	O
time	O
trying	O
to	O
avoid	O
apply	O
will	O
probably	O
yield	O
reusable	O
and	O
more	O
performant	O
code	O
.	O

Try	O
the	O
simplest	O
of	O
operations	O
:	O
string	O
concatenation	O
,	O
with	O
two	O
Series	O
of	O
length	O
1,000,000	O
.	O

Do	O
this	O
by	O
adding	O
them	O
together	O
directly	O
`	O
a	O
+	O
b	O
`	O
then	O
try	O
putting	O
them	O
in	O
a	O
`	O
DataFrame	B-API
`	O
and	O
calling	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
x.a	O
+	O
x.b	O
,	O
axis=1	O
)`	O
.	O

The	O
latter	O
takes	O
an	O
unbearably	O
long	O
time	O
(	O
about	O
22	O
seconds	O
)	O
where	O
as	O
the	O
former	O
takes	O
about	O
60	O
milliseconds	O
on	O
my	O
machine	O
.	O

Trust	O
me	O
,	O
the	O
string	O
methods	O
in	O
pandas	O
are	O
orders	O
of	O
magnitude	O
faster	O
than	O
calling	O
`	O
apply	O
`	O
.	O

What	O
you	O
are	O
looking	O
for	O
is	O
`	O
apply	O
(	O
func	O
,	O
axis=1	O
)`	O
This	O
will	O
apply	O
a	O
function	O
row	O
wise	O
through	O
your	O
dataframe	B-API
.	O

I	O
have	O
a	O
function	O
which	O
returns	O
a	O
list	O
of	O
length	O
2	O
.	O

I	O
would	O
like	O
to	O
apply	O
this	O
function	O
to	O
one	O
column	O
in	O
my	O
dataframe	B-API
and	O
assign	O
the	O
result	O
to	O
two	O
columns	O
.	O

That's	O
too	O
bad	O
,	O
since	O
performance	O
is	O
much	O
better	O
when	O
you	O
can	O
apply	O
functions	O
to	O
whole	O
Series	O
rather	O
than	O
to	O
individual	O
values	O
one-at-a-time	O
.	O

2	O
)	O
group	O
it	O
up	O
and	O
apply	O
a	O
function	O
to	O
index	O
your	O
values	O
.	O

#CODE	O

How	O
to	O
apply	O
a	O
function	O
(	O
numpy	O
ufunc	O
)	O
with	O
two	O
array	O
arguments	O
to	O
one	O
pandas	O
Series	O
?	O

As	O
for	O
`	O
apply	O
`	O
,	O
you're	O
looking	O
at	O
the	O
wrong	O
documentation	O
.	O

You're	O
looking	O
at	O
`	O
Dataframe.apply	B-API
`	O
,	O
but	O
you	O
have	O
a	O
series	O
,	O
so	O
you	O
should	O
be	O
looking	O
at	O
`	O
Series.apply	B-API
`	O
.	O

`	O
Series.apply	B-API
`	O
doesn't	O
take	O
a	O
`	O
raw	O
`	O
argument	O
.	O

You	O
might	O
think	O
that	O
removing	O
the	O
`	O
raw	O
`	O
argument	O
would	O
fix	O
your	O
attempt	O
,	O
but	O
`	O
Series.apply	B-API
`	O
has	O
a	O
peculiar	O
behavior	O
where	O
if	O
`	O
f	O
`	O
is	O
a	O
ufunc	O
and	O
no	O
keyword	O
arguments	O
to	O
`	O
f	O
`	O
are	O
supplied	O
,	O
it	O
completely	O
ignores	O
`	O
args	O
`	O
.	O

I	O
think	O
this	O
is	O
actually	O
a	O
bug	O
.	O

The	O
workaround	O
is	O
to	O
not	O
use	O
`	O
apply	O
`	O
for	O
this	O
;	O
the	O
broadcasting	O
rules	O
make	O
`	O
apply	O
`	O
redundant	O
for	O
your	O
situation	O
.	O

Beautiful	O
.	O

I	O
still	O
don't	O
know	O
how	O
apply	O
should	O
work	O
if	O
I	O
need	O
it	O
again	O
,	O
but	O
this	O
solves	O
the	O
problem	O
at	O
hand	O
.	O

Thanks	O
.	O

Actually	O
,	O
note	O
that	O
this	O
is	O
not	O
really	O
an	O
answer	O
for	O
the	O
question	O
as	O
stated	O
.	O

I	O
would	O
give	O
you	O
credit	O
,	O
but	O
this	O
would	O
mislead	O
others	O
finding	O
the	O
question	O
for	O
an	O
answer	O
on	O
`	O
apply	O
.	O

`	O
Sorry	O

@USER	O
szl	O
:	O
Well	O
,	O
this	O
*	O
is	O
*	O
how	O
you	O
apply	O
a	O
NumPy	O
ufunc	O
in	O
the	O
way	O
you	O
want	O
.	O

I've	O
expanded	O
the	O
answer	O
explaining	O
why	O
your	O
attempt	O
failed	O
;	O
does	O
that	O
answer	O
your	O
question	O
?	O

Thanks	O
,	O
I	O
accepted	O
the	O
answer	O
.	O

Maybe	O
you	O
could	O
be	O
even	O
clearer	O
about	O
no	O
use	O
of	O
apply	O
could	O
broadcast	O
(	O
if	O
that's	O
the	O
right	O
word	O
)	O
the	O
second	O
argument	O
if	O
the	O
ufunc	O
expects	O
an	O
array	O
.	O

2	O
)	O
apply	O
it	O
to	O
your	O
Series	O
after	O
converting	O
to	O
dataframe	B-API
#CODE	O

to	O
individually	O
query	O
each	O
column	O
and	O
find	O
the	O
information	O
I'm	O
looking	O
for	O
but	O
this	O
is	O
tedious	O
even	O
if	O
I	O
figure	O
out	O
how	O
to	O
use	O
the	O
abs	O
function	O
to	O
combine	O
the	O
two	O
queries	O
into	O
one.How	O
can	O
I	O
apply	O
this	O
filtration	O
to	O
the	O
whole	O
dataframe	B-API
?	O

You	O
don't	O
have	O
to	O
apply	O
the	O
filtration	O
to	O
columns	O
,	O
you	O
can	O
also	O
do	O
#CODE	O

I	O
use	O
this	O
function	O
with	O
pandas	O
to	O
apply	O
it	O
to	O
each	O
month	O
of	O
a	O
historical	O
record	O
:	O
#CODE	O

and	O
when	O
I	O
apply	O
the	O
command	O
pd.to_datetime()	B-API
to	O
these	O
columns	O
I	O
get	O
fields	O
resulting	O
that	O
look	O
like	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
create	O
a	O
new	O
column	O
`	O
time_hour	O
`	O
.	O

I	O
can	O
create	O
it	O
by	O
writing	O
a	O
short	O
function	O
as	O
so	O
and	O
using	O
`	O
apply()	B-API
`	O
to	O
apply	O
it	O
iteratively	O
:	O
#CODE	O

You	O
can	O
apply	O
a	O
lambda	O
,	O
e.g	O
.	O

how	O
to	O
apply	O
different	O
functions	O
to	O
each	O
group	O
of	O
pandas	O
groupby	B-API
?	O

I	O
want	O
to	O
group	O
the	O
dataframe	B-API
by	O
the	O
column	O
'	O
type	O
'	O
and	O
apply	O
different	O
function	O
to	O
each	O
group	O
,	O
say	O
,	O
`	O
min	O
`	O
for	O
group	O
with	O
type	O
A	O
,	O
`	O
max	O
`	O
for	O
group	O
with	O
type	O
B	O
and	O
`	O
mean	O
`	O
for	O
group	O
with	O
type	O
C	O
.	O

I	O
think	O
you	O
might	O
be	O
misunderstanding	O
the	O
intent	O
behind	O
`	O
groupby	B-API
`	O
.	O

No	O
worries	O
,	O
it	O
happens	O
to	O
the	O
best	O
of	O
us	O
too	O
.	O

The	O
intent	O
behind	O
`	O
groupby	B-API
`	O
is	O
such	O
that	O
you	O
can	O
apply	O
the	O
same	O
operations	O
to	O
subgroups	O
of	O
your	O
data	O
,	O
as	O
grouped	O
by	O
the	O
`	O
groupby	B-API
`	O
operation	O
.	O

My	O
system	O
has	O
16gb	O
of	O
RAM	O
and	O
is	O
running	O
Debian	O
(	O
Mint	O
)	O
.	O

After	O
creating	O
the	O
dataframe	B-API
I	O
was	O
using	O
~600mb	O
of	O
RAM	O
.	O

As	O
soon	O
as	O
the	O
apply	O
method	O
began	O
to	O
execute	O
,	O
that	O
value	O
started	O
to	O
soar	O
.	O

It	O
steadily	O
climbed	O
up	O
to	O
around	O
7gb	O
(	O
!	O
)	O
before	O
finishing	O
the	O
command	O
and	O
settling	O
back	O
down	O
to	O
5.4gb	O
(	O
while	O
the	O
shell	O
was	O
still	O
active	O
)	O
.	O

The	O
problem	O
is	O
,	O
my	O
work	O
requires	O
doing	O
more	O
than	O
the	O
'	O
do_nothing	O
'	O
method	O
and	O
as	O
such	O
while	O
executing	O
the	O
real	O
program	O
,	O
I	O
cap	O
my	O
16gb	O
of	O
RAM	O
and	O
start	O
swapping	O
,	O
making	O
the	O
program	O
unusable	O
.	O

Is	O
this	O
intended	O
?	O

I	O
can't	O
see	O
why	O
Pandas	O
should	O
need	O
7gb	O
of	O
RAM	O
to	O
effectively	O
'	O
do_nothing	O
'	O
,	O
even	O
if	O
it	O
has	O
to	O
store	O
the	O
grouped	O
object	O
.	O

That	O
example	O
is	O
somewhat	O
pathological	O
.	O

The	O
groupby	B-API
creates	O
a	O
separate	O
group	O
for	O
each	O
distinct	O
value	O
.	O

Since	O
you	O
generated	O
the	O
values	O
as	O
random	O
floats	O
,	O
it's	O
likely	O
that	O
they	O
are	O
all	O
distinct	O
,	O
which	O
means	O
there	O
are	O
3	O
million	O
groups	O
.	O

Each	O
group	O
passed	O
to	O
your	O
`	O
do_nothing	O
`	O
is	O
a	O
DataFrame	B-API
,	O
so	O
you	O
are	O
creating	O
3	O
million	O
DataFrames	O
(	O
which	O
`	O
apply	O
`	O
then	O
has	O
to	O
aggregate	O
into	O
a	O
single	O
result	O
)	O
.	O

Even	O
if	O
each	O
has	O
only	O
one	O
row	O
,	O
this	O
is	O
a	O
lot	O
of	O
overhead	O
.	O

It	O
might	O
be	O
more	O
illuminating	O
to	O
create	O
an	O
exmaple	O
whose	O
"	O
groupiness	O
"	O
(	O
i.e.	O
,	O
number	O
of	O
distinct	O
groups	O
)	O
is	O
more	O
in	O
line	O
with	O
your	O
actual	O
data	O
.	O

I	O
need	O
to	O
expand	O
this	O
as	O
matrix	O
.	O

How	O
to	O
do	O
that	O
?	O

My	O
first	O
thought	O
was	O
iterate	O
through	O
the	O
rows	O
and	O
apply	O
numpy.hstack	B-API
for	O
joining	O
,	O
store	O
it	O
and	O
numpy.vstack	B-API
the	O
stored	O
rows	O
,	O
but	O
it	O
doesn't	O
work	O
as	O
intended	O
.	O

I	O
had	O
the	O
same	O
issue	O
:	O
This	O
does	O
it	O
all	O
in	O
place	O
using	O
pandas	O
apply	O
function	O
.	O

Should	O
be	O
the	O
fastest	O
method	O
.	O

#CODE	O

A	O
more	O
memory	O
efficient	O
way	O
to	O
do	O
this	O
.	O

The	O
key	O
is	O
to	O
apply	O
`	O
usecols	O
`	O
in	O
`	O
pd.read_csv	B-API
`	O
.	O

#CODE	O

Looking	O
at	O
your	O
code	O
,	O
it	O
seems	O
you	O
could	O
use	O
pandas	O
built	O
in	O
moving	O
average	O
/	O
sliding	O
windows	O
functionality	O
,	O
combined	O
with	O
a	O
group	O
by	O
and	O
apply	O
.	O

this	O
makes	O
me	O
think	O
that	O
there	O
must	O
be	O
an	O
easier	O
,	O
perhaps	O
vectorized	O
way	O
...	O
perhaps	O
using	O
some	O
kind	O
of	O
"	O
apply	O
"	O
,	O
however	O
i'm	O
not	O
sure	O
how	O
to	O
do	O
that	O
when	O
each	O
column	O
needs	O
to	O
be	O
shifted	O
down	O
as	O
a	O
function	O
of	O
its	O
position	O
in	O
the	O
array	O
.	O

Apply	O
still	O
uses	O
loops	O
by	O
the	O
way	O

Just	O
apply	O
the	O
function	O
directly	O
-	O
I	O
guess	O
this	O
will	O
take	O
more	O
CPU	O
as	O
it's	O
calculating	O
all	O
the	O
maxes	O
,	O
then	O
just	O
getting	O
the	O
ones	O
you	O
want	O
,	O
but	O
doesn't	O
create	O
a	O
new	O
variable	O
.	O

#CODE	O

Then	O
apply	O
a	O
groupby	B-API
on	O
the	O
first	O
level	O
of	O
the	O
MultiIndex	O
to	O
apply	O
the	O
operation	O
you	O
want	O
.	O

#CODE	O

That	O
isn't	O
fully	O
vectorized	O
,	O
though	O
,	O
because	O
of	O
the	O
`	O
apply	O
`	O
.	O

Something	O
like	O
`	O
np.isfinite	B-API
(	O
df	O
)	O
.sum	B-API
(	O
axis=1	O
)	O
-1	O
`	O
should	O
bypass	O
all	O
Python	O
loops	O
.	O

I	O
am	O
trying	O
to	O
understand	O
how	O
to	O
apply	O
function	O
within	O
the	O
'	O
groupby	B-API
'	O
or	O
each	O
groups	O
of	O
the	O
groups	O
in	O
a	O
dataframe	B-API
.	O

#CODE	O

I'm	O
having	O
some	O
trouble	O
figuring	O
out	O
what	O
I'm	O
doing	O
wrong	O
here	O
,	O
trying	O
to	O
append	O
columns	O
to	O
an	O
existing	O
pd.DataFrame	B-API
object	O
.	O

Specifically	O
,	O
my	O
original	O
dataframe	B-API
has	O
n-many	O
columns	O
,	O
and	O
I	O
want	O
to	O
use	O
apply	O
to	O
append	O
an	O
additional	O
2n-many	O
columns	O
to	O
it	O
.	O

The	O
problem	O
seems	O
to	O
be	O
that	O
doing	O
this	O
via	O
apply()	B-API
doesn't	O
work	O
,	O
in	O
that	O
if	O
I	O
try	O
to	O
append	O
more	O
than	O
n-many	O
columns	O
,	O
it	O
falls	O
over	O
.	O

This	O
doesn't	O
make	O
sense	O
to	O
me	O
,	O
and	O
I	O
was	O
hoping	O
somebody	O
could	O
either	O
shed	O
some	O
light	O
on	O
to	O
why	O
I'm	O
seeing	O
this	O
behaviour	O
,	O
or	O
suggest	O
a	O
better	O
approach	O
.	O

In	O
general	O
you	O
want	O
apply	O
to	O
return	O
either	O
:	O

why	O
are	O
you	O
showing	O
using	O
apply	O
anyhow	O
?	O

this	O
should	O
just	O
be	O
column	O
assignment	O
,	O
no	O
?	O

Here	O
are	O
solutions	O
using	O
apply	O
.	O

#CODE	O

Can't	O
think	O
of	O
anything	O
great	O
for	O
unique	O
.	O

This	O
uses	O
apply	O
,	O
but	O
may	O
be	O
faster	O
,	O
depending	O
on	O
the	O
shape	O
of	O
the	O
data	O
.	O

#CODE	O

apply	O
function	O
on	O
dataframe	B-API
involving	O
two	O
rows	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
calculate	O
distance	O
based	O
on	O
the	O
longitude	O
and	O
latitude	O
.	O

Basically	O
I	O
need	O
a	O
way	O
to	O
express	O
the	O
function	O
can	O
handle	O
two	O
adjacent	O
rows	O
in	O
dataframe	B-API

I	O
know	O
there	O
are	O
ways	O
to	O
apply	O
function	O
along	O
axis	O
1	O
and	O
0	O
,	O
but	O
they	O
seem	O
only	O
apply	O
to	O
single	O
row	O
or	O
column	O
.	O

How	O
can	O
I	O
express	O
something	O
involving	O
several	O
rows	O
or	O
columns	O
.	O

Apply	O
won't	O
be	O
able	O
to	O
this	O
,	O
but	O
you	O
can	O
do	O
something	O
simple	O
like	O
the	O
following	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
group	O
the	O
series	O
by	O
hours	O
or	O
days	O
and	O
apply	O
a	O
function	O
group-wise	O
which	O
calculate	O
the	O
ratio	O
#CODE	O

Why	O
does	O
the	O
second	O
block	O
of	O
code	O
not	O
work	O
?	O

Doesn't	O
DataFrame.apply()	B-API
default	O
to	O
inplace	O
?	O

There	O
is	O
no	O
inplace	O
parameter	O
to	O
the	O
apply	O
function	O
.	O

If	O
it	O
doesn't	O
work	O
in	O
place	O
,	O
doesn't	O
this	O
make	O
pandas	O
a	O
terrible	O
memory	O
handler	O
?	O

Do	O
all	O
pandas	O
data	O
frame	O
operations	O
copy	O
everything	O
in	O
situations	O
like	O
this	O
?	O

Wouldn't	O
it	O
be	O
better	O
to	O
just	O
do	O
it	O
inplace	O
?	O

Even	O
if	O
it	O
doesn't	O
default	O
to	O
inplace	O
,	O
shouldn't	O
it	O
provide	O
an	O
inplace	O
parameter	O
the	O
way	O
replace()	B-API
does	O
?	O

No	O
,	O
apply	O
does	O
not	O
work	O
inplace*	O
.	O

In	O
general	O
apply	O
is	O
slow	O
(	O
since	O
you	O
are	O
basically	O
iterating	O
through	O
each	O
row	O
in	O
python	O
)	O
,	O
and	O
the	O
"	O
game	O
"	O
is	O
to	O
rewrite	O
that	O
function	O
in	O
terms	O
of	O
pandas	O
/	O
numpy	O
native	O
functions	O
and	O
indexing	O
.	O

If	O
you	O
want	O
to	O
delve	O
into	O
more	O
details	O
about	O
the	O
internals	O
,	O
check	O
out	O
the	O
BlockManager	O
in	O
core	O
/	O
internals.py	O
,	O
this	O
is	O
the	O
object	O
which	O
holds	O
the	O
underlying	O
numpy	O
arrays	O
.	O

But	O
to	O
be	O
honest	O
I	O
think	O
your	O
most	O
useful	O
tool	O
is	O
`	O
%timeit	O
`	O
and	O
looking	O
at	O
the	O
source	O
code	O
for	O
specific	O
functions	O
(	O
`	O
??	O
`	O
in	O
ipython	O
)	O
.	O

*	O
apply	O
is	O
not	O
usually	O
going	O
to	O
make	O
sense	O
inplace	O
(	O
and	O
IMO	O
this	O
behaviour	O
would	O
rarely	O
be	O
desired	O
)	O
.	O

Just	O
apply	O
it	O
to	O
every	O
column	O
:	O
#CODE	O

There's	O
nothing	O
built-in	O
,	O
so	O
you'll	O
need	O
to	O
calculate	O
it	O
with	O
apply	O
.	O

For	O
example	O
,	O
for	O
an	O
easy	O
'	O
how	O
many	O
7	O
day	O
periods	O
have	O
passed	O
'	O
measure	O
.	O

#CODE	O

JohnB	O
-	O
Yes	O
I	O
know	O
how	O
to	O
group-by	O
based	O
on	O
the	O
location	O
.	O

That	O
it	O
actually	O
included	O
as	O
part	O
of	O
the	O
question	O
.	O

But	O
when	O
you	O
group	O
by	O
you	O
end	O
up	O
with	O
a	O
group-by	O
object	O
which	O
you	O
can	O
iterate	O
over	O
.	O
for	O
a	O
specific	O
group	O
is	O
there	O
a	O
way	O
to	O
apply	O
a	O
shift	O
to	O
it	O
.	O

Or	O
do	O
I	O
need	O
to	O
iterate	O
over	O
it	O
.	O

Also	O
once	O
you	O
have	O
the	O
groups	O
there	O
seems	O
to	O
be	O
options	O
to	O
process	O
the	O
data	O
but	O
not	O
add	O
another	O
column	O
to	O
the	O
group	O
.	O

This	O
is	O
kind	O
of	O
where	O
I'm	O
stuck	O
.	O

Use	O
transform	O
(	O
instead	O
of	O
apply	O
)	O
,	O
as	O
chrisb	O
suggests	O
,	O
and	O
assign	O
the	O
result	O
to	O
`	O
portfolios	O
[	O
columname	O
]`	O
:	O
#CODE	O

Thanks	O
@USER	O
,	O
thanks	O
for	O
code	O
,	O
I	O
have	O
small	O
problem	O
now	O
,	O
two	O
months	O
of	O
cvs1	O
has	O
50,000	O
data	O
Value	O
and	O
two	O
months	O
of	O
csv2	O
has	O
4,000	O
data	O
Value	O
and	O
so	O
on	O
,	O
it's	O
really	O
hard	O
to	O
fit	O
all	O
the	O
graph	O
for	O
two	O
months	O
at	O
same	O
size	O
,	O
[	O
link	O
]	O
(	O
#URL	O
)	O
from	O
the	O
graph	O
,	O
only	O
two	O
months	O
of	O
data	O
is	O
shown	O
but	O
all	O
the	O
signals	O
doesn't	O
fit	O
.	O

Python	O
is	O
plotting	O
based	O
on	O
the	O
data	O
points	O
but	O
I	O
want	O
to	O
plot	O
based	O
on	O
days	O
(	O
for	O
ex	O
:	O
2	O
months	O
/	O
60	O
days	O
)	O
.	O

Is	O
there	O
any	O
logic	O
to	O
apply	O
,	O
or	O
methods	O
,	O
any	O
suggestions	O
are	O
highly	O
appreciable	O
,	O
since	O
I	O
am	O
in	O
this	O
for	O
long	O
time	O
.	O

Thank	O
you	O
very	O
much	O
.	O

and	O
then	O
apply	O
the	O
above	O
technique	O
.	O

(	O
I	O
sometimes	O
toss	O
in	O
a	O
`	O
reset_index	B-API
(	O
drop=True	O
)`	O
,	O
but	O
that's	O
up	O
to	O
you	O
.	O
)	O

I	O
am	O
trying	O
to	O
run	O
the	O
`	O
scipy.stats.entropy	O
`	O
function	O
on	O
two	O
arrays	O
.	O

It	O
is	O
being	O
run	O
on	O
each	O
row	O
of	O
a	O
Pandas	O
DataFrame	B-API
via	O
the	O
apply	O
function	O
:	O
#CODE	O

Turns	O
out	O
if	O
any	O
column	O
in	O
the	O
original	O
dataframe	B-API
is	O
an	O
object	O
,	O
the	O
series	O
created	O
via	O
apply	O
is	O
of	O
object	O
type	O
.	O

Thanks	O
again	O
.	O

#URL	O

Then	O
define	O
my	O
group	O
operation	O
and	O
apply	O
it	O
:	O
#CODE	O

Then	O
,	O
using	O
the	O
approach	O
from	O
this	O
answer	O
,	O
pivot	B-API
into	O
columns	O
,	O
and	O
drop	O
the	O
sentinel	O
.	O

This	O
won't	O
be	O
ultra	O
performant	O
because	O
of	O
the	O
apply	O
,	O
but	O
probably	O
reasonable	O
on	O
data	O
of	O
your	O
size	O
.	O

#CODE	O

How	O
do	O
I	O
apply	O
filters	O
and	O
functions	O
to	O
previous	O
rows	O
in	O
pandas	O
?	O

The	O
proper	O
use	O
of	O
apply	O
is	O
a	O
bit	O
unclear	O
to	O
me	O
.	O

Further	O
,	O
you	O
should	O
not	O
repeatedly	O
using	O
`	O
get_group	B-API
`	O
,	O
instead	O
use	O
the	O
cythonized	O
functions	O
,	O
`	O
apply	O
`	O
,	O
or	O
iteration	O
,	O
see	O
docs	O
here	O

Say	O
I	O
have	O
a	O
large	O
dataframe	B-API
and	O
that	O
I	O
want	O
to	O
apply	O
one	O
operation	O
to	O
every	O
element	O
in	O
a	O
column	O
.	O

I	O
was	O
looking	O
for	O
an	O
option	O
like	O
example	O
2	O
,	O
except	O
it	O
won't	O
apply	O
the	O
formatting	O
to	O
future	O
dataframes	O
.	O

Thanks	O
!	O

You	O
can	O
apply	O
any	O
operator	O
or	O
across	O
a	O
column	O
.	O

To	O
mutate	O
it	O
in-place	O
,	O
just	O
multiply	O
the	O
column	O
by	O
-1	O
:	O
#CODE	O

You	O
don't	O
need	O
the	O
apply	O
,	O
just	O
do	O
`	O
-	O
frame.abs()	O
`	O

The	O
online	O
docs	O
show	O
how	O
to	O
apply	O
an	O
operation	O
element	O
wise	O
,	O
as	O
does	O
the	O
excellent	O
book	O

The	O
typical	O
trick	O
is	O
to	O
write	O
a	O
general	O
mathematical	O
operation	O
to	O
apply	O
to	O
the	O
whole	O
column	O
,	O
but	O
then	O
use	O
indicators	O
to	O
select	O
rows	O
for	O
which	O
we	O
actually	O
apply	O
it	O
:	O
#CODE	O

pandas	O
apply	O
with	O
inputs	O
from	O
multiple	O
rows	O

I	O
need	O
to	O
do	O
an	O
apply	O
on	O
a	O
dataframe	B-API
using	O
inputs	O
from	O
multiple	O
rows	O
.	O

As	O
a	O
simple	O
example	O
,	O
I	O
can	O
do	O
the	O
following	O
if	O
all	O
the	O
inputs	O
are	O
from	O
a	O
single	O
row	O
:	O
#CODE	O

However	O
,	O
if	O
I	O
need	O
'	O
a	O
'	O
from	O
the	O
current	O
row	O
,	O
and	O
'	O
b	O
'	O
from	O
the	O
previous	O
row	O
,	O
is	O
there	O
a	O
way	O
to	O
do	O
that	O
with	O
apply	O
?	O

I	O
could	O
add	O
a	O
new	O
'	O
bshift	O
'	O
column	O
and	O
then	O
just	O
use	O
df	O
[[	O
'	O
a	O
'	O
,	O
'	O
bshift	O
']]	O
but	O
it	O
seems	O
there	O
must	O
be	O
a	O
more	O
direct	O
way	O
.	O

Point	O
taken	O
about	O
apply	O
not	O
being	O
magically	O
faster	O
.	O

Come	O
to	O
think	O
of	O
it	O
I	O
suppose	O
doing	O
multiple	O
applies	O
could	O
well	O
end	O
up	O
being	O
slower	O
than	O
a	O
single	O
large	O
for	O
loop	O
.	O

The	O
first	O
answer	O
to	O
#URL	O
made	O
me	O
want	O
to	O
try	O
it	O
.	O

Added	O
a	O
little	O
background	O
.	O

Considering	O
your	O
point	O
about	O
apply	O
and	O
speed	O
,	O
I	O
think	O
what	O
I'll	O
do	O
is	O
try	O
to	O
vectorize	B-API
as	O
much	O
as	O
I	O
can	O
,	O
and	O
see	O
what	O
I'm	O
left	O
with	O
,	O
and	O
then	O
come	O
back	O
with	O
more	O
questions	O
as	O
I	O
have	O
them	O
.	O

If	O
I	O
tried	O
to	O
post	O
all	O
my	O
code	O
as	O
it	O
is	O
it'd	O
just	O
be	O
overload	O
.	O

Appreciate	O
your	O
advice	O
.	O

This	O
should	O
directly	O
answer	O
your	O
question	O
and	O
let	O
you	O
use	O
apply	O
,	O
although	O
I'm	O
not	O
sure	O
it's	O
ultimately	O
any	O
better	O
than	O
a	O
two-line	O
solution	O
.	O

It	O
does	O
avoid	O
creating	O
extra	O
variables	O
at	O
least	O
.	O

Thanks	O
.	O

I	O
timed	O
your	O
first	O
method	O
vs	O
adding	O
a	O
shifted	O
column	O
and	O
then	O
deleting	O
it	O
after	O
I	O
finished	O
the	O
apply	O
,	O
and	O
interestingly	O
they	O
were	O
virtually	O
identical	O
(	O
and	O
not	O
very	O
fast	O
)	O
for	O
any	O
df	O
size	O
I	O
tried	O
,	O
so	O
I	O
guess	O
the	O
time	O
is	O
all	O
spent	O
in	O
the	O
apply	O
itself	O
.	O

Indeed	O
the	O
2nd	O
method	O
(	O
vectorized	O
)	O
is	O
much	O
faster	O
and	O
I'll	O
try	O
to	O
do	O
as	O
much	O
of	O
that	O
as	O
possible	O
but	O
unfortunately	O
I	O
don't	O
think	O
it's	O
possible	O
to	O
vectorize	B-API
all	O
of	O
it	O
.	O

@USER	O
It's	O
not	O
just	O
the	O
apply	O
,	O
it's	O
also	O
somewhat	O
expensive	O
to	O
concatenate	O
/	O
merge	O
or	O
create	O
a	O
new	O
variable	O
.	O

In	O
my	O
example	O
data	O
,	O
about	O
half	O
the	O
time	O
cost	O
is	O
due	O
to	O
concat	O
and	O
half	O
due	O
to	O
apply	O
.	O

Just	O
replace	O
the	O
apply	O
(	O
mean	O
)	O
with	O
mean()	B-API
and	O
you'll	O
see	O
it's	O
still	O
slower	O
.	O

Apply	O
function	O
to	O
pandas	O
dataframe	B-API
that	O
returns	O
multiple	O
rows	O

I	O
would	O
like	O
to	O
apply	O
a	O
function	O
to	O
a	O
pandas	O
DataFrame	B-API
that	O
splits	O
some	O
of	O
the	O
rows	O
into	O
two	O
.	O

So	O
for	O
example	O
,	O
I	O
may	O
have	O
this	O
as	O
input	O
:	O
#CODE	O

Then	O
I	O
would	O
simply	O
apply	O
the	O
extract	O
function	O
with	O
a	O
regex	O
:	O
#CODE	O

That	O
is	O
,	O
the	O
first	O
two	O
lines	O
together	O
constitute	O
the	O
headers	O
.	O

Is	O
there	O
any	O
way	O
to	O
apply	O
`	O
read_csv()	B-API
`	O
to	O
this	O
without	O
any	O
major	O
hassle	O
?	O

I	O
would	O
like	O
to	O
map	O
the	O
values	O
in	O
the	O
Probability	O
column	O
to	O
'	O
s	O
'	O
for	O
'	O
success	O
'	O
for	O
the	O
first	O
10	O
values	O
,	O
and	O
'	O
f	O
'	O
for	O
'	O
fail	O
'	O
for	O
the	O
rest	O
.	O

To	O
do	O
this	O
,	O
I	O
create	O
a	O
dummy	O
column	O
called	O
Index	O
,	O
apply	O
a	O
transformation	O
,	O
and	O
then	O
drop	O
the	O
dummy	O
column	O
.	O

#CODE	O

If	O
you	O
want	O
to	O
use	O
`	O
apply	O
`	O
it	O
can	O
be	O
done	O
,	O
but	O
you	O
will	O
loose	O
the	O
column	O
names	O
:	O
#CODE	O

See	O
edit	O
,	O
if	O
you	O
want	O
to	O
use	O
`	O
apply	O
`	O
,	O
it	O
can	O
be	O
done	O
but	O
you	O
will	O
loose	O
the	O
column	O
names	O
.	O

Basically	O
the	O
`	O
apply	O
`	O
function	O
should	O
return	O
a	O
`	O
Series	O
`	O
of	O
length	O
of	O
3	O
,	O
compare	O
the	O
two	O
new	O
edits	O
.	O

Thanks	O
!	O

Probably	O
the	O
most	O
readable	O
way	O
to	O
do	O
it	O
,	O
although	O
I	O
generally	O
try	O
to	O
avoid	O
apply	O
/	O
lambda	O
if	O
possible	O
for	O
speed	O
reasons	O
if	O
there	O
is	O
a	O
good	O
alternative	O
(	O
though	O
speed	O
is	O
not	O
a	O
concern	O
here	O
)	O
.	O

I'd	O
apply	O
`	O
value_counts	B-API
`	O
columnwise	O
rather	O
than	O
doing	O
`	O
groupby	B-API
`	O
:	O
#CODE	O

Thanks	O
a	O
lot	O
Jeff	O
,	O
I	O
updated	O
the	O
OP	O
with	O
an	O
example	O
.	O

I	O
basically	O
want	O
to	O
apply	O
the	O
solution	O
that	O
you	O
described	O
to	O
**	O
each	O
item	O
**	O
in	O
the	O
series	O
(	O
i.e.	O
get	O
the	O
offset	O
with	O
respect	O
to	O
**	O
each	O
timestamp**	O
'	O
s	O
hour	O
in	O
`	O
ms	O
`)	O

See	O
the	O
docs	O
on	O
apply	O
.	O

Pandas	O
will	O
call	O
the	O
function	O
twice	O
on	O
the	O
first	O
group	O
(	O
to	O
determine	O
between	O
a	O
fast	O
/	O
slow	O
code	O
path	O
)	O
,	O
so	O
the	O
side	O
effects	O
of	O
the	O
function	O
(	O
IO	O
)	O
will	O
happen	O
twice	O
for	O
the	O
first	O
group	O
.	O

Yeah	O
,	O
or	O
you	O
could	O
even	O
still	O
use	O
apply	O
on	O
the	O
main	O
df	O
,	O
but	O
then	O
change	O
item_grouper	O
to	O
iterate	O
.	O

I	O
didn't	O
step	O
through	O
all	O
the	O
code	O
,	O
but	O
if	O
possible	O
,	O
your	O
life	O
might	O
be	O
easier	O
if	O
you	O
avoid	O
any	O
IO	O
in	O
the	O
groupby	B-API
and	O
use	O
standard	O
pandas	O
IO	O
(	O
i.e.	O
`	O
df.to_csv	B-API
(	O
sep=	O
'	O
\t	O
')`	O
to	O
write	O
your	O
tab	O
separated	O
file	O
.	O

So	O
I	O
have	O
a	O
dataset	O
consisting	O
of	O
several	O
million	O
rows	O
of	O
trading	O
data	O
that	O
I	O
am	O
trying	O
to	O
apply	O
a	O
filter	O
to	O
as	O
in	O
the	O
following	O
code	O
.	O

The	O
function	O
`	O
trade_quant_filter	O
`	O
looks	O
for	O
outliers	O
and	O
then	O
adds	O
the	O
index	O
of	O
all	O
the	O
outliers	O
to	O
a	O
list	O
to	O
deal	O
with	O
later	O
.	O

#CODE	O

I'm	O
really	O
struggling	O
with	O
the	O
Pandas	O
`	O
rolling_apply	B-API
function	O
`	O
.	O

I'm	O
trying	O
to	O
apply	O
a	O
filter	O
to	O
some	O
time	O
series	O
data	O
like	O
below	O
and	O
make	O
a	O
new	O
series	O
for	O
outliers	O
.	O

I	O
want	O
the	O
value	O
to	O
return	O
`	O
True	O
`	O
when	O
the	O
value	O
is	O
an	O
outlier	O
.	O

#CODE	O

`	O
group_user=	O
store.select	O
(	O
'	O
clean_input	O
'	O
,	O
where	O
=[	O
'	O
user_id	O
==	O
%s	O
'	O
%user	O
])`	O
is	O
too	O
heavy	O
in	O
time	O
complexity	O
since	O
I	O
have	O
really	O
a	O
lot	O
of	O
groups	O
,	O
and	O
I	O
am	O
sure	O
there	O
is	O
a	O
lot	O
of	O
redundant	O
sorting	O
in	O
the	O
routine	O
of	O
`	O
store.select	O
`	O
if	O
I	O
apply	O
it	O
10	O
millions	O
times	O
.	O

But	O
you	O
have	O
not	O
introduced	O
the	O
variable	O
sub_group_chunk	O
,	O
and	O
If	O
i	O
try	O
chunk.groupby	O
(	O
sub_group_hash	O
)	O
I	O
get	O
an	O
error	O
of	O
the	O
form	O
:	O
long	O
object	O
have	O
no	O
attribute	O
_____get.item____	O
because	O
It	O
tries	O
to	O
apply	O
the	O
function	O
to	O
the	O
index	O
.	O

In	O
my	O
experience	O
,	O
this	O
approach	O
seems	O
slower	O
than	O
using	O
an	O
approach	O
like	O
`	O
apply	O
`	O
or	O
`	O
map	O
`	O
,	O
but	O
as	O
always	O
,	O
it's	O
up	O
to	O
you	O
to	O
decide	O
how	O
to	O
make	O
the	O
performance	O
/	O
ease	O
of	O
coding	O
tradeoff	O
.	O

You	O
could	O
apply	O
`	O
f	O
`	O
first	O
,	O
and	O
pass	O
the	O
return	O
value	O
to	O
`	O
groupby	B-API
`	O
:	O
#CODE	O

pandas	O
apply	O
function	O
to	O
corresponding	O
cells	O
of	O
multiple	O
frames	O

I'm	O
trying	O
to	O
apply	O
a	O
function	O
to	O
corresponding	O
cells	O
of	O
two	O
identically	O
sized	O
dataFrames	O
to	O
create	O
a	O
new	O
frame	O
.	O

Did	O
you	O
test	O
if	O
looping	O
is	O
actually	O
too	O
slow	O
?	O

(	O
it	O
will	O
depend	O
on	O
the	O
timing	O
of	O
the	O
applied	O
function	O
if	O
the	O
looping	O
will	O
be	O
determinant	O
for	O
speed	O
)	O
And	O
can	O
the	O
function	O
you	O
want	O
to	O
apply	O
be	O
vectorized	O
?	O

_	O
"	O
What	O
fast	O
methods	O
could	O
I	O
use	O
to	O
load	O
/	O
save	O
the	O
data	O
from	O
disk	O
?	O

"	O
_	O
I	O
don't	O
know	O
if	O
this	O
can	O
apply	O
to	O
your	O
use	O
case	O
,	O
but	O
have	O
you	O
investigated	O
[	O
PyTables	O
]	O
(	O
#URL	O
)	O
?	O

Its	O
blazing	O
fast	O
at	O
loading	O
data	O
and	O
interfaces	O
nicely	O
with	O
`	O
numpy	O
`	O
.	O

Don't	O
know	O
about	O
`	O
Panda	O
`	O
though	O
.	O

You're	O
looking	O
for	O
a	O
groupby	B-API
with	O
an	O
apply	O
.	O

#CODE	O

Hi	O
zerovector	O
,	O
I	O
am	O
getting	O
an	O
error	O
when	O
I	O
try	O
to	O
apply	O
that	O
idea	O
:	O
def	O
func	O
(	O
x	O
):	O

Thank	O
you	O
zerovector	O
--	O
your	O
help	O
put	O
me	O
on	O
the	O
right	O
path	O
to	O
solve	O
the	O
problem	O
!	O

An	O
apply	O
function	O
was	O
what	O
I	O
was	O
looking	O
for	O
!	O

I	O
am	O
wondering	O
if	O
there	O
is	O
a	O
way	O
to	O
do	O
a	O
pandas	O
dataframe	B-API
apply	O
function	O
in	O
parallel	O
.	O

I	O
have	O
looked	O
around	O
and	O
haven't	O
found	O
anything	O
.	O

At	O
least	O
in	O
theory	O
I	O
think	O
it	O
should	O
be	O
fairly	O
simple	O
to	O
implement	O
but	O
haven't	O
seen	O
anything	O
.	O

This	O
is	O
practically	O
the	O
textbook	O
definition	O
of	O
parallel	O
after	O
all	O
..	O

Has	O
anyone	O
else	O
tried	O
this	O
or	O
know	O
of	O
a	O
way	O
?	O

If	O
no	O
one	O
has	O
any	O
ideas	O
I	O
think	O
I	O
might	O
just	O
try	O
writing	O
it	O
myself	O
.	O

That	O
is	O
a	O
good	O
idea	O
.	O

I	O
was	O
planning	O
on	O
doing	O
something	O
much	O
more	O
dynamic	O
but	O
much	O
more	O
complicated	O
.	O

I	O
think	O
your	O
way	O
is	O
much	O
better	O
and	O
simpler	O
though	O
.	O

I	O
will	O
give	O
it	O
a	O
try	O
with	O
the	O
apply	O
function	O
and	O
report	O
back	O
.	O

(	O
Note	O
that	O
there	O
is	O
no	O
.fit	O
function	O
for	O
OLS	O
in	O
Pandas	O
)	O
Could	O
somebody	O
shed	O
some	O
light	O
on	O
how	O
I	O
might	O
get	O
future	O
predictions	O
from	O
my	O
OLS	O
model	O
in	O
either	O
pandas	O
or	O
statsmodel-I	O
realize	O
I	O
must	O
not	O
be	O
using	O
.predict	O
properly	O
and	O
I've	O
read	O
the	O
multiple	O
other	O
problems	O
people	O
have	O
had	O
but	O
they	O
do	O
not	O
seem	O
to	O
apply	O
to	O
my	O
case	O
.	O

You	O
can	O
use	O
numpy	O
where	O
and	O
apply	O
to	O
do	O
it	O
for	O
all	O
columns	O
in	O
a	O
DataFrame	B-API
:	O
#CODE	O

I	O
start	O
by	O
chunking	O
the	O
CSV	O
file	O
,	O
and	O
apply	O
a	O
`	O
groupby	B-API
`	O
(	O
on	O
the	O
two	O
last	O
figures	O
of	O
the	O
`	O
user_id	O
`)	O
on	O
the	O
chunks	O
files	O
so	O
I	O
can	O
store	O
a	O
total	O
of	O
100	O
files	O
containing	O
groups	O
of	O
users	O
,	O
and	O
storing	O
them	O
in	O
a	O
HDF5	O
store	O
.	O

The	O
difference	O
lies	O
in	O
the	O
fact	O
that	O
`	O
grouped.median()	O
`	O
calls	O
an	O
optimized	O
(	O
cythonized	O
)	O
`	O
median	O
`	O
aggregation	O
function	O
,	O
while	O
`	O
grouped.quantile()	O
`	O
calls	O
a	O
generic	O
wrapper	O
to	O
apply	O
the	O
function	O
on	O
the	O
groups	O
.	O

So	O
`	O
grouped.quantile()	O
`	O
does	O
a	O
general	O
apply	O
and	O
not	O
an	O
aggregation	O
.	O

The	O
reason	O
for	O
this	O
is	O
that	O
`	O
quantile	O
`	O
can	O
also	O
return	O
a	O
DataFrame	B-API
(	O
and	O
thus	O
is	O
not	O
always	O
a	O
pure	O
aggregation	O
)	O
,	O
if	O
you	O
calculate	O
multiple	O
quantiles	O
at	O
once	O
,	O
eg	O
with	O
`	O
grouped.quantile	O
([	O
0.1	O
,	O
0.5	O
,	O
0.9	O
])`	O
:	O
#CODE	O

In	O
terms	O
of	O
how	O
you	O
make	O
a	O
new	O
column	O
based	O
on	O
other	O
columns	O
-	O
if	O
you	O
absolutely	O
need	O
to	O
iterate	O
,	O
then	O
you	O
can	O
assign	O
using	O
`	O
loc	O
`	O
,	O
as	O
you	O
did	O
in	O
one	O
example	O
.	O

But	O
you	O
should	O
always	O
look	O
for	O
a	O
vectorized	O
solution	O
,	O
then	O
look	O
at	O
`	O
apply	O
`	O
,	O
and	O
only	O
then	O
think	O
about	O
iterating	O
.	O

See	O
this	O
answer	O
for	O
some	O
more	O
background	O
.	O

This	O
give	O
yous	O
a	O
boolean	O
mask	O
for	O
groupby	B-API
of	O
each	O
store	O
for	O
each	O
date	O
where	O
there	O
are	O
exactly	O
two	O
unique	O
`	O
Item_Id	O
`	O
present	O
.	O

From	O
this	O
you	O
can	O
now	O
apply	O
the	O
function	O
that	O
concatenates	O
your	O
prices	O
:	O
#CODE	O

@USER	O
Not	O
quite	O
.	O

`	O
join	O
`	O
is	O
shorthand	O
for	O
merging	O
on	O
index	O
with	O
both	O
frames	O
,	O
so	O
the	O
indices	O
need	O
only	O
be	O
consistent	O
(	O
which	O
it	O
will	O
be	O
here	O
as	O
the	O
apply	O
and	O
col	O
selection	O
don't	O
affect	O
it	O
)	O
.	O

I'll	O
edit	O
the	O
answer	O
.	O

You	O
could	O
use	O
lambda	O
function	O
and	O
`	O
apply	O
`	O
.	O

In	O
this	O
case	O
,	O
I	O
made	O
the	O
new	O
index	O
level	O
by	O
taking	O
the	O
first	O
character	O
of	O
the	O
original	O
columns	O
,	O
but	O
of	O
course	O
you	O
can	O
apply	O
another	O
function	O
here	O
if	O
wanted	O
.	O

As	O
user	O
@USER	O
has	O
pointed	O
out	O
using	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
should	O
be	O
a	O
last	O
resort	O
if	O
a	O
vectorised	O
solution	O
can	O
be	O
applied	O
.	O

What	O
you	O
wrote	O
is	O
incorrect	O
,	O
you	O
are	O
calling	O
apply	O
on	O
the	O
df	O
but	O
the	O
column	O
as	O
a	O
label	O
does	O
not	O
exist	O
,	O
see	O
below	O
:	O
#CODE	O

in	O
general	O
I	O
wouldn't	O
show	O
a	O
map	O
/	O
apply	O
based	O
soln	O
if	O
the	O
vectorized	O
one	O
works	O
(	O
it's	O
confusing	O
and	O
much	O
slower	O
)	O

I've	O
managed	O
to	O
do	O
this	O
with	O
apply	O
,	O
like	O
this	O
:	O
#CODE	O

Is	O
there	O
a	O
more	O
efficient	O
way	O
to	O
compare	O
every	O
column	O
in	O
every	O
row	O
in	O
one	O
DF	O
to	O
every	O
column	O
in	O
every	O
row	O
of	O
another	O
DF	O
?	O

This	O
feels	O
sloppy	O
to	O
me	O
,	O
but	O
my	O
loop	O
/	O
apply	O
attempts	O
have	O
been	O
much	O
slower	O
.	O

#CODE	O

I	O
forgot	O
to	O
mention	O
,	O
my	O
actual	O
DF's	O
have	O
millions	O
of	O
rows	O
and	O
dozens	O
of	O
columns	O
to	O
compare	O
.	O

With	O
that	O
size	O
,	O
the	O
apply	O
attempts	O
were	O
taking	O
hours	O
.	O

I	O
would	O
go	O
for	O
apply	O
:	O
#CODE	O

You	O
can	O
then	O
use	O
apply	O
to	O
concatenate	O
:	O
#CODE	O

`	O
drop_duplicates()	B-API
'	O
is	O
the	O
right	O
function	O
.	O

Coming	O
from	O
sql	O
I	O
immediately	O
thought	O
to	O
GROUP	O
BY	O
.	O

If	O
the	O
fierst	O
column	O
is	O
intger	O
type	O
you	O
suggest	O
to	O
cast	O
to	O
string	O
and	O
the	O
to	O
use	O
apply	O
?	O

You	O
can	O
groupby	B-API
the	O
Label	O
column	O
,	O
apply	O
the	O
list	O
constructor	O
.	O

Here	O
is	O
an	O
minimal	O
example	O
.	O

#CODE	O

if	O
you	O
want	O
to	O
convert	O
it	O
to	O
strings	O
,	O
you	O
can	O
apply	O
`	O
strfitme	O
`	O
(	O
`	O
df	O
[	O
'	O
timestamp	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x.strftime	O
(	O
'	O
%Y-%m-%d	O
'))`)	O
.	O

Or	O
if	O
it	O
is	O
to	O
write	O
it	O
as	O
strings	O
to	O
csv	O
,	O
use	O
the	O
`	O
date_format	O
`	O
keyword	O
in	O
`	O
to_csv	B-API
`	O

The	O
reason	O
I	O
say	O
this	O
is	O
that	O
Jeff	O
has	O
always	O
commented	O
to	O
me	O
that	O
`	O
map	O
`	O
and	O
`	O
apply	O
`	O
are	O
last	O
resort	O
methods	O
so	O
I	O
thought	O
`	O
update	O
`	O
would	O
perform	O
better	O

I	O
have	O
a	O
large	O
dataframe	B-API
.	O

I	O
want	O
to	O
groupby	B-API
three	O
columns	O
in	O
the	O
dataframe	B-API
,	O
and	O
then	O
apply	O
a	O
function	O
to	O
each	O
group	O
.	O

However	O
,	O
I'm	O
also	O
interested	O
in	O
some	O
groups	O
and	O
keys	O
that	O
are	O
NOT	O
in	O
the	O
dataframe	B-API
.	O

How	O
do	O
I	O
add	O
those	O
to	O
the	O
groupby	B-API
object	O
,	O
so	O
I	O
may	O
use	O
`	O
groupby.apply()	B-API
`	O
uniformly	O
on	O
all	O
groups	O
?	O

The	O
reason	O
that	O
`	O
df	O
[	O
'	O
column_with_times	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x.days	O
)`	O
does	O
not	O
work	O
is	O
that	O
apply	O
is	O
given	O
the	O
`	O
timedelta64	O
`	O
values	O
(	O
and	O
not	O
the	O
`	O
Timedelta	O
`	O
pandas	O
type	O
)	O
,	O
and	O
these	O
don't	O
have	O
such	O
attributes	O
.	O

I	O
would	O
assume	O
to_excel()	B-API
would	O
only	O
try	O
to	O
apply	O
the	O
parameter	O
to	O
float-formatted	O
columns	O
(	O
or	O
even	O
specific	O
cells	O
)	O
rather	O
than	O
to	O
every	O
piece	O
of	O
data	O
,	O
so	O
I'm	O
not	O
sure	O
what	O
I'm	O
missing	O
.	O

If	O
need	O
be	O
I'll	O
post	O
a	O
cleaned	O
version	O
of	O
the	O
specific	O
table	O
that	O
reproduces	O
the	O
error	O
,	O
but	O
I	O
thought	O
perhaps	O
someone	O
would	O
recognize	O
what	O
I'm	O
facing	O
.	O

I	O
think	O
you	O
are	O
looking	O
for	O
a	O
rolling	O
apply	O
(	O
rolling	O
mean	O
in	O
this	O
case	O
)	O
?	O

See	O
the	O
docs	O
:	O
#URL	O
.	O

But	O
then	O
applied	O
for	O
each	O
weekday	B-API
seperately	O
,	O
this	O
can	O
be	O
achieved	O
by	O
combining	O
`	O
rolling_mean	B-API
`	O
with	O
grouping	O
on	O
the	O
weekday	B-API
with	O
`	O
groupby	B-API
`	O
.	O

Cleaner	O
pandas	O
apply	O
with	O
function	O
that	O
cannot	O
use	O
pandas.Series	B-API
and	O
non-unique	O
index	O

The	O
use	O
case	O
:	O
I	O
want	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
via	O
a	O
parallel	O
map	O
in	O
IPython	O
.	O

It	O
doesn't	O
matter	O
which	O
rows	O
go	O
to	O
which	O
back-end	O
engine	O
,	O
as	O
the	O
function	O
calculates	O
a	O
result	O
based	O
on	O
one	O
row	O
at	O
a	O
time	O
.	O

(	O
Conceptually	O
at	O
least	O
;	O
in	O
reality	O
it's	O
vectorized	O
.	O
)	O

Pandas	O
-	O
Create	O
a	O
new	O
column	O
with	O
apply	O
for	O
float	O
indexed	O
dataframe	B-API

No	O
worries	O
.	O

As	O
a	O
general	O
rule	O
avoid	O
using	O
`	O
apply	O
`	O
if	O
there	O
is	O
a	O
vectorised	O
operation	O
,	O
for	O
basic	O
operations	O
such	O
as	O
add	O
/	O
subtract	O
/	O
div	O
and	O
multiply	O
there	O
are	O
built	O
in	O
operator	O
support	O
for	O
these	O
that	O
are	O
many	O
orders	O
of	O
magnitude	O
faster	O
.	O

Returning	O
multiple	O
columns	O
with	O
pandas	O
apply	O
and	O
user-defined	O
functions	O

And	O
I	O
want	O
to	O
use	O
`	O
df	O
[	O
'	O
x	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
fn	O
(	O
x	O
))`	O
to	O
return	O
both	O
`	O
y	O
`	O
and	O
`	O
z	O
`	O
in	O
separate	O
columns	O
.	O

Is	O
there	O
a	O
good	O
way	O
to	O
do	O
this	O
by	O
still	O
using	O
`	O
fn	O
(	O
x	O
)`	O
?	O

In	O
reality	O
,	O
my	O
function	O
will	O
be	O
much	O
more	O
complicated	O
-	O
so	O
I	O
only	O
want	O
to	O
run	O
it	O
once	O
within	O
the	O
apply	O
and	O
assign	O
`	O
output	O
[	O
0	O
]`	O
,	O
`	O
output	O
[	O
1	O
]`	O
,	O
etc	O
to	O
individual	O
columns	O
.	O

How	O
about	O
this	O
method	O
?	O

(	O
n.b.	O
,	O
I	O
edited	O
this	O
answer	O
in	O
light	O
of	O
the	O
comment	O
below	O
)	O
so	O
the	O
apply	O
step	O
could	O
take	O
a	O
single	O
function	O
with	O
shared	O
calculations	O
and	O
return	O
the	O
required	O
series	O
for	O
the	O
merge	O
step	O
.	O

#CODE	O

`	O
apply	O
(	O
Series	O
)`	O
gives	O
me	O
a	O
DataFrame	B-API
with	O
two	O
columns	O
.	O

To	O
join	O
them	O
into	O
one	O
while	O
keeping	O
the	O
original	O
index	O
,	O
I	O
use	O
`	O
unstack	O
`	O
.	O

`	O
reset_index	B-API
`	O
removes	O
the	O
first	O
level	O
of	O
the	O
index	O
,	O
which	O
basically	O
holds	O
the	O
index	O
of	O
the	O
value	O
in	O
the	O
original	O
list	O
which	O
was	O
in	O
C	O
.	O

Then	O
I	O
join	O
it	O
back	O
into	O
the	O
df	O
.	O

Anyway	O
,	O
you	O
can	O
do	O
this	O
using	O
apply	O
:	O
#CODE	O

The	O
function	O
in	O
the	O
apply	O
works	O
by	O
first	O
seeing	O
if	O
the	O
ID	O
is	O
in	O
the	O
dictionary	O
(	O
and	O
tuples	O
won't	O
be	O
)	O
and	O
if	O
it	O
is	O
,	O
go	O
for	O
that	O
,	O
and	O
if	O
it	O
isn't	O
find	O
the	O
first	O
one	O
that	O
is	O
...	O

This	O
was	O
a	O
bit	O
more	O
annoying	O
to	O
code	O
,	O
basically	O
we	O
can	O
apply	O
a	O
custom	O
function	O
that	O
performs	O
the	O
lookup	O
for	O
you	O
:	O
#CODE	O

OK	O
but	O
generally	O
using	O
`	O
apply	O
`	O
should	O
be	O
a	O
last	O
resort	O
,	O
there	O
are	O
vectorised	O
functions	O
in	O
pandas	O
and	O
numpy	O
that	O
will	O
perform	O
math	O
operations	O
on	O
the	O
whole	O
df	O
,	O
please	O
check	O
the	O
numbers	O
I	O
can't	O
guarantee	O
anything	O

Compared	O
to	O
the	O
apply	O
function	O
which	O
took	O
4.3s	O
so	O
nearly	O
250	O
times	O
quicker	O
,	O
something	O
to	O
note	O
in	O
the	O
future	O

Use	O
`	O
axis=0	O
`	O
to	O
apply	O
a	O
method	O
down	O
each	O
column	O
,	O
or	O
to	O
the	O
row	O
labels	O
(	O
the	O
index	O
)	O
.	O

Use	O
`	O
axis=1	O
`	O
to	O
apply	O
a	O
method	O
across	O
each	O
row	O
,	O
or	O
to	O
the	O
column	O
labels	O
.	O

You	O
can	O
call	O
the	O
`	O
str	O
`	O
method	O
and	O
apply	O
a	O
slice	O
,	O
this	O
will	O
be	O
much	O
quicker	O
than	O
the	O
other	O
method	O
as	O
this	O
is	O
vectorised	O
(	O
thanks	O
@USER	O
):	O
#CODE	O

Just	O
out	O
of	O
interest	O
how	O
would	O
I	O
go	O
about	O
apply	O
this	O
to	O
the	O
index	O
column	O
?	O

As	O
I	O
can't	O
seem	O
to	O
get	O
that	O
to	O
work	O
-	O
I	O
can	O
always	O
just	O
reset_index()	B-API
the	O
column	O
and	O
do	O
it	O
then	O
..	O

Furthermore	O
,	O
the	O
mean	O
(	O
or	O
whatever	O
other	O
function	O
I	O
want	O
to	O
use	O
to	O
generate	O
a	O
value	O
)	O
must	O
be	O
based	O
on	O
the	O
original	O
data	O
and	O
applied	O
to	O
new	O
data	O
.	O

Imagine	O
the	O
situation	O
where	O
I	O
calculate	O
mean	O
bad	O
rates	O
for	O
a	O
continuous	O
variable	O
on	O
a	O
training	O
data	O
set	O
,	O
build	O
a	O
model	O
and	O
then	O
have	O
to	O
apply	O
that	O
same	O
transformation	O
logic	O
to	O
new	O
data	O
.	O

yes	O
,	O
thank	O
you	O
for	O
the	O
suggestions	O
.	O

I	O
should	O
clarify	O
(	O
and	O
will	O
do	O
so	O
in	O
an	O
edit	O
)	O
that	O
I	O
need	O
to	O
be	O
able	O
to	O
apply	O
whatever	O
transformation	O
I	O
devise	O
to	O
new	O
data	O
.	O

So	O
I	O
have	O
to	O
save	O
the	O
lookup	O
information	O
somehow	O
so	O
I	O
can	O
use	O
it	O
later	O
.	O

Thanks	O
for	O
your	O
comments	O
.	O

The	O
documentation	O
I	O
linked	O
says	O
that	O
the	O
`	O
data	O
`	O
argument	O
may	O
be	O
a	O
"	O
numpy	O
ndarray	B-API
(	O
structured	O
or	O
homogeneous	O
)	O
,	O
dict	O
,	O
or	O
DataFrame	B-API
"	O
,	O
and	O
follows	O
this	O
line	O
with	O
one	O
that	O
says	O
"	O
***	O
Dict	O
can	O
contain	O
***	O
Series	O
,	O
arrays	O
,	O
constants	O
,	O
or	O
list-like	O
objects	O
"	O
(	O
my	O
emphasis	O
)	O
.	O

I	O
interpret	O
this	O
to	O
mean	O
that	O
*	O
when	O
the	O
`	O
data	O
`	O
argument	O
is	O
a	O
`	O
dict	O
`	O
*	O
,	O
its	O
values	O
can	O
be	O
Series	O
,	O
arrays	O
,	O
etc	O
.	O

IOW	O
,	O
the	O
"	O
list-like	O
objects	O
"	O
bit	O
is	O
not	O
referring	O
to	O
the	O
`	O
data	O
`	O
argument	O
itself	O
.	O

I	O
am	O
specifically	O
looking	O
for	O
a	O
`	O
data	O
`	O
argument	O
that	O
is	O
a	O
Python	O
list	O
,	O
not	O
a	O
dict	O
,	O
so	O
this	O
clause	O
does	O
not	O
apply	O
.	O

I'm	O
looking	O
for	O
a	O
method	O
to	O
perform	O
an	O
ANOVA	O
and	O
HSD	O
tests	O
from	O
a	O
dataframe	B-API
in	O
Python	O
.	O

I	O
tried	O
to	O
read	O
some	O
examples	O
on	O
forums	O
and	O
tutorials	O
but	O
i	O
didn't	O
achieve	O
to	O
apply	O
it	O
to	O
my	O
work	O
.	O

but	O
i	O
can't	O
achieve	O
to	O
apply	O
them	O
to	O
my	O
example	O

For	O
pairwise	O
comparison	O
for	O
only	O
some	O
effects	O
,	O
we	O
would	O
need	O
the	O
pairwise	O
comparison	O
after	O
estimating	O
the	O
multiway	O
ANOVA	O
with	O
OLS	O
.	O

This	O
is	O
currently	O
not	O
available	O
in	O
statsmodels	O
.	O

The	O
critical	O
values	O
and	O
p-values	O
of	O
Tukey-HSD	O
would	O
not	O
apply	O
in	O
that	O
case	O
.	O

What	O
would	O
be	O
possible	O
in	O
this	O
case	O
is	O
to	O
estimate	O
the	O
full	O
model	O
with	O
OLS	O
,	O
define	O
all	O
desired	O
pairwise	O
contrasts	O
,	O
use	O
the	O
`	O
t_test	O
`	O
to	O
get	O
the	O
raw	O
p-values	O
for	O
the	O
comparisons	O
,	O
and	O
then	O
apply	O
one	O
of	O
the	O
multiple	O
p-value	O
corrections	O
that	O
are	O
available	O
.	O

The	O
reason	O
it	O
overwrites	O
is	O
because	O
the	O
indexing	O
on	O
the	O
left	O
hand	O
side	O
is	O
defaulting	O
to	O
the	O
entire	O
dataframe	B-API
,	O
if	O
you	O
apply	O
the	O
mask	O
to	O
the	O
left	O
hand	O
also	O
using	O
`	O
loc	O
`	O
then	O
it	O
only	O
affects	O
those	O
rows	O
where	O
the	O
condition	O
is	O
met	O
:	O
#CODE	O

How	O
to	O
apply	O
Pandas	O
Groupby	B-API
with	O
multiple	O
conditions	O
for	O
split	O
and	O
apply	O
multiple	O
calculations	O
?	O

I	O
could	O
possibly	O
live	O
without	O
floats	O
and	O
use	O
strings	O
,	O
but	O
curiously	O
the	O
things	O
in	O
my	O
Dataframe	B-API
appear	O
to	O
BE	O
strings	O
,	O
since	O
when	O
I	O
try	O
to	O
apply	O
the	O
round()	B-API
function	O
on	O
any	O
value	O
extracted	O
from	O
there	O
,	O
it	O
will	O
protest	O
that	O
the	O
input	O
is	O
not	O
a	O
float	O
...	O

I	O
would	O
like	O
to	O
apply	O
dummy-coding	O
contrasting	O
on	O
it	O
so	O
that	O
I	O
get	O
:	O
#CODE	O

But	O
I	O
need	O
to	O
time	O
where	O
those	O
peaks	O
occur	O
as	O
well	O
.	O

I	O
know	O
I	O
could	O
iterate	O
over	O
the	O
output	O
and	O
find	O
where	O
in	O
the	O
original	O
dataset	O
those	O
values	O
occur	O
,	O
but	O
that	O
seems	O
like	O
a	O
rather	O
brute-force	O
way	O
to	O
do	O
it	O
.	O

I	O
also	O
could	O
write	O
a	O
different	O
function	O
to	O
apply	O
to	O
the	O
grouped	O
object	O
that	O
returns	O
both	O
the	O
max	O
and	O
the	O
time	O
where	O
that	O
max	O
occurs	O
(	O
at	O
least	O
in	O
theory	O
-	O
haven't	O
tried	O
to	O
do	O
this	O
,	O
but	O
I	O
assume	O
it's	O
pretty	O
straightforward	O
)	O
.	O

As	O
an	O
alternative	O
you	O
could	O
index	O
the	O
group	O
by	O
using	O
the	O
`	O
argmin()	B-API
`	O
function	O
.	O

I	O
tried	O
to	O
do	O
this	O
with	O
transform	O
but	O
it	O
was	O
just	O
returning	O
the	O
entire	O
dataframe	B-API
.	O

I'm	O
not	O
sure	O
why	O
that	O
should	O
be	O
,	O
it	O
does	O
however	O
work	O
with	O
`	O
apply	O
`	O
:	O
#CODE	O

In	O
my	O
opinion	O
the	O
`	O
transform	O
`	O
and	O
`	O
apply	O
`	O
functions	O
are	O
very	O
opaque	O
and	O
the	O
docs	O
are	O
not	O
a	O
great	O
help	O
.	O

They	O
are	O
however	O
extremely	O
useful	O
once	O
you	O
get	O
to	O
grips	O
with	O
them	O
.	O

is	O
incorrect	O
,	O
as	O
you	O
have	O
18:00	O
:	O
00	O
twice	O
for	O
the	O
same	O
date	O
,	O
and	O
in	O
your	O
initial	O
data	O
,	O
they	O
apply	O
to	O
different	O
dates	O
.	O

it	O
is	O
probably	O
better	O
to	O
do	O
datetime	O
conversion	O
doing	O
`	O
df	O
[	O
'	O
t	B-API
']	O
=	O
pd.to_datetime	B-API
(	O
df	O
[	O
'	O
t	B-API
'])`	O
rather	O
than	O
call	O
`	O
apply	O
`	O

we	O
need	O
to	O
write	O
a	O
apply	O
function	O
first	O
and	O
then	O
use	O
group	O
by	O
.	O

This	O
is	O
my	O
latest	O
guess	O

There	O
maybe	O
actually	O
something	O
a	O
little	O
cleaner	O
.	O

The	O
solution	O
above	O
is	O
just	O
a	O
general	O
solution	O
for	O
quickly	O
merging	O
a	O
bunch	O
of	O
dataframes	O
.	O

Your	O
particular	O
problem	O
might	O
be	O
more	O
cleanly	O
(	O
and	O
quickly	O
?	O
)	O
solved	O
with	O
a	O
cross-product	O
solution	O
(	O
#URL	O
)	O
,	O
but	O
I'd	O
have	O
to	O
think	O
more	O
about	O
how	O
something	O
like	O
this	O
would	O
apply	O
.	O

I	O
think	O
split	O
is	O
a	O
little	O
more	O
clear	O
than	O
regex	O
but	O
you	O
can	O
`	O
apply	O
`	O
any	O
function	O
you	O
choose	O
to	O
a	O
series	O
.	O

#CODE	O

Sorry	O
,	O
I'm	O
not	O
sure	O
about	O
that	O
.	O

I	O
misread	O
and	O
thought	O
the	O
data	O
was	O
more	O
regular	O
.	O

Perhaps	O
resample()	B-API
and	O
then	O
apply	O
the	O
above	O
method	O
?	O

If	O
your	O
data	O
is	O
consistently	O
spaced	O
except	O
for	O
some	O
missing	O
rows	O
,	O
then	O
resampling	O
ought	O
to	O
work	O
fine	O
and	O
be	O
easy	O
to	O
do	O
.	O

I'm	O
sure	O
you	O
could	O
do	O
something	O
with	O
groupby	B-API
but	O
that	O
could	O
be	O
a	O
lot	O
slower	O
.	O

Maybe	O
someone	O
else	O
will	O
have	O
a	O
better	O
idea	O
though	O
.	O

Where	O
the	O
"	O
0	O
"	O
column	O
is	O
no	O
longer	O
the	O
index	O
for	O
rows	O
.	O

Then	O
we	O
can	O
apply	O
`	O
df1	O
=	O
df1	O
[	O
df1	O
[	O
3	O
]	O
.isin	B-API
(	O
df2	O
[	O
0	O
])]`	O
.	O

NOTE	O
:	O
application	O
of	O
`	O
df1	O
=	O
df1	O
[	O
df1	O
[	O
3	O
]	O
==	O
df2	O
[	O
0	O
]]`	O
will	O
raise	O
the	O
error	O
message	O
`	O
Series	O
lengths	O
must	O
match	O
to	O
compare	O
`	O

2	O
ways	O
,	O
define	O
a	O
func	O
and	O
call	O
apply	O
#CODE	O

@USER	O
you	O
can	O
upvote	O
too	O
;)	O
,	O
the	O
thing	O
to	O
take	O
from	O
this	O
is	O
to	O
avoid	O
loops	O
and	O
using	O
apply	O
unless	O
it	O
is	O
not	O
possible	O
,	O
what	O
you	O
want	O
to	O
do	O
is	O
to	O
find	O
if	O
you	O
vectorise	O
your	O
operation	O
,	O
that	O
is	O
perform	O
your	O
operation	O
on	O
the	O
entire	O
dataframe	B-API
or	O
series	O
rather	O
than	O
a	O
row	O
at	O
a	O
time	O
.	O

apply	O
is	O
just	O
a	O
loop	O
and	O
should	O
be	O
avoided	O
where	O
possible	O
,	O
your	O
solution	O
is	O
fine	O
,	O
there	O
are	O
many	O
ways	O
of	O
doing	O
what	O
you	O
want	O
.	O

It	O
depends	O
on	O
the	O
size	O
of	O
the	O
data	O
,	O
your	O
sample	O
code	O
could	O
be	O
simplified	O
:	O
`	O
df.loc	B-API
[	O
df	O
[	O
'	O
C	O
']	O
==	O
'	O
a	O
'	O
,	O
'	O
new	O
']	O
=	O
df	O
[	O
'	O
A	O
']`	O
and	O
likewise	O
for	O
the	O
other	O
condition	O

You	O
create	O
a	O
lookup	O
function	O
and	O
call	O
`	O
apply	O
`	O
on	O
your	O
dataframe	B-API
row-wise	O
,	O
this	O
isn't	O
very	O
efficient	O
for	O
large	O
dfs	O
though	O
#CODE	O

There	O
is	O
a	O
built	O
in	O
`	O
lookup	O
`	O
function	O
that	O
can	O
handle	O
this	O
type	O
of	O
situation	O
(	O
looks	O
up	O
by	O
row	O
/	O
column	O
)	O
.	O

I	O
don't	O
know	O
how	O
optimized	O
it	O
is	O
,	O
but	O
may	O
be	O
faster	O
than	O
the	O
apply	O
solution	O
.	O

#CODE	O

On	O
the	O
toy	O
dataset	O
apply	O
takes	O
470us	O
,	O
lookup	O
takes	O
531us	O

Hmm	O
for	O
some	O
reason	O
timeit	O
gets	O
a	O
memory	O
error	O
when	O
I	O
try	O
this	O
on	O
even	O
a	O
modest	O
sized	O
df	O
of	O
say	O
4000	O
rows	O
,	O
for	O
400	O
rows	O
I	O
get	O
8.17ms	O
using	O
apply	O
and	O
3.05ms	O
using	O
lookup	O
,	O
so	O
I	O
expect	O
lookup	O
to	O
scale	O
better	O

You	O
can	O
create	O
a	O
function	O
that	O
determines	O
if	O
the	O
value	O
column	O
ends	O
in	O
`'	O
_regen	O
'`	O
and	O
then	O
apply	O
it	O
your	O
values	O
:	O
#CODE	O

Yes	O
but	O
how	O
to	O
you	O
actually	O
pass	O
the	O
arguments	O
within	O
the	O
apply	O
function	O
.	O

You	O
can't	O
simply	O
have	O
a.loc	O
[	O
a	O
[	O
'	O
value	O
']	O
.apply	B-API
(	O
has_substring	O
(	O
s	O
,	O
"	O
regen	O
"))	O
,	O
'	O
key	O
']	O
+=	O
'	O
_regen	O
'	O
.	O

Within	O
the	O
apply	O
function	O
arguments	O
are	O
passed	O
with	O
the	O
"	O
args=	O
"	O
parameter	O
,	O
something	O
like	O
this	O
a.loc	O
[	O
a	O
[	O
'	O
value	O
']	O
.apply	B-API
(	O
func=has_substring	O
args=	O
"	O
regen	O
"	O
,	O
'	O
key	O
']	O
+=	O
'	O
_regen	O
'	O
How	O
ever	O
I	O
can't	O
get	O
this	O
to	O
work	O
.	O

What	O
you	O
have	O
will	O
work	O
,	O
args	O
just	O
needs	O
to	O
be	O
an	O
array	O
within	O
the	O
apply	O
function	O
:	O
`	O
a.loc	O
[	O
a	O
[	O
'	O
value	O
']	O
.apply	B-API
(	O
has_substring	O
,	O
args	O
=[	O
'	O
regen	O
'])	O
,	O
'	O
key	O
']	O
+=	O
'	O
_regen	O
'`	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
check	O
whether	O
each	O
row	O
satisfy	O
the	O
condition	O
,	O
and	O
use	O
the	O
resulting	O
boolean	O
Series	O
to	O
do	O
the	O
slicing	O
:	O
#CODE	O

Thank	O
you	O
!	O

`	O
apply	O
`	O
does	O
the	O
trick	O
.	O

I	O
need	O
the	O
try	O
statement	O
to	O
filter	O
some	O
NaNs	O
...	O

1st	O
problem	O
:	O
I	O
couldnt	O
figure	O
out	O
how	O
to	O
use	O
'	O
apply	O
'	O
or	O
something	O
instead	O
of	O
the	O
for	O
loop	O
.	O

Does	O
anyone	O
know	O
a	O
more	O
efficient	O
way	O
?	O

Second	O
problem	O
:	O
#CODE	O

I	O
use	O
`	O
np.vectorize	B-API
`	O
to	O
apply	O
this	O
function	O
on	O
a	O
`	O
DataFrame	B-API
`	O
-	O
`	O
dataFrame	B-API
`	O
-	O
that	O
has	O
about	O
22	O
million	O
rows	O
.	O

#CODE	O

plz	O
show	O
the	O
related	O
code	O
where	O
you	O
apply	O
`	O
getData	B-API
`	O
over	O
the	O
data-frame	O

Warning	O
:	O
In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O

@USER	O
I	O
agree	O
that	O
this	O
should	O
raise	O
for	O
now	O
.	O

I	O
wasn't	O
sure	O
if	O
I	O
was	O
using	O
this	O
method	O
wrong	O
but	O
an	O
obvious	O
workaround	O
would	O
be	O
to	O
iterate	O
through	O
each	O
column	O
and	O
apply	O
fillna()	B-API
with	O
axis=0	O
.	O

Would	O
it	O
be	O
so	O
hard	O
to	O
incorporate	O
this	O
for	O
when	O
the	O
method	O
is	O
applied	O
to	O
dataframes	O
?	O

Hi	O
CT	O
--	O
so	O
a	O
bit	O
of	O
a	O
problem	O
/	O
update	O
that	O
I	O
am	O
struggling	O
with	O
here	O
.	O

This	O
solution	O
works	O
..	O
sorta	O
.	O

I	O
tried	O
to	O
apply	O
this	O
solution	O
to	O
my	O
larger	O
data	O
frame	O
and	O
at	O
first	O
glance	O
it	O
worked	O
wonders	O
,	O
but	O
now	O
taking	O
a	O
closer	O
look	O
there	O
are	O
several	O
instances	O
of	O
"	O
looped	O
phrases	O
"	O
that	O
slipped	O
through	O
the	O
cracks	O
.	O

Any	O
idea	O
why	O
this	O
could	O
be	O
?	O

You	O
could	O
sort	O
the	O
values	O
in	O
columns	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O
so	O
that	O
for	O
each	O
row	O
the	O
value	O
in	O
`	O
A	O
`	O
is	O
less	O
than	O
or	O
equal	O
to	O
the	O
value	O
in	O
`	O
B	O
`	O
.	O

Once	O
the	O
values	O
are	O
ordered	O
,	O
then	O
you	O
could	O
apply	O
`	O
groupby-transform-max	O
`	O
as	O
usual	O
:	O
#CODE	O

I	O
first	O
tried	O
using	O
apply	O
but	O
it's	O
not	O
possible	O
to	O
return	O
multiple	O
Series	O
as	O
far	O
as	O
I	O
know	O
.	O
iterrows	B-API
seems	O
to	O
be	O
the	O
trick	O
.	O

But	O
the	O
code	O
below	O
gives	O
me	O
an	O
empty	O
dataframe	B-API
...	O

#CODE	O

no	O
need	O
for	O
apply	O
;	O
you	O
can	O
directly	O
subtract	O
a	O
Timestamp	O
from	O
a	O
column	O
to	O
yield	O
a	O
timedelta64	O
dtype	B-API

Desired	O
output	O
-	O
A	O
new	O
DataFrame	B-API
of	O
grouped	O
/	O
aggregated	O
coordinates	O
in	O
an	O
array	O
so	O
that	O
I	O
can	O
apply	O
a	O
fuction	O
to	O
each	O
array	O
:	O
#CODE	O

Distance	O
calculation	O
I	O
wish	O
to	O
apply	O
...	O

#CODE	O

note	O
that	O
to	O
apply	O
your	O
distance	O
function	O
you	O
have	O
to	O
do	O
:	O
#CODE	O

One	O
method	O
could	O
be	O
to	O
apply	O
a	O
lambda	O
to	O
the	O
column	O
and	O
use	O
the	O
boolean	O
index	O
returned	O
this	O
to	O
index	O
against	O
:	O
#CODE	O

FYI	O
-	O
no	O
need	O
to	O
use	O
apply	O
here	O
(	O
tz_localize	B-API
/	O
convert	O
are	O
methods	O
on	O
index	O
and	O
series	O
)	O

Thanks	O
@USER	O
.	O

I	O
tried	O
that	O
in	O
the	O
past	O
without	O
luck	O
.	O

I	O
opened	O
this	O
question	O
separately	O
:	O
[	O
Unable	O
to	O
apply	O
methods	O
on	O
timestamps	O
in	O
Pandas	O
using	O
Series	O
built-ins	O
]	O
(	O
#URL	O
)	O

Unable	O
to	O
apply	O
methods	O
on	O
timestamps	O
using	O
Series	O
built-ins	O

In	O
norm.ppf	O
(	O
probability	O
,	O
mean	O
,	O
standard	O
deviation	O
)	O
so	O
10	O
is	O
mean	O
and	O
5	O
is	O
std	O
.	O

My	O
code	O
will	O
apply	O
the	O
norm.ppf	O
for	O
every	O
element	O
of	O
lts	O
.	O

Using	O
Apply	O
Map	O
to	O
Remove	O
Unwanted	O
Phrases	O
from	O
DF	O
(	O
Pandas	O
,	O
Python	O
3	O
)	O

What	O
do	O
you	O
mean	O
by	O
"	O
remove	O
cells	O
"	O
?	O

I	O
think	O
you	O
mean	O
remove	O
rows	O
right	O
?	O

Then	O
this	O
will	O
be	O
an	O
`	O
apply	O
`	O
since	O
you'll	O
consider	O
things	O
rowwise	O
.	O

#CODE	O

You	O
can	O
vectorize	B-API
'	O
Words1	O
'	O
into	O
a	O
series	O
and	O
then	O
apply	O
a	O
regex	O
:	O
#CODE	O

The	O
second	O
part	O
of	O
my	O
code	O
is	O
function	O
I	O
am	O
trying	O
to	O
apply	O
#CODE	O

Pandas	O
Groupby	B-API
Apply	O
Function	O
to	O
Level	O

Assuming	O
you	O
have	O
a	O
series	O
`	O
s	O
`	O
,	O
with	O
a	O
MultiIndex	O
andthe	O
two	O
levels	O
you	O
have	O
shown	O
,	O
you	O
can	O
groupby	B-API
the	O
first	O
level	O
and	O
apply	O
the	O
`'	O
first	O
'`	O
/	O
`'	O
last	O
'`	O
aggregations	O
to	O
get	O
the	O
values	O
you	O
want	O
.	O

#CODE	O

What	O
have	O
you	O
tried	O
here	O
?	O

You	O
could	O
apply	O
your	O
function	O
row-wise	O
which	O
would	O
look	O
something	O
like	O
`	O
df	O
[	O
'	O
ls	O
']	O
=	O
df.apply	B-API
(	O
lambda	O
row	O
:	O
checker	O
(	O
x.Review	O
)	O
,	O
axis=1	O
)`	O
but	O
ideally	O
you	O
want	O
to	O
vectorise	O
your	O
function	O
so	O
that	O
it	O
can	O
be	O
done	O
on	O
the	O
whole	O
column	O
,	O
at	O
the	O
moment	O
your	O
function	O
looks	O
incomplete	O
so	O
it's	O
hard	O
to	O
suggest	O
what	O
improvements	O
can	O
be	O
made	O

The	O
easiest	O
way	O
would	O
be	O
to	O
specific	O
a	O
single	O
column	O
of	O
the	O
groupby	B-API
(	O
doesn't	O
matter	O
which	O
one	O
)	O
,	O
and	O
use	O
`	O
transform	O
`	O
instead	O
of	O
`	O
apply	O
`	O
,	O
like	O
this	O
.	O

#CODE	O

The	O
reason	O
this	O
didn't	O
work	O
while	O
your	O
first	O
did	O
is	O
that	O
your	O
function	O
returns	O
a	O
single	O
value	O
,	O
rather	O
than	O
an	O
array	O
of	O
values	O
,	O
so	O
`	O
transform	O
`	O
broadcasts	O
back	O
to	O
the	O
original	O
frame's	O
shape	O
,	O
while	O
`	O
apply	O
`	O
is	O
more	O
flexible	O
and	O
generally	O
passes	O
back	O
whatever	O
shape	O
your	O
function	O
returns	O
.	O

If	O
you	O
just	O
want	O
the	O
column	O
headings	O
,	O
you	O
can	O
apply	O
the	O
mask	O
to	O
itself	O
.	O

#CODE	O

But	O
what	O
if	O
I	O
want	O
to	O
get	O
the	O
percentage	O
of	O
the	O
vote	O
each	O
candidate	O
got	O
?	O

Would	O
I	O
have	O
to	O
apply	O
some	O
sort	O
of	O
function	O
on	O
each	O
data	O
object	O
?	O

Ideally	O
I	O
would	O
like	O
the	O
final	O
data	O
object	O
to	O
look	O
like	O
:	O
#CODE	O

We	O
can	O
perform	O
a	O
groupby	B-API
on	O
'	O
A	O
'	O
and	O
then	O
apply	O
a	O
function	O
(	O
lambda	O
in	O
this	O
case	O
)	O
where	O
we	O
join	O
the	O
desired	O
delimiter	O
`	O
;	O
`	O
with	O
a	O
list	O
comprehension	O
of	O
the	O
B	O
values	O
.	O

In	O
Python	O
you	O
can	O
join	O
things	O
by	O
using	O
`	O
some_delimiter.join	O
(	O
things_you_want_to_join	O
)`	O
,	O
e.g.	O
`'	O
,	O
'	O
.join	B-API
(	O
"	O
abc	O
")	O
==	O
'	O
a	O
,	O
b	O
,	O
c	O
'`	O
.	O

We	O
can	O
apply	O
that	O
to	O
the	O
`	O
B	O
`	O
column	O
after	O
grouping	O
on	O
`	O
A	O
`	O
:	O
#CODE	O

I	O
wouldn't	O
worry	O
about	O
it	O
,	O
it	O
seems	O
ok	O
but	O
I	O
think	O
you	O
have	O
to	O
show	O
what	O
you've	O
tried	O
at	O
the	O
very	O
least	O
plus	O
any	O
code	O
and	O
approaches	O
,	O
it	O
would	O
help	O
also	O
to	O
show	O
what	O
you've	O
tried	O
that	O
works	O
on	O
simple	O
data	O
i.e.	O
not	O
in	O
a	O
pandas	O
dataframe	B-API
and	O
are	O
asking	O
how	O
to	O
apply	O
that	O
to	O
pandas	O
would	O
probably	O
help	O
.	O

I	O
guess	O
at	O
this	O
point	O
this	O
looks	O
like	O
an	O
open	O
exercise	O
without	O
demonstrating	O
your	O
efforts	O

since	O
,	O
per	O
the	O
docs	O
,	O
"	O
[	O
a	O
]	O
dditional	O
keyword	O
arguments	O
[	O
to	O
`	O
apply	O
`]	O
will	O
be	O
passed	O
as	O
keywords	O
to	O
the	O
function	O
"	O
.	O

hmmm	O
this	O
gets	O
me	O
sort	O
of	O
the	O
way	O
here	O
but	O
not	O
quite	O
--	O
how	O
can	O
I	O
apply	O
that	O
if	O
I	O
need	O
to	O
actually	O
CALL	O
the	O
dataframe	B-API
in	O
the	O
arguement	O
?	O

Edited	O
OP	O
above	O

One	O
way	O
would	O
be	O
to	O
create	O
a	O
custom	O
apply	O
function	O
and	O
check	O
each	O
datum's	O
YMD	O
and	O
look	O
up	O
the	O
corresponding	O
low	O
frequency	O
data	O
,	O
but	O
that	O
seems	O
pretty	O
inefficient	O
.	O

It	O
does	O
what	O
you	O
describe	O
,	O
go	O
row-wise	O
(	O
so	O
apply	O
over	O
`	O
axis=1	O
`)	O
along	O
`	O
df	O
`	O
and	O
use	O
the	O
entries	O
as	O
index	O
for	O
selecting	O
in	O
`	O
P	O
`	O
.	O

Parallelize	O
apply	O
after	O
pandas	O
groupby	B-API

I	O
have	O
used	O
rosetta.parallel.pandas_easy	O
to	O
parallelize	O
apply	O
after	O
group	O
by	O
,	O
for	O
example	O
:	O
#CODE	O

I	O
have	O
a	O
hack	O
I	O
use	O
for	O
getting	O
parallelization	O
in	O
Pandas	O
.	O

I	O
break	O
my	O
dataframe	B-API
into	O
chunks	O
,	O
put	O
each	O
chunk	O
into	O
the	O
element	O
of	O
a	O
list	O
,	O
and	O
then	O
use	O
ipython's	O
parallel	O
bits	O
to	O
do	O
a	O
parallel	O
apply	O
on	O
the	O
list	O
of	O
dataframes	O
.	O

Then	O
I	O
put	O
the	O
list	O
back	O
together	O
using	O
pandas	O
`	O
concat	O
`	O
function	O
.	O

This	O
is	O
not	O
generally	O
applicable	O
,	O
however	O
.	O

It	O
works	O
for	O
me	O
because	O
the	O
function	O
I	O
want	O
to	O
apply	O
to	O
each	O
chunk	O
of	O
the	O
dataframe	B-API
takes	O
about	O
a	O
minute	O
.	O

And	O
the	O
pulling	O
apart	O
and	O
putting	O
together	O
of	O
my	O
data	O
does	O
not	O
take	O
all	O
that	O
long	O
.	O

So	O
this	O
is	O
clearly	O
a	O
kludge	O
.	O

With	O
that	O
said	O
,	O
here's	O
an	O
example	O
.	O

I'm	O
using	O
Ipython	O
notebook	O
so	O
you'll	O
see	O
`	O
%%time	O
`	O
magic	O
in	O
my	O
code	O
:	O
#CODE	O

write	O
a	O
silly	O
function	O
to	O
apply	O
to	O
our	O
data	O
#CODE	O

I	O
will	O
try	O
this	O
with	O
my	O
code	O
,	O
thank	O
you	O
.	O

Can	O
you	O
explain	O
to	O
me	O
why	O
apply	O
does	O
not	O
automatically	O
parallelize	O
operations	O
?	O

It	O
seems	O
like	O
the	O
whole	O
benefit	O
of	O
having	O
the	O
apply	O
function	O
is	O
to	O
avoid	O
looping	O
,	O
but	O
if	O
it	O
is	O
not	O
doing	O
that	O
with	O
these	O
groups	O
,	O
what	O
gives	O
?	O

There's	O
a	O
long	O
story	O
about	O
parallelization	O
being	O
hard	O
in	O
Python	O
because	O
of	O
the	O
GIL	O
.	O

Keep	O
in	O
mind	O
that	O
apply	O
is	O
usually	O
syntactic	O
sugar	O
and	O
underneath	O
it's	O
doing	O
the	O
implied	O
loop	O
.	O

Using	O
parallelization	O
is	O
somewhat	O
tricky	O
because	O
there	O
are	O
runtime	O
costs	O
to	O
parallelization	O
which	O
sometimes	O
negate	O
the	O
benefits	O
of	O
parallelization	O
.	O

By	O
doing	O
small	O
modification	O
to	O
the	O
function	O
it	O
can	O
be	O
made	O
to	O
return	O
the	O
hierarchical	O
index	O
that	O
the	O
regular	O
apply	O
returns	O
:	O

pandas	O
:	O
how	O
to	O
apply	O
scipy.stats	O
test	O
on	O
a	O
groupby	B-API
object	O
?	O

How	O
to	O
use	O
groupby	B-API
to	O
apply	O
multiple	O
functions	O
to	O
multiple	O
columns	O
in	O
Pandas	O
?	O

Since	O
you	O
are	O
aggregating	O
each	O
grouped	O
column	O
into	O
one	O
value	O
,	O
you	O
can	O
use	O
`	O
agg	O
`	O
instead	O
of	O
`	O
apply	O
`	O
.	O

The	O
`	O
agg	O
`	O
method	O
can	O
take	O
a	O
list	O
of	O
functions	O
as	O
input	O
.	O

The	O
functions	O
will	O
be	O
applied	O
to	O
each	O
column	O
:	O
#CODE	O

ok	O
,	O
I	O
can	O
combine	O
the	O
function	O
`	O
value_counts	B-API
`	O
and	O
`	O
groupby	B-API
`	O
through	O
`	O
apply	O
`	O
function	O
.	O

Thank	O
you	O
very	O
much	O
!	O

@USER	O
I	O
tried	O
with	O
a	O
100,000	O
row	O
dataframe	B-API
and	O
the	O
difference	O
becomes	O
11.4ms	O
vs	O
.	O

8.9ms	O
for	O
my	O
implementation	O
versus	O
yours	O
.	O

There	O
is	O
probably	O
some	O
battle	O
/	O
tradeoff	O
between	O
the	O
vectorised	O
`	O
value_counts	B-API
`	O
and	O
calling	O
`	O
apply	O
`	O
,	O
there	O
maybe	O
a	O
better	O
way	O
but	O
I've	O
not	O
figured	O
out	O
a	O
better	O
way	O
yet	O

Panda's	O
DataFrame	B-API
dup	O
each	O
row	O
,	O
apply	O
changes	O
to	O
the	O
duplicate	O
and	O
combine	O
back	O
into	O
a	O
dataframe	B-API

I	O
need	O
to	O
create	O
a	O
duplicate	O
for	O
each	O
row	O
in	O
a	O
dataframe	B-API
,	O
apply	O
some	O
basic	O
operations	O
to	O
the	O
duplicate	O
row	O
and	O
then	O
combine	O
these	O
dupped	O
rows	O
along	O
with	O
the	O
originals	O
back	O
into	O
a	O
dataframe	B-API
.	O

I'm	O
trying	O
to	O
use	O
apply	O
for	O
it	O
and	O
the	O
print	O
shows	O
that	O
it's	O
working	O
correctly	O
but	O
when	O
I	O
return	O
these	O
2	O
rows	O
from	O
the	O
function	O
and	O
the	O
dataframe	B-API
is	O
assembled	O
I	O
get	O
an	O
error	O
message	O
"	O
cannot	O
copy	O
sequence	O
with	O
size	O
7	O
to	O
array	O
axis	O
with	O
dimension	O
2	O
"	O
.	O

It	O
is	O
as	O
if	O
it's	O
trying	O
to	O
fit	O
these	O
2	O
new	O
rows	O
back	O
into	O
the	O
original	O
1	O
row	O
slot	O
.	O

Any	O
insight	O
on	O
how	O
I	O
can	O
achieve	O
it	O
within	O
apply	O
(	O
and	O
not	O
by	O
iterating	O
over	O
every	O
row	O
in	O
a	O
loop	O
)	O
?	O

#CODE	O

The	O
`	O
apply	O
`	O
function	O
of	O
pandas	O
operates	O
along	O
an	O
axis	O
.	O

With	O
`	O
axis=1	O
`	O
,	O
it	O
operates	O
along	O
every	O
row	O
.	O

To	O
do	O
something	O
like	O
what	O
you're	O
trying	O
to	O
do	O
,	O
think	O
of	O
how	O
you	O
would	O
construct	O
a	O
new	O
row	O
from	O
your	O
existing	O
row	O
.	O

Something	O
like	O
this	O
should	O
work	O
:	O
#CODE	O

But	O
I	O
don't	O
understand	O
how	O
to	O
apply	O
it	O
to	O
my	O
case	O
.	O

Any	O
idea	O
how	O
to	O
solve	O
this	O
problem	O
in	O
a	O
efficient	O
pandas	O
approach	O
?	O

(	O
using	O
apply	O
,	O
map	O
or	O
rolling	O
?	O
)	O

What	O
you	O
needed	O
to	O
do	O
from	O
the	O
answer	O
you	O
linked	O
to	O
was	O
to	O
turn	O
the	O
index	O
into	O
a	O
series	O
so	O
you	O
can	O
then	O
call	O
apply	O
on	O
it	O
.	O

The	O
other	O
key	O
thing	O
here	O
is	O
that	O
you	O
also	O
have	O
to	O
index	O
the	O
constructed	O
series	O
the	O
same	O
as	O
your	O
df	O
index	O
as	O
the	O
default	O
is	O
to	O
just	O
create	O
an	O
index	O
from	O
scratch	O
like	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
...	O

#CODE	O

You	O
can	O
apply	O
`	O
merge	O
`	O
to	O
a	O
list	O
of	O
DataFrames	O
using	O
reduce	O
:	O
#CODE	O

Probably	O
the	O
simplest	O
solution	O
is	O
to	O
use	O
the	O
APPLYMAP	B-API
or	O
APPLY	O
fucntions	O
which	O
applies	O
the	O
function	O
to	O
every	O
data	O
value	O
in	O
the	O
entire	O
data	O
set	O
.	O

Apply	O
Docs	O

So	O
I	O
have	O
data	O
that	O
I	O
am	O
outputting	O
to	O
an	O
excel	O
file	O
using	O
pandas	O
'	O
ExcelWriter	O
.	O

After	O
the	O
entire	O
data	O
is	O
outputted	O
to	O
the	O
Excel	O
file	O
,	O
what	O
is	O
the	O
easiest	O
way	O
to	O
apply	O
conditional	O
formatting	O
to	O
it	O
programmatically	O
using	O
Python	O
?	O

After	O
the	O
data	O
is	O
written	O
,	O
I	O
need	O
a	O
way	O
to	O
apply	O
the	O
conditional	O
formatting	O
using	O
python	O
.	O

To	O
make	O
it	O
simple	O
,	O
I	O
want	O
the	O
colors	O
to	O
be	O
darker	O
shades	O
of	O
blue	O
the	O
more	O
positive	O
(	O
>	O
0	O
)	O
the	O
values	O
are	O
and	O
to	O
be	O
darker	O
shades	O
of	O
red	O
the	O
more	O
negative	O
the	O
values	O
are	O
(	O
0	O
)	O
and	O
the	O
cell	O
to	O
be	O
white	O
if	O
the	O
value	O
is	O
0	O
.	O

Here	O
is	O
an	O
example	O
of	O
how	O
to	O
apply	O
a	O
conditional	O
format	O
to	O
the	O
XlsxWriter	O
Excel	O
file	O
created	O
by	O
Pandas	O
:	O
#CODE	O

I	O
need	O
to	O
split	O
a	O
dataframe	B-API
into	O
groups	O
,	O
and	O
for	O
those	O
groups	O
that	O
have	O
odd	O
number	O
of	O
lines	O
,	O
i	O
need	O
to	O
pull	O
in	O
the	O
first	O
line	O
whose	O
column	O
matches	O
a	O
certain	O
condition	O
and	O
then	O
i	O
need	O
to	O
assemble	O
back	O
all	O
such	O
first	O
lines	O
(	O
so	O
only	O
the	O
first	O
ones	O
in	O
odd	O
numbered	O
groups	O
matching	O
a	O
condition	O
)	O
.	O

I	O
can	O
do	O
it	O
in	O
a	O
loop	O
like	O
below	O
(	O
it	O
works	O
)	O
but	O
can't	O
rework	O
it	O
into	O
a	O
groupby	B-API
with	O
apply	O
.	O

Could	O
you	O
help	O
?	O

#CODE	O

Interesting	O
problem	O
which	O
I	O
would	O
solve	O
by	O
writing	O
a	O
function	O
which	O
you	O
then	O
pass	O
to	O
apply	O
.	O

Note	O
that	O
when	O
calling	O
passing	O
a	O
function	O
to	O
apply	O
,	O
the	O
fist	O
argument	O
passed	O
is	O
the	O
DataFrame	B-API
itself	O
and	O
this	O
is	O
done	O
so	O
automatically	O
.	O

That	O
is	O
why	O
you	O
don't	O
need	O
to	O
specify	O
the	O
'	O
df	O
'	O
argument	O
when	O
passing	O
the	O
function	O
to	O
apply	O
.	O

In	O
fact	O
if	O
you	O
do	O
you	O
get	O
an	O
error	O
saying	O
you	O
have	O
passed	O
too	O
many	O
arguments	O
.	O

Also	O
somewhat	O
strangely	O
in	O
my	O
view	O
when	O
passing	O
the	O
function	O
the	O
arguments	O
are	O
supplied	O
after	O
commas	O
rather	O
than	O
in	O
parenthese	O
.	O

This	O
I	O
find	O
confusing	O
to	O
look	O
at	O
,	O
but	O
it	O
is	O
what	O
it	O
is	O
....	O

Is	O
this	O
expected	O
?	O

I	O
know	O
I	O
can	O
apply	O
`	O
dropna()	B-API
`	O
on	O
this	O
output	O
,	O
but	O
isn't	O
the	O
above	O
already	O
supposed	O
to	O
filter	O
out	O
the	O
values	O
I	O
ask	O
for	O
?	O

(	O
it	O
typically	O
works	O
on	O
dataframes	O
wihtout	O
having	O
to	O
call	O
`	O
dropna	B-API
`)	O

I	O
use	O
this	O
to	O
get	O
the	O
vote	O
totals	O
and	O
I	O
apply	O
a	O
function	O
to	O
the	O
group	O
to	O
get	O
the	O
number	O
of	O
precincts	O
reporting	O
and	O
the	O
total	O
number	O
.	O

#CODE	O

I	O
think	O
you	O
can	O
use	O
the	O
select	O
method	O
to	O
apply	O
a	O
filter	O
to	O
the	O
index	O
:	O
`	O
df_raw.select	O
(	O
lambda	O
r	O
:	O
r.lower	O
in	O
my_list_of_rows	O
)`	O

Compare	O
what	O
happens	O
when	O
you	O
call	O
apply	O
with	O
`	O
mean	O
`	O
:	O
#CODE	O

How	O
do	O
I	O
define	O
the	O
function	O
which	O
calculates	O
the	O
percentage	O
columns	O
and	O
how	O
to	O
apply	O
that	O
function	O
to	O
my	O
two	O
columns	O
namely	O
`	O
Qd	O
(	O
cb	O
)`	O
and	O
`	O
Autopass	O
(	O
cb	O
)`	O
to	O
give	O
me	O
additional	O
calculated	O
columns	O

How	O
to	O
apply	O
a	O
custom	O
formula	O
over	O
a	O
group	O
element	O
in	O
a	O
grouped.apply()	O
.unstack()	B-API
method	O
?	O

Looks	O
like	O
when	O
you	O
group	O
the	O
dataframe	B-API
it	O
returns	O
a	O
bunch	O
of	O
series	O
due	O
to	O
your	O
original	O
only	O
having	O
two	O
columns	O
.	O

`	O
applymap	B-API
`	O
is	O
a	O
Dataframe	B-API
method	O
that	O
applies	O
a	O
method	O
element	O
wise	O
.	O

It	O
looks	O
like	O
you	O
are	O
looking	O
for	O
apply	O
in	O
this	O
instance	O
.	O

Try	O
the	O
following	O
...	O

#CODE	O

and	O
then	O
apply	O
a	O
method	O
to	O
the	O
groups	O
or	O
whatever	O
you	O
want	O
to	O
do	O
.	O

If	O
you	O
just	O
want	O
these	O
groups	O
separated	O
call	O
`	O
grouped.groups	O
`	O

If	O
you	O
want	O
to	O
apply	O
additional	O
filtering	O
,	O
with	O
this	O
index	O
,	O
you	O
can	O
even	O
select	O
a	O
specific	O
year	O
using	O
`	O
df	O
[	O
'	O
2013	O
']`	O
.	O

It's	O
still	O
quite	O
misleading	O
.	O

Imagine	O
if	O
this	O
happened	O
when	O
you	O
called	O
`	O
to_dict	B-API
`	O
.	O

You	O
could	O
just	O
as	O
well	O
say	O
that	O
you	O
are	O
"	O
leaving	O
Pandas	O
"	O
and	O
going	O
back	O
to	O
"	O
pure	O
Python	O
"	O
,	O
and	O
then	O
apply	O
some	O
type	O
conversion	O
on	O
the	O
values	O
that	O
will	O
be	O
`	O
dict	O
`	O
values	O
.	O

Then	O
`	O
o.head()	O
.datetime	O
.to_dict()	B-API
[	O
0	O
]`	O
would	O
be	O
different	O
than	O
`	O
o.head()	O
.datetime	O
[	O
0	O
]`	O
.	O

In	O
any	O
of	O
these	O
cases	O
,	O
if	O
you	O
are	O
asking	O
for	O
some	O
iterable	O
thing	O
that	O
has	O
values	O
in	O
it	O
as	O
a	O
sequence	O
(	O
whether	O
dict	O
,	O
Series	O
,	O
or	O
ndarray	B-API
)	O
,	O
you	O
expect	O
the	O
entries	O
to	O
be	O
references	O
to	O
a	O
single	O
value	O
in	O
memory	O
.	O

You	O
don't	O
expect	O
to	O
get	O
a	O
different	O
value	O
.	O

To	O
do	O
this	O
,	O
you	O
would	O
group	O
the	O
data	O
and	O
use	O
the	O
`	O
apply	O
`	O
method	O
to	O
apply	O
a	O
function	O
that	O
does	O
the	O
above	O
.	O

And	O
then	O
pass	O
that	O
function	O
to	O
`	O
apply	O
`	O
using	O
the	O
groupby	B-API
object	O
as	O
follows	O
:	O
#CODE	O

In	O
Pandas	O
,	O
how	O
to	O
apply	O
2	O
custom	O
formulas	O
in	O
a	O
groupby.agg()	O
method	O
?	O

The	O
apply	O
functionality	O
is	O
probably	O
what	O
your	O
are	O
looking	O
for	O
:	O
#CODE	O

How	O
to	O
concatenate	O
within	O
'	O
apply	O
'	O
on	O
a	O
grouped	O
object	O

I	O
have	O
a	O
dataframe	B-API
where	O
I	O
wish	O
to	O
edit	O
the	O
information	O
in	O
columns	O
a	O
and	O
b	O
,	O
within	O
groups	O
defined	O
by	O
columns	O
d	O
and	O
e	O
.	O

The	O
procedure	O
to	O
apply	O
to	O
a	O
and	O
b	O
is	O
:	O
set	O
all	O
rows	O
equal	O
to	O
the	O
row	O
where	O
c	O
is	O
a	O
minimum	O
.	O

Columns	O
c	O
,	O
d	O
and	O
e	O
must	O
remain	O
unchanged	O
.	O

I	O
am	O
using	O
an	O
apply	O
function	O
on	O
a	O
grouped	O
object	O
.	O

I	O
use	O
'	O
reindex	O
'	O
to	O
change	O
a	O
and	O
b	O
.	O

The	O
difficulty	O
comes	O
with	O
concatenating	O
,	O
"	O
cannot	O
concatenate	O
a	O
non-NDFrame	O
object	O
"	O

Either	O
apply	O
a	O
regex	O
pattern	O
or	O
apply	O
a	O
function	O
that	O
returns	O
the	O
characters	O
you	O
want	O
,	O
even	O
if	O
length	O
did	O
work	O
,	O
it'll	O
just	O
return	O
the	O
length	O
of	O
each	O
row	O
which	O
is	O
no	O
different	O
to	O
doing	O
nothing	O
.	O

You've	O
not	O
clarified	O
the	O
requirement	O
,	O
are	O
you	O
just	O
wanting	O
numbers	O
only	O
?	O

Is	O
the	O
number	O
length	O
fixed	O
etc	O
..	O

docs	O
,	O
so	O
I'd	O
use	O
numpy	O
to	O
get	O
a	O
"	O
windowing	O
"	O
view	O
on	O
the	O
array	O
and	O
apply	O
a	O
ufunc	O

Group	O
this	O
new	O
dataframe	B-API
on	O
ID	O
,	O
and	O
use	O
the	O
`	O
shift()	B-API
`	O
method	O
to	O
get	O
the	O
differences	O
in	O
the	O
stock	O
prices	O
using	O
the	O
`	O
apply	O
`	O
method	O

No	O
,	O
of	O
that	O
you'd	O
have	O
to	O
apply	O
a	O
regex	O
or	O
a	O
lambda	O
to	O
test	O
each	O
word	O
for	O
that	O
character	O
and	O
strip	O
it	O

You	O
can	O
apply	O
a	O
post-processing	O
step	O
that	O
first	O
converts	O
the	O
string	O
to	O
a	O
datetime	O
and	O
then	O
applies	O
a	O
lambda	O
to	O
keep	O
just	O
the	O
date	O
portion	O
:	O
#CODE	O

Create	O
a	O
new	O
column	O
,	O
then	O
just	O
apply	O
simple	O
`	O
datetime	O
`	O
functions	O
using	O
`	O
lambda	O
`	O
and	O
`	O
apply	O
`	O
.	O

#CODE	O

That	O
error	O
should	O
only	O
occur	O
if	O
you	O
have	O
a	O
date	O
whose	O
year	O
is	O
below	O
1900	O
.	O

Otherwise	O
,	O
`	O
strftime	B-API
`	O
is	O
smart	O
enough	O
to	O
convert	O
it	O
as	O
shown	O
above	O
without	O
errors	O
.	O

Are	O
you	O
sure	O
your	O
values	O
are	O
correct	O
?	O

Try	O
exporting	O
to	O
CSV	O
right	O
before	O
doing	O
the	O
`	O
apply	O
`	O
.	O

A	O
date	O
might	O
have	O
been	O
incorrectly	O
converted	O
from	O
`	O
Created	O
Date	O
`	O
.	O

You	O
can	O
pass	O
a	O
function	O
to	O
apply	O
,	O
but	O
it	O
shouldn't	O
return	O
a	O
dict	O
.	O

If	O
you	O
want	O
to	O
add	O
a	O
sum	O
column	O
your	O
way	O
-	O
do	O
it	O
like	O
this	O
:	O
#CODE	O

I've	O
designed	O
this	O
method	O
so	O
I	O
can	O
apply	O
any	O
function	O
I	O
wish	O
to	O
the	O
table	O
at	O
any	O
point	O
.	O

It	O
needs	O
to	O
stay	O
this	O
flexible	O
,	O
but	O
it	O
just	O
seems	O
horrible	O
!	O

Is	O
there	O
a	O
more	O
efficient	O
way	O
to	O
do	O
something	O
like	O
this	O
?	O

Is	O
iterating	O
over	O
groups	O
+	O
appending	O
better	O
?	O

Thanks	O
.	O

I	O
was	O
aware	O
of	O
this	O
type	O
of	O
solution	O
.	O

But	O
the	O
problem	O
is	O
:	O
I	O
may	O
need	O
to	O
apply	O
an	O
aggregate	O
function	O
which	O
needs	O
access	O
to	O
more	O
than	O
one	O
column	O
(	O
table	O
manipulation	O
)	O
.	O

And	O
I	O
will	O
need	O
to	O
apply	O
more	O
than	O
one	O
of	O
these	O
in	O
batch	O
to	O
different	O
data	O
!	O

Any	O
chance	O
of	O
a	O
little	O
spoonfeeding	O
?	O

Not	O
sure	O
how	O
to	O
apply	O
this	O
to	O
my	O
dataframe	B-API
...	O

there	O
is	O
an	O
apply	O
function	O
,	O
e.g.	O
frame.apply	O
(	O
f	O
,	O
axis=1	O
)	O
where	O
f	O
is	O
a	O
function	O
that	O
does	O
something	O
with	O
a	O
row	O
...	O

It	O
seems	O
to	O
cast	O
all	O
values	O
to	O
`	O
bool	O
`	O
,	O
unless	O
I	O
"	O
touch	O
"	O
the	O
`	O
DataFrame	B-API
`	O
by	O
adding	O
a	O
new	O
column	O
.	O

This	O
happens	O
regardless	O
of	O
whether	O
I	O
use	O
row	O
or	O
column-based	O
`	O
apply	O
`	O
(	O
i.e.	O
`	O
axis=0	O
`	O
or	O
`	O
axis=1	O
`)	O
.	O

The	O
problem	O
comes	O
from	O
the	O
`	O
samples	O
=	O
data	O
[	O
idx	O
]`	O
line	O
.	O

I	O
suspect	O
I	O
need	O
to	O
be	O
more	O
specific	O
than	O
using	O
'	O
grouped	O
'	O
for	O
the	O
data	O
field	O
in	O
bootstrap	O
,	O
but	O
I	O
am	O
unsure	O
how	O
to	O
do	O
this	O
.	O

Do	O
I	O
need	O
to	O
apply	O
this	O
as	O
a	O
lambda	O
function	O
?	O

Or	O
maybe	O
with	O
a	O
for	O
loop	O
?	O

Any	O
suggestions	O
would	O
be	O
much	O
appreciated	O
.	O

Pandas	O
:	O
apply	O
different	O
functions	O
to	O
different	O
columns	O

At	O
this	O
point	O
,	O
I	O
should	O
be	O
able	O
to	O
use	O
something	O
like	O
an	O
"	O
apply	O
"	O
function	O
on	O
`	O
df	O
`	O
using	O
`	O
months	O
`	O
,	O
but	O
am	O
a	O
bit	O
lost	O
...	O

I	O
think	O
a	O
way	O
should	O
exist	O
to	O
avoid	O
the	O
use	O
of	O
apply	O
but	O
I	O
didn't	O
find	O
it	O
.	O

I	O
think	O
'	O
apply	O
'	O
is	O
a	O
good	O
way	O
to	O
go	O
.	O

Is	O
there	O
a	O
solution	O
that	O
works	O
for	O
all	O
three	O
cases	O
?	O

Or	O
is	O
there	O
some	O
way	O
to	O
apply	O
a	O
condition	O
in	O
string	O
splits	O
,	O
without	O
iterating	O
over	O
each	O
row	O
in	O
the	O
data	O
frame	O
?	O

How	O
can	O
I	O
use	O
the	O
`	O
drop_duplicates	B-API
`	O
method	O
to	O
remove	O
all	O
the	O
duplicate	O
dates	O
for	O
each	O
persons	O
set	O
of	O
records	O
?	O

Or	O
is	O
there	O
another	O
way	O
-	O
such	O
as	O
apply	O
?	O

#CODE	O

I	O
made	O
something	O
that	O
works	O
,	O
but	O
there	O
is	O
probably	O
a	O
better	O
way	O
to	O
do	O
this	O
.	O

For	O
each	O
column	O
in	O
my	O
dataframe	B-API
`	O
df	O
[	O
column	O
]	O
=	O
df	O
[	O
column	O
]	O
.map	B-API
(	O
mapdict	O
)`	O
.	O

`	O
apply	O
`	O
doesn't	O
seem	O
to	O
work	O
on	O
a	O
dataframe	B-API
.	O

Thank	O
you	O
!	O

Very	O
slow	O
single	O
pandas	O
apply	O
/	O
groupby	B-API
call	O

I	O
have	O
a	O
small	O
dataframe	B-API
(	O
200	O
*	O
19	O
)	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
.	O

There's	O
no	O
sub-loops	O
.	O

I've	O
tried	O
using	O
groupby	B-API
and	O
row	O
apply	O
:	O
#CODE	O

Incidentally	O
,	O
I	O
don't	O
see	O
the	O
use	O
of	O
the	O
groupby	B-API
version	O
.	O

If	O
you	O
want	O
to	O
apply	O
a	O
function	O
to	O
*	O
every	O
*	O
row	O
,	O
groupby	B-API
doesn't	O
make	O
sense	O
.	O

was	O
just	O
using	O
it	O
for	O
clarity	O
/	O
possible	O
future	O
abstraction	O
.	O
at	O
the	O
time	O
,	O
each	O
row	O
is	O
it's	O
own	O
round	O
,	O
so	O
each	O
group	O
is	O
a	O
df	O
with	O
one	O
row	O
.	O

This	O
might	O
not	O
always	O
be	O
the	O
case	O
,	O
so	O
the	O
row	O
apply	O
would	O
only	O
be	O
a	O
temporary	O
fix	O
(	O
but	O
it's	O
not	O
faster	O
,	O
anyway	O
,	O
so	O
I	O
guess	O
not	O
)	O

As	O
a	O
work-around	O
I'm	O
trying	O
to	O
do	O
the	O
same	O
thing	O
filter	O
does	O
with	O
groupby	B-API
and	O
apply	O
but	O
it	O
doesn't	O
work	O
as	O
expected	O
.	O

Any	O
suggestions	O
?	O

#CODE	O

The	O
problem	O
with	O
your	O
example	O
code	O
is	O
that	O
the	O
`	O
apply	O
`	O
doesn't	O
know	O
what	O
to	O
do	O
with	O
the	O
`	O
None	O
`	O
when	O
putting	O
the	O
dataframe	B-API
back	O
together	O
.	O

Your	O
`	O
apply	O
`	O
function	O
needs	O
to	O
output	O
the	O
same	O
type	O
of	O
object	O
every	O
time	O
.	O

If	O
you	O
return	O
`	O
pd.DataFrame()	B-API
`	O
instead	O
of	O
None	O
you	O
should	O
get	O
what	O
you're	O
looking	O
for	O
.	O

I	O
did	O
not	O
play	O
around	O
with	O
that	O
approach	O
long	O
enough	O
to	O
figure	O
out	O
how	O
to	O
"	O
enlarge	O
"	O
batches	O
of	O
indexes	O
all	O
at	O
once	O
.	O

But	O
,	O
if	O
you	O
figure	O
that	O
out	O
,	O
you	O
can	O
just	O
"	O
enlarge	O
"	O
the	O
original	O
data	O
frame	O
with	O
all	O
NaN	O
values	O
(	O
at	O
index	O
values	O
from	O
`	O
DatesEOY	O
`)	O
,	O
and	O
then	O
apply	O
the	O
function	O
about	O
to	O
`	O
YTDSales	O
`	O
instead	O
of	O
bringing	O
`	O
output	O
`	O
into	O
it	O
at	O
all	O
.	O

I	O
came	O
up	O
with	O
this	O
function	O
,	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

then	O
I	O
apply	O
the	O
multi-indexing	O
and	O
unstacking	O
so	O
I	O
can	O
plot	O
the	O
yearly	O
data	O
on	O
top	O
of	O
each	O
other	O
like	O
this	O
:	O
#CODE	O

AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
to_csv	B-API
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

@USER	O
-Hypothesis	O
my	O
original	O
answer	O
was	O
incorrect	O
,	O
have	O
corrected	O
it	O
now	O
,	O
I	O
now	O
apply	O
row-wise	O
dividing	O
each	O
item	O
by	O
the	O
row	O
sum	O
,	O
the	O
values	O
seem	O
correct	O
to	O
me	O
now	O

If	O
I	O
apply	O
the	O
rule	O
in	O
the	O
df	O
example	O
,	O
the	O
output	O
should	O
be	O
:	O
#CODE	O

Thanks	O
for	O
the	O
example	O
.	O

In	O
my	O
case	O
,	O
there	O
are	O
around	O
30	O
columns	O
:	O
'	O
measure1	O
'	O
,	O
'	O
measure2	O
'	O
...	O

'	O
measure30	O
'	O
.	O

However	O
,	O
I	O
only	O
want	O
to	O
apply	O
sum()	B-API
to	O
'	O
measure1	O
'	O
...	O

'	O
measure20	O
'	O
.	O

is	O
there	O
a	O
way	O
df.groupby	B-API
([	O
'	O
dim1	O
'])	O
[	O
'	O
measure1	O
'	O
,	O
'	O
measure2	O
']	O
.sum()	B-API
can	O
be	O
written	O
without	O
having	O
to	O
write	O
all	O
20	O
column	O
names	O
.	O

This	O
is	O
important	O
because	O
some	O
of	O
my	O
column	O
names	O
are	O
generated	O
programatically	O
,	O
and	O
I	O
do	O
not	O
know	O
their	O
names	O
beforehand	O
.	O

I	O
need	O
to	O
apply	O
the	O
formula	O
above	O
for	O
each	O
chunk	O
.	O

So	O
following	O
this	O
recipe	O
I	O
tried	O
:	O
#CODE	O

You	O
just	O
need	O
to	O
add	O
the	O
param	O
`	O
axis=1	O
`	O
:	O
apply	O
(	O
lambda	O
row	O
:	O
func	O
(	O
row	O
)	O
,	O
axis=1	O
)`	O
then	O
whatever	O
your	O
func	O
does	O
access	O
the	O
columns	O
of	O
interest	O
:	O
`	O
def	O
func	O
(	O
x	O
):	O
return	O
x	O
[	O
'	O
A	O
']	O
+	O
x	O
[	O
'	O
C	O
']`	O
as	O
an	O
example	O

using	O
right_on	O
:	O
result	O
of	O
function	O
f	O
apply	O
to	O
col	O
'	O
Y	O
'	O
from	O
df2	O
.	O

Can	O
anyone	O
suggest	O
a	O
way	O
to	O
apply	O
a	O
function	O
sequentially	O
,	O
so	O
not	O
only	O
using	O
the	O
last	O
calculated	O
value	O
of	O
the	O
column	O
being	O
computed	O
but	O
also	O
using	O
the	O
present	O
and	O
past	O
values	O
of	O
other	O
columns	O
in	O
a	O
pandas	O
dataframe	B-API
.	O

@USER	O
:	O
Thanks	O
for	O
responding	O
,	O
I	O
have	O
added	O
clarification	O
as	O
asked	O
for	O
.	O

The	O
crux	O
of	O
what	O
I	O
am	O
trying	O
to	O
do	O
is	O
to	O
be	O
able	O
to	O
apply	O
a	O
function	O
such	O
that	O
it	O
has	O
access	O
to	O
current	O
values	O
of	O
all	O
columns	O
and	O
past	O
calculated	O
values	O
of	O
the	O
current	O
column	O
.	O

Resample	O
everything	O
to	O
5	O
minute	O
data	O
and	O
then	O
apply	O
a	O
rolling	O
average	O
.	O

Something	O
like	O
that	O
is	O
apllied	O
here	O
:	O
Pandas	O
:	O
rolling	O
mean	O
by	O
time	O
interval	O

Resample	O
everything	O
to	O
5	O
minute	O
data	O
and	O
then	O
apply	O
linear	O
interpolation	O
.	O

This	O
method	O
is	O
close	O
to	O
method	O
3	O
.	O

Pandas	O
data	O
frame	O
:	O
resample	O
with	O
linear	O
interpolation	O

Apply	O
the	O
function	O
to	O
the	O
array	O
like	O
this	O
:	O
#CODE	O

groupby	B-API
the	O
user	O
and	O
apply	O
a	O
lambda	O
:	O
#CODE	O

Python	O
pandas	O
apply	O
function	O
if	O
a	O
column	O
value	O
is	O
not	O
NULL	O

I	O
want	O
to	O
apply	O
a	O
simple	O
function	O
for	O
rows	O
that	O
does	O
not	O
contain	O
NULL	O
values	O
in	O
a	O
specific	O
column	O
.	O

My	O
function	O
is	O
as	O
simple	O
as	O
possible	O
:	O
#CODE	O

And	O
my	O
apply	O
code	O
is	O
the	O
following	O
:	O
#CODE	O

Just	O
apply	O
this	O
:	O
#CODE	O

Thought	O
this	O
would	O
be	O
straight	O
forward	O
but	O
had	O
some	O
trouble	O
tracking	O
down	O
an	O
elegant	O
way	O
to	O
search	O
all	O
columns	O
in	O
a	O
dataframe	B-API
at	O
same	O
time	O
for	O
a	O
partial	O
string	O
match	O
.	O

Basically	O
how	O
would	O
I	O
apply	O
`	O
df	O
[	O
'	O
col1	O
']	O
.str	B-API
.contains	B-API
(	O
'	O
^	O
')`	O
to	O
an	O
entire	O
dataframe	B-API
at	O
once	O
and	O
filter	O
down	O
to	O
any	O
rows	O
that	O
have	O
records	O
containing	O
the	O
match	O
?	O

You	O
can	O
do	O
that	O
using	O
`	O
apply	O
`	O
to	O
traverse	O
and	O
apply	O
function	O
on	O
every	O
element	O
,	O
and	O
lambda	O
to	O
write	O
a	O
function	O
to	O
replace	O
the	O
key	O
with	O
the	O
value	O
of	O
in	O
your	O
dictionary	O
.	O

You	O
can	O
use	O
this	O
to	O
go	O
through	O
the	O
dates	O
that	O
you	O
have	O
classified	O
as	O
"	O
year-month	O
"	O
and	O
apply	O
cretiria	O
on	O
it	O
to	O
get	O
related	O
data	O
.	O

#CODE	O

But	O
those	O
have	O
to	O
be	O
ints	O
.	O

Add	O
a	O
separate	O
issue	O
on	O
Github	O
to	O
have	O
the	O
str.slice	B-API
method	O
take	O
series	O
objects	O
and	O
apply	O
element-wise	O
.	O

getting	O
the	O
index	O
of	O
a	O
row	O
in	O
a	O
pandas	O
apply	O
function	O

I	O
can	O
apply	O
it	O
like	O
so	O
:	O
#CODE	O

Aside	O
:	O
is	O
there	O
a	O
reason	O
you	O
need	O
to	O
use	O
`	O
apply	O
`	O
?	O

It's	O
much	O
slower	O
than	O
performing	O
vectorized	O
ops	O
on	O
the	O
frame	O
itself	O
.	O

(	O
Sometimes	O
apply	O
*	O
is	O
*	O
the	O
simplest	O
way	O
to	O
do	O
something	O
,	O
and	O
performance	O
considerations	O
are	O
often	O
exaggerated	O
,	O
but	O
for	O
your	O
particular	O
example	O
it's	O
as	O
easy	O
*	O
not	O
*	O
to	O
use	O
it	O
.	O
)	O

`	O
apply	O
`	O
is	O
too	O
slow	O
.	O

@USER	O
:	O
I	O
have	O
a	O
script	O
that	O
I	O
(	O
would	O
like	O
to	O
)	O
run	O
fairly	O
frequently	O
that	O
spent	O
about	O
300	O
seconds	O
in	O
this	O
computation	O
when	O
using	O
`	O
apply	O
`	O
(	O
more	O
like	O
100	O
with	O
the	O
awful	O
hack	O
above	O
)	O
.	O

It	O
goes	O
through	O
tens	O
of	O
thousands	O
of	O
rows	O
,	O
tens	O
of	O
times	O
.	O

Pandas	O
0.14.1	O
.	O

I	O
was	O
not	O
able	O
to	O
find	O
a	O
way	O
without	O
at	O
least	O
using	O
an	O
`	O
apply	O
`	O
for	O
setup	O
but	O
assuming	O
that	O
is	O
okay	O
:	O
#CODE	O

Note	O
that	O
you	O
must	O
use	O
the	O
`	O
datetime	O
`	O
from	O
the	O
`	O
datetime	O
`	O
module	O
rather	O
than	O
the	O
`	O
numpy	O
`	O
one	O
or	O
the	O
`	O
pandas	O
`	O
one	O
.	O

Since	O
you	O
are	O
only	O
creating	O
the	O
delta	O
with	O
the	O
apply	O
I	O
would	O
hope	O
you	O
experience	O
a	O
speedup	O
.	O

Here	O
is	O
a	O
way	O
to	O
do	O
it	O
(	O
by	O
adding	O
NumPy	O
datetime64s	O
with	O
timedelta64s	O
)	O
without	O
calling	O
`	O
apply	O
`	O
:	O
#CODE	O

`	O
array_split	B-API
`	O
accepts	O
any	O
array-like	O
argument	O
(	O
including	O
`	O
pandas.DataFrame	B-API
`	O
objects	O
)	O
,	O
but	O
only	O
returns	O
guarantees	O
that	O
it	O
return	O
a	O
`	O
numpy.ndarray	B-API
`	O
(	O
which	O
DataFrames	O
are	O
not	O
)	O
.	O

Of	O
course	O
,	O
ndarrays	O
don't	O
have	O
an	O
`	O
apply	O
`	O
method	O
,	O
which	O
is	O
exactly	O
the	O
error	O
you're	O
seeing	O
.	O

I'm	O
actually	O
surprised	O
that	O
this	O
works	O
in	O
any	O
scenario	O
.	O

You'll	O
either	O
need	O
to	O
split	O
the	O
dataframe	B-API
into	O
sub-frames	O
or	O
apply	O
a	O
function	O
that	O
operations	O
on	O
ndarrays	O
.	O

Since	O
Limit	O
varies	O
on	O
each	O
row	O
,	O
you	O
should	O
use	O
,	O
for	O
example	O
,	O
apply	O
like	O
following	O
:	O
#CODE	O

Since	O
you	O
want	O
to	O
apply	O
the	O
operation	O
generically	O
,	O
to	O
any	O
given	O
`	O
foo	O
`	O
function	O
,	O
you	O
have	O
no	O
choice	O
but	O
to	O
call	O
that	O
function	O
`	O
na	O
`	O
-times-	O
`	O
nb	O
`	O
times	O
.	O

That	O
part	O
is	O
not	O
likely	O
to	O
be	O
further	O
optimizable	O
.	O

The	O
`	O
pandas	O
`	O
way	O
actively	O
shuns	O
looping	O
in	O
favor	O
of	O
proper	O
indexing	O
and	O
selecting	O
due	O
to	O
the	O
expensive	O
overhead	O
incurred	O
in	O
looping	O
.	O

Are	O
you	O
sure	O
you	O
cannot	O
apply	O
indexing	O
plus	O
,	O
for	O
example	O
,	O
a	O
lambda	O
expression	O
to	O
apply	O
these	O
filters	O
?	O

You	O
could	O
also	O
create	O
a	O
mask	O
in	O
a	O
loop	O
and	O
apply	O
it	O
all	O
at	O
once	O
:	O
#CODE	O

set	O
`	O
ts	O
`	O
as	O
index	O
and	O
then	O
`	O
groupby	B-API
`	O
second	O
,	O
and	O
transform	O
with	O
`	O
cumsum()	B-API
`	O
as	O
a	O
new	O
column	O
s	O
,	O
then	O
apply	O
`	O
reset_index	B-API
`	O
,	O
like	O
this	O
:	O
#CODE	O

Apply	O
the	O
ranker	O
function	O
on	O
each	O
group	O
separately	O
:	O

Another	O
option	O
,	O
inspired	O
by	O
HYRY's	O
solution	O
,	O
would	O
be	O
to	O
hide	O
the	O
common	O
columns	O
in	O
the	O
index	O
,	O
and	O
then	O
apply	O
HYRY's	O
`	O
stack	O
`	O
ing	O
trick	O
:	O
#CODE	O

I	O
want	O
to	O
apply	O
one	O
single	O
function	O
call	O
on	O
"	O
df	O
"	O
.	O

Sometimes	O
the	O
function	O
will	O
call	O
member	O
functions	O
of	O
"	O
df	O
"	O
.	O

Sometimes	O
it	O
will	O
just	O
print	O
"	O
df	O
"	O
.	O

I	O
dont	O
want	O
a	O
switch	O
case	O
.	O

I	O
am	O
a	O
Python	O
newbie	O
,	O
so	O
I	O
dont	O
really	O
understand	O
how	O
my	O
question	O
is	O
unclear	O
.	O

As	O
I	O
know	O
so	O
little	O
,	O
I	O
tend	O
to	O
skip	O
over	O
crucial	O
details	O
.	O

What	O
are	O
those	O
crucial	O
details	O
you	O
need	O
to	O
know	O
?	O

In	O
Pandas	O
version	O
0.14	O
and	O
older	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
to	O
extract	O
the	O
dates	O
from	O
the	O
`	O
datetime	O
`	O
values	O
:	O
#CODE	O

I	O
think	O
you	O
should	O
wrap	O
the	O
dict	O
in	O
a	O
Series	O
,	O
and	O
then	O
this	O
will	O
already	O
expand	O
in	O
the	O
groupby	B-API
call	O
(	O
but	O
then	O
using	O
`	O
apply	O
`	O
instead	O
of	O
`	O
agg	O
`	O
as	O
it	O
is	O
not	O
an	O
aggregated	O
(	O
scalar	O
)	O
result	O
anymore	O
):	O
#CODE	O

Using	O
apply	O
in	O
pandas	O
data	O
frame	O
gives	O
ValueError	O

I	O
have	O
a	O
vector	O
that	O
I	O
want	O
to	O
apply	O
a	O
pearson	O
correlation	O
to	O
all	O
rows	O
of	O
a	O
pandas	O
data	O
frame	O
.	O

I	O
am	O
trying	O
the	O
following	O
:	O
#CODE	O

Apply	O
func	O
simply	O
takes	O
two	O
`	O
numpy	O
`	O
arrays	O
and	O
calculates	O
the	O
correlation	O
#CODE	O

python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O
.	O

Update	O

I	O
ensure	O
that	O
args	O
is	O
a	O
tuple	O
which	O
is	O
what	O
the	O
`	O
apply	O
`	O
function	O
is	O
expecting	O
and	O
I	O
get	O
the	O
result	O
I	O
was	O
expecting	O

`	O
df.apply	B-API
`	O
is	O
to	O
each	O
value	O
in	O
array	O
,	O
so	O
`	O
df.apply	B-API
(	O
list	O
,	O
axis=1	O
)`	O
is	O
equivalent	O
to	O
:	O
apply	O
`	O
list()	B-API
`	O
on	O
each	O
value	O
in	O
the	O
array	O
,	O
ie	O
.	O

`	O
81	O
=	O
[	O
81	O
]	O
,	O
88	O
=	O
[	O
8	O
8]	O
,	O
...	O

`	O
individually	O
.	O

So	O
it	O
will	O
have	O
no	O
effects	O
.	O

Actually	O
no	O
.	O
apply	O
works	O
with	O
entire	O
row	O
(	O
if	O
axis	O
parameter	O
=	O
1	O
)	O
.	O

If	O
you	O
make	O
df.apply	B-API
(	O
sum	O
,	O
axis=1	O
)	O
you	O
will	O
receive	O
sum	O
of	O
entire	O
row	O
.	O

Additionally	O
,	O
try	O
df.apply	B-API
(	O
lambda	O
r	O
:	O
'	O
,	O
'	O
.join	B-API
([	O
str	O
(	O
e	O
)	O
for	O
e	O
in	O
r	O
])	O
,	O
axis=1	O
)	O
and	O
you	O
will	O
get	O
one	O
result	O
for	O
each	O
row	O
.	O

@USER	O
,	O
I	O
can't	O
see	O
why	O
`	O
sum	O
`	O
is	O
applicable	O
here	O
.	O

The	O
OP	O
is	O
asking	O
for	O
a	O
method	O
of	O
aggregating	O
values	O
into	O
a	O
list	O
structure	O
,	O
not	O
a	O
numerical	O
operation	O
.	O

From	O
your	O
first	O
comment	O
,	O
it	O
looks	O
like	O
you're	O
arguing	O
that	O
`	O
list()	B-API
`	O
in	O
Python	O
takes	O
more	O
than	O
one	O
parameter	O
.	O

It	O
doesn't	O
.	O

The	O
behavior	O
you're	O
attributing	O
to	O
apply	O
,	O
element-wise	O
operations	O
,	O
is	O
what	O
df.applymap	B-API
does	O
.	O

Can	O
you	O
clarify	O
what	O
you	O
mean	O
,	O
please	O
?	O

I	O
think	O
my	O
presentation	O
skills	O
need	O
improving	O
,	O
I	O
only	O
refer	O
to	O
`	O
sum	O
`	O
as	O
@USER	O
mentioned	O
in	O
comment	O
about	O
why	O
`	O
sum	O
`	O
works	O
on	O
`	O
apply	O
`	O
but	O
`	O
list	O
`	O
doesn't	O
.	O

my	O
first	O
comment	O
was	O
trying	O
to	O
make	O
a	O
point	O
how	O
`	O
list	O
`	O
doesn't	O
change	O
the	O
element	O
in	O
the	O
row	O
array	O
,	O
I	O
guess	O
I	O
didn't	O
explain	O
it	O
in	O
a	O
clear	O
way	O
.	O

Just	O
assign	O
another	O
column	O
as	O
a	O
`	O
cumsum	B-API
`	O
of	O
`	O
indicator	O
`	O
,	O
then	O
apply	O
`	O
groupby	B-API
`	O
,	O
this	O
should	O
do	O
the	O
trick	O
:	O
#CODE	O

I'm	O
trying	O
to	O
use	O
multiprocessing	O
with	O
pandas	O
dataframe	B-API
,	O
that	O
is	O
split	O
the	O
dataframe	B-API
to	O
8	O
parts	O
.	O
apply	O
some	O
function	O
to	O
each	O
part	O
using	O
apply	O
(	O
with	O
each	O
part	O
processed	O
in	O
different	O
process	O
)	O
.	O

there	O
is	O
a	O
space	O
in	O
the	O
`	O
res	O
=	O
df.apply	B-API
(	O
process	O
apply	O
,	O
axis=1	O
)`	O
,	O
is	O
that	O
right	O
?	O

currently	O
apply	O
only	O
saturates	O
one	O
core	O
of	O
the	O
CPU	O
.	O

I	O
want	O
to	O
use	O
multiprocess	O
and	O
use	O
all	O
cores	O
to	O
decrease	O
processing	O
time	O

Iam	O
trying	O
to	O
get	O
the	O
row	O
with	O
maximum	O
value	O
based	O
on	O
another	O
column	O
of	O
a	O
groupby	B-API
,	O
I	O
am	O
trying	O
to	O
follow	O
the	O
solutions	O
given	O
here	O
Python	O
:	O
How	O
can	O
I	O
get	O
the	O
Row	O
which	O
has	O
the	O
max	O
value	O
in	O
goups	O
making	O
groupby	B-API
?	O

,	O
however	O
it	O
doesn't	O
work	O
when	O
you	O
apply	O
#CODE	O

Alternatively	O
,	O
you	O
could	O
use	O
`	O
apply	O
`	O
to	O
split	O
each	O
variant	O
on	O
commas	O
:	O
#CODE	O

Thus	O
,	O
to	O
avoid	O
possibly	O
complicated	O
regex	O
or	O
a	O
relatively	O
slow	O
call	O
to	O
`	O
apply	O
`	O
,	O
I	O
think	O
your	O
best	O
bet	O
is	O
to	O
build	O
the	O
DataFrame	B-API
with	O
one	O
integer	O
variant	O
per	O
row	O
.	O

This	O
is	O
slow	O
,	O
but	O
I	O
am	O
not	O
sure	O
how	O
to	O
translate	O
it	O
into	O
something	O
using	O
apply	O
.	O

Any	O
hints	O
?	O

You	O
can	O
use	O
`	O
apply	O
`	O
function	O
,	O
but	O
you	O
need	O
to	O
do	O
extra	O
work	O
here	O
(	O
just	O
to	O
simplify	O
the	O
work	O
)	O
.	O

It	O
is	O
not	O
`	O
map	O
`	O
that	O
is	O
fast	O
,	O
but	O
`	O
iterrows	B-API
`	O
that	O
is	O
very	O
slow	O
.	O

You	O
can	O
use	O
`	O
itertuples	B-API
`	O
and	O
will	O
get	O
something	O
almost	O
as	O
fast	O
as	O
`	O
map	O
`	O
,	O
but	O
as	O
@USER	O
says	O
,	O
you	O
should	O
try	O
to	O
see	O
if	O
you	O
can	O
apply	O
this	O
function	O
on	O
the	O
whole	O
columns	O
.	O

Dear	O
JD	O
,	O
I	O
dont	O
want	O
to	O
create	O
the	O
custom	O
column	O
in	O
the	O
dataframe	B-API
gain.I	O
want	O
to	O
apply	O
the	O
where	O
condition	O
for	O
the	O
custome	O
column	O

Then	O
go	O
through	O
the	O
`	O
rno_cd	O
`	O
column	O
,	O
and	O
apply	O
a	O
function	O
that	O
transform	O
the	O
data	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
function	O
`	O
tranform	O
`	O
where	O
you	O
can	O
verify	O
whether	O
x	O
is	O
a	O
key	O
so	O
you	O
get	O
the	O
values	O
using	O
your	O
dictionary	O
`	O
D	O
[	O
x	O
]`	O
if	O
it's	O
not	O
the	O
case	O
,	O
you	O
just	O
return	O
`"	O
unknown	O
"`	O
#CODE	O

Is	O
there	O
a	O
way	O
that	O
I	O
can	O
apply	O
a	O
function	O
to	O
a	O
pandas	O
dataframe	B-API
that	O
returns	O
a	O
list	O
for	O
each	O
row	O
that	O
it	O
is	O
applied	O
to	O
,	O
and	O
then	O
take	O
that	O
list	O
and	O
put	O
each	O
item	O
into	O
new	O
columns	O
of	O
that	O
existing	O
dataframe	B-API
?	O

Right	O
now	O
the	O
return	O
of	O
the	O
apply	O
function	O
is	O
a	O
list	O
of	O
lists	O
each	O
of	O
the	O
inner	O
lists	O
is	O
a	O
9	O
item	O
list	O
like	O
that	O
shown	O
above	O
.	O

I	O
am	O
fine	O
putting	O
the	O
response	O
into	O
a	O
new	O
dataframe	B-API
such	O
as	O
the	O
below	O
,	O
but	O
I	O
haven't	O
figured	O
out	O
how	O
to	O
get	O
the	O
apply	O
function	O
to	O
write	O
to	O
each	O
new	O
row	O
for	O
each	O
return	O
or	O
get	O
the	O
list	O
of	O
lists	O
in	O
to	O
the	O
right	O
form	O
.	O

#CODE	O

I	O
like	O
this	O
structure	O
of	O
data	O
before	O
`	O
apply	O
`	O
ing	O
,	O
before	O
I	O
am	O
usually	O
able	O
to	O
just	O
`	O
df	O
[	O
'	O
someNewColumn	O
']	O
=	O
df.apply	B-API
(	O
...	O
)`	O
.	O

But	O
strangely	O
,	O
this	O
time	O
,	O
I'm	O
not	O
able	O
to	O
instantly	O
remerge	O
the	O
results	O
.	O

@USER	O
,	O
`	O
level=0	O
`	O
will	O
give	O
the	O
same	O
result	O
as	O
above	O
as	O
you	O
have	O
only	O
1	O
index	O
by	O
the	O
time	O
you	O
do	O
the	O
`	O
apply	O
`	O
.	O
the	O
**	O
...	O

**	O
is	O
exactly	O
from	O
the	O
output	O
as	O
you're	O
trying	O
to	O
apply	O
the	O
`	O
...	O

/	O
x.coef.mean()	O
`	O
on	O
a	O
group	O
level	O
.	O

However	O
,	O
I	O
think	O
JD	O
Long's	O
suggestion	O
is	O
more	O
likely	O
what	O
you're	O
trying	O
to	O
achieve	O
.	O

And	O
my	O
pandas's	O
version	O
is	O
**	O
0.14.1	O
**	O

It's	O
not	O
obvious	O
to	O
me	O
which	O
version	O
of	O
pandas	O
you're	O
using	O
,	O
but	O
your	O
apply	O
does	O
not	O
work	O
for	O
me	O
at	O
all	O
.	O

whoops	O
.	O

You	O
are	O
correct	O
.	O

I	O
read	O
his	O
code	O
too	O
quickly	O
and	O
didn't	O
notice	O
the	O
apply	O
was	O
on	O
the	O
grouped	O
data	O
.	O

I'll	O
fix	O
my	O
comments	O
above	O
.	O

I	O
already	O
know	O
about	O
the	O
np.isfinite	B-API
and	O
pd.notnull	B-API
commands	O
from	O
this	O
question	O
but	O
I	O
do	O
not	O
know	O
how	O
to	O
apply	O
them	O
to	O
combinations	O
of	O
columns	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
lambda	O
function	O
where	O
you	O
choose	O
non-Nan	O
value	O
.	O

You	O
can	O
verify	O
if	O
it's	O
Nan	O
value	O
using	O
`	O
Numpy.isNan	B-API
(	O
..	O
)`	O
.	O

#CODE	O

What	O
do	O
your	O
data	O
actually	O
look	O
like	O
?	O

Also	O
,	O
are	O
you	O
sure	O
you	O
want	O
a	O
groupby	B-API
and	O
apply	O
together	O
(	O
i.e.	O
not	O
`	O
agg	O
`	O
instead	O
)	O
?	O

When	O
you	O
say	O
"	O
they	O
all	O
fail	O
"	O
,	O
a	O
specific	O
error	O
message	O
would	O
be	O
helpful	O
,	O
as	O
would	O
a	O
description	O
of	O
what	O
exactly	O
you	O
are	O
trying	O
to	O
do	O
by	O
doing	O
this	O
operation	O
.	O

So	O
if	O
apply	O
a	O
simple	O
function	O
,	O
`	O
mean	O
`	O
,	O
to	O
the	O
grouped	O
data	O
we	O
get	O
the	O
following	O
:	O
#CODE	O

This	O
works	O
just	O
fine	O
(	O
i.e.	O
`	O
ctt_ask	O
(	O
example_data	O
)`	O
yields	O
2.90	O
)	O
for	O
the	O
above	O
example	O
but	O
my	O
real	O
dataset	O
has	O
several	O
stocks	O
and	O
many	O
date	O
times	O
(	O
it	O
has	O
a	O
`	O
MultiIndex	O
`)	O
.	O

When	O
I	O
use	O
`	O
groupby	B-API
`	O
and	O
`	O
agg	O
`	O
to	O
apply	O
this	O
function	O
to	O
every	O
stock-date	O
time	O
combination	O
(	O
`	O
full_book_ask.groupby	O
(	O
level	O
=[	O
0	O
,	O
1	O
])	O
.agg	B-API
(	O
ctt_ask	O
)`)	O
I	O
get	O
an	O
error	O
:	O
`	O
KeyError	O
:	O
'	O
avail_shares	O
'`	O
.	O

This	O
is	O
strange	O
because	O
I	O
do	O
have	O
a	O
column	O
named	O
avail_shares	O
in	O
my	O
actual	O
dataset	O
.	O

I	O
have	O
also	O
tried	O
the	O
same	O
with	O
the	O
`	O
apply	O
`	O
functionality	O
but	O
this	O
raises	O
the	O
error	O
message	O
`	O
Exception	O
:	O
cannot	O
handle	O
a	O
non-unique	O
multi-index	O
!	O

Thank	O
you	O
for	O
the	O
comments	O
.	O

@USER	O
H	O
,	O
as	O
I	O
state	O
in	O
the	O
description	O
there	O
is	O
a	O
column	O
called	O
avail_shares	O
in	O
my	O
dataset	O
so	O
this	O
can't	O
be	O
the	O
issue	O
.	O

@USER	O
Pride	O
,	O
you	O
are	O
correct	O
,	O
I	O
understand	O
now	O
why	O
I	O
can't	O
use	O
`	O
agg	O
`	O
.	O

However	O
,	O
both	O
`	O
apply	O
`	O
and	O
`	O
transform	O
`	O
give	O
me	O
an	O
error	O
as	O
well	O
:	O
`	O
Exception	O
:	O
cannot	O
handle	O
a	O
non-unique	O
multi-index	O
!	O

`	O
.	O

So	O
there	O
must	O
be	O
something	O
else	O
going	O
on	O
.	O

I	O
guess	O
there	O
is	O
a	O
problem	O
with	O
the	O
use	O
of	O
`	O
ix	O
`	O
but	O
I	O
don't	O
know	O
why	O
or	O
what	O
I	O
should	O
do	O
to	O
solve	O
it	O
.	O

OP	O
asked	O
for	O
a	O
way	O
to	O
apply	O
multiple	O
aggregate	O
functions	O
at	O
the	O
same	O
time	O
.	O

A	O
short	O
answer	O
is	O
still	O
an	O
answer	O
.	O

There	O
ought	O
to	O
be	O
a	O
metric	O
you	O
can	O
apply	O
that	O
takes	O
a	O
baseline	O
picture	O
of	O
memory	O
usage	O
prior	O
to	O
creating	O
the	O
object	O
under	O
inspection	O
,	O
then	O
another	O
picture	O
afterwards	O
.	O

Comparison	O
of	O
the	O
two	O
memory	O
maps	O
(	O
assuming	O
nothing	O
else	O
has	O
been	O
created	O
and	O
we	O
can	O
isolate	O
the	O
change	O
is	O
due	O
to	O
the	O
new	O
object	O
)	O
should	O
provide	O
an	O
idea	O
of	O
whether	O
a	O
view	O
or	O
copy	O
has	O
been	O
produced	O
.	O

Next	O
,	O
use	O
the	O
apply	O
function	O
in	O
pandas	O
to	O
apply	O
the	O
function	O
-	O
e.g.	O
#CODE	O

Finally	O
we	O
must	O
replace	O
the	O
obtained	O
Series	O
with	O
`	O
value	O
`	O
if	O
`	O
col	O
==	O
"	O
E	O
"`	O
and	O
`	O
value	O
==	O
False	O
`	O
.	O

You	O
can't	O
apply	O
a	O
condition	O
on	O
the	O
index	O
of	O
a	O
Series	O
,	O
thats	O
why	O
you	O
need	O
the	O
`	O
reset_index	B-API
`	O
first	O
.	O

I	O
would	O
like	O
to	O
use	O
the	O
to_datetime	B-API
method	O
to	O
convert	O
the	O
recognized	O
string	O
date	O
formats	O
into	O
datetimes	O
in	O
the	O
dataframe	B-API
column	O
,	O
leaving	O
the	O
unrecognized	O
strings	O
in	O
excel	O
format	O
which	O
I	O
can	O
then	O
isolate	O
and	O
correct	O
off	O
line	O
.	O

But	O
unless	O
I	O
apply	O
the	O
method	O
row	O
by	O
row	O
(	O
way	O
too	O
slow	O
)	O
,	O
it	O
fails	O
to	O
do	O
this	O
.	O

My	O
idea	O
was	O
to	O
then	O
apply	O
the	O
rolling	O
mean	O
on	O
this	O
time	O
period	O
.	O

How	O
do	O
I	O
apply	O
a	O
lambda	O
function	O
on	O
pandas	O
slices	O
,	O
and	O
return	O
the	O
same	O
format	O
as	O
the	O
input	O
data	O
frame	O
?	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
row	O
slices	O
of	O
dataframe	B-API
in	O
pandas	O
for	O
each	O
row	O
and	O
returning	O
a	O
dataframe	B-API
with	O
for	O
each	O
row	O
the	O
value	O
and	O
number	O
of	O
slices	O
that	O
was	O
calculated	O
.	O

What	O
I	O
want	O
is	O
to	O
apply	O
lambda	O
function	O
f	O
from	O
column	O
0	O
to	O
5	O
and	O
from	O
column	O
5	O
to	O
10	O
.	O

let's	O
see	O
..	O

I	O
want	O
to	O
apply	O
the	O
function	O
to	O
the	O
slice	O
on	O
columns	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
and	O
then	O
also	O
on	O
5	O
,	O
6	O
,	O
7	O
,	O
8	O
,	O
9	O
.	O

However	O
,	O
I	O
want	O
the	O
function	O
to	O
run	O
on	O
the	O
original	O
data	O
where	O
the	O
mean	O
is	O
taken	O
only	O
from	O
the	O
first	O
5	O
in	O
the	O
first	O
round	O
and	O
then	O
on	O
the	O
last	O
5	O
in	O
the	O
second	O
round	O
.	O

Does	O
that	O
make	O
sense	O
?	O

hmmmm	O
....	O

it's	O
so	O
weird	O
..	O

it	O
worked	O
and	O
now	O
it	O
doesn't	O
apply	O
any	O
kind	O
of	O
calculation	O
,	O
even	O
when	O
I	O
take	O
exactly	O
your	O
code	O
..	O

>>>	O
When	O
I	O
use	O
`	O
df1	O
=d	O
f.copy()	O
`	O
it	O
works	O
,	O
but	O
not	O
with	O
`	O
df1	O
=d	O
f	O
`	O
..	O

don't	O
know	O
how	O
that	O
makes	O
sense	O
..	O

I	O
want	O
to	O
apply	O
a	O
function	O
f	O
to	O
many	O
slices	O
within	O
each	O
row	O
of	O
a	O
pandas	O
DataFrame	B-API
.	O

If	O
you're	O
applying	O
the	O
same	O
function	O
to	O
all	O
of	O
the	O
groups	O
,	O
why	O
not	O
just	O
apply	O
it	O
to	O
the	O
whole	O
dataframe	B-API
?	O

does	O
the	O
function	O
aggregate	O
the	O
values	O
in	O
some	O
why	O
?	O

(	O
all	O
of	O
these	O
questions	O
I	O
have	O
could	O
be	O
avoided	O
if	O
you	O
simply	O
included	O
some	O
example	O
output	O
that	O
you	O
would	O
like	O
to	O
see	O
)	O

First	O
,	O
I	O
want	O
to	O
say	O
that	O
I've	O
studied	O
basic	O
python	O
and	O
had	O
an	O
intro	O
into	O
pandas	O
,	O
but	O
I'm	O
overwhelmed	O
by	O
pandas	O
a	O
bit	O
..	O

So	O
,	O
I	O
found	O
it	O
hard	O
for	O
me	O
to	O
breakdown	O
my	O
eventual	O
goals	O
into	O
one	O
question	O
,	O
so	O
I	O
thought	O
it	O
made	O
more	O
sense	O
to	O
go	O
in	O
little	O
steps	O
and	O
build	O
on	O
top	O
of	O
each	O
other	O
to	O
finally	O
get	O
the	O
full	O
picture	O
,	O
but	O
I	O
was	O
worried	O
that	O
it	O
would	O
seem	O
like	O
I'm	O
repeating	O
myself	O
.	O

But	O
yes	O
,	O
one	O
of	O
the	O
things	O
I	O
want	O
to	O
do	O
I	O
guess	O
is	O
transform	O
matrices	O
into	O
same-size	O
output	O
matrices	O
,	O
not	O
so	O
much	O
aggregating-	O
but	O
mostly	O
I	O
need	O
to	O
apply	O
functions	O
to	O
slices	O
of	O
the	O
rows	O
of	O
my	O
input	O
matrix	O
..	O

it'll	O
take	O
me	O
a	O
bit	O
to	O
digest	O
your	O
answer	O
,	O
but	O
this	O
is	O
very	O
useful	O
info	O
for	O
me	O
at	O
this	O
point	O
.	O

I	O
do	O
want	O
eventually	O
be	O
fluent	O
in	O
applying	O
these	O
things	O
as	O
such	O
,	O
but	O
didn't	O
know	O
how	O
to	O
step	O
into	O
the	O
whole	O
indexing	O
and	O
grouping	O
with	O
pandas	O
.	O

Delicate	O
balancing	O
between	O
learning	O
code	O
and	O
getting	O
my	O
project	O
done	O
...	O

I'll	O
be	O
trying	O
to	O
apply	O
your	O
answer	O
to	O
my	O
needs	O
.	O

Thank	O
you	O
!	O

Read	O
my	O
data	O
from	O
file	O
and	O
trying	O
to	O
apply	O
indexes	O
to	O
the	O
(	O
43	O
,	O
49	O
)	O
df	O
.	O

I	O
put	O
all	O
my	O
indexes	O
as	O
a	O
list	O
of	O
tuples	O
(	O
idx_tuple	O
)	O
and	O
then	O
created	O
multi-index	O
by	O
`	O
index	O
=	O
pd.MultiIndex.from_tuples	B-API
(	O
idx_tuple	O
,	O
names	O
=[	O
'	O
nr	O
'	O
,	O
'	O
date_sample	O
'	O
,	O
'	O
month	O
'	O
,	O
'	O
conc	O
'	O
,	O
'	O
time	O
'])`	O
.	O

Now	O
tried	O
to	O
update	O
my	O
df	O
as	O
such	O
:	O

Sorry	O
but	O
how	O
would	O
I	O
apply	O
this	O
for	O
a	O
dataframe	B-API
?	O

df.values.apply	O
(	O
lambda	O
x	O
:	O
round	O
(	O
x	O
))	O
??	O

This	O
code	O
generates	O
the	O
error	O
'	O
Int64Index	O
'	O
object	O
has	O
no	O
attribute	O
'	O
apply	O
'	O

Index	O
types	O
don't	O
have	O
an	O
`	O
apply	O
`	O
method	O
,	O
but	O
`	O
Series	O
`	O
does	O
.	O

To	O
apply	O
a	O
function	O
to	O
your	O
index	O
,	O
you	O
can	O
convert	O
it	O
to	O
a	O
series	O
first	O
,	O
using	O
its	O
`	O
to_series	B-API
`	O
method	O
:	O
#CODE	O

and	O
then	O
pass	O
it	O
to	O
`	O
apply	O
`	O
on	O
data	O
grouped	O
by	O
s_id	O
:	O
#CODE	O

So	O
`	O
apply	O
`	O
passes	O
each	O
chunk	O
of	O
grouped	O
data	O
to	O
the	O
function	O
and	O
the	O
the	O
pieces	O
are	O
glues	O
back	O
together	O
once	O
this	O
has	O
been	O
done	O
for	O
each	O
group	O
of	O
data	O
.	O

One	O
possible	O
method	O
without	O
using	O
`	O
regex	O
`	O
is	O
to	O
write	O
your	O
own	O
function	O
and	O
just	O
`	O
apply	O
`	O
it	O
to	O
the	O
column	O
/	O
Series	O
of	O
your	O
choosing	O
.	O

You	O
could	O
apply	O
that	O
regular	O
expression	O
to	O
the	O
elements	O
in	O
the	O
data	O
.	O

However	O
,	O
the	O
solution	O
of	O
mapping	O
your	O
own	O
function	O
over	O
the	O
data	O
works	O
well	O
.	O

Thought	O
you	O
might	O
want	O
to	O
see	O
how	O
you	O
could	O
approach	O
this	O
using	O
your	O
original	O
idea	O
.	O

I'm	O
having	O
problems	O
when	O
trying	O
to	O
use	O
apply	O
on	O
the	O
result	O
of	O
a	O
groupby	B-API
operation	O
.	O

And	O
I	O
now	O
would	O
like	O
to	O
use	O
apply	O
,	O
but	O
I	O
need	O
to	O
feed	O
it	O
id1	O
,	O
which	O
is	O
part	O
of	O
the	O
index	O
,	O
so	O
I	O
get	O
an	O
error	O
when	O
I	O
try	O
to	O
do	O
the	O
following	O
:	O
#CODE	O

The	O
`	O
DataFrame	B-API
`	O
object	O
doesn't	O
have	O
`	O
nunique	B-API
`	O
.	O

You	O
have	O
to	O
pick	O
out	O
which	O
column	O
you	O
want	O
to	O
apply	O
`	O
nunique()	B-API
`	O
on	O
.	O

You	O
can	O
do	O
this	O
with	O
a	O
simple	O
dot	O
operator	O
:	O
#CODE	O

To	O
answer	O
your	O
question	O
about	O
why	O
your	O
recursive	O
lambda	O
prints	O
the	O
`	O
A	O
`	O
column	O
as	O
well	O
,	O
it's	O
because	O
when	O
you	O
do	O
a	O
`	O
groupby	B-API
`	O
/	O
`	O
apply	O
`	O
operation	O
,	O
you're	O
now	O
iterating	O
through	O
three	O
`	O
DataFrame	B-API
`	O
objects	O
.	O

Each	O
`	O
DataFrame	B-API
`	O
object	O
is	O
a	O
sub-	O
`	O
DataFrame	B-API
`	O
of	O
the	O
original	O
.	O

Applying	O
an	O
operation	O
to	O
that	O
will	O
apply	O
it	O
to	O
each	O
`	O
Series	O
`	O
.	O

There	O
are	O
three	O
`	O
Series	O
`	O
per	O
`	O
DataFrame	B-API
`	O
you're	O
applying	O
the	O
`	O
nunique()	B-API
`	O
operator	O
to	O
.	O

I	O
am	O
using	O
groupby	B-API
and	O
apply	O
,	O
so	O
I	O
am	O
not	O
explicitly	O
pulling	O
the	O
groups	O
,	O
which	O
is	O
why	O
i	O
need	O
to	O
do	O
this	O
.	O

Apply	O
will	O
break	O
the	O
dataframe	B-API
into	O
multiple	O
smaller	O
dataframes	O
by	O
the	O
groupby	B-API
columns	O
.	O

The	O
columns	O
you	O
group	O
by	O
are	O
still	O
inside	O
the	O
smaller	O
dataframes	O
.	O

Is	O
that	O
what	O
you	O
are	O
after	O
?	O

so	O
you	O
can	O
see	O
in	O
the	O
resulting	O
printed	O
output	O
that	O
each	O
iteration	O
of	O
the	O
`	O
apply	O
`	O
gets	O
all	O
columns	O
of	O
the	O
input	O
dataframe	B-API
.	O

I'm	O
not	O
sure	O
how	O
to	O
grab	O
a	O
tuple	O
of	O
keys	O
from	O
an	O
`	O
apply	O
`	O
but	O
I	O
can	O
from	O
a	O
loop	O
:	O
#CODE	O

so	O
are	O
you	O
asking	O
how	O
to	O
write	O
a	O
function	O
which	O
,	O
when	O
you	O
apply	O
it	O
to	O
grouped	O
data	O
,	O
can	O
see	O
the	O
keys	O
?	O

I	O
get	O
it	O
now	O
.	O
not	O
sure	O
how	O
to	O
do	O
this	O
from	O
apply	O
,	O
but	O
I	O
added	O
an	O
example	O
of	O
how	O
to	O
do	O
it	O
from	O
a	O
loop	O

Parallelizing	O
apply	O
function	O
in	O
pandas	O
python	O
.	O
worked	O
on	O
groupby	B-API

The	O
same	O
"	O
apply	O
"	O
pattern	O
works	O
for	O
SFrames	O
as	O
well	O
.	O

You	O
could	O
do	O
:	O
#CODE	O

I'm	O
guessing	O
that	O
I	O
can't	O
apply	O
a	O
sort	O
method	O
to	O
the	O
returned	O
groupby	B-API
object	O
.	O

so	O
that	O
fills	O
in	O
all	O
the	O
missing	O
dates	O
with	O
zeros	B-API
.	O

Now	O
we	O
can	O
apply	O
the	O
rolling	O
sum	O
.	O

#CODE	O

You	O
can	O
define	O
a	O
function	O
which	O
returns	O
your	O
different	O
states	O
"	O
Full	O
"	O
,	O
"	O
Partial	O
"	O
,	O
"	O
Empty	O
"	O
,	O
etc	O
and	O
then	O
use	O
`	O
df.apply	B-API
`	O
to	O
apply	O
the	O
function	O
to	O
each	O
row	O
.	O

Note	O
that	O
you	O
have	O
to	O
pass	O
the	O
keyword	O
argument	O
`	O
axis=1	O
`	O
to	O
ensure	O
that	O
it	O
applies	O
the	O
function	O
to	O
rows	O
.	O

#CODE	O

Then	O
using	O
apply	O
:	O
#CODE	O

I	O
am	O
creating	O
the	O
dataframe	B-API
by	O
concatenating	O
two	O
other	O
frames	O
immediately	O
before	O
trying	O
to	O
apply	O
the	O
filter	O
.	O

an	O
intuitive	O
way	O
to	O
understand	O
the	O
pandas	O
groupby	B-API
is	O
to	O
treat	O
the	O
return	O
obj	O
of	O
DataFrame.groupby()	B-API
as	O
a	O
list	O
of	O
dataframe	B-API
.	O

so	O
when	O
u	O
try	O
to	O
using	O
filter	O
to	O
apply	O
the	O
lambda	O
function	O
upon	O
x	O
,	O
x	O
is	O
actually	O
one	O
of	O
those	O
dataframes	O
:	O
#CODE	O

What	O
I'd	O
like	O
to	O
do	O
is	O
:	O
for	O
each	O
day	O
,	O
apply	O
a	O
function	O
that	O
takes	O
the	O
sum	O
of	O
all	O
logvol	O
between	O
14:40	O
:	O
00	O
and	O
15:00	O
:	O
00	O
.	O

`	O
apply	O
`	O
that	O
function	O
to	O
each	O
row	O
,	O
save	O
in	O
the	O
original	O
dataframe	B-API
#CODE	O

Apply	O
multiple	O
functions	O
to	O
multiple	O
groupby	B-API
columns	O

You	O
might	O
start	O
by	O
looking	O
for	O
conditional	O
`	O
apply	O
`	O
-	O
there	O
are	O
plenty	O
examples	O
on	O
how	O
this	O
can	O
be	O
done	O
.	O

Alternatively	O
`	O
numpy.where	B-API
`	O
can	O
do	O
`	O
if	O
...	O
else	O
`	O
replacement	O
/	O
assignment	O
.	O

And	O
for	O
comparing	O
current	O
value	O
(	O
s	O
)	O
with	O
previous	O
ones	O
`	O
pandas	O
`	O
has	O
`	O
.shift	B-API
`	O
method	O
,	O
which	O
you	O
could	O
use	O
with	O
any	O
of	O
the	O
first	O
two	O
approaches	O
.	O

It's	O
a	O
list	O
...	O

In	O
[	O
81	O
]:	O
type	O
(	O
parsedSeries.ix	O
[	O
0	O
])	O
Out	O
[8	O
1	O
]:	O
list	O
.	O

I	O
apply	O
str.split	B-API
to	O
a	O
df	O
to	O
create	O
that	O
list	O

The	O
"	O
best	O
"	O
solution	O
probably	O
involves	O
not	O
finding	O
yourself	O
in	O
this	O
situation	O
in	O
the	O
first	O
place	O
.	O

Most	O
of	O
the	O
time	O
when	O
you	O
have	O
non-scalar	O
quantities	O
in	O
a	O
Series	O
or	O
DataFrame	B-API
you've	O
already	O
taken	O
a	O
step	O
in	O
the	O
wrong	O
direction	O
,	O
because	O
you	O
can't	O
really	O
apply	O
vector	O
ops	O
.	O

This	O
tells	O
u	O
that	O
the	O
datetime	O
format	O
of	O
variable	O
{	O
b	O
}	O
is	O
wrong	O
.	O

so	O
two	O
choices	O
here	O
.	O
the	O
first	O
one	O
is	O
to	O
correct	O
the	O
str	O
format	O
(	O
modify	O
"	O
24	O
"	O
to	O
"	O
00	O
")	O
,	O
then	O
apply	O
the	O
{	O
pd.to_datetime	B-API
}	O
func	O
:	O
#CODE	O

I	O
know	O
about	O
`	O
scipy.interpolate	O
`	O
mentioned	O
in	O
this	O
article	O
(	O
which	O
is	O
where	O
I	O
got	O
the	O
images	O
from	O
)	O
,	O
but	O
how	O
can	O
I	O
apply	O
it	O
for	O
Pandas	O
time	O
series	O
?	O

Your	O
`	O
apply	O
`	O
approach	O
would	O
work	O
too	O
if	O
you	O
used	O
`	O
x	O
`	O
instead	O
of	O
`	O
df.radon	O
`	O
:	O
#CODE	O

I	O
struggled	O
with	O
this	O
problem	O
for	O
several	O
hours	O
to	O
little	O
avail	O
.	O

Ultimately	O
,	O
I	O
wound	O
up	O
writing	O
a	O
nested	O
for	O
loop	O
and	O
solved	O
the	O
problem	O
iteratively	O
.	O

Unfortunately	O
,	O
that	O
solution	O
is	O
painfully	O
slow	O
and	O
I'd	O
much	O
prefer	O
something	O
that	O
utilizes	O
nice	O
features	O
in	O
Pandas	O
such	O
as	O
groupby	B-API
or	O
apply	O
.	O

I	O
have	O
found	O
workaround	O
which	O
is	O
extremely	O
slow	O
due	O
to	O
the	O
"	O
in	O
python	O
"	O
apply	O
:	O
#CODE	O

Apply	O
a	O
function	O
to	O
a	O
specific	O
row	O
using	O
the	O
index	O
value	O

How	O
can	O
i	O
apply	O
a	O
function	O
to	O
the	O
dataframes	O
index	O
?	O

I	O
want	O
to	O
round	O
the	O
numbers	O
for	O
every	O
column	O
where	O
the	O
index	O
is	O
"	O
c	O
"	O
.	O

#CODE	O

I	O
think	O
your	O
title	O
is	O
a	O
bit	O
misleading	O
,	O
what	O
you	O
are	O
saying	O
really	O
is	O
you	O
want	O
to	O
apply	O
a	O
function	O
to	O
a	O
specific	O
row	O
using	O
the	O
index	O
value	O

I	O
think	O
what	O
you	O
want	O
to	O
do	O
won't	O
work	O
due	O
to	O
the	O
shape	O
of	O
the	O
returned	O
values	O
and	O
expected	O
return	O
type	O
.	O

Another	O
way	O
would	O
be	O
to	O
apply	O
a	O
lambda	O
and	O
concatenate	O
the	O
result	O
:	O
#CODE	O

Is	O
there	O
any	O
magic	O
I	O
can	O
apply	O
to	O
the	O
code	O
below	O
?	O

#CODE	O

One	O
way	O
I	O
could	O
conceive	O
a	O
solution	O
would	O
be	O
to	O
groupby	B-API
all	O
duplicated	O
columns	O
and	O
then	O
apply	O
a	O
concatenation	O
operation	O
on	O
unique	O
values	O
:	O
#CODE	O

Now	O
,	O
I've	O
made	O
a	O
little	O
method	O
that	O
will	O
take	O
an	O
input	O
string	O
and	O
do	O
this	O
,	O
spitting	O
back	O
the	O
value	O
I	O
desire	O
.	O

However	O
,	O
it	O
seems	O
to	O
be	O
horribly	O
inefficient	O
.	O

I'm	O
using	O
pandas	O
for	O
data	O
manipulation	O
and	O
this	O
method	O
gets	O
applied	O
to	O
a	O
whole	O
column	O
of	O
timeseries	O
string	O
data	O
in	O
the	O
above	O
string	O
format	O
.	O

Calling	O
the	O
apply	O
method	O
via	O
interactive	O
shell	O
finished	O
execution	O
in	O
~2sec	O
,	O
but	O
strangely	O
,	O
letting	O
the	O
code	O
run	O
as	O
compiled	O
/	O
interpreted	O
on	O
the	O
same	O
dataframe	B-API
takes	O
more	O
like	O
15-20	O
seconds	O
.	O

Why	O
is	O
that	O
?	O

This	O
is	O
how	O
I'm	O
calling	O
it	O
for	O
the	O
dataframe	B-API
/	O
series	O
:	O

Pandas	O
apply	O
with	O
argument	O
that	O
varies	O
by	O
row	O

I	O
am	O
attempting	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
,	O
where	O
the	O
function	O
takes	O
a	O
'	O
size	O
'	O
argument	O
.	O

#CODE	O

but	O
is	O
there	O
a	O
better	O
way	O
using	O
apply	O
functions	O
?	O

Why	O
don't	O
you	O
make	O
`	O
size	O
`	O
another	O
column	O
in	O
your	O
data	O
,	O
so	O
it	O
is	O
passed	O
as	O
part	O
of	O
the	O
`	O
apply	O
`	O
?	O

You	O
can	O
create	O
function	O
and	O
`	O
apply	O
`	O
it	O
to	O
your	O
dataset	O
:	O
#CODE	O

`	O
read_csv	B-API
`	O
accepts	O
an	O
argument	O
named	O
`	O
converters	O
`	O
.	O

This	O
can	O
be	O
used	O
to	O
apply	O
functions	O
to	O
particular	O
columns	O
as	O
a	O
file	O
is	O
read	O
in	O
.	O

`	O
converters	O
`	O
should	O
be	O
passed	O
in	O
as	O
a	O
dictionary	O
of	O
the	O
following	O
form	O
:	O
#CODE	O

You	O
could	O
use	O
this	O
to	O
apply	O
a	O
function	O
to	O
the	O
third	O
column	O
.	O

All	O
you	O
need	O
to	O
do	O
is	O
set	O
the	O
function	O
to	O
get	O
a	O
value	O
from	O
a	O
dictionary	O
`	O
d	O
`	O
which	O
maps	O
`"	O
male	O
"`	O
to	O
`	O
0	O
`	O
and	O
`"	O
female	O
"`	O
to	O
`	O
1	O
`	O
:	O
#CODE	O

Can	O
someone	O
point	O
me	O
to	O
a	O
link	O
or	O
provide	O
an	O
explanation	O
of	O
the	O
benefits	O
of	O
indexing	O
in	O
pandas	O
?	O

I	O
routinely	O
deal	O
with	O
tables	O
and	O
join	O
them	O
based	O
on	O
columns	O
,	O
and	O
this	O
joining	O
/	O
merging	O
process	O
seems	O
to	O
re-index	O
things	O
anyway	O
,	O
so	O
it's	O
a	O
bit	O
cumbersome	O
to	O
apply	O
index	O
criteria	O
considering	O
I	O
don't	O
think	O
I	O
need	O
to	O
.	O

This	O
needs	O
to	O
be	O
done	O
to	O
several	O
million	O
rows	O
of	O
data	O
.	O

Any	O
thoughts	O
on	O
how	O
to	O
speed	O
up	O
the	O
process	O
?	O

I	O
am	O
using	O
pandas	O
data	O
frame's	O
map	O
function	O
to	O
apply	O
the	O
function	O
`	O
toTheExp	O
`	O
to	O
my	O
column	O
of	O
data	O
already	O
.	O

This	O
step	O
is	O
still	O
pretty	O
slow	O
though	O
.	O

Currently	O
I'm	O
trying	O
something	O
like	O
:	O
#CODE	O

A	O
little	O
unclear	O
what	O
you	O
want	O
,	O
`	O
applymap	B-API
`	O
is	O
for	O
a	O
dataframe	B-API
it	O
doesn't	O
make	O
much	O
sense	O
to	O
call	O
`	O
applymap	B-API
`	O
on	O
a	O
series	O
when	O
`	O
apply	O
`	O
is	O
specifically	O
for	O
this	O
.	O

You	O
can	O
get	O
a	O
df	O
by	O
using	O
double	O
square	O
brackets	O
:	O
`	O
pd.DataFrame	B-API
(	O
df	O
[[	O
'	O
col	O
']])	O
.applymap	B-API
(	O
isnan	B-API
)`	O

Apply	O
FROM_UNIXTIME	O
on	O
column	O
,	O
c	O

If	O
you	O
want	O
sequential	O
index	O
,	O
you	O
can	O
apply	O
`	O
reset_index	B-API
(	O
drop=True	O
)`	O
to	O
the	O
result	O
.	O

the	O
code	O
below	O
perfectly	O
fine	O
,	O
but	O
i	O
need	O
to	O
create	O
a	O
function	O
that	O
will	O
do	O
that	O
for	O
me	O
rather	O
than	O
creating	O
lambda	O
functions	O
for	O
every	O
block	O
of	O
columns	O
that	O
i	O
like	O
to	O
merge	O
.	O

(	O
I	O
still	O
have	O
other	O
similar	O
columns	O
that	O
i	O
like	O
to	O
apply	O
the	O
same	O
logic	O
on	O
them	O
.	O
)	O
#CODE	O

I	O
don't	O
get	O
how	O
I	O
can	O
use	O
groupby	B-API
and	O
apply	O
some	O
sort	O
of	O
concatenation	O
of	O
the	O
strings	O
in	O
the	O
column	O
"	O
text	O
"	O
.	O

Any	O
help	O
appreciated	O
!	O

You	O
can	O
groupby	B-API
the	O
`'	O
name	O
'`	O
and	O
`'	O
month	O
'`	O
columns	O
,	O
then	O
call	O
`	O
transform	O
`	O
which	O
will	O
return	O
data	O
aligned	O
to	O
the	O
original	O
df	O
and	O
apply	O
a	O
lambda	O
where	O
we	O
`	O
join	O
`	O
the	O
text	O
entries	O
:	O
#CODE	O

EDIT	O
actually	O
I	O
can	O
just	O
call	O
`	O
apply	O
`	O
and	O
then	O
`	O
reset_index	B-API
`	O
:	O
#CODE	O

I	O
have	O
been	O
messing	O
around	O
with	O
groupby	B-API
/	O
transform	O
/	O
apply	O
but	O
haven't	O
gotten	O
anything	O
to	O
work	O
so	O
far	O
.	O

If	O
I	O
groupby	B-API
and	O
then	O
shift	O
,	O
it	O
shifts	O
each	O
group	O
giving	O
the	O
output	O
of	O
:	O
#CODE	O

Is	O
there	O
anyway	O
to	O
randomly	O
apply	O
changes	O
of	O
stings	O
by	O
row	O
to	O
a	O
Pandas	O
data	O
frame	O
.	O

Pandas	O
use	O
groupby	B-API
to	O
apply	O
a	O
different	O
function	O
for	O
each	O
value	O
of	O
the	O
groupby	B-API
variable	O

I'd	O
like	O
to	O
use	O
groupby	B-API
,	O
but	O
instead	O
of	O
applying	O
the	O
same	O
functions	O
to	O
each	O
group	O
,	O
I	O
want	O
to	O
specify	O
which	O
function	O
to	O
apply	O
to	O
which	O
group	O
value	O
.	O

I'm	O
providing	O
a	O
very	O
simple	O
example	O
here	O
to	O
illustrate	O
the	O
point	O
,	O
but	O
in	O
reality	O
there	O
are	O
many	O
values	O
of	O
my	O
groupby	B-API
variable	O
,	O
and	O
my	O
functions	O
are	O
all	O
user-defined	O
and	O
fairly	O
complex	O
--	O
so	O
solutions	O
that	O
involve	O
selecting	O
each	O
group	O
separately	O
or	O
apply	O
the	O
same	O
functions	O
to	O
all	O
groups	O
will	O
not	O
be	O
practical	O
.	O

(	O
Answers	O
of	O
that	O
sort	O
were	O
provided	O
to	O
this	O
very	O
similar	O
question	O
:	O
how	O
to	O
apply	O
different	O
functions	O
to	O
each	O
group	O
of	O
pandas	O
groupby	B-API
?	O
but	O
they	O
don't	O
address	O
my	O
question	O
)	O
#CODE	O

This	O
makes	O
sense	O
,	O
but	O
how	O
do	O
I	O
specify	O
function_map	O
so	O
that	O
it	O
contains	O
functions	O
in	O
valid	O
python	O
syntax	O
?	O

Or	O
,	O
alternatively	O
,	O
if	O
I	O
store	O
the	O
names	O
of	O
the	O
functions	O
as	O
strings	O
,	O
how	O
do	O
I	O
then	O
pass	O
them	O
as	O
functions	O
to	O
apply	O
?	O

i.e.	O
to	O
compute	O
the	O
value	O
of	O
C	O
I	O
need	O
the	O
previously	O
computed	O
value	O
of	O
C	O
.	O

This	O
can	O
be	O
done	O
by	O
a	O
simple	O
for	O
loop	O
,	O
but	O
I	O
would	O
like	O
to	O
use	O
map	O
,	O
apply	O
or	O
some	O
other	O
pandas	O
functionality	O
.	O

Can	O
this	O
be	O
done	O
i	O
a	O
simple	O
manner	O
?	O

Thanks	O
@USER	O
Paulo	O
-	O
Is	O
there	O
a	O
way	O
of	O
specifying	O
the	O
size	O
of	O
the	O
title	O
when	O
it	O
is	O
inside	O
the	O
df.plot	B-API
(	O
title=MyTitle	O
)	O
.	O

if	O
I	O
move	O
the	O
plt.title	B-API
(	O
MyTitle	O
,	O
size=20	O
)	O
outside	O
of	O
the	O
PLOT	O
brackets	O
then	O
in	O
my	O
for	O
loop	O
it	O
creates	O
a	O
title	O
above	O
every	O
subplot	O
and	O
I	O
don't	O
want	O
that	O
.	O

I	O
want	O
a	O
single	O
title	O
for	O
a	O
group	O
of	O
subplots	O
-	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
the	O
size	O
property	O
when	O
it's	O
in	O
the	O
brackets	O
plot	O
(	O
title=MyTitle	O
)	O
.	O

I	O
can	O
tell	O
you	O
from	O
experience	O
that	O
this	O
will	O
need	O
to	O
be	O
performed	O
in	O
some	O
kind	O
of	O
for	O
loop	O
/	O
apply	O
method	O
.	O

As	O
there	O
are	O
no	O
exact	O
matches	O
you	O
have	O
to	O
find	O
the	O
appropriate	O
index	O
value	O
to	O
set	O
the	O
new	O
column	O
values	O
,	O
I	O
would	O
use	O
`	O
numpy.searchsorted	B-API
`	O
or	O
you	O
could	O
use	O
a	O
filter	O
,	O
in	O
`	O
0.15.1	O
`	O
I	O
think	O
you	O
can	O
do	O
some	O
fancy	O
filtering	O
if	O
you	O
pass	O
a	O
range	O
but	O
not	O
sure	O
it	O
applies	O
to	O
dates	O
,	O
worth	O
a	O
try	O
though	O
.	O

I	O
want	O
to	O
apply	O
this	O
function	O
on	O
my	O
data	O
,	O
stored	O
in	O
a	O
data	O
frame	O
.	O

However	O
,	O
the	O
data	O
frame	O
consists	O
many	O
experiment	O
subjects	O
and	O
4	O
experiment	O
conditions	O
,	O
while	O
the	O
outlier	O
detection	O
function	O
should	O
be	O
applied	O
on	O
the	O
level	O
and	O
for	O
each	O
subject	O
+	O
trialcode	O
.	O

Is	O
there	O
a	O
way	O
to	O
apply	O
this	O
function	O
on	O
groups	O
of	O
subject+trialcode	O
?	O

Groupby	B-API
and	O
apply	O
`	O
.mean	B-API
`	O
multiplying	O
by	O
30	O
:	O
#CODE	O

My	O
problem	O
is	O
that	O
I'm	O
having	O
trouble	O
getting	O
pandas	O
to	O
create	O
a	O
date	O
column	O
which	O
I	O
can	O
then	O
apply	O
a	O
timedelta	O
to	O
.	O

Here's	O
my	O
offending	O
line	O
:	O
#CODE	O

Yes	O
,	O
this	O
is	O
the	O
output	O
I	O
want	O
to	O
have	O
.	O

However	O
,	O
I	O
want	O
to	O
apply	O
this	O
procedure	O
several	O
times	O
with	O
different	O
filter	O
criteria	O
to	O
df1	O
.	O

Using	O
the	O
above	O
code	O
snippet	O
would	O
overwrite	O
older	O
inserted	O
values	O
in	O
'	O
eins	O
'	O
everytime	O
with	O
NaN	O
.	O

Therefor	O
I	O
look	O
for	O
joining	O
only	O
those	O
rows	O
of	O
df1	O
,	O
which	O
fulfill	O
the	O
filter	O
criteria	O
.	O

When	O
you	O
apply	O
a	O
function	O
on	O
the	O
groupby	B-API
,	O
in	O
your	O
example	O
`	O
df.groupby	B-API
(	O
...	O
)	O
.agg	B-API
(	O
...	O
)`	O
(	O
but	O
this	O
can	O
also	O
be	O
`	O
transform	O
`	O
,	O
`	O
apply	O
`	O
,	O
`	O
mean	O
`	O
,	O
...	O
)	O
,	O
you	O
combine	O
the	O
result	O
of	O
applying	O
the	O
function	O
to	O
the	O
different	O
groups	O
together	O
in	O
one	O
dataframe	B-API
(	O
the	O
apply	O
and	O
combine	O
step	O
of	O
the	O
'	O
split-apply-combine	O
'	O
paradigm	O
of	O
groupby	B-API
)	O
.	O

So	O
the	O
result	O
of	O
this	O
will	O
always	O
be	O
again	O
a	O
DataFrame	B-API
(	O
or	O
a	O
Series	O
depending	O
on	O
the	O
applied	O
function	O
)	O
.	O

Now	O
you	O
can	O
apply	O
the	O
condition	O
like	O
this	O
:	O
#CODE	O

You	O
need	O
to	O
`	O
apply	O
`	O
your	O
logic	O
to	O
each	O
row	O
,	O
like	O
this	O
:	O
#CODE	O

This	O
works	O
,	O
except	O
that	O
it's	O
very	O
slow	O
,	O
presumably	O
due	O
to	O
the	O
nested	O
`	O
apply	O
`	O
calls	O
:	O
one	O
on	O
each	O
group	O
,	O
and	O
then	O
one	O
for	O
each	O
column	O
in	O
each	O
group	O
.	O

I	O
tried	O
getting	O
rid	O
of	O
the	O
second	O
`	O
apply	O
`	O
by	O
computing	O
quantiles	O
for	O
all	O
columns	O
at	O
once	O
,	O
but	O
got	O
stuck	O
trying	O
to	O
threshold	O
each	O
column	O
by	O
a	O
different	O
value	O
.	O

Is	O
there	O
a	O
faster	O
way	O
to	O
accomplish	O
this	O
procedure	O
?	O

I	O
have	O
data	O
stored	O
in	O
a	O
DataFrameGroupBy	B-API
object	O
.	O

Therefore	O
,	O
I	O
would	O
like	O
to	O
apply	O
the	O
function	O
to	O
the	O
entire	O
column	O
.	O

Also	O
,	O
the	O
`	O
apply	O
`	O
method	O
of	O
a	O
GroupBy	B-API
object	O
doesnt	O
have	O
the	O
`	O
axis	O
`	O
keyword	O
,	O
die	O
`	O
apply	O
`	O
method	O
of	O
a	O
DataFrame	B-API
does	O
.	O

@USER	O
:	O
I	O
think	O
I	O
read	O
in	O
the	O
linked	O
stackoverflow	O
question	O
that	O
`	O
axis	O
`	O
has	O
been	O
added	O
to	O
the	O
`	O
apply	O
`	O
method	O
of	O
the	O
`	O
GroupBy	B-API
`	O
object	O
.	O

But	O
this	O
is	O
obviously	O
not	O
the	O
case	O
,	O
given	O
the	O
error	O
message	O
I	O
get	O
back	O
from	O
the	O
Python	O
console	O
.	O

You	O
could	O
set	O
`	O
files	O
`	O
as	O
the	O
index	O
in	O
`	O
df1	O
`	O
and	O
then	O
apply	O
a	O
function	O
which	O
uses	O
`	O
loc	O
`	O
to	O
look	O
up	O
the	O
`	O
pkid	O
`	O
value	O
corresponding	O
to	O
the	O
index	O
:	O
#CODE	O

A	O
faster	O
method	O
than	O
@USER	O
'	O
s	O
is	O
to	O
use	O
`	O
map	O
`	O
here	O
because	O
you	O
have	O
a	O
unique	O
index	O
then	O
this	O
will	O
be	O
much	O
faster	O
than	O
calling	O
apply	O
which	O
is	O
essentially	O
a	O
for	O
loop	O
:	O
#CODE	O

yep	O
,	O
this	O
is	O
MUCH	O
better	O
than	O
using	O
apply	O
as	O
its	O
fully	O
vectorized	O

It	O
is	O
possible	O
that	O
pandas	O
gets	O
confused	O
if	O
your	O
function	O
sometimes	O
returns	O
a	O
list	O
and	O
sometimes	O
a	O
single	O
value	O
,	O
since	O
different	O
dtypes	B-API
would	O
be	O
used	O
for	O
those	O
two	O
cases	O
.	O

It	O
is	O
probably	O
better	O
not	O
to	O
do	O
it	O
that	O
way	O
.	O

The	O
calling-twice	O
behavior	O
could	O
be	O
related	O
to	O
the	O
issue	O
described	O
[	O
here	O
]	O
(	O
#URL	O
)	O
for	O
`	O
apply	O
`	O
:	O
it	O
calls	O
the	O
function	O
twice	O
on	O
the	O
first	O
group	O
in	O
order	O
to	O
check	O
whether	O
the	O
function	O
mutates	O
the	O
existing	O
data	O
.	O

The	O
strangest	O
thing	O
is	O
,	O
im	O
reuse	O
this	O
code	O
all	O
the	O
time	O
with	O
no	O
issues	O
.	O

I	O
know	O
apply	O
and	O
transform	O
pass	O
different	O
packets	O
of	O
data	O
such	O
that	O
it	O
is	O
quite	O
hard	O
to	O
ascertain	O
from	O
print	O
statements	O
what	O
is	O
going	O
on	O
,	O
but	O
agh	O
is	O
fairly	O
straightforward	O
.	O

Were	O
you	O
able	O
to	O
recreate	O
the	O
error	O
?	O

I	O
cannot	O
send	O
the	O
data	O
frame	O
to	O
the	O
function	O
row	O
by	O
row	O
because	O
there	O
is	O
a	O
rank	O
by	O
group	O
aspect	O
to	O
the	O
algorithm	O
.	O

So	O
I	O
have	O
to	O
send	O
at	O
least	O
one	O
group	O
of	O
data	O
at	O
a	O
time	O
to	O
the	O
function	O
.	O

I	O
tried	O
groupby.apply	B-API
but	O
there	O
were	O
unexpected	O
results	O
due	O
to	O
the	O
apply	O
calling	O
the	O
function	O
twice	O
on	O
the	O
first	O
group	O
.	O

So	O
now	O
I	O
am	O
using	O
a	O
lambda	O
like	O
this	O
.	O

#CODE	O

In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O
first	O

My	O
recommendation	O
would	O
be	O
to	O
concat	O
the	O
list	O
of	O
dataframes	O
using	O
pd.concat	B-API
.	O

This	O
will	O
allow	O
you	O
to	O
use	O
the	O
standard	O
group-by	O
/	O
apply	O
.	O

In	O
this	O
example	O
,	O
multi_df	O
is	O
a	O
MultiIndex	O
which	O
behaves	O
like	O
a	O
standard	O
data	O
frame	O
,	O
only	O
the	O
indexing	O
and	O
group	O
by	O
is	O
a	O
little	O
different	O
:	O
#CODE	O

By	O
"	O
Finding	O
it	O
hard	O
"	O
I	O
mean	O
that	O
strptime	O
on	O
the	O
x	O
[	O
'	O
datex	O
']	O
doesn't	O
work	O
because	O
those	O
are	O
series	O
and	O
not	O
values	O
and	O
I	O
can't	O
apply	O
it	O
to	O
the	O
x	O
in	O
"	O
lambda	O
x	O
"	O
or	O
use	O
%Y%M%d	O
instead	O
of	O
%s	O
.	O

An	O
example	O
would	O
be	O
date1	O
=	O
datetime.datetime	O
(	O
2014	O
,	O
1	O
,	O
1	O
)	O
and	O
date2	O
=	O
datetime.datetime	O
(	O
2014	O
,	O
1	O
,	O
3	O
)	O
.	O

Well	O
,	O
since	O
you're	O
already	O
using	O
`	O
apply	O
`	O
,	O
you're	O
dealing	O
with	O
two	O
values	O
(	O
not	O
columns	O
)	O
,	O
so	O
you	O
can	O
call	O
the	O
`	O
date	O
`	O
method	O
on	O
each	O
:	O
#CODE	O

python	O
/	O
numpy	O
/	O
pandas	O
fastest	O
way	O
apply	O
algorithm	O
for	O
expanding	O
calculations	O

In	O
other	O
words	O
I'd	O
like	O
a	O
function	O
`	O
f	O
`	O
so	O
that	O
I	O
can	O
apply	O
`	O
f	O
`	O
to	O
a	O
series	O
(	O
or	O
multiple	O
series	O
)	O
as	O
well	O
as	O
applying	O
`	O
f	O
`	O
to	O
a	O
float	O
(	O
or	O
multiple	O
floats	O
)	O
,	O
and	O
ideally	O
apply	O
`	O
f	O
`	O
to	O
a	O
combination	O
of	O
floats	O
and	O
series	O
.	O

However	O
I	O
am	O
struggling	O
to	O
figure	O
out	O
how	O
to	O
apply	O
one	O
function	O
`	O
convertToMeters	O
`	O
to	O
the	O
first	O
column	O
and	O
`	O
convertToNewtons	O
`	O
for	O
the	O
second	O
column	O
.	O

it	O
will	O
apply	O
the	O
respective	O
function	O
to	O
each	O
column	O
and	O
not	O
just	O
the	O
desired	O
column	O
.	O

Can	O
you	O
show	O
how	O
`	O
convertToMeters	O
`	O
looks	O
like	O
?	O

Probably	O
you	O
can	O
write	O
this	O
function	O
so	O
that	O
you	O
can	O
just	O
do	O
`	O
df	O
[	O
'	O
col_meters	O
']	O
=	O
convertToMeters	O
(	O
df	O
[	O
'	O
col	O
'])`	O
without	O
using	O
the	O
apply	O
.	O

Sorry	O
I	O
was	O
a	O
little	O
bit	O
busy	O
when	O
writting	O
this	O
question	O
.	O

Data	O
are	O
correct	O
now	O
.	O

Well	O
I	O
mean	O
just	O
to	O
delete	O
rows	O
from	O
groups	O
and	O
keep	O
these	O
groups	O
as	O
they	O
are	O
-	O
I	O
need	O
to	O
apply	O
several	O
filters	O
and	O
after	O
each	O
apply	O
is	O
needed	O
new	O
groupby	B-API
.	O

You	O
just	O
need	O
to	O
use	O
`	O
apply	O
`	O
on	O
the	O
`	O
groupby	B-API
`	O
object	O
.	O

I	O
modified	O
your	O
example	O
data	O
to	O
make	O
this	O
a	O
little	O
more	O
clear	O
:	O
#CODE	O

Similarly	O
if	O
I	O
create	O
a	O
column	O
to	O
store	O
the	O
int	O
day	O
value	O
and	O
then	O
perform	O
the	O
apply	O
then	O
it	O
works	O
also	O
:	O
#CODE	O

I	O
guess	O
you	O
could	O
easily	O
turn	O
this	O
into	O
a	O
function	O
to	O
apply	O
on	O
a	O
dataframe	B-API
inplace	O
.	O

Please	O
see	O
edit	O
in	O
the	O
answer	O
to	O
see	O
the	O
fix	O
for	O
this	O
error	O
(	O
since	O
you	O
added	O
more	O
columns	O
`	O
transform	O
`	O
was	O
being	O
applied	O
on	O
a	O
GroupbyDataframe	O
and	O
not	O
on	O
the	O
Series	O
)	O
-	O
all	O
it	O
takes	O
is	O
to	O
pass	O
name	O
of	O
the	O
column	O
after	O
`	O
groupby	B-API
`	O
to	O
apply	O
`	O
transform	O
`	O
on	O
.	O

It	O
seems	O
I	O
can	O
apply	O
some	O
functions	O
without	O
problems	O
to	O
a	O
DataFrame	B-API
,	O
but	O
other	O
give	O
a	O
Value	O
Error	O
.	O

#CODE	O

The	O
first	O
apply	O
works	O
fine	O
,	O
the	O
second	O
one	O
generates	O
a	O
:	O

I	O
know	O
I	O
can	O
generate	O
the	O
"	O
max	O
(	O
df	O
,	O
0	O
)"	O
in	O
other	O
ways	O
(	O
e.g.	O
by	O
df	O
[	O
df	O
0	O
]=	O
0	O
)	O
,	O
so	O
I'm	O
not	O
looking	O
for	O
a	O
solution	O
to	O
this	O
particular	O
problem	O
.	O

Rather	O
,	O
I'm	O
interested	O
in	O
why	O
the	O
apply	O
above	O
doesn't	O
work	O
.	O

Actually	O
it's	O
quicker	O
to	O
convert	O
the	O
type	O
to	O
string	O
and	O
then	O
convert	O
the	O
entire	O
series	O
to	O
a	O
datetime	O
rather	O
than	O
calling	O
apply	O
on	O
every	O
value	O
:	O
#CODE	O

How	O
can	O
i	O
apply	O
do_calcuations	O
without	O
loops	O
like	O
this	O
.	O

Loops	O
like	O
that	O
is	O
discourage	O
in	O
panda	O
because	O
slow	O
,	O
right	O
?	O

groupby	B-API
these	O
event	O
numbers	O
and	O
apply	O
`	O
do_calculations	O
`	O
to	O
each	O
group	O
.	O

Apply	O
vs	O
transform	O
on	O
a	O
group	O
object	O

In	O
other	O
words	O
,	O
I	O
thought	O
that	O
transform	O
is	O
essentially	O
a	O
specific	O
type	O
of	O
apply	O
(	O
the	O
one	O
that	O
does	O
not	O
aggregate	O
)	O
.	O

Where	O
am	O
I	O
wrong	O
?	O

X	O
and	O
Y	O
are	O
actually	O
pairs	O
of	O
coordinates	O
and	O
the	O
function	O
I	O
would	O
like	O
to	O
apply	O
is	O
the	O
vincenty	O
distance	O
from	O
the	O
geopy	O
package	O
.	O

And	O
another	O
problem	O
:	O
Even	O
if	O
I	O
just	O
want	O
to	O
apply	O
the	O
vincenty	O
formula	O
to	O
the	O
series	O
in	O
my	O
dataframe	B-API
,	O
I	O
receive	O
an	O
error	O
message	O
:	O
#CODE	O

The	O
problem	O
is	O
that	O
I	O
have	O
not	O
clue	O
how	O
I	O
get	O
these	O
errors	O
.	O

I	O
can	O
give	O
four	O
single	O
values	O
as	O
coordinates	O
to	O
the	O
vincenty	O
formula	O
or	O
a	O
list	O
or	O
a	O
string	O
and	O
it	O
will	O
work	O
.	O

But	O
the	O
only	O
way	O
I	O
can	O
apply	O
the	O
formula	O
to	O
several	O
entries	O
is	O
using	O
lists	O
.	O

Gives	O
you	O
a	O
generator	O
with	O
the	O
values	O
,	O
which	O
you	O
can	O
reshape	O
and	O
print	O
as	O
you	O
need	O
.	O

Substitute	O
operator.mul	O
with	O
the	O
pertinent	O
function	O
you	O
need	O
to	O
apply	O
.	O

IIUC	O
,	O
your	O
function	O
probably	O
doesn't	O
support	O
sequences	O
of	O
strings	O
as	O
input	O
,	O
only	O
strings	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
pass	O
the	O
values	O
individually	O
:	O
#CODE	O

It	O
works	O
for	O
the	O
first	O
row	O
if	O
all	O
the	O
strings	O
are	O
inside	O
one	O
double	O
quotes	O
.	O

But	O
it	O
doesn't	O
apply	O
for	O
the	O
third	O
and	O
second	O
row	O
if	O
there're	O
commas	O
outside	O
the	O
quotes	O
(	O
single	O
or	O
double	O
)	O

I	O
have	O
a	O
pandas	O
DataFrame	B-API
with	O
a	O
mix	O
of	O
numerical	O
(	O
float	O
)	O
and	O
text	O
columns	O
.	O

Some	O
of	O
the	O
numerical	O
values	O
seem	O
to	O
be	O
off	O
by	O
a	O
factor	O
10	O
and	O
I	O
want	O
to	O
modify	O
them	O
in	O
place	O
.	O

I	O
can	O
do	O
with	O
apply	O
,	O
but	O
I	O
was	O
wondering	O
if	O
there	O
is	O
any	O
way	O
to	O
only	O
indexing	O
instead	O
.	O

This	O
works	O
of	O
course	O
,	O
it	O
is	O
similar	O
to	O
the	O
apply	O
solution	O
,	O
it	O
just	O
make	O
the	O
loop	O
over	O
the	O
columns	O
explicit	O
.	O

I	O
am	O
still	O
surprised	O
that	O
this	O
is	O
a	O
faster	O
than	O
a	O
solution	O
with	O
no	O
(	O
apparent	O
)	O
loop	O
.	O

Thanks	O
for	O
the	O
performance	O
numbers	O
.	O

I	O
may	O
be	O
doing	O
something	O
wrong	O
,	O
but	O
on	O
my	O
machine	O
I	O
got	O
the	O
following	O
timing	O
information	O
:	O
1.58	O
ms	O
for	O
apply	O
on	O
subset	O
of	O
columns	O
,	O
62.3	O
ms	O
for	O
fillna	B-API
,	O
and	O
2.65	O
ms	O
for	O
the	O
explicit	O
loop	O
.	O

Second	O
,	O
we're	O
going	O
to	O
use	O
the	O
dataframe	B-API
method	O
`	O
apply	O
`	O
.	O

What	O
`	O
apply	O
`	O
does	O
is	O
it	O
takes	O
a	O
function	O
and	O
runs	O
every	O
row	O
(	O
axis=1	O
)	O
or	O
column	O
(	O
axis=0	O
)	O
through	O
it	O
,	O
and	O
builds	O
a	O
new	O
pandas	O
object	O
with	O
all	O
of	O
the	O
returned	O
values	O
.	O

So	O
we	O
need	O
to	O
set	O
up	O
`	O
haversine	O
`	O
totake	O
row	O
of	O
a	O
dataframe	B-API
and	O
unpack	O
the	O
values	O
.	O

It	O
becomes	O
:	O
#CODE	O

So	O
now	O
we	O
can	O
`	O
apply	O
`	O
the	O
Haversine	O
function	O
:	O
#CODE	O

I	O
have	O
a	O
pandas	O
series	O
`	O
series	O
`	O
.	O

If	O
I	O
want	O
to	O
get	O
the	O
element-wise	O
floor	O
or	O
ceiling	O
,	O
is	O
there	O
a	O
built	O
in	O
method	O
or	O
do	O
I	O
have	O
to	O
write	O
the	O
function	O
and	O
use	O
apply	O
?	O

I	O
ask	O
because	O
the	O
data	O
is	O
big	O
so	O
I	O
appreciate	O
efficiency	O
.	O

Also	O
this	O
question	O
has	O
not	O
been	O
asked	O
with	O
respect	O
to	O
the	O
Pandas	O
package	O
.	O

Sorry	O
,	O
forgot	O
to	O
mention	O
the	O
first	O
column	O
(	O
which	O
I	O
used	O
as	O
label	O
and	O
really	O
do	O
not	O
need	O
the	O
index	O
)	O
is	O
str	O
.	O

Can	O
I	O
ignore	O
that	O
while	O
apply	O
the	O
dropna	B-API
or	O
use	O
that	O
column	O
as	O
axis	O
?	O

take	O
a	O
look	O
at	O
the	O
example	O
file	O
at	O
the	O
link	O
?	O

#URL	O

Is	O
it	O
feasible	O
to	O
apply	O
your	O
techniques	O
when	O
no_row=1600000	O
and	O
no_colors=230000	O
?	O

Yon	O
convert	O
a	O
unixtimestamp	O
by	O
using	O
pandas	O
to_datetime	B-API
.	O

You	O
can	O
read	O
in	O
the	O
timecode	O
from	O
the	O
csv	O
as	O
an	O
integer	O
and	O
then	O
apply	O
pd.to_datetime	B-API
#CODE	O

Then	O
(	O
since	O
False	O
==	O
0	O
and	O
True	O
==	O
1	O
)	O
we	O
can	O
apply	O
a	O
cumulative	O
sum	O
to	O
get	O
a	O
number	O
for	O
the	O
groups	O
:	O
#CODE	O

There	O
are	O
lots	O
of	O
ways	O
to	O
apply	O
this	O
to	O
your	O
problem	O
,	O
but	O
if	O
I	O
understand	O
your	O
approach	O
correctly	O
--	O
a	O
straightforward	O
application	O
that	O
follows	O
your	O
structure	O
would	O
be	O
something	O
like	O
this	O
:	O
#CODE	O

I	O
think	O
I	O
need	O
to	O
use	O
the	O
apply	O
method	O
to	O
trim	O
the	O
column	O
data	O
.	O

So	O
if	O
there	O
is	O
anything	O
after	O
the	O
period	O
keep	O
the	O
data	O
unchanged	O
but	O
if	O
there	O
is	O
nothing	O
after	O
the	O
period	O
then	O
return	O
just	O
the	O
letters	O
without	O
the	O
period	O
at	O
the	O
end	O
.	O

I	O
know	O
I	O
can	O
probably	O
use	O
a	O
lambda	O
function	O
and	O
maybe	O
a	O
string	O
split	O
or	O
something	O
to	O
do	O
this	O
but	O
have	O
not	O
much	O
of	O
an	O
idea	O
to	O
make	O
it	O
happen	O
.	O

But	O
that	O
does	O
not	O
work	O
,	O
is	O
there	O
some	O
other	O
way	O
to	O
do	O
what	O
I	O
need	O
?	O

I	O
think	O
my	O
issue	O
is	O
that	O
method	O
is	O
for	O
a	O
series	O
and	O
not	O
a	O
column	O
of	O
values	O
.	O

I	O
tried	O
apply	O
and	O
could	O
not	O
seem	O
to	O
get	O
that	O
to	O
work	O
either	O
.	O

I	O
also	O
tried	O
using	O
the	O
apply	O
function	O
,	O
but	O
very	O
likely	O
I	O
am	O
doing	O
it	O
wrong	O
.	O

My	O
guess	O
is	O
that	O
I	O
am	O
either	O
not	O
applying	O
the	O
functions	O
correctly	O
for	O
a	O
column	O
or	O
the	O
values	O
I	O
am	O
getting	O
arent	O
integers	O
.	O

I	O
have	O
been	O
trying	O
for	O
days	O
so	O
now	O
am	O
breaking	O
down	O
to	O
ask	O
for	O
help	O
....	O

I	O
see	O
.	O

By	O
messed	O
up	O
,	O
I	O
realized	O
that	O
what	O
it	O
did	O
was	O
change	O
the	O
ordering	O
around	O
.	O

I'll	O
just	O
apply	O
a	O
sort	O
again	O
and	O
get	O
it	O
in	O
the	O
correct	O
order	O
.	O

This	O
answer	O
worked	O
,	O
thanks	O
a	O
bunch	O
!	O

I	O
spent	O
6	O
hours	O
trying	O
different	O
methods	O
.	O

:(	O

Unclear	O
if	O
it	O
should	O
work	O
at	O
all	O
but	O
you	O
could	O
apply	O
the	O
function	O
:	O
`	O
s.apply	O
(	O
pd.DataFrame.mean	B-API
)`	O

I	O
have	O
to	O
calibrate	O
a	O
distance	O
measuring	O
instrument	O
which	O
gives	O
capacitance	O
as	O
output	O
,	O
I	O
am	O
able	O
to	O
use	O
`	O
numpy	O
polyfit	B-API
`	O
to	O
find	O
a	O
relation	O
and	O
apply	O
it	O
get	O
distance	O
.	O

But	O
I	O
need	O
to	O
include	O
limits	O
of	O
detection	O
0.0008	O
m	O
as	O
it	O
is	O
the	O
resolution	O
of	O
the	O
instrument	O
.	O

For	O
example	O
If	O
I	O
have	O
a	O
capacitance	O
value	O
of	O
3044	O
and	O
if	O
you	O
look	O
into	O
calibration	O
data	O
the	O
distance	O
should	O
be	O
between	O
0.4	O
m	O
to	O
1	O
m	O
and	O
If	O
I	O
do	O
the	O
present	O
method	O
I	O
get	O
distance	O
like	O
0.8967892678	O
m	O
(	O
for	O
example	O
)	O
,	O
instead	O
something	O
like	O
0.8008	O
(	O
example	O
)	O
.	O

Because	O
the	O
instrument	O
will	O
only	O
able	O
to	O
differentiate	O
0.0008	O
m	O
.	O

I	O
need	O
to	O
apply	O
a	O
correction	O
like	O
if	O
the	O
value	O
is	O
between	O
the	O
two	O
numbers	O
it	O
is	O
rounded	O
and	O
shows	O
the	O
limits	O
of	O
detection	O

use	O
your	O
raw	O
data	O
of	O
known	O
distances	O
(	O
your	O
calibration	O
set	O
)	O
and	O
apply	O
the	O
fit	O
.	O
you	O
can	O
then	O
see	O
how	O
much	O
variation	O
you	O
have	O
from	O
the	O
actual	O
values	O
(	O
range	O
)	O
and	O
standard	O
deviation	O
(	O
1	O
sigma	O
)	O

@USER	O
I	O
mean	O
the	O
logic	O
behind	O
the	O
fact	O
that	O
I	O
can	O
apply	O
the	O
comparison	O
to	O
the	O
whole	O
DataFrame	B-API
only	O
if	O
the	O
rhs	O
is	O
a	O
Timedelta	O
,	O
although	O
it	O
works	O
just	O
fine	O
with	O
separate	O
columns	O
and	O
ints	O
.	O

Sorry	O
for	O
being	O
unclear	O
.	O

How	O
to	O
efficiently	O
apply	O
a	O
function	O
to	O
each	O
DataFrame	B-API
of	O
a	O
Pandas	O
Panel	O

I	O
am	O
trying	O
to	O
apply	O
a	O
function	O
to	O
every	O
DataFrame	B-API
in	O
a	O
Pandas	O
Panel	O
.	O

I	O
can	O
write	O
it	O
as	O
a	O
loop	O
but	O
the	O
indexing	O
seems	O
to	O
take	O
a	O
long	O
time	O
.	O

I	O
am	O
hoping	O
a	O
builtin	O
Pandas	O
function	O
might	O
be	O
faster	O
.	O

I	O
looked	O
at	O
`	O
mypanel.apply	O
(	O
condenser	O
,	O
axis	O
=	O
'	O
items	O
'	O
)`	O
but	O
this	O
loops	O
over	O
each	O
column	O
of	O
my	O
DataFrames	O
separately	O
.	O

Is	O
there	O
something	O
which	O
would	O
apply	O
a	O
function	O
to	O
each	O
DataFrame	B-API
?	O

apply	O
is	O
correct	O
,	O
but	O
the	O
usage	O
is	O
:	O

@USER	O
:	O
Thanks	O
!	O

Also	O
good	O
to	O
see	O
a	O
solution	O
using	O
`	O
apply	O
`	O
;	O
it	O
could	O
be	O
handy	O
for	O
implementing	O
more	O
exotic	O
concatenation	O
functions	O
.	O

try	O
to	O
use	O
str.cat	B-API
over	O
apply	O
whenever	O
you	O
can	O
.	O
feels	O
a	O
gazillion	O
times	O
faster	O
.	O

You	O
can	O
use	O
`	O
pandas.apply	O
(	O
args	O
)`	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
in	O
the	O
`	O
transdf	O
`	O
data	O
frame	O
if	O
you	O
know	O
that	O
the	O
rules	O
set	O
in	O
the	O
`	O
segmentdf	O
`	O
are	O
static	O
and	O
don't	O
change	O
.	O

Perhaps	O
the	O
following	O
code	O
snippet	O
may	O
help	O
you	O
.	O

I	O
haven't	O
tested	O
this	O
so	O
be	O
wary	O
,	O
but	O
I	O
think	O
it	O
should	O
get	O
you	O
started	O
in	O
the	O
right	O
direction	O
.	O

#CODE	O

Basically	O
,	O
the	O
cumulative	O
sum	O
operation	O
(	O
with	O
a	O
factor	O
)	O
is	O
done	O
using	O
`	O
numpy.convolve	B-API
`	O
.	O

The	O
rest	O
is	O
straight	O
forward	O
:	O
just	O
`	O
groupby	B-API
`	O
the	O
data	O
into	O
groups	O
,	O
apply	O
the	O
`	O
convolve	O
`	O
and	O
then	O
`	O
concat	O
`	O
the	O
resultants	O
together	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
force	O
all	O
your	O
objects	O
to	O
be	O
immutable	O
.	O

Try	O
#CODE	O

However	O
,	O
I	O
think	O
the	O
`	O
apply	O
`	O
function	O
does	O
not	O
allow	O
for	O
`	O
inplace	O
`	O
modification	O
,	O
right	O
?	O

So	O
what	O
I	O
basically	O
ended	O
up	O
doing	O
is	O
:	O
#CODE	O

You	O
can	O
apply	O
a	O
`	O
lambda	O
`	O
to	O
only	O
the	O
relevant	O
column	O
,	O
instead	O
of	O
the	O
whole	O
row	O
:	O
#CODE	O

I	O
believe	O
that	O
str()	B-API
or	O
the	O
int()	O
in	O
the	O
1st	O
line	O
of	O
your	O
function	O
wouldn't	O
like	O
a	O
NaN	O
.	O

You	O
could	O
change	O
your	O
apply	O
to	O
df.new_var	O
=	O
df.ID.dropna()	O
.apply	B-API
(	O
checker	O
)	O
or	O
test	O
for	O
NaN	O
in	O
your	O
function	O

I	O
think	O
using	O
`	O
nunique	B-API
`	O
is	O
better	O
than	O
calling	O
`	O
apply	O
(	O
len	O
)`	O
though	O
;)	O
+1	O

@USER	O
check	O
out	O
timings	O
,	O
`	O
nunique()	B-API
`	O
is	O
worse	O
than	O
`	O
apply	O
(	O
len	O
)`	O
:)	O

Now	O
add	O
another	O
column	O
for	O
the	O
week	O
and	O
year	O
(	O
one	O
way	O
is	O
to	O
use	O
`	O
apply	O
`	O
and	O
generate	O
a	O
string	O
of	O
the	O
week	O
/	O
year	O
numbers	O
):	O
#CODE	O

However	O
,	O
if	O
you	O
need	O
/	O
want	O
date	O
strings	O
with	O
3-letter	O
months	O
like	O
`'	O
NOV	O
'`	O
converted	O
to	O
`	O
-11-	O
`	O
,	O
then	O
you	O
can	O
convert	O
the	O
Timestamps	O
with	O
`	O
strftime	B-API
`	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

To	O
answer	O
your	O
question	O
literally	O
,	O
in	O
order	O
to	O
use	O
`	O
Series.str.replace	B-API
`	O
you	O
need	O
a	O
column	O
with	O
the	O
month	O
string	O
abbreviations	O
all	O
by	O
themselves	O
.	O

You	O
can	O
arrange	O
for	O
that	O
by	O
first	O
calling	O
`	O
Series.str.extract	B-API
`	O
.	O

Then	O
you	O
can	O
join	O
the	O
columns	O
back	O
into	O
one	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

what	O
column	O
are	O
you	O
calling	O
your	O
`	O
apply	O
`	O
on	O
?	O

A	O
sample	O
of	O
your	O
data	O
would	O
help	O
you	O
get	O
an	O
answer	O
much	O
quicker	O
.	O

I	O
would	O
like	O
to	O
apply	O
the	O
function	O
to	O
the	O
new	O
column	O
and	O
get	O
the	O
results	O
by	O
referencing	O
the	O
other	O
two	O
columns	O
.	O

The	O
data	O
is	O
a	O
bit	O
messy	O
and	O
also	O
confidentially	O
,	O
i	O
will	O
try	O
and	O
knock	O
together	O
some	O
simple	O
data	O
for	O
the	O
question	O
.	O

also	O
avoid	O
using	O
`	O
apply	O
`	O
where	O
possible	O
as	O
this	O
is	O
just	O
going	O
to	O
loop	O
over	O
the	O
values	O
,	O
`	O
np.where	B-API
`	O
is	O
a	O
vectorised	O
method	O
and	O
will	O
scale	O
much	O
better	O
.	O

@USER	O
no	O
worries	O
,	O
the	O
key	O
thing	O
to	O
take	O
away	O
from	O
this	O
is	O
to	O
look	O
for	O
a	O
vectorised	O
method	O
that	O
will	O
operate	O
on	O
the	O
whole	O
df	O
or	O
series	O
rather	O
than	O
calling	O
apply	O
which	O
loops	O
over	O
the	O
values	O

You'r	O
lambda	O
is	O
operating	O
on	O
the	O
0	O
axis	O
which	O
is	O
columnwise	O
.	O

Simply	O
add	O
`	O
axis=1	O
`	O
to	O
the	O
`	O
apply	O
`	O
arg	O
list	O
.	O

This	O
is	O
clearly	O
documented	O
.	O

#CODE	O

How	O
is	O
a	O
DataFrameGroupBy	B-API
structured	O
to	O
then	O
apply	O
functions	O
to	O
it	O
(	O
like	O
a	O
for	O
loop	O
)	O
?	O

Applying	O
a	O
cumulative	O
sum	O
on	O
this	O
DataFrame	B-API
is	O
easy	O
,	O
just	O
using	O
e.g.	O
`	O
df.cumsum()	B-API
`	O
.	O

But	O
is	O
it	O
possible	O
to	O
apply	O
a	O
cumulative	O
sum	O
every	O
`	O
X	O
`	O
days	O
(	O
or	O
data	O
points	O
)	O
say	O
,	O
yielding	O
only	O
the	O
cumulative	O
sum	O
of	O
the	O
last	O
`	O
Y	O
`	O
days	O
(	O
data	O
points	O
)	O
.	O

I	O
suppose	O
you	O
could	O
always	O
define	O
a	O
function	O
`	O
f	O
`	O
that	O
accepts	O
the	O
parameters	O
of	O
column	O
`	O
A	O
`	O
,	O
column	O
`	O
C	O
`	O
,	O
and	O
column	O
`	O
L	O
`	O
and	O
then	O
`	O
apply	O
`	O
it	O
to	O
your	O
data	O
frame	O
.	O

See	O
-->	O
#URL	O

You	O
need	O
to	O
explicitly	O
read	O
the	O
data	O
from	O
the	O
table	O
.	O

Table.read	O
will	O
pull	O
in	O
the	O
entire	O
table	O
,	O
and	O
Table.read_where	O
allows	O
you	O
to	O
apply	O
a	O
conditional	O
statement	O
to	O
filter	O
the	O
data	O
that	O
is	O
returned	O
.	O

#CODE	O

Going	O
around	O
,	O
I	O
have	O
found	O
also	O
this	O
solution	O
based	O
on	O
apply	O
method	O

So	O
for	O
the	O
short	O
example	O
I	O
give	O
df.index	O
has	O
shape	O
(	O
3	O
,	O
)	O
and	O
df.T	B-API
has	O
shape	O
(	O
2	O
,	O
3	O
)	O
.	O

I	O
think	O
numpy	O
broadcasting	O
(	O
which	O
I	O
thought	O
should	O
apply	O
here	O
)	O
goes	O
from	O
last	O
dimension	O
to	O
the	O
first	O
.	O

So	O
the	O
3's	O
should	O
match	O
and	O
the	O
operation	O
should	O
be	O
successful	O
.	O

That's	O
why	O
df.T.values	O
*	O
df.index.values	O
will	O
always	O
work	O
.	O

Is	O
there	O
any	O
smart	O
way	O
to	O
do	O
this	O
or	O
to	O
apply	O
gensim	O
from	O
pandas	O
data	O
?	O

Until	O
I	O
learn	O
how	O
to	O
use	O
map	O
/	O
apply	O
,	O
looping	O
through	O
a	O
pandas	O
dataframe	B-API
is	O
good	O
enough	O
.	O

`	O
df	O
[	O
'	O
ids	O
']	O
.str	B-API
`	O
allows	O
us	O
to	O
apply	O
vectorized	O
string	O
methods	O
(	O
e.g.	O
,	O
`	O
lower	O
`	O
,	O
`	O
contains	O
`)	O
to	O
the	O
Series	O

Here	O
comes	O
my	O
problem	O
,	O
I	O
would	O
like	O
to	O
apply	O
a	O
PCA	B-API
on	O
the	O
table	O
which	O
requires	O
the	O
whole	O
DataFrame	B-API
to	O
be	O
loaded	O
but	O
I	O
don't	O
have	O
enough	O
memory	O
to	O
do	O
that	O
.	O

The	O
PCA	B-API
function	O
takes	O
a	O
numpy	O
array	O
or	O
a	O
pandas	O
DataFrame	B-API
as	O
input	O
,	O
is	O
there	O
another	O
way	O
to	O
apply	O
a	O
PCA	B-API
that	O
would	O
directly	O
use	O
an	O
object	O
stored	O
on	O
disk	O
?	O

If	O
you	O
look	O
in	O
the	O
[	O
documentation	O
]	O
(	O
#URL	O
)	O
,	O
you	O
can	O
see	O
the	O
`	O
rolling_apply	B-API
`	O
function	O
,	O
which	O
allows	O
you	O
to	O
apply	O
any	O
function	O
in	O
a	O
rolling	O
way	O
.	O

Your	O
function	O
must	O
take	O
the	O
data	O
inside	O
the	O
"	O
rolling	O
window	O
"	O
as	O
an	O
argument	O
.	O

It's	O
not	O
clear	O
how	O
your	O
hodgesLehmannMean	O
involves	O
a	O
window	O
.	O

What	O
is	O
`	O
x	O
`	O
?	O

Is	O
it	O
the	O
window	O
or	O
the	O
whole	O
data	O
set	O
?	O

Pandas	O
apply	O
to	O
dateframe	O
produces	O
'	O
<	O
built-in	O
method	O
values	O
of	O
...	O

'	O

The	O
weirdest	O
part	O
is	O
,	O
when	O
I	O
directly	O
call	O
the	O
function	O
(	O
i.e.	O
`	O
make_geojson	O
(	O
data.loc	O
[	O
0	O
])`	O
I	O
do	O
in	O
fact	O
get	O
the	O
dictionary	O
I'm	O
expecting	O
.	O

Perhaps	O
even	O
weirder	O
is	O
that	O
,	O
when	O
I	O
call	O
the	O
functions	O
I'm	O
getting	O
from	O
the	O
apply	O
(	O
e.g.	O
`	O
data.output	O
[	O
0	O
]	O
(	O
)`	O
,	O
`	O
data.loc	O
[	O
0	O
]	O
[	O
'	O
output	O
']	O
(	O
)`)	O
I	O
get	O
the	O
equivalent	O
of	O
the	O
following	O
list	O
:	O

@USER	O
I	O
am	O
following	O
the	O
example	O
[	O
here	O
]	O
(	O
#URL	O
)	O
,	O
but	O
my	O
equivalent	O
of	O
`	O
f()	B-API
`	O
is	O
returning	O
a	O
`	O
dict	O
`	O
.	O

Same	O
issue	O
as	O
this	O
question	O
.	O

Yet	O
it's	O
possible	O
to	O
store	O
a	O
`	O
dict	O
`	O
in	O
a	O
`	O
DataFrame	B-API
`	O
.	O

I	O
don't	O
know	O
quite	O
what	O
you	O
mean	O
by	O
"	O
a	O
branch	O
is	O
taken	O
"	O
--	O
does	O
that	O
mean	O
:	O
`	O
apply	O
`	O
with	O
a	O
returned	O
`	O
dict	O
`	O
is	O
not	O
possible	O
at	O
all	O
?	O

Is	O
there	O
another	O
way	O
to	O
operate	O
on	O
each	O
row	O
while	O
storing	O
the	O
`	O
dict	O
`	O
result	O
in	O
a	O
new	O
column	O
?	O

You	O
can	O
pass	O
a	O
function	O
to	O
a	O
`	O
groupby	B-API
`	O
object	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

Then	O
you	O
can	O
apply	O
a	O
function	O
to	O
each	O
subset	O
.	O

It	O
sounds	O
like	O
you	O
want	O
either	O
`	O
rolling_mean	B-API
`	O
or	O
`	O
expanding_mean	B-API
`	O
,	O
both	O
of	O
which	O
are	O
already	O
available	O
in	O
`	O
pandas	O
`	O
:	O
#CODE	O

I'm	O
not	O
sure	O
how	O
you	O
can	O
do	O
things	O
within	O
the	O
function	O
,	O
it's	O
just	O
not	O
really	O
how	O
groupby	B-API
and	O
apply	O
work	O
.	O

`	O
frame.groupby	O
(	O
'	O
year	O
')	O
[[	O
'	O
gate	O
'	O
,	O
'	O
pop	O
']]`	O
is	O
almost	O
the	O
same	O
as	O
`	O
frame.groupby	O
(	O
'	O
year	O
')`	O
,	O
it	O
just	O
excludes	O
the	O
state	O
column	O
.	O

You	O
need	O
to	O
use	O
`	O
pandas.DataFrame.apply	B-API
`	O
.	O

The	O
code	O
below	O
will	O
apply	O
the	O
lambda	O
function	O
to	O
each	O
row	O
of	O
`	O
df	O
`	O
.	O

You	O
could	O
,	O
of	O
course	O
,	O
define	O
a	O
separate	O
function	O
(	O
if	O
you	O
need	O
to	O
do	O
more	O
something	O
more	O
complicated	O
)	O
.	O

#CODE	O

Apply	O
a	O
lambda	O
with	O
a	O
shift	O
function	O
in	O
python	O
pandas	O
were	O
some	O
null	O
elements	O
are	O
to	O
be	O
replaced	O

for	O
the	O
last	O
part	O
,	O
in	O
row	O
2	O
period	O
3	O
I	O
was	O
hoping	O
this	O
would	O
also	O
subsequently	O
be	O
filled	O
with	O
the	O
same	O
formula	O
i.e.	O
period	O
2	O
(	O
0.425	O
)	O
x	O
0.94	O
.	O

I	O
am	O
guessing	O
I	O
would	O
need	O
to	O
step	O
through	O
each	O
row	O
or	O
repeat	O
the	O
lambda	O
until	O
there	O
are	O
no	O
more	O
NaNs	O
?	O

I	O
was	O
assuming	O
a	O
lambda	O
function	O
would	O
automatically	O
apply	O
the	O
function	O
in	O
a	O
sort	O
of	O
iterrows	B-API
fashion	O
.	O

(	O
I'm	O
not	O
very	O
familiar	O
with	O
Pandas	O
,	O
but	O
this	O
describes	O
a	O
very	O
generic	O
idea	O
-	O
you	O
should	O
be	O
able	O
to	O
apply	O
it	O
.	O
If	O
necessary	O
,	O
adapt	O
the	O
Pandas-specific	O
functions	O
.	O
)	O

The	O
`	O
apply	O
`	O
method	O
calls	O
the	O
lambda	O
function	O
once	O
for	O
each	O
row	O
of	O
the	O
Series	O
,	O

using	O
Pandas	O
,	O
only	O
use	O
the	O
`	O
apply	O
`	O
method	O
if	O
there	O
is	O
no	O
other	O
option	O
.	O

space-efficient	O
.	O

So	O
`	O
zip	O
`	O
,	O
like	O
`	O
apply	O
`	O
,	O
should	O
be	O
avoided	O
here	O
if	O
possible	O
.	O

Both	O
functions	O
works	O
,	O
but	O
they	O
are	O
very	O
slow	O
if	O
I	O
use	O
them	O
on	O
thousands	O
of	O
csv	O
files	O
.	O

I	O
think	O
the	O
main	O
bottleneck	O
is	O
the	O
apply	O
method	O
.	O

Is	O
there	O
anyway	O
to	O
speed	O
it	O
up	O
?	O

Thank	O
you	O

You	O
are	O
right	O
that	O
using	O
`	O
apply	O
`	O
here	O
is	O
also	O
a	O
potential	O
bottleneck	O
,	O
since	O
it	O
is	O
calling	O
a	O
Python	O
function	O
once	O
for	O
each	O
row	O
of	O
the	O
dataframe	B-API
.	O

Instead	O
of	O
parsing	O
the	O
time	O
strings	O
using	O
`	O
to_timestamp	B-API
`	O
,	O
you	O
could	O
instead	O
use	O
`	O
pd.read_csv	B-API
`'	O
s	O
built-in	O
date	O
string	O
parsing	O
ability	O
:	O
#CODE	O

Oh	O
just	O
noticed	O
that	O
you	O
mentioned	O
you're	O
using	O
`	O
set_context	O
`	O
,	O
you	O
can	O
also	O
pass	O
that	O
information	O
to	O
the	O
`	O
rc	O
`	O
parameter	O
in	O
that	O
function	O
and	O
it	O
will	O
apply	O
to	O
all	O
figures	O
.	O

The	O
main	O
idea	O
behind	O
`	O
groupby	B-API
`	O
and	O
similar	O
functions	O
is	O
"	O
Split	O
-	O
Apply	O
-	O
Combine	O
"	O
whereby	O
,	O
in	O
general	O
,	O
you	O
:	O

Apply	O
some	O
aggregate	O
function	O
to	O
each	O
of	O
the	O
individual	O
groups	O
,	O

Finally	O
in	O
pandas	O
you	O
need	O
to	O
apply	O
some	O
aggregate	O
function	O
to	O
your	O
groups	O
(	O
the	O
apply	O
stage	O
)	O
,	O
we're	O
going	O
to	O
use	O
`	O
count()	B-API
`	O
to	O
count	O
the	O
amount	O
of	O
results	O
.	O

This	O
line	O
then	O
becomes	O
:	O
#CODE	O

You	O
can	O
use	O
the	O
`	O
xlsxwriter	O
`	O
engine	O
from	O
Pandas	O
to	O
apply	O
a	O
conditional	O
format	O
to	O
data	O
in	O
an	O
Excel	O
worksheet	O
.	O

See	O
this	O
answer	O
to	O
[	O
Easiest	O
way	O
to	O
create	O
a	O
color	O
gradient	O
on	O
excel	O
using	O
python	O
/	O
pandas	O
?	O
]	O
(	O
#URL	O
)	O
.	O

That	O
may	O
be	O
close	O
to	O
what	O
you	O
want	O
to	O
do	O
.	O

I've	O
been	O
through	O
lots	O
of	O
questions	O
in	O
stack	O
overflow	O
but	O
still	O
can't	O
figure	O
this	O
out	O
.	O

I	O
understand	O
it's	O
returning	O
a	O
Bool	O
etc	O
but	O
basically	O
I	O
want	O
to	O
apply	O
multiple	O
conditionals	O
to	O
a	O
DataFrame	B-API
(	O
If	O
And	O
Else	O
,	O
Else	O
if	O
...	O
)	O
But	O
continue	O
to	O
get	O
Ambiguous	O
Error	O
asking	O
to	O
you	O
use	O
any()	B-API
,	O
all()	B-API

I	O
don't	O
know	O
how	O
to	O
use	O
apply	O
,	O
or	O
whatever	O
else	O
,	O
to	O
figure	O
this	O
out	O
by	O
group	O
and	O
return	O
a	O
dataframe	B-API
of	O
only	O
those	O
groups	O
.	O

I	O
just	O
figured	O
out	O
the	O
answer	O
.	O

I	O
was	O
looking	O
at	O
apply	O
but	O
I	O
needed	O
to	O
use	O
filter	O
#CODE	O

Create	O
a	O
group	O
by	O
on	O
the	O
column	O
you	O
want	O
to	O
reduce	O
over	O
and	O
then	O
apply	O
a	O
function	O
that	O
returns	O
the	O
results	O
of	O
the	O
group	O
by	O
an	O
a	O
list	O
per	O
group	O
.	O

Note	O
this	O
returns	O
a	O
series	O
.	O

Note	O
that	O
the	O
type	O
on	O
the	O
date	O
is	O
now	O
Timestamp	O
,	O
not	O
datetime	O
.	O

Down	O
the	O
other	O
portion	O
of	O
my	O
code	O
it	O
stays	O
datettime	O
(	O
which	O
is	O
the	O
correct	O
chain	O
of	O
events	O
,	O
yes	O
?	O
)	O
and	O
so	O
now	O
they	O
both	O
reference	O
the	O
same	O
date	O
but	O
test	O
as	O
not	O
equal	O
so	O
I	O
can't	O
apply	O
DataFrame.update	B-API
to	O
push	O
data	O
from	O
one	O
to	O
the	O
other	O
.	O

Unfortunately	O
both	O
paths	O
have	O
strong	O
data-driven	O
reasons	O
why	O
they	O
should	O
be	O
done	O
the	O
way	O
they	O
are	O
.	O

`	O
df.columns.levels	O
[	O
1	O
]	O
[	O
0	O
]	O
.to_datetime()	B-API
`	O
will	O
convert	O
the	O
timestamps	O
back	O
to	O
datetime	O
.	O

I	O
can't	O
find	O
away	O
to	O
apply	O
this	O
to	O
the	O
whole	O
level	O
of	O
the	O
index	O
at	O
once	O
.	O

List	O
comprehension	O
will	O
work	O
but	O
i	O
guess	O
it	O
isn't	O
very	O
`	O
pandas	O
`	O

It	O
should	O
be	O
quite	O
straightforward	O
to	O
get	O
time	O
objects	O
into	O
a	O
dataframe	B-API
(	O
load	O
them	O
as	O
string	O
,	O
then	O
use	O
an	O
apply	O
to	O
transform	O
into	O
a	O
time	O
object	O
)	O

@USER	O
,	O
as	O
a	O
side	O
note	O
,	O
although	O
current	O
method	O
is	O
very	O
quick	O
,	O
it	O
could	O
benefit	O
even	O
more	O
if	O
you	O
apply	O
**	O
compiled	O
**	O
regexp	O
.	O

A	O
simple	O
`	O
apply	O
`	O
can	O
solve	O
this	O
.	O

If	O
you	O
can	O
weather	O
a	O
few	O
seconds	O
of	O
processing	O
,	O
I	O
think	O
this	O
is	O
the	O
simplest	O
method	O
available	O
to	O
you	O
without	O
venturing	O
outside	O
`	O
pandas	O
`	O
.	O

#CODE	O

Another	O
way	O
to	O
achieve	O
this	O
is	O
to	O
use	O
pd.Series.isin()	B-API
with	O
map	O
and	O
apply	O
,	O
with	O
your	O
sample	O
it	O
will	O
be	O
like	O
:	O
#CODE	O

@USER	O
,	O
I	O
think	O
speed-wise	O
,	O
using	O
regexp	O
will	O
be	O
faster	O
as	O
my	O
method	O
requires	O
3	O
x	O
**	O
apply	O
**	O
to	O
transform	O
the	O
string	O
content	O
,	O
efficiency	O
wise	O
,	O
using	O
**	O
map	O
**	O
will	O
yield	O
each	O
**	O
lambda	O
**	O
whereas	O
**	O
findall	B-API
**	O
may	O
eventually	O
max	O
out	O
memory	O

This	O
works	O
,	O
but	O
be	O
very	O
wary	O
of	O
applies	O
as	O
they	O
slow	O
things	O
down	O
as	O
your	O
data	O
grows	O
in	O
size	O
...	O

Regexs	O
are	O
so	O
fast	O
because	O
they	O
are	O
basically	O
just	O
lexical	O
parsing	O
.	O

If	O
you	O
really	O
are	O
that	O
concerned	O
about	O
memory	O
usage	O
(	O
which	O
shouldn't	O
be	O
the	O
case	O
here	O
as	O
you	O
are	O
already	O
holding	O
a	O
DF	O
in	O
memory	O
that	O
is	O
bigger	O
or	O
equal	O
in	O
size	O
to	O
the	O
resulting	O
df	O
)	O
and	O
want	O
to	O
use	O
apply	O
,	O
then	O
at	O
least	O
use	O
regexs	O
in	O
your	O
lambda	O
function	O
.	O

This	O
can	O
be	O
accomplished	O
with	O
a	O
one	O
line	O
solution	O
using	O
Pandas	O
'	O
boolean	O
indexing	O
.	O

The	O
one-liner	O
also	O
employs	O
some	O
other	O
tricks	O
:	O
Pandas	O
'	O
`	O
map	O
`	O
and	O
`	O
diff	O
`	O
methods	O
and	O
a	O
`	O
lambda	O
`	O
function	O
.	O

`	O
map	O
`	O
is	O
used	O
to	O
apply	O
the	O
`	O
lambda	O
`	O
function	O
to	O
all	O
rows	O
.	O

The	O
`	O
lambda	O
`	O
function	O
is	O
needed	O
to	O
create	O
a	O
custom	O
less-then	O
comparison	O
that	O
will	O
evaluate	O
NaN	O
values	O
to	O
True	O
.	O

Please	O
let	O
me	O
know	O
the	O
command	O
,	O
I	O
am	O
trying	O
with	O
apply	O
but	O
it	O
ll	O
only	O
given	O
the	O
boolean	O
expression	O
.	O

I	O
want	O
the	O
entire	O
row	O
with	O
latest	O
year	O
.	O

If	O
you	O
are	O
intending	O
to	O
apply	O
some	O
sorting	O
on	O
the	O
result	O
of	O
`	O
transform	O
`	O
then	O
sort	O
the	O
df	O
first	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
add	O
a	O
new	O
column	O
,	O
`	O
d	O
`	O
,	O
where	O
I	O
apply	O
a	O
rolling	O
function	O
,	O
on	O
a	O
fixed	O
window	O
(	O
6	O
here	O
)	O
,	O
where	O
I	O
somehow	O
,	O
for	O
each	O
row	O
(	O
or	O
date	O
)	O
,	O
fix	O
the	O
value	O
`	O
c	O
`	O
.	O

One	O
loop	O
in	O
this	O
rolling	O
function	O
should	O
be	O
(	O
pseudo	O
):	O
#CODE	O

I	O
am	O
trying	O
to	O
apply	O
a	O
filter	O
on	O
a	O
series	O
of	O
values	O
stored	O
in	O
a	O
pandas	O
series	O
object	O
.	O

The	O
desired	O
output	O
is	O
the	O
value	O
itself	O
if	O
it	O
meets	O
the	O
criterion	O
otherwise	O
zero	O
.	O

I	O
can	O
only	O
get	O
it	O
to	O
half	O
work	O
:	O
#CODE	O

Agree	O
with	O
@USER	O
.	O

`	O
to_datetime	B-API
`	O
is	O
another	O
option	O
,	O
though	O
for	O
more	O
esoteric	O
formats	O
,	O
`	O
strptime	O
`	O
and	O
`	O
apply	O
`	O
work	O
wonders	O
.	O

What	O
does	O
work	O
is	O
if	O
you	O
apply	O
the	O
same	O
mask	O
to	O
the	O
left	O
hand	O
side	O
like	O
so	O
:	O
#CODE	O

We	O
can	O
see	O
that	O
my	O
combined	O
code	O
is	O
marginally	O
faster	O
than	O
yours	O
so	O
there's	O
not	O
much	O
saved	O
by	O
doing	O
this	O
,	O
normally	O
you	O
can	O
apply	O
multiple	O
aggregation	O
functions	O
so	O
that	O
you	O
can	O
return	O
multiple	O
columns	O
,	O
but	O
the	O
problem	O
here	O
is	O
that	O
you	O
are	O
grouping	O
by	O
different	O
columns	O
so	O
we	O
have	O
to	O
perform	O
2	O
expensive	O
groupby	B-API
operations	O
.	O

This	O
obviously	O
means	O
that	O
I	O
wanted	O
to	O
search	O
for	O
words	O
like	O
rigour	O
and	O
rigour	O
s	O
,	O
en	O
demeanour	O
and	O
demeanour	O
s	O
,	O
centre	O
and	O
centre	O
s	O
,	O
h	O
arbour	O
and	O
arbour	O
,	O
and	O
fulfil	O
.	O

So	O
the	O
keywords	O
list	O
I	O
have	O
is	O
a	O
mix	O
of	O
complete	O
and	O
partial	O
strings	O
to	O
find	O
.	O

I	O
would	O
like	O
to	O
apply	O
the	O
search	O
on	O
this	O
DataFrame	B-API
"	O
df	O
"	O
:	O
#CODE	O

I	O
think	O
you've	O
neglected	O
to	O
pass	O
the	O
`	O
axis=1	O
`	O
param	O
to	O
apply	O
,	O
so	O
it's	O
operating	O
column-wise	O
hence	O
the	O
error	O
.	O

Try	O
:	O
`	O
holdings	O
[	O
'	O
wt	O
']	O
=	O
holdings.groupby	O
([	O
'	O
holdings.portfolio	O
'	O
,	O
'	O
holdings.date	O
'])	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
[	O
'	O
mv	O
']	O
/	O
sum	O
(	O
x	O
[	O
'	O
mv	O
'])	O
,	O
axis=1	O
)`	O

I'm	O
looking	O
into	O
using	O
the	O
`	O
sklearn.linear_model.LinearRegression	O
`	O
module	O
but	O
am	O
unsure	O
on	O
the	O
syntax	O
to	O
use	O
the	O
`	O
LinearRegression	O
`	O
in	O
the	O
`	O
apply	O
`	O
function	O
that	O
BrenBarn	O
suggested	O
.	O

I	O
thought	O
about	O
doing	O
an	O
`	O
apply	O
`	O
of	O
some	O
sorts	O
to	O
the	O
`	O
Category	O
`	O
column	O
after	O
`	O
groupby	B-API
`	O
but	O
I	O
am	O
having	O
trouble	O
figuring	O
out	O
the	O
right	O
function	O
.	O

As	O
requested	O
by	O
OP	O
,	O
if	O
you	O
want	O
to	O
implement	O
an	O
`	O
apply	O
(	O
lambda	O
...	O
)`	O
to	O
all	O
the	O
columns	O
then	O
you	O
can	O
either	O
explicitly	O
set	O
each	O
column	O
with	O
a	O
line	O
that	O
looks	O
like	O
the	O
one	O
above	O
replacing	O
`'	O
col1	O
'`	O
with	O
each	O
of	O
the	O
column	O
names	O
you	O
wish	O
to	O
alter	O
or	O
you	O
can	O
just	O
loop	O
over	O
the	O
columns	O
like	O
this	O
:	O

but	O
how	O
can	O
I	O
apply	O
this	O
to	O
my	O
entire	O
data	O
frame	O
??	O

can	O
you	O
edit	O
your	O
answer	O
to	O
my	O
question	O
,	O
it	O
would	O
be	O
really	O
helpful	O

It	O
varies	O
;	O
always	O
a	O
good	O
idea	O
to	O
use	O
`	O
timeit	O
`	O
yourself	O
to	O
find	O
out	O
,	O
if	O
it's	O
really	O
a	O
bottleneck	O
.	O

For	O
longer	O
frames	O
it'll	O
be	O
much	O
faster	O
than	O
`	O
apply	O
`	O
,	O
but	O
for	O
smaller	O
ones	O
you	O
won't	O
be	O
able	O
to	O
amortize	O
the	O
startup	O
cost	O
and	O
soit	O
might	O
be	O
a	O
little	O
slower	O
.	O

Use	O
`	O
any	O
`	O
and	O
pass	O
param	O
`	O
axis=1	O
`	O
which	O
tests	O
row-wise	O
this	O
will	O
produce	O
a	O
boolean	O
array	O
which	O
when	O
converted	O
to	O
int	O
will	O
convert	O
all	O
`	O
True	O
`	O
values	O
to	O
`	O
1	O
`	O
and	O
`	O
False	O
`	O
values	O
to	O
`	O
0	O
`	O
,	O
this	O
will	O
be	O
much	O
faster	O
than	O
calling	O
`	O
apply	O
`	O
which	O
is	O
going	O
to	O
iterate	O
row-wise	O
and	O
will	O
be	O
very	O
slow	O
:	O
#CODE	O

Using	O
the	O
`	O
%timeit	O
`	O
module	O
running	O
in	O
IPython	O
Notebook	O
the	O
`	O
for	O
`	O
loop	O
compared	O
to	O
the	O
`	O
apply	O
.	O

(	O
lambda	O
...	O
)`	O
is	O
a	O
little	O
over	O
3	O
times	O
as	O
fast	O
.	O

#CODE	O

@USER	O
is	O
there	O
a	O
reason	O
you	O
don't	O
want	O
to	O
use	O
a	O
loop	O
?	O

According	O
to	O
the	O
`	O
%timeit	O
`	O
module	O
running	O
in	O
IPython	O
Notebook	O
,	O
the	O
for	O
loop	O
implementation	O
is	O
over	O
3	O
times	O
as	O
fast	O
as	O
a	O
lambda	O
apply	O
.	O

I	O
thought	O
the	O
for	O
loop	O
is	O
less	O
efficient	O
as	O
l	O
thought	O
the	O
dataframe	B-API
apply	O
is	O
optimized	O
for	O
matrix	O
type	O
operation	O
like	O
MATLAB	O
.	O

I	O
probably	O
use	O
your	O
approach	O
and	O
stitch	O
the	O
result	O
back	O
to	O
the	O
main	O
dataframe	B-API
.	O

What's	O
is	O
the	O
most	O
efficient	O
to	O
stitch	O
that	O
column	O
vector	O
back	O
to	O
the	O
data	O
frame	O

I	O
know	O
that	O
this	O
very	O
possible	O
to	O
do	O
with	O
an	O
apply	O
command	O
but	O
I	O
would	O
like	O
to	O
keep	O
this	O
as	O
vectorized	O
as	O
possible	O
so	O
that	O
is	O
not	O
what	O
I	O
am	O
looking	O
for	O
.	O

So	O
far	O
I	O
haven't	O
found	O
any	O
solutions	O
anywhere	O
else	O
on	O
stack	O
overflow	O
.	O

I	O
knew	O
there	O
had	O
to	O
be	O
a	O
way	O
to	O
do	O
this	O
without	O
resorting	O
to	O
an	O
apply	O
function	O
.	O

Thank	O
you	O
so	O
much	O
.	O

If	O
you	O
want	O
to	O
mutate	O
a	O
series	O
(	O
column	O
)	O
in	O
pandas	O
,	O
the	O
pattern	O
is	O
to	O
`	O
apply	O
`	O
a	O
function	O
to	O
it	O
(	O
that	O
updates	O
on	O
element	O
in	O
the	O
series	O
at	O
a	O
time	O
)	O
,	O
and	O
to	O
then	O
assign	O
that	O
series	O
back	O
into	O
into	O
the	O
dataframe	B-API
#CODE	O

While	O
this	O
will	O
work	O
,	O
`	O
apply	O
`	O
is	O
the	O
method	O
of	O
last	O
resort	O
:	O
it	O
tends	O
to	O
be	O
pretty	O
slow	O
.	O

In	O
this	O
case	O
,	O
we	O
can	O
reach	O
for	O
the	O
vectorized	O
`	O
dt	O
`	O
accessor	O
,	O
and	O
get	O
the	O
times	O
via	O
`	O
df	O
[	O
"	O
date	O
"]	O
.dt	B-API
.time	B-API
`	O
(	O
after	O
we've	O
ensured	O
the	O
column	O
is	O
datetimelike	O
,	O
anyway	O
.	O
)	O

but	O
can't	O
figure	O
out	O
how	O
to	O
apply	O
this	O
to	O
my	O
problem	O
?	O

@USER	O
I	O
am	O
getting	O
an	O
Nan	O
value	O
if	O
I	O
apply	O
this	O
map	O
function	O
directly	O
to	O
my	O
data_org	O
data	O
frame	O
.	O

@USER	O
Sounds	O
like	O
the	O
apply	O
isn't	O
working	O
.	O

Can	O
you	O
post	O
the	O
exact	O
code	O
you	O
have	O
?	O

If	O
you're	O
using	O
a	O
full	O
dataframe	B-API
,	O
you	O
would	O
have	O
to	O
do	O
something	O
like	O
:	O
DF	O
[	O
'	O
COL	O
']	O
=	O
DF	O
[	O
'	O
COL	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
.......	O

apply	O
to	O
the	O
entire	O
dataframe	B-API
a	O
user-defined	O
function	O
involving	O
another	O
dataframe	B-API
in	O
pandas	O

Also	O
,	O
I	O
am	O
always	O
confused	O
by	O
apply	O
and	O
applymap	B-API
,	O
what	O
is	O
the	O
difference	O
and	O
when	O
should	O
use	O
one	O
over	O
the	O
other	O
?	O

Never	O
used	O
'	O
where	O
'	O
before	O
,	O
thank	O
you	O
very	O
much	O
!	O

is	O
there	O
any	O
other	O
method	O
to	O
do	O
it	O
?	O

maybe	O
using	O
apply	O
?	O

@USER	O
apply	O
won't	O
be	O
as	O
efficient	O
/	O
fast	O
as	O
vectorizing	O
or	O
using	O
where	O
,	O
since	O
basically	O
it	O
has	O
to	O
loop	O
through	O
within	O
python	O
just	O
like	O
you	O
do	O
in	O
your	O
example	O
code	O
(	O
rather	O
than	O
using	O
much	O
faster	O
numpy	O
/	O
C	O
)	O
.	O

Thanks	O
@USER	O
could	O
I	O
just	O
check	O
if	O
you	O
have	O
any	O
thoughts	O
on	O
the	O
first	O
question	O
?	O

Are	O
there	O
more	O
efficient	O
ways	O
to	O
pick	O
items	O
from	O
the	O
date	O
index	O
other	O
than	O
the	O
four	O
I've	O
described	O
above	O
?	O
..	O
and	O
thanks	O
for	O
explaining	O
the	O
get_loc_level	O
.	O

Do	O
you	O
any	O
use	O
case	O
examples	O
you	O
could	O
share	O
.	O

Where	O
might	O
I	O
apply	O
it	O
?	O

Some	O
timings	O
indicate	O
that	O
both	O
my	O
solution	O
as	O
that	O
of	O
@USER	O
is	O
much	O
faster	O
than	O
the	O
apply	O
(	O
pd.Series	B-API
)	O
approach	O
(	O
and	O
the	O
difference	O
between	O
both	O
is	O
negligible	O
):	O
#CODE	O

Python	O
pandas	O
apply	O
on	O
more	O
columns	O

How	O
can	O
I	O
generate	O
more	O
columns	O
in	O
a	O
dataframe	B-API
using	O
apply	O
with	O
more	O
columns	O
?	O

My	O
df	O
is	O
:	O
#CODE	O

But	O
what	O
if	O
I	O
want	O
to	O
use	O
more	O
than	O
two	O
columns	O
at	O
apply	O
?	O

#CODE	O

Using	O
the	O
Series	O
constructor	O
within	O
the	O
apply	O
usually	O
does	O
the	O
trick	O
:	O
#CODE	O

Thank	O
you	O
this	O
is	O
very	O
helpful	O
reference	O
.	O

I	O
had	O
tried	O
similar	O
methods	O
but	O
was	O
too	O
narrow	O
minded	O
on	O
solely	O
using	O
the	O
Datetimeindex	B-API
where	O
groupby	B-API
,	O
map	O
,	O
and	O
apply	O
were	O
running	O
into	O
errors	O
.	O

I	O
see	O
this	O
option	O
when	O
I	O
want	O
to	O
apply	O
a	O
scalar	O
result	O
,	O
but	O
I	O
couldn't	O
figure	O
out	O
how	O
to	O
put	O
df	O
into	O
lambda	O
like	O
this	O
:	O
#CODE	O

you	O
can	O
use	O
`	O
apply	O
`	O
column-wise	O
on	O
the	O
whole	O
dataframe	B-API
.	O

#CODE	O

@USER	O
you	O
might	O
be	O
able	O
to	O
use	O
slicing	O
to	O
index	O
a	O
range	O
of	O
columns	O
in	O
a	O
single	O
operation	O
and	O
an	O
`	O
apply	O
`	O
.	O

Check	O
out	O
the	O
Pandas	O
documentation	O
as	O
well	O
as	O
the	O
numerous	O
SO	O
questions	O
for	O
better	O
guidance	O
.	O

@USER	O
Hello	O
,	O
I	O
have	O
actually	O
came	O
across	O
groupby	B-API
in	O
the	O
documentation	O
/	O
cookbook	O
/	O
tutorials	O
.	O

I	O
felt	O
like	O
it	O
is	O
what	O
I	O
am	O
looking	O
for	O
,	O
however	O
I	O
was	O
not	O
able	O
to	O
apply	O
it	O
on	O
my	O
problem	O
.	O

You	O
can	O
pass	O
a	O
dictionary	O
to	O
`	O
aggfunc	O
`	O
with	O
what	O
functions	O
you	O
want	O
to	O
apply	O
for	O
each	O
column	O
like	O
this	O
:	O

Why	O
can't	O
I	O
apply	O
shift	O
from	O
within	O
a	O
pandas	O
function	O
?	O

Try	O
passing	O
the	O
frame	O
to	O
the	O
function	O
,	O
rather	O
than	O
using	O
`	O
apply	O
`	O
(	O
I	O
am	O
not	O
sure	O
why	O
`	O
apply	O
`	O
doesn't	O
work	O
,	O
even	O
column-wise	O
):	O
#CODE	O

have	O
not	O
seen	O
this	O
anywhere	O
in	O
the	O
pandas	O
documentation	O
!	O

will	O
pursue	O
further	O
,	O
but	O
is	O
this	O
performant	O
on	O
par	O
with	O
apply	O
?	O

My	O
assumption	O
is	O
that	O
this	O
is	O
more	O
performant	O
than	O
apply	O
as	O
(	O
if	O
?	O
)	O
the	O
shift	O
and	O
sum	O
are	O
vectorized	O
.	O

Apply	O
a	O
function	O
to	O
a	O
DataFrame	B-API
that	O
is	O
intended	O
to	O
operate	O

Where	O
is	O
it	O
that	O
I	O
have	O
to	O
apply	O
`	O
toarray	O
`	O
or	O
`	O
todense	O
`	O
?	O

This	O
is	O
one	O
method	O
,	O
I'm	O
trying	O
to	O
figure	O
out	O
a	O
vectorised	O
method	O
,	O
basically	O
you	O
define	O
a	O
function	O
that	O
takes	O
your	O
row	O
and	O
then	O
call	O
apply	O
,	O
passing	O
the	O
function	O
name	O
and	O
param	O
`	O
axis=1	O
`	O
to	O
apply	O
row-wise	O
.	O

The	O
color_cols	O
is	O
just	O
a	O
list	O
of	O
your	O
color	O
column	O
names	O
defined	O
by	O
:	O
`	O
color_cols	O
=	O
[	O
col	O
for	O
col	O
in	O
df	O
if	O
'	O
color	O
'	O
in	O
col	O
]`	O
#CODE	O

The	O
mask	O
method	O
is	O
over	O
2x	O
faster	O
than	O
the	O
query	O
and	O
eval	O
method	O
for	O
this	O
sample	O
dataset	O
.	O

The	O
`	O
apply	O
`	O
method	O
is	O
actually	O
the	O
fastest	O
method	O
but	O
it	O
will	O
not	O
scale	O
as	O
well	O
as	O
the	O
other	O
methods	O
as	O
this	O
essentially	O
loops	O
over	O
each	O
row	O
.	O

Your	O
method	O
works	O
well	O
.	O

But	O
am	O
struggling	O
to	O
apply	O
it	O
when	O
there	O
are	O
multiple	O
columns	O
in	O
the	O
df1	O
.	O

and	O
now	O
the	O
muzz	O
function	O
.	O

EDIT	O
:	O
Added	O
choices=	O
right	O
[	O
match_col_name	O
]	O
line	O
and	O
used	O
choices	O
in	O
the	O
apply	O
per	O
Brenbarn	O
suggestion	O
.	O

I	O
also	O
,	O
per	O
Brenbarn	O
suggestion	O
,	O
ran	O
some	O
tests	O
with	O
the	O
extractOne()	O
without	O
the	O
apply	O
and	O
it	O
it	O
appears	O
to	O
be	O
the	O
bottleneck	O
.	O

Maybe	O
there's	O
a	O
faster	O
way	O
to	O
do	O
the	O
fuzzy	O
matching	O
?	O

#CODE	O

One	O
possibility	O
is	O
to	O
pull	O
the	O
`	O
right	O
[	O
match_col_name	O
]`	O
outside	O
of	O
the	O
`	O
apply	O
`	O
,	O
so	O
that	O
you	O
don't	O
recalculate	O
it	O
every	O
time	O
.	O

You	O
should	O
try	O
profiling	O
your	O
code	O
and	O
testing	O
it	O
with	O
different	O
inputs	O
to	O
see	O
if	O
the	O
bottleneck	O
is	O
really	O
in	O
the	O
apply	O
or	O
in	O
the	O
fuzzy	O
matching	O
itself	O
.	O

Yes	O
,	O
but	O
that	O
is	O
inside	O
the	O
function	O
you	O
apply	O
,	O
which	O
is	O
called	O
once	O
for	O
each	O
element	O
in	O
the	O
series	O
you	O
apply	O
it	O
on	O
.	O

Your	O
code	O
retrieves	O
`	O
right	O
[	O
match_col_name	O
]`	O
repeatedly	O
,	O
once	O
for	O
each	O
element	O
in	O
the	O
Series	O
.	O

If	O
you	O
extract	O
this	O
once	O
to	O
a	O
variable	O
and	O
then	O
use	O
the	O
variable	O
in	O
the	O
call	O
,	O
you	O
will	O
avoid	O
all	O
those	O
redundant	O
lookups	O
.	O

Why	O
the	O
mismatch	O
in	O
second	O
doing	O
grouping	O
one	O
by	O
one	O
in	O
A	O
then	O
C	O
vs	O
doing	O
them	O
together	O
.	O

Is	O
it	O
a	O
bug	O
or	O
feature	O
?	O

Normally	O
multi	O
grouping	O
should	O
proceed	O
in	O
this	O
fashion	O
.	O

First	O
take	O
out	O
elements	O
satisfying	O
predicate	O
'	O
A	O
'	O
and	O
then	O
use	O
those	O
groups	O
to	O
apply	O
'	O
C	O
'	O
grouping	O
.	O

that	O
should	O
be	O
one	O
of	O
the	O
behaviours	O
of	O
groupby	B-API
.	O
apply	O
qcut	B-API
to	O
subset	O
of	O
values	O
in	O
column	O
C	O
.	O

Coz	O
already	O
it's	O
been	O
cut	O
into	O
2	O
parts	O
via	O
'	O
A	O
'	O
cut	O

is	O
it	O
possible	O
to	O
do	O
grouping	O
via	O
'	O
A	O
'	O
,	O
and	O
then	O
for	O
each	O
of	O
those	O
groups	O
apply	O
grouping	O
to	O
column	O
'	O
C	O
'	O
via	O
map	O
/	O
lambda's	O
?	O

But	O
I	O
can't	O
find	O
how	O
to	O
apply	O
this	O
to	O
multiple	O
columns	O

An	O
alternative	O
is	O
to	O
apply	O
:	O
#CODE	O

Thanks	O
@USER	O
.	O

It's	O
interesting	O
that	O
you	O
sort	O
entries	O
within	O
apply	O
(	O
e.g.	O
as	O
opposed	O
to	O
sorting	O
them	O
*	O
before	O
*	O
running	O
groupby	B-API
and	O
apply	O
)	O
.	O

Is	O
this	O
because	O
`	O
groupby	B-API
`	O
is	O
not	O
guaranteed	O
to	O
preserve	O
the	O
original	O
ordering	O
?	O

@USER	O
-Reina	O
in	O
situations	O
like	O
this	O
(	O
when	O
the	O
function	O
doesn't	O
"	O
reduce	O
")	O
then	O
transform	O
and	O
apply	O
are	O
the	O
same	O
.	O

In	O
retrospect	O
,	O
I	O
think	O
that	O
sorting	O
globally	O
may	O
be	O
faster	O
...	O

I	O
mistakenly	O
thought	O
that	O
was	O
the	O
issue	O
causing	O
the	O
most	O
slow	O
down	O
.	O

I	O
think	O
I	O
have	O
a	O
better	O
solution	O
.	O

One	O
way	O
is	O
to	O
use	O
`	O
functools.partial	O
`	O
to	O
partially	O
apply	O
the	O
merge	O
function	O
.	O

#CODE	O

Hi	O
,	O
thanks	O
,	O
but	O
I	O
don't	O
think	O
this	O
answers	O
my	O
question	O
though	O
.	O

Those	O
methods	O
don't	O
create	O
the	O
rank	O
over	O
a	O
window	O
.	O

I	O
have	O
read	O
through	O
the	O
documentation	O
which	O
led	O
me	O
to	O
`	O
rolling_apply	B-API
`	O
.	O

However	O
this	O
appears	O
to	O
simply	O
apply	O
the	O
function	O
a	O
fresh	O
to	O
each	O
window	O
and	O
over	O
a	O
large	O
dataset	O
in	O
can	O
take	O
a	O
long	O
time	O
to	O
iteratively	O
apply	O
that	O
function	O
.	O

Using	O
the	O
pandas	O
roll	O
function	O
was	O
far	O
to	O
slow	O
.	O
argsort	B-API
was	O
faster	O
,	O
closer	O
to	O
the	O
bottleneck	O
method	O
above	O
,	O
but	O
I	O
still	O
believe	O
it	O
shouldn't	O
be	O
to	O
difficult	O
to	O
implement	O
a	O
much	O
more	O
efficient	O
way	O
,	O
either	O
by	O
using	O
online	O
windows	O
,	O
or	O
a	O
method	O
I	O
am	O
missing	O
?	O

Apply	O
will	O
only	O
return	O
more	O
rows	O
than	O
it	O
gets	O
with	O
a	O
groupby	B-API
,	O
so	O
we're	O
going	O
to	O
use	O
groupby	B-API
artificially	O
(	O
i.e.	O
groupby	B-API
a	O
column	O
of	O
unique	O
values	O
,	O
so	O
each	O
group	O
is	O
one	O
line	O
)	O
.	O

#CODE	O

If	O
you	O
want	O
to	O
stay	O
in	O
pure	O
pandas	O
you	O
can	O
throw	O
in	O
a	O
tricky	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
which	O
ends	O
up	O
boiling	O
down	O
to	O
a	O
one	O
liner	O
if	O
you	O
don't	O
count	O
the	O
column	O
rename	O
.	O

#CODE	O

We	O
want	O
the	O
date	O
to	O
become	O
the	O
single	O
index	O
for	O
the	O
new	O
rows	O
so	O
we	O
use	O
`	O
groupby	B-API
`	O
which	O
puts	O
the	O
desired	O
row	O
value	O
into	O
an	O
index	O
.	O

Then	O
inside	O
that	O
operation	O
I	O
want	O
to	O
split	O
only	O
this	O
list	O
for	O
this	O
date	O
which	O
is	O
what	O
`	O
apply	O
`	O
will	O
do	O
for	O
us	O
.	O

I'm	O
passing	O
`	O
apply	O
`	O
a	O
pandas	O
`	O
Series	O
`	O
which	O
consists	O
of	O
a	O
single	O
list	O
but	O
I	O
can	O
access	O
that	O
list	O
via	O
a	O
`	O
.values	B-API
[	O
0	O
]`	O
which	O
pushes	O
the	O
sole	O
row	O
of	O
the	O
`	O
Series	O
`	O
to	O
an	O
array	O
with	O
a	O
single	O
entry	O
.	O

Speed	O
wise	O
this	O
tends	O
to	O
be	O
pretty	O
good	O
and	O
since	O
it	O
relies	O
on	O
`	O
apply	O
`	O
any	O
parallelization	O
tricks	O
that	O
work	O
with	O
`	O
apply	O
`	O
work	O
here	O
.	O

I've	O
checked	O
out	O
map	O
,	O
apply	O
,	O
mapapply	O
,	O
and	O
combine	O
,	O
but	O
can't	O
seem	O
to	O
find	O
a	O
simple	O
way	O
of	O
doing	O
the	O
following	O
:	O

I	O
want	O
to	O
apply	O
this	O
and	O
create	O
a	O
new	O
column	O
in	O
the	O
dataframe	B-API
with	O
the	O
result	O
.	O

#CODE	O

@USER	O
you	O
not	O
allowing	O
pandas	O
to	O
do	O
anything	O
with	O
your	O
UDF	O
here	O
.	O

You	O
are	O
doing	O
way	O
too	O
much	O
in	O
the	O
apply	O
of	O
the	O
groupby	B-API
.	O

I	O
am	O
not	O
exactly	O
sure	O
what	O
you	O
are	O
trying	O
to	O
achieve	O
,	O
but	O
using	O
try	O
except	O
blocks	O
,	O
loc	O
,	O
and	O
mutation	O
of	O
the	O
passed	O
in	O
data	O
INSIDE	O
OF	O
A	O
GROUPBY	B-API
is	O
quite	O
inefficient	O
.	O

A	O
combination	O
of	O
filter	O
and	O
/	O
or	O
indexing	O
will	O
achieve	O
what	O
you	O
want	O
in	O
a	O
much	O
more	O
efficient	O
way	O
.	O

Pls	O
read	O
the	O
docs	O
#URL	O
and	O
possibly	O
provide	O
a	O
self-reproducing	O
example	O
(	O
in	O
a	O
new	O
question	O
)	O
if	O
you	O
still	O
have	O
concerns	O
.	O

Pandas	O
to_html()	B-API
:	O
Apply	O
CSS	O
style	O
to	O
<	O
td	O
>	O
tag	O

Easy	O
way	O
to	O
apply	O
transformation	O
from	O
`	O
pandas.get_dummies	B-API
`	O
to	O
new	O
data	O
?	O

Then	O
apply	O
the	O
rule	O
to	O
the	O
datatime	O
index	O
,	O
and	O
to	O
a	O
datetime	O
object	O
using	O
'	O
to_period	B-API
`	O
for	O
filtering	O
:	O
#CODE	O

Pandas	O
on	O
Apply	O
passing	O
wrong	O
value	O

Apply	O
function	O
to	O
Dataframe	B-API
GroupBy	B-API
Object	O
and	O
return	O
dataframe	B-API

Using	O
`	O
groupby	B-API
`	O
with	O
`	O
apply	O
`	O
will	O
give	O
you	O
a	O
Series	O
mapping	O
old	O
to	O
new	O
IPs	O
:	O
#CODE	O

Can	O
you	O
show	O
how	O
you	O
were	O
using	O
pd.to_datetime	B-API
?	O

That	O
should	O
work	O
fine	O
.	O

If	O
for	O
some	O
reason	O
it	O
won't	O
work	O
,	O
you	O
can	O
apply	O
a	O
strptime	O
function	O
to	O
the	O
str	O
series	O
.	O

#URL	O

How	O
would	O
I	O
apply	O
it	O
on	O
a	O
specific	O
slice	O
of	O
the	O
data	O
frame	O
,	O
e.g.	O
I	O
want	O
to	O
run	O
the	O
script	O
for	O
each	O
row	O
,	O
but	O
only	O
using	O
columns	O
6	O
through	O
12	O
?	O

Both	O
of	O
these	O
methods	O
are	O
10	O
times	O
more	O
efficient	O
than	O
the	O
previous	O
one	O
,	O
iterate	O
on	O
rows	O
which	O
is	O
good	O
and	O
work	O
perfectly	O
on	O
my	O
"	O
debug	O
"	O
table	O
`	O
df	O
`	O
.	O

But	O
,	O
when	O
I	O
apply	O
it	O
to	O
my	O
"	O
test	O
"	O
table	O
of	O
18k	O
x	O
40k	O
,	O
it	O
leads	O
to	O
a	O
`	O
MemoryError	O
:	O
`	O
(	O
I	O
have	O
60%	O
of	O
my	O
32GB	O
of	O
RAM	O
occupied	O
after	O
reading	O
the	O
corresponding	O
csv	O
file	O
)	O
.	O

I	O
don't	O
understand	O
your	O
question	O
if	O
you	O
did	O
this	O
:	O
`	O
df.groupby	B-API
(	O
'	O
A	O
')	O
[	O
'	O
B	O
']`	O
then	O
you	O
explicitly	O
select	O
just	O
column	O
'	O
B	O
'	O
and	O
then	O
you	O
can	O
still	O
apply	O
your	O
functions	O
to	O
this	O
only	O

If	O
I	O
apply	O
an	O
operation	O
to	O
the	O
Value	O
column	O
I	O
would	O
then	O
like	O
to	O
recalculate	O
the	O
groupby	B-API
operation	O
:	O
#CODE	O

I	O
think	O
the	O
calculated	O
groupby	B-API
MultiIndex	O
should	O
be	O
re-usable	O
to	O
re-calculate	O
the	O
new	O
agg	O
functions	O
(	O
np.sum	B-API
is	O
an	O
example	O
)	O
,	O
but	O
I	O
can't	O
work	O
out	O
how	O
to	O
apply	O
it	O
.	O

How	O
would	O
one	O
most	O
efficiently	O
reuse	O
a	O
groupby	B-API
method	O
on	O
a	O
dataframe	B-API
of	O
the	O
same	O
shape	O
and	O
columns	O
structure	O
multiple	O
times	O
?	O

True	O
and	O
I	O
often	O
do	O
,	O
but	O
in	O
this	O
instance	O
I	O
want	O
to	O
be	O
able	O
to	O
use	O
the	O
groupby	B-API
data	O
/	O
construct	O
to	O
apply	O
the	O
operation	O
on	O
a	O
fresh	O
data	O
frame	O
.	O

In	O
actual	O
fact	O
I	O
would	O
want	O
to	O
save	O
the	O
groupby	B-API
to	O
a	O
hdf	O
and	O
reload	O
it	O
in	O
separate	O
threads	O
,	O
but	O
it	O
doesn't	O
seem	O
possible	O
to	O
save	O
a	O
groupby	B-API
object	O
to	O
a	O
file	O
.	O

Pandas	O
speedup	O
apply	O
on	O
max()	B-API

I	O
got	O
some	O
fantasy	O
football	O
data	O
and	O
I'm	O
trying	O
to	O
sort	O
it	O
out	O
so	O
I	O
can	O
later	O
apply	O
on	O
it	O
,	O
the	O
full	O
force	O
of	O
scikit-learn	O
.	O

Here's	O
solution	O
for	O
you	O
test	O
data	O
,	O
I	O
think	O
you	O
can	O
easily	O
apply	O
it	O
to	O
your	O
real	O
data	O
#CODE	O

You	O
don't	O
need	O
to	O
use	O
`	O
where	O
`	O
.	O

Just	O
use	O
`	O
isin	B-API
`	O
and	O
apply	O
your	O
condition	O
directly	O
to	O
the	O
columns	O
:	O
#CODE	O

This	O
will	O
apply	O
it	O
to	O
only	O
the	O
columns	O
you	O
desire	O
and	O
assign	O
the	O
result	O
back	O
to	O
those	O
columns	O
.	O

Alternatively	O
you	O
could	O
set	O
them	O
to	O
new	O
,	O
normalized	O
columns	O
and	O
keep	O
the	O
originals	O
if	O
you	O
want	O
.	O

Otherwise	O
you	O
can	O
call	O
`	O
apply	O
`	O
like	O
so	O
:	O
#CODE	O

In	O
the	O
case	O
where	O
the	O
above	O
won't	O
work	O
as	O
it	O
can't	O
generate	O
a	O
Series	O
to	O
align	O
with	O
you	O
df	O
you	O
can	O
apply	O
row-wise	O
passing	O
`	O
axis=1	O
`	O
to	O
the	O
df	O
:	O
#CODE	O

pandas	O
apply	O
over	O
a	O
single	O
column	O

how	O
can	O
I	O
apply	O
this	O
function	O
over	O
a	O
single	O
column	O
of	O
pandas	O
?	O

In	O
pandas	O
documentation	O
,	O
the	O
structure	O
of	O
the	O
function	O
is	O
given	O
as	O

but	O
I	O
don't	O
see	O
any	O
ability	O
to	O
apply	O
it	O
to	O
a	O
column	O
of	O
the	O
dataframe	B-API
.	O

1	O
.	O

I'd	O
just	O
convert	O
the	O
columns	O
to	O
datetime	O
and	O
then	O
access	O
the	O
date	O
attribute	O
,	O
so	O
`	O
df	O
[	O
'	O
time	O
']	O
=	O
pd.to_datetime	B-API
(	O
df	O
[	O
'	O
time	O
'])	O
.date	B-API
`	O
2	O
.	O

You	O
can	O
apply	O
to	O
a	O
series	O
also	O
but	O
if	O
you	O
want	O
to	O
use	O
the	O
axis	O
param	O
then	O
you	O
can	O
force	O
a	O
df	O
with	O
a	O
single	O
column	O
using	O
double	O
sqaure	O
brackets	O
:	O
`	O
df	O
[[	O
col_name	O
]]	O
.apply	B-API
(	O
func	O
,	O
axis=0	O
)`	O
3	O
.	O
to	O
check	O
if	O
an	O
element	O
is	O
nan	O
you	O
can	O
use	O
the	O
top-level	O
`	O
isnull	O
`	O
method	O
so	O
`	O
pd.isnull	B-API
(	O
x	O
)`	O
will	O
return	O
True	O
or	O
False	O

If	O
you	O
can	O
write	O
this	O
as	O
a	O
function	O
that	O
takes	O
in	O
a	O
1d	O
array	O
(	O
list	O
,	O
numpy	O
array	O
etc	O
...	O
)	O
,	O
you	O
can	O
use	O
df.apply	B-API
to	O
apply	O
it	O
to	O
any	O
column	O
,	O
using	O
`	O
df.apply()	B-API
`	O
.	O

Pandas	O
already	O
knows	O
that	O
it	O
must	O
apply	O
the	O
equation	O
to	O
every	O
row	O
and	O
return	O
each	O
value	O
to	O
its	O
proper	O
index	O
.	O

I	O
didn't	O
realize	O
it	O
would	O
be	O
this	O
easy	O
and	O
was	O
looking	O
for	O
more	O
explicit	O
code	O
.	O

apply	O
the	O
function	O
to	O
the	O
dataframe	B-API
:	O
#CODE	O

I	O
would	O
like	O
to	O
create	O
a	O
function	O
that	O
does	O
this	O
for	O
one	O
imo	O
,	O
and	O
then	O
I	O
can	O
apply	O
it	O
to	O
all	O
of	O
them	O
but	O
I	O
am	O
unfortunately	O
stuck	O
.	O

Apply	O
a	O
function	O
data	O
frame	O
column	O

But	O
note	O
!	O

my	O
test	O
data	O
was	O
evenly	O
sampled	O
.	O

Looks	O
like	O
`	O
rolling_*	O
`	O
don't	O
apply	O
to	O
irregular	O
time	O
series	O
yet	O
,	O
though	O
there	O
are	O
some	O
workarounds	O
:	O
Pandas	O
:	O
rolling	O
mean	O
by	O
time	O
interval	O

I	O
want	O
to	O
loop	O
through	O
and	O
apply	O
a	O
function	O
to	O
the	O
dataframes	O
within	O
`	O
groups	O
`	O
that	O
have	O
more	O
than	O
one	O
row	O
in	O
them	O
.	O

My	O
code	O
is	O
below	O
,	O
here	O
each	O
dataframe	B-API
is	O
the	O
`	O
value	O
`	O
in	O
the	O
key	O
,	O
value	O
pair	O
:	O
#CODE	O

Then	O
you	O
can	O
apply	O
the	O
following	O
logic	O
.	O

#CODE	O

Your	O
original	O
issue	O
was	O
caused	O
because	O
your	O
individual	O
loops	O
did	O
not	O
contain	O
the	O
same	O
amount	O
of	O
each	O
element	O
you	O
were	O
looping	O
through	O
(	O
i.e.	O
-	O
15	O
stars	O
,	O
v	O
.	O
20	O
prices	O
)	O
.	O

The	O
best	O
way	O
to	O
avoid	O
this	O
type	O
of	O
issue	O
is	O
to	O
firstly	O
have	O
one	O
loop	O
and	O
then	O
to	O
apply	O
a	O
try	O
except	O
value	O
to	O
each	O
item	O
you're	O
scaping	O
.	O

That	O
way	O
if	O
there	O
are	O
any	O
issues	O
with	O
the	O
constant	O
presence	O
of	O
the	O
items	O
you	O
want	O
,	O
you	O
can	O
still	O
collect	O
what	O
is	O
present	O
.	O

#CODE	O

Is	O
there	O
a	O
way	O
that	O
I	O
can	O
apply	O
this	O
to	O
the	O
entire	O
dataframe	B-API
at	O
once	O
,	O
rather	O
than	O
looping	O
through	O
rows	O
?	O

Or	O
other	O
suggestions	O
to	O
speed	O
this	O
up	O
?	O

How	O
to	O
apply	O
rolling	O
functions	O
in	O
a	O
group	O
by	O
object	O
in	O
pandas	O

Apply	O
rolling	O
mean	O
function	O
on	O
data	O
frames	O
with	O
duplicated	O
indices	O
in	O
pandas	O

You	O
can	O
check	O
this	O
question	O
and	O
its	O
answer	O
to	O
see	O
how	O
to	O
apply	O
a	O
function	O
row	O
by	O
row	O
:	O
#URL	O
Otherwise	O
,	O
in	O
order	O
to	O
fully	O
answer	O
the	O
question	O
i.e.	O
be	O
able	O
to	O
have	O
all	O
desired	O
fields	O
,	O
we	O
need	O
to	O
know	O
exactly	O
what's	O
in	O
the	O
data	O
(	O
not	O
just	O
one	O
line	O
)	O
.	O

Could	O
you	O
for	O
instance	O
split	O
on	O
"	O
two	O
blanks	O
or	O
more	O
"	O
(	O
typically	O
no	O
if	O
there	O
are	O
missing	O
values	O
)	O
...	O
or	O
do	O
columns	O
have	O
the	O
same	O
position	O
in	O
the	O
string	O
in	O
each	O
row	O
etc	O
.	O

Python	O
Pandas	O
:	O
Apply	O
function	O
to	O
dataframe	B-API
in	O
place	O

Although	O
apply	O
doesn't	O
offer	O
an	O
inplace	O
,	O
you	O
could	O
do	O
something	O
like	O
the	O
following	O
(	O
which	O
I	O
would	O
argue	O
was	O
more	O
explicit	O
anyway	O
):	O
#CODE	O

How	O
can	O
I	O
apply	O
a	O
function	O
that	O
transforms	O
it	O
into	O
a	O
dataframe	B-API
like	O
this	O
:	O
#CODE	O

I	O
could	O
use	O
a	O
list	O
comprehension	O
to	O
apply	O
the	O
selected	O
result	O
on	O
the	O
`	O
get_loc	B-API
`	O
function	O
,	O
but	O
perhaps	O
there's	O
some	O
Pandas-built-in	O
function	O
.	O

Apply	O
permutation	O
matrix	O
to	O
pandas	O
DataFrame	B-API

I	O
have	O
two	O
identically	O
sized	O
DataFrames	O
(	O
call	O
them	O
`	O
A	O
`	O
and	O
`	O
B	O
`)	O
with	O
the	O
same	O
set	O
of	O
index	O
and	O
column	O
names	O
.	O

`	O
A	O
`	O
and	O
`	O
B	O
`	O
have	O
a	O
different	O
ordering	O
of	O
their	O
(	O
row	O
/	O
column	O
)	O
labels	O
and	O
I	O
want	O
them	O
to	O
be	O
identically	O
labeled	O
so	O
I	O
can	O
directly	O
manipulate	O
the	O
matrices	O
in	O
other	O
programs	O
.	O

Mathematically	O
,	O
there	O
is	O
a	O
permutation	O
matrix	O
`	O
P	O
`	O
that	O
reshuffles	O
one	O
matrix	O
labels	O
to	O
another	O
,	O
so	O
I	O
can	O
apply	O
this	O
transformation	O
by	O
constructing	O
the	O
matrix	O
.	O

I	O
feel	O
however	O
,	O
that	O
this	O
is	O
overkill	O
and	O
a	O
solution	O
should	O
exist	O
within	O
pandas	O
itself	O
.	O

Calculate	O
the	O
weights	O
you'll	O
need	O
to	O
apply	O
to	O
achieve	O
your	O
target	O
age	O
/	O
gender	O
distribution	O
:	O
#CODE	O

If	O
anyone	O
has	O
experience	O
with	O
this	O
I'd	O
love	O
to	O
see	O
what	O
you	O
wrote	O
.	O

There	O
are	O
examples	O
online	O
for	O
using	O
a	O
.csvreader	O
with	O
python	O
which	O
loops	O
through	O
the	O
rows	O
and	O
adds	O
them	O
as	O
they	O
are	O
being	O
read	O
but	O
I	O
can't	O
find	O
any	O
example	O
of	O
how	O
to	O
take	O
data	O
stored	O
in	O
a	O
dataframe	B-API
and	O
apply	O
it	O
to	O
a	O
table	O
defined	O
as	O
part	O
of	O
an	O
extract	O
.	O

I've	O
read	O
all	O
the	O
documentation	O
I'm	O
just	O
not	O
sure	O
how	O
to	O
apply	O
it	O
.	O

There	O
is	O
no	O
clear	O
instruction	O
as	O
to	O
moving	O
data	O
from	O
a	O
dataframe	B-API
to	O
a	O
virtual	O
table	O
in	O
python	O
and	O
I	O
know	O
this	O
is	O
a	O
problem	O
for	O
other	O
people	O
using	O
different	O
type	O
of	O
target	O
table	O
(	O
#URL	O
)	O
.	O
when	O
I	O
try	O
to	O
insert	O
the	O
dataframe	B-API
to	O
the	O
table	O
as	O
shown	O
in	O
the	O
tutorials	O
,	O
an	O
error	O
returns	O
:	O
"	O
dataframe	B-API
not	O
callable	O
"	O

I	O
then	O
want	O
to	O
apply	O
poisson	B-API
sampling	O
noise	O
to	O
all	O
data	O
in	O
the	O
abundance	O
frame	O
.	O

#CODE	O

You	O
have	O
to	O
call	O
`	O
apply	O
`	O
and	O
pass	O
the	O
data	O
to	O
`	O
strftime	B-API
`	O
:	O
#CODE	O

you	O
can	O
apply	O
a	O
lambda	O
function	O
to	O
the	O
column	O
`	O
a	O
`	O
in	O
your	O
dataframe	B-API
that	O
returns	O
the	O
lowercase	O
of	O
the	O
string	O
contained	O
,	O
if	O
your	O
correction	O
is	O
just	O
making	O
the	O
string	O
lowercase	O
.	O

the	O
`	O
apply	O
function	O
`	O
method	O
can	O
be	O
extended	O
for	O
other	O
more	O
specific	O
replacements	O
.	O

Also	O
you	O
can	O
probably	O
generate	O
the	O
new	O
rows	O
by	O
calling	O
`	O
apply	O
`	O
which	O
would	O
be	O
much	O
easier	O
to	O
read	O
than	O
what	O
you're	O
doingnow	O

so	O
I	O
tried	O
replacing	O
the	O
row	O
[	O
'	O
J	O
']	O
and	O
row	O
[	O
'	O
K	O
']	O
with	O
row.loc	O
(	O
'	O
J	O
')	O
and	O
row.loc	O
(	O
'	O
K	O
')	O
but	O
that	O
ended	O
up	O
in	O
some	O
error	O
messages	O
.	O

Am	O
I	O
just	O
going	O
about	O
this	O
all	O
wrong	O
by	O
the	O
for	O
looping	O
through	O
index	O
and	O
row	O
?	O

Should	O
I	O
just	O
apply	O
a	O
function	O
directly	O
to	O
row.loc	O
(	O
'	O
I	O
')	O
?	O

For	O
the	O
email	O
bit	O
we	O
can	O
just	O
use	O
the	O
same	O
regex	O
and	O
call	O
`	O
findall	B-API
`	O
,	O
for	O
the	O
other	O
bit	O
we	O
just	O
pass	O
the	O
func	O
as	O
a	O
param	O
to	O
`	O
apply	O
:	O
#CODE	O

@USER	O
OK	O
,	O
I've	O
updated	O
my	O
code	O
,	O
we	O
can	O
use	O
your	O
email	O
regex	O
directly	O
as	O
a	O
param	O
to	O
`	O
findall	B-API
`	O
,	O
for	O
the	O
name	O
bit	O
we	O
can	O
just	O
pass	O
that	O
as	O
the	O
param	O
to	O
`	O
apply	O
`	O

I	O
am	O
trying	O
to	O
apply	O
this	O
function	O
to	O
each	O
row	O
in	O
player_points_position	O
and	O
create	O
a	O
new	O
column	O
`	O
zscore	O
`	O
.	O

However	O
,	O
the	O
entire	O
data	O
set	O
is	O
returning	O
the	O
same	O
value	O
.	O

#CODE	O

I	O
can	O
group	O
by	O
id	O
and	O
apply	O
a	O
function	O
per	O
group	O
to	O
define	O
wich	O
data	O
is	O
the	O
right	O
one	O
.	O

I	O
can	O
unstack	O
the	O
dataframe	B-API
and	O
put	O
'	O
group	O
'	O
as	O
columns	O
and	O
apply	O
a	O
function	O
.	O

Is	O
there	O
a	O
simpler	O
more	O
elegant	O
way	O
to	O
do	O
this	O
?	O

Pandas	O
apply	O
exponential	O
decay	O
+	O
dataset	O
to	O
function	O

I'd	O
like	O
to	O
make	O
a	O
function	O
in	O
pandas	O
that	O
calculates	O
the	O
resulting	O
,	O
continuous	O
dataset	O
for	O
my	O
activation	O
function	O
,	O
but	O
I	O
don't	O
know	O
which	O
functions	O
to	O
apply	O
.	O

pandas	O
-	O
apply	O
time	O
and	O
space	O
functions	O
to	O
groupby	B-API

This	O
may	O
be	O
an	O
excellent	O
opportunity	O
to	O
highlight	O
the	O
"	O
Split	O
,	O
Apply	O
,	O
Combine	O
"	O
premise	O
and	O
with	O
a	O
simple	O
case	O
use	O
?	O

If	O
you	O
have	O
a	O
DataFrame	B-API
where	O
all	O
columns	O
are	O
booleans	O
(	O
like	O
the	O
slice	O
you	O
mention	O
at	O
the	O
end	O
of	O
your	O
question	O
,	O
you	O
could	O
apply	O
`	O
all	O
`	O
to	O
it	O
row-wise	O
:	O
#CODE	O

Usually	O
,	O
you	O
can	O
apply	O
the	O
function	O
in	O
one	O
of	O
the	O
following	O
ways	O
:	O
#CODE	O

If	O
the	O
dataframe	B-API
is	O
empty	O
,	O
or	O
has	O
only	O
one	O
entry	O
,	O
these	O
methods	O
no	O
longer	O
work	O
.	O

A	O
Series	O
does	O
not	O
have	O
an	O
`	O
iterrows()	B-API
`	O
method	O
and	O
`	O
apply	O
`	O
applies	O
the	O
function	O
to	O
each	O
column	O
(	O
not	O
rows	O
)	O
.	O

Is	O
there	O
a	O
cleaner	O
built	O
in	O
method	O
to	O
iterate	O
/	O
apply	O
functions	O
to	O
DataFrames	O
of	O
variable	O
length	O
?	O

Otherwise	O
you	O
have	O
to	O
constantly	O
write	O
cumbersome	O
logic	O
.	O

#CODE	O

I	O
realize	O
there	O
are	O
methods	O
to	O
ensure	O
you	O
form	O
length	O
1	O
DataFrames	O
,	O
but	O
what	O
I	O
am	O
asking	O
is	O
for	O
a	O
clean	O
way	O
to	O
apply	O
/	O
iterate	O
on	O
the	O
various	O
pandas	O
data	O
structures	O
when	O
it	O
could	O
be	O
like-formatted	O
dataframes	O
or	O
series	O
.	O

Instead	O
of	O
doing	O
either	O
of	O
those	O
things	O
,	O
I	O
think	O
it	O
is	O
better	O
to	O
make	O
sure	O
you	O
create	O
the	O
right	O
type	O
of	O
object	O
before	O
calling	O
`	O
apply	O
`	O
.	O

For	O
example	O
,	O
instead	O
of	O
using	O
`	O
df.iloc	B-API
[	O
0	O
]`	O
which	O
returns	O
a	O
Series	O
,	O
use	O
`	O
df.iloc	B-API
[:	O
1	O
]`	O
to	O
select	O
a	O
DataFrame	B-API
of	O
length	O
1	O
.	O

As	O
long	O
as	O
you	O
pass	O
a	O
slice	O
range	O
instead	O
of	O
a	O
single	O
value	O
to	O
`	O
df.iloc	B-API
`	O
,	O
you'll	O
get	O
back	O
a	O
DataFrame	B-API
.	O

#CODE	O

Python	O
Pandas	O
:	O
Using	O
'	O
apply	O
'	O
to	O
apply	O
1	O
function	O
to	O
multiple	O
columns	O

Essentially	O
,	O
I'd	O
like	O
to	O
know	O
if	O
I	O
could	O
apply	O
`	O
function	O
`	O
to	O
`	O
df	O
`	O
to	O
get	O
the	O
following	O
output	O
:	O
#CODE	O

you	O
need	O
to	O
apply	O
the	O
function	O
on	O
each	O
row	O
,	O
for	O
this	O
you	O
need	O
to	O
specify	O
axis=1	O
#CODE	O

Use	O
apply	O
/	O
map	O
for	O
pandass	O
dataframe	B-API
column	O

But	O
id	O
does	O
not	O
work	O
with	O
`	O
apply	O
`	O
method	O
:	O
#CODE	O

What	O
am	O
I	O
doing	O
wrong	O
and	O
why	O
apply	O
method	O
takes	O
this	O
int	O
index	O
as	O
parameter	O
?	O

After	O
reading	O
your	O
data	O
and	O
puting	O
in	O
a	O
dataframe	B-API
,	O
you	O
can	O
groupby	B-API
values	O
based	O
on	O
one	O
of	O
the	O
columns	O
`	O
groupby	B-API
([	O
'	O
month	O
'])`	O
,	O
and	O
then	O
apply	O
a	O
function	O
on	O
these	O
values	O
,	O
Pandas	O
includes	O
a	O
number	O
of	O
common	O
ones	O
such	O
as	O
mean()	B-API
,	O
max()	B-API
,	O
median()	B-API
,	O
etc	O
.	O

:	O
you	O
can	O
use	O
`	O
sum()	B-API
`	O
for	O
example	O
.	O

#CODE	O

I	O
only	O
know	O
I	O
could	O
use	O
`	O
concat()	B-API
`	O
to	O
combine	O
columns	O
and	O
use	O
`	O
apply	O
(	O
lambda	O
xxx	O
...	O
)`	O
to	O
set	O
up	O
a	O
suitable	O
function	O
.	O

That	O
works	O
perfectly	O
.	O

I	O
was	O
apply	O
to	O
modify	O
the	O
format	O
a	O
bit	O
to	O
help	O
me	O
out	O
on	O
another	O
file	O
as	O
well	O
!	O

Thanks	O
!	O

Ideally	O
,	O
I	O
want	O
to	O
store	O
the	O
output	O
in	O
a	O
new	O
DataFrame	B-API
,	O
where	O
each	O
row	O
corresponds	O
to	O
the	O
rows	O
in	O
the	O
original	O
DataFrame	B-API
,	O
and	O
there	O
are	O
3	O
columns	O
.	O

I	O
was	O
asked	O
not	O
to	O
use	O
a	O
loop	O
to	O
do	O
this	O
,	O
and	O
to	O
use	O
apply	O
,	O
but	O
I	O
cannot	O
figure	O
out	O
the	O
syntax	O
(	O
see	O
attempts	O
below	O
)	O
.	O

What	O
are	O
my	O
options	O
for	O
getting	O
the	O
desired	O
output	O
?	O

(	O
I'm	O
new	O
to	O
python	O
and	O
pandas	O
,	O
so	O
please	O
excuse	O
my	O
ignorance	O
and	O
let	O
me	O
know	O
if	O
I've	O
left	O
out	O
any	O
necessary	O
info	O
)	O
.	O

#CODE	O

if	O
you	O
want	O
to	O
store	O
the	O
results	O
in	O
your	O
data	O
frame	O
,	O
I	O
would	O
define	O
a	O
function	O
and	O
then	O
apply	O
it	O
to	O
the	O
data	O
frame	O
like	O
this	O
:	O
#CODE	O

Apply	O
function	O
over	O
relative	O
rows	O
in	O
Pandas	O

of	O
course	O
,	O
one	O
alternative	O
is	O
writing	O
a	O
for	O
loop	O
employing	O
df.loc	B-API
[	O
i	O
,	O
col	O
]	O
and	O
df.loc	B-API
[	O
i-1	O
,	O
col	O
]	O
,	O
but	O
I	O
generally	O
find	O
apply	O
or	O
transform	O
with	O
functions	O
computationally	O
faster	O

You	O
could	O
use	O
a	O
mask	O
and	O
apply	O
it	O
to	O
the	O
dataframe	B-API
#CODE	O

The	O
above	O
is	O
then	O
groupby'd	O
on	O
customer	O
and	O
then	O
we	O
can	O
apply	O
a	O
filter	O
where	O
the	O
number	O
of	O
unique	O
(	O
nunique	B-API
)	O
customers	O
is	O
equal	O
to	O
2	O

First	O
,	O
I	O
would	O
like	O
to	O
add	O
3	O
extra	O
columns	O
with	O
order	O
numbers	O
,	O
sorting	O
on	O
sum	O
,	O
sum_sq	O
and	O
max	O
,	O
respectively	O
.	O

Next	O
,	O
these	O
3	O
columns	O
should	O
be	O
combined	O
into	O
one	O
column	O
-	O
the	O
mean	O
of	O
the	O
order	O
numbers	O
-	O
but	O
I	O
do	O
know	O
how	O
to	O
do	O
that	O
part	O
(	O
with	O
apply	O
and	O
axis=1	O
)	O
.	O

Then	O
apply	O
the	O
rolling_mean	B-API
to	O
`	O
result	O
`	O
,	O
so	O
you	O
get	O
two	O
columns	O
of	O
rolling	O
means	O
:	O
#CODE	O

Hmmm	O
,	O
I	O
guess	O
I	O
should	O
have	O
transposed	O
the	O
data	O
...	O
well	O
that	O
was	O
a	O
relatively	O
simple	O
fix	O
.	O

Instead	O
of	O
using	O
groupby	B-API
and	O
apply	O
,	O
#CODE	O

Thanks	O
for	O
the	O
reply	O
!	O

It	O
works	O
when	O
I	O
just	O
pass	O
a	O
single	O
string	O
to	O
that	O
function	O
but	O
not	O
when	O
I	O
apply	O
that	O
function	O
to	O
a	O
column	O
---->	O
df	O
[	O
'	O
Duration	O
']	O
=	O
df	O
[	O
'	O
Avg	O
.	O
Session	O
Duration	O
']	O
.apply	B-API
(	O
convertTime	O
)	O
.	O

It	O
returned	O
this	O
error	O
=	O
TypeError	O
:	O
expected	O
string	O
or	O
buffer	O

This	O
avoids	O
the	O
need	O
for	O
a	O
bespoke	O
Python	O
function	O
and	O
the	O
use	O
of	O
`	O
apply	O
`	O
.	O

Testing	O
it	O
for	O
the	O
small	O
example	O
DataFrame	B-API
in	O
your	O
question	O
showed	O
that	O
it	O
was	O
around	O
8	O
times	O
faster	O
.	O

I	O
am	O
really	O
sorry	O
for	O
being	O
that	O
naive	O
,	O
I	O
promise	O
to	O
learn	O
as	O
much	O
as	O
I	O
can	O
if	O
someone	O
could	O
guide	O
me	O
towards	O
the	O
right	O
direction	O
(	O
regarding	O
the	O
theory	O
and	O
technologies	O
to	O
apply	O
)	O
.	O

Do	O
I	O
really	O
need	O
to	O
`	O
apply	O
`	O
and	O
iterate	O
through	O
each	O
row	O
,	O
or	O
is	O
there	O
a	O
more	O
efficient	O
alternative	O
?	O

`	O
map	O
`	O
can	O
take	O
a	O
dictionary	O
,	O
Series	O
or	O
function	O
and	O
return	O
a	O
new	O
Series	O
with	O
the	O
mapped	O
values	O
.	O

It	O
is	O
also	O
very	O
efficiently	O
implemented	O
(	O
much	O
more	O
so	O
than	O
`	O
apply	O
`	O
,	O
for	O
example	O
)	O
.	O

What	O
is	O
a	O
better	O
way	O
to	O
apply	O
the	O
function	O
to	O
each	O
row	O
?	O

I	O
have	O
looked	O
into	O
ways	O
of	O
creating	O
a	O
function	O
to	O
do	O
this	O
,	O
but	O
confused	O
as	O
to	O
how	O
to	O
map	O
and	O
/	O
or	O
apply	O
it	O
in	O
my	O
case	O
,	O
especially	O
the	O
part	O
returning	O
the	O
result	O
as	O
a	O
new	O
column	O
.	O

Just	O
trying	O
to	O
find	O
the	O
most	O
elegant	O
way	O
to	O
apply	O
a	O
really	O
simple	O
transformation	O
to	O
values	O
in	O
different	O
columns	O
with	O
each	O
column	O
having	O
it's	O
own	O
condition	O
.	O

So	O
given	O
a	O
dataframe	B-API
like	O
this	O
:	O
#CODE	O

I	O
was	O
thinking	O
the	O
where	O
function	O
in	O
pandas	O
would	O
come	O
in	O
handy	O
here	O
but	O
wasn't	O
sure	O
how	O
to	O
apply	O
it	O
.	O

I	O
could	O
do	O
the	O
below	O
but	O
does	O
not	O
seem	O
very	O
efficient	O
and	O
I	O
would	O
have	O
to	O
create	O
a	O
different	O
function	O
for	O
each	O
col	O
:	O
#CODE	O

You	O
can't	O
just	O
just	O
stick	O
your	O
expression	O
in	O
brackets	O
onto	O
the	O
groupby	B-API
like	O
that	O
.	O

What	O
you	O
need	O
to	O
do	O
is	O
use	O
`	O
apply	O
`	O
to	O
apply	O
a	O
function	O
that	O
calculates	O
what	O
you	O
want	O
.	O

What	O
you	O
want	O
can	O
be	O
calculated	O
more	O
simply	O
using	O
the	O
`	O
diff	O
`	O
method	O
:	O
#CODE	O

However	O
,	O
it	O
is	O
good	O
to	O
be	O
aware	O
of	O
how	O
to	O
do	O
it	O
with	O
`	O
apply	O
`	O
because	O
you'll	O
need	O
to	O
do	O
things	O
that	O
way	O
if	O
you	O
want	O
to	O
do	O
a	O
more	O
complex	O
operation	O
on	O
the	O
groups	O
(	O
i.e.	O
,	O
an	O
operation	O
for	O
which	O
there	O
is	O
no	O
predefined	O
one-shot	O
method	O
)	O
.	O

You	O
don't	O
need	O
a	O
regex	O
here	O
,	O
just	O
create	O
a	O
lookup	O
table	O
and	O
apply	O
to	O
your	O
DataFrame's	O
column	O
based	O
on	O
that	O
column's	O
first	O
character	O
,	O
eg	O
:	O
#CODE	O

To	O
apply	O
this	O
to	O
all	O
columns	O
,	O
then	O
loop	O
over	O
the	O
columns	O
:	O
#CODE	O

@USER	O
then	O
just	O
apply	O
it	O
to	O
all	O
relevant	O
columns	O
?	O

Could	O
you	O
[	O
edit	O
]	O
(	O
#URL	O
)	O
your	O
question	O
to	O
clarify	O
exactly	O
what	O
you	O
do	O
have	O
...	O

?	O

You	O
can	O
groupby	B-API
the	O
user_id	O
column	O
and	O
then	O
call	O
`	O
apply	O
`	O
and	O
pass	O
a	O
lambda	O
which	O
filters	O
the	O
results	O
where	O
the	O
start	O
time	O
is	O
equal	O
to	O
the	O
max	O
value	O
,	O
we	O
want	O
to	O
generate	O
a	O
boolean	O
index	O
from	O
this	O
.	O

We	O
can	O
then	O
call	O
`	O
reset_index	B-API
`	O
but	O
due	O
to	O
the	O
way	O
the	O
groupby	B-API
was	O
filtered	O
we	O
will	O
get	O
an	O
error	O
with	O
duplicate	O
columns	O
so	O
we	O
have	O
to	O
drop	O
this	O
duplicate	O
column	O
:	O
#CODE	O

thank	O
you	O
,	O
the	O
`	O
apply	O
`	O
version	O
actually	O
worked	O
but	O
not	O
the	O
direct	O
`	O
unique()	B-API
`	O
version	O
.	O

The	O
solution	O
below	O
uses	O
a	O
lambda	O
function	O
to	O
apply	O
a	O
regex	O
to	O
remove	O
non-digit	O
characters	O
.	O

Solution	O
is	O
great	O
.	O
but	O
when	O
I	O
apply	O
this	O
to	O
my	O
original	O
data	O
frame	O
I	O
am	O
getting	O
an	O
error	O
"	O
invalid	O
literal	O
for	O
int()	O
with	O
base	O
10	O
:	O
'	O
16a	O
'"	O

pandas	O
-	O
show	O
results	O
of	O
apply	O
next	O
to	O
original	O
dataframe	B-API

I	O
have	O
a	O
pandas	O
DataFrame	B-API
,	O
then	O
I	O
apply	O
a	O
function	O
to	O
a	O
bunch	O
of	O
columns	O
and	O
I	O
get	O
a	O
new	O
result	O
column	O
.	O

Then	O
I	O
want	O
to	O
be	O
able	O
to	O
check	O
the	O
results	O
of	O
the	O
new	O
column	O
with	O
the	O
original	O
column	O
values	O
.	O

#CODE	O

One	O
way	O
to	O
calculate	O
this	O
is	O
to	O
use	O
`	O
apply	O
`	O
on	O
the	O
`	O
groupby	B-API
`	O
object	O
:	O
#CODE	O

When	O
I	O
apply	O
this	O
on	O
my	O
real	O
data	O
frame	O
(	O
problem	O
set	O
)	O
.	O

I	O
am	O
getting	O
an	O
error	O
`	O
TypeError	O
:	O
Argument	O
'	O
values	O
'	O
has	O
incorrect	O
type	O
(	O
expected	O
numpy.ndarray	B-API
,	O
got	O
Series	O
)`	O
what	O
would	O
be	O
the	O
reason	O
?	O

Ok	O
I	O
am	O
working	O
on	O
it	O
right	O
now	O
.	O
will	O
let	O
you	O
know	O
after	O
I	O
apply	O
it	O
to	O
my	O
code	O
!!	O

How	O
do	O
you	O
apply	O
a	O
function	O
to	O
one	O
of	O
several	O
columns	O
in	O
a	O
DataFrame	B-API
?	O

I	O
would	O
like	O
to	O
apply	O
a	O
function	O
to	O
data	O
in	O
one	O
of	O
the	O
columns	O
and	O
return	O
the	O
same	O
DataFrame	B-API
but	O
with	O
new	O
values	O
in	O
the	O
column	O
to	O
which	O
the	O
function	O
was	O
applied	O
to	O
.	O

Sorry	O
it's	O
unclear	O
why	O
you	O
need	O
to	O
apply	O
on	O
several	O
columns	O
when	O
the	O
following	O
does	O
what	O
you	O
want	O
:	O
`	O
df	O
[	O
'	O
Numbers	O
']	O
=	O
df	O
[	O
'	O
Numbers	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
int	O
(	O
'	O
1	O
'	O
+str	O
(	O
x	O
)))`	O
can	O
you	O
explain	O
what	O
you	O
are	O
trying	O
to	O
do	O
?	O

I	O
only	O
want	O
to	O
apply	O
on	O
one	O
column	O
.	O

In	O
your	O
example	O
I	O
would	O
get	O
a	O
DataFrame	B-API
or	O
Series	O
with	O
one	O
column	O
only	O
,	O
which	O
I	O
would	O
further	O
have	O
to	O
merge	O
with	O
the	O
the	O
initial	O
DataFrame	B-API
.	O

I	O
hoped	O
I	O
could	O
avoid	O
this	O
by	O
applying	O
a	O
function	O
to	O
one	O
column	O
and	O
leave	O
everything	O
else	O
untouched	O
.	O

I	O
saw	O
that	O
it's	O
possible	O
to	O
convert	O
the	O
column	O
into	O
the	O
datetime	O
format	O
by	O
DF	O
=	O
pd.to_datetime	B-API
(	O
DF	O
,	O
'	O
%Y-%m-%d	O
%H	O
:	O
%M	O
:	O
%S	O
')	O
but	O
when	O
I	O
try	O
to	O
then	O
apply	O
datetime.datetime.year	O
(	O
DF	O
)	O
it	O
doesn't	O
work	O
.	O

I	O
will	O
also	O
need	O
to	O
parse	O
the	O
timestamps	O
to	O
months	O
and	O
combinations	O
of	O
years-months	O
and	O
so	O
on	O
...	O

No	O
need	O
to	O
apply	O
a	O
function	O
for	O
each	O
row	O
there	O
is	O
a	O
new	O
datetime	O
attribute	O
you	O
can	O
call	O
to	O
access	O
the	O
year	O
attribute	O
:	O
#CODE	O

Thanks	O
,	O
@USER	O
,	O
but	O
it	O
doesn't	O
work	O
,	O
giving	O
AttributeError	O
:	O
'	O
Series	O
'	O
object	O
has	O
no	O
attribute	O
'	O
year	O
'	O
,	O
although	O
I	O
converted	O
the	O
original	O
DF	O
into	O
datetime64	O
[	O
ns	O
]	O
...	O

I	O
tried	O
to	O
apply	O
DF.year	O
and	O
it	O
is	O
not	O
working	O
...	O

Thanks	O
for	O
your	O
effort	O
.	O

I	O
posted	O
another	O
question	O
but	O
I	O
think	O
I	O
am	O
getting	O
close	O
....	O
using	O
the	O
apply	O
method	O
with	O
a	O
lambda	O
function	O
seems	O
to	O
be	O
headed	O
in	O
the	O
right	O
direction	O
.	O

I'd	O
like	O
to	O
apply	O
the	O
model	O
to	O
column	O
`	O
c	O
`	O
,	O
but	O
a	O
naive	O
attempt	O
to	O
do	O
so	O
doesn't	O
work	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
select	O
certain	O
rows	O
from	O
a	O
DataFrame	B-API
and	O
apply	O
a	O
result	O
from	O
lambda	O
from	O
it	O
,	O
and	O
I	O
am	O
not	O
able	O
to	O
assign	O
it	O
correctly	O
,	O
either	O
all	O
the	O
other	O
columns	O
become	O
NaN	O
or	O
the	O
DataFrame	B-API
not	O
changed	O
at	O
all	O
(	O
I	O
believe	O
this	O
is	O
related	O
to	O
DataFrame	B-API
returning	O
a	O
copy	O
,	O
read	O
that	O
caveat	O
)	O

I	O
am	O
using	O
the	O
.to_excel	B-API
method	O
in	O
pandas	O
to	O
write	O
dataframe	B-API
in	O
an	O
excel	O
file	O
.	O

However	O
i	O
want	O
to	O
change	O
the	O
default	O
formatting	O
.	O

The	O
answer	O
at	O
Apply	O
styles	O
while	O
exporting	O
to	O
xlsx	O
in	O
pandas	O
with	O
XlsxWriter	O
helps	O
with	O
the	O
basic	O
formatting	O
.	O

Apply	O
function	O
on	O
cumulative	O
values	O
of	O
pandas	O
series	O

Is	O
there	O
an	O
equivalent	O
of	O
`	O
rolling_apply	B-API
`	O
in	O
pandas	O
that	O
applies	O
function	O
to	O
the	O
cumulative	O
values	O
of	O
a	O
series	O
rather	O
than	O
the	O
rolling	O
values	O
?	O

I	O
realize	O
`	O
cumsum	B-API
`	O
,	O
`	O
cumprod	B-API
`	O
,	O
`	O
cummax	B-API
`	O
,	O
and	O
`	O
cummin	B-API
`	O
exist	O
,	O
but	O
I'd	O
like	O
to	O
apply	O
a	O
custom	O
function	O
.	O

@USER	O
,	O
you	O
started	O
with	O
a	O
different	O
input	O
(	O
a	O
string	O
that	O
formats	O
as	O
a	O
list	O
,	O
I	O
start	O
from	O
a	O
list	O
)	O
,	O
but	O
I	O
am	O
not	O
sure	O
what	O
the	O
OP	O
wants	O
.	O

Apart	O
from	O
that	O
,	O
you	O
did	O
the	O
`	O
get_dummies	B-API
`	O
within	O
the	O
apply	O
(	O
so	O
for	O
each	O
row	O
instead	O
of	O
once	O
on	O
all	O
)	O
,	O
which	O
made	O
it	O
slower	O
as	O
the	O
approach	O
above	O
.	O

I	O
have	O
a	O
dataframe	B-API
'	O
clicks	O
'	O
created	O
by	O
parsing	O
CSV	O
of	O
size	O
1.4G	O
.	O

I'm	O
trying	O
to	O
create	O
a	O
new	O
column	O
'	O
bought	O
'	O
using	O
apply	O
function	O
.	O

#CODE	O

`	O
apply	O
`	O
is	O
essentially	O
just	O
syntactic	O
sugar	O
for	O
a	O
`	O
for	O
`	O
loop	O
over	O
the	O
rows	O
of	O
a	O
column	O
.	O

There's	O
also	O
an	O
explicit	O
`	O
for	O
`	O
loop	O
over	O
a	O
NumPy	O
array	O
in	O
your	O
function	O
(	O
the	O
`	O
for	O
row	O
in	O
boughtSessions	O
`	O
part	O
)	O
.	O

Looping	O
in	O
this	O
(	O
non-vectorised	O
)	O
way	O
is	O
best	O
avoided	O
whenever	O
possible	O
as	O
it	O
impacts	O
performance	O
heavily	O
.	O

First	O
use	O
`	O
groupby	B-API
`	O
to	O
group	O
the	O
rows	O
of	O
`	O
buys	O
`	O
by	O
the	O
values	O
in	O
'	O
session	O
'	O
.	O

`	O
apply	O
`	O
is	O
used	O
to	O
join	O
up	O
the	O
strings	O
for	O
each	O
value	O
:	O
#CODE	O

`	O
groupby	B-API
`	O
means	O
that	O
only	O
one	O
pass	O
through	O
the	O
DataFrame	B-API
is	O
needed	O
and	O
is	O
pretty	O
well-optimised	O
in	O
Pandas	O
.	O

The	O
use	O
of	O
`	O
apply	O
`	O
to	O
join	O
the	O
strings	O
is	O
unavoidable	O
here	O
,	O
but	O
only	O
one	O
pass	O
through	O
the	O
grouped	O
values	O
is	O
needed	O
.	O

To	O
match	O
each	O
string	O
in	O
`	O
boughtSessions	O
`	O
to	O
the	O
approach	O
value	O
in	O
`	O
clicks	O
[	O
'	O
session	O
']`	O
you	O
can	O
use	O
`	O
map	O
`	O
.	O

Unlike	O
`	O
apply	O
`	O
,	O
`	O
map	O
`	O
is	O
fully	O
vectorised	O
and	O
should	O
be	O
very	O
fast	O
:	O
#CODE	O

Using	O
apply	O
(	O
or	O
some	O
other	O
vectorisation	O
)	O
to	O
perform	O
calculation	O
involving	O
two	O
(	O
or	O
more	O
)	O
data	O
frames	O
?	O

So	O
,	O
I'm	O
not	O
sure	O
how	O
to	O
go	O
about	O
vectorising	O
this	O
.	O

Naively	O
I	O
could	O
split	O
this	O
into	O
two	O
apply	O
statements	O
,	O
each	O
effectively	O
replacing	O
each	O
iterrows	B-API
call	O
.	O

But	O
is	O
there	O
some	O
other	O
clever	O
approach	O
,	O
as	O
there	O
will	O
still	O
be	O
significant	O
looping	O
overhead	O
with	O
that	O
solution	O
.	O

python	O
apply	O
function	O
to	O
list	O
and	O
return	O
data	O
frame	O

I	O
am	O
new	O
to	O
python	O
.	O

I	O
wrote	O
a	O
function	O
that	O
returns	O
a	O
pandas	O
data	O
frame	O
.	O

I	O
am	O
trying	O
to	O
apply	O
this	O
function	O
to	O
a	O
list	O
and	O
I	O
would	O
like	O
to	O
merge	O
all	O
the	O
results	O
to	O
one	O
data	O
frame	O
.	O

For	O
example	O
,	O
if	O
my	O
function	O
looks	O
like	O
:	O
#CODE	O

I	O
want	O
to	O
apply	O
it	O
to	O
list	O
`	O
[	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
]`	O
,	O
and	O
get	O
the	O
result	O
as	O
a	O
data	O
frame	O
which	O
looks	O
like	O
:	O
#CODE	O

This	O
works	O
for	O
me	O
in	O
pandas	O
0.12	O
.	O

Can	O
you	O
check	O
which	O
part	O
throws	O
the	O
error	O
?	O

(	O
the	O
`	O
to_datetime	B-API
`	O
part	O
,	O
or	O
the	O
`	O
apply	O
`	O
part	O
)	O

Probably	O
it	O
is	O
due	O
to	O
some	O
missing	O
values	O
.	O

If	O
you	O
use	O
`	O
dropna	B-API
`	O
before	O
using	O
`	O
to_datetime	B-API
`	O
and	O
`	O
apply	O
(	O
...	O
strftime()	B-API
)`	O
,	O
this	O
will	O
work	O
.	O

A	O
small	O
example	O
:	O
#CODE	O

Yes	O
.	O

I	O
want	O
to	O
apply	O
that	O
function	O
in	O
Time	O
column	O
of	O
data	O
frame	O
.	O

I	O
think	O
your	O
problem	O
maybe	O
that	O
you're	O
not	O
assigning	O
the	O
result	O
of	O
your	O
`	O
apply	O
`	O
back	O
:	O
#CODE	O

and	O
then	O
scale	O
the	O
count	O
array	O
to	O
apply	O
kde()	O
to	O
it	O
?	O

One	O
pandas	O
method	O
would	O
be	O
to	O
call	O
apply	O
on	O
the	O
df	O
column	O
to	O
perform	O
the	O
conversion	O
:	O
#CODE	O

One	O
method	O
,	O
so	O
long	O
as	O
datetime	O
is	O
already	O
a	O
datetime	O
column	O
is	O
to	O
apply	O
`	O
datetime.strftime	O
`	O
to	O
get	O
the	O
string	O
for	O
the	O
weekday	B-API
:	O
#CODE	O

Then	O
I	O
have	O
to	O
apply	O
a	O
function	O
to	O
the	O
dataframe	B-API
to	O
create	O
a	O
new	O
column	O
based	O
on	O
some	O
values	O
:	O
#CODE	O

Yes	O
thanks	O
!	O

So	O
,	O
should	O
be	O
better	O
to	O
concatenate	O
the	O
dataframe	B-API
inside	O
the	O
loop	O
instead	O
of	O
build	O
the	O
whole	O
dataframe	B-API
outside	O
and	O
then	O
apply	O
the	O
function	O
?	O

The	O
RAM	O
consumption	O
is	O
proportional	O
to	O
the	O
size	O
of	O
the	O
chunk	O
,	O
no	O
matter	O
the	O
final	O
dimension	O
of	O
the	O
whole	O
concatenate	O
DataFrame	B-API
?	O

The	O
"	O
dumb	O
"	O
way	O
would	O
be	O
to	O
cycle	O
through	O
the	O
frame	O
(	O
iterrows	B-API
)	O
and	O
compare	O
one	O
by	O
one	O
.	O

There	O
must	O
be	O
a	O
smarter	O
,	O
Pandas	O
way	O
like	O
using	O
something	O
like	O
apply	O
/	O
join	O
/	O
whatever	O
.	O

Here's	O
one	O
way	O
of	O
doing	O
it	O
,	O
using	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

Trouble	O
passing	O
in	O
lambda	O
to	O
apply	O
for	O
pandas	O
DataFrame	B-API

I'm	O
trying	O
to	O
apply	O
a	O
function	O
to	O
all	O
rows	O
of	O
a	O
pandas	O
DataFrame	B-API
(	O
actually	O
just	O
one	O
column	O
in	O
that	O
DataFrame	B-API
)	O

Can	O
you	O
show	O
`	O
df.info()`	O
and	O
which	O
columns	O
you	O
are	O
trying	O
to	O
perform	O
the	O
calculations	O
on	O
,	O
you	O
will	O
not	O
be	O
able	O
to	O
pass	O
2	O
columns	O
row-wise	O
if	O
you	O
are	O
calling	O
apply	O
on	O
a	O
series	O

I	O
am	O
unable	O
to	O
apply	O
the	O
last	O
operation	O
across	O
all	O
of	O
the	O
DataFrames	O
.	O

It	O
seems	O
I	O
can	O
only	O
get	O
it	O
to	O
apply	O
to	O
the	O
last	O
DataFrame	B-API
in	O
my	O
list	O
.	O

Once	O
I	O
get	O
past	O
this	O
point	O
I	O
will	O
have	O
to	O
append	O
all	O
of	O
the	O
DataFrames	O
to	O
form	O
one	O
large	O
DataFrame	B-API
.	O

I	O
need	O
to	O
create	O
an	O
index	O
on	O
a	O
specific	O
frequency	O
,	O
however	O
I	O
need	O
to	O
apply	O
that	O
frequency	O
only	O
for	O
certain	O
months	O
.	O

This	O
is	O
the	O
frequency	O
:	O
#CODE	O

I	O
suppose	O
the	O
issue	O
is	O
that	O
VALUE	O
does	O
not	O
have	O
an	O
upper	O
level	O
.	O

A	O
similar	O
operation	O
is	O
not	O
described	O
in	O
the	O
manual	O
.	O

Isn't	O
there	O
a	O
way	O
to	O
apply	O
`	O
stack	O
`	O
only	O
to	O
some	O
columns	O
?	O

how	O
to	O
apply	O
ceiling	O
to	O
pandas	O
DateTime	O

I	O
was	O
considering	O
this	O
as	O
well	O
,	O
but	O
I	O
need	O
to	O
slice	O
several	O
dataframes	O
in	O
the	O
same	O
way	O
,	O
so	O
I	O
would	O
need	O
to	O
do	O
it	O
multiple	O
times	O
.	O

I	O
was	O
looking	O
to	O
have	O
the	O
function	O
take	O
the	O
locationargument	O
and	O
apply	O
it	O
to	O
all	O
dataframes	O
in	O
one	O
call	O
.	O

Thanks	O
!	O

I	O
will	O
get	O
different	O
groups	O
that	O
do	O
not	O
coincide	O
.	O

Is	O
there	O
some	O
way	O
to	O
get	O
the	O
`	O
datetime	O
`	O
related	O
groups	O
from	O
the	O
first	O
grouping	O
,	O
and	O
apply	O
them	O
to	O
the	O
second	O
grouping	O
instead	O
?	O

Or	O
how	O
could	O
I	O
achieve	O
this	O
else	O
wise	O
?	O

this	O
won't	O
work	O
because	O
you	O
are	O
calling	O
apply	O
on	O
the	O
df	O
,	O
naturally	O
this	O
will	O
iterate	O
over	O
the	O
columns	O
and	O
you	O
are	O
trying	O
to	O
check	O
the	O
probability	O
column	O
it's	O
unclear	O
to	O
me	O
what	O
you	O
are	O
trying	O
to	O
do	O
here	O
,	O
are	O
you	O
checking	O
just	O
the	O
probability	O
column	O
or	O
all	O
columns	O
?	O

So	O
it	O
would	O
be	O
great	O
if	O
there's	O
some	O
option	O
to	O
do	O
the	O
job	O
with	O
a	O
*	O
.csv	O
with	O
two	O
rows	O
.	O

On	O
the	O
left	O
all	O
"	O
Industry	O
Category	O
"	O
items	O
and	O
on	O
the	O
right	O
the	O
desired	O
"	O
Parent	O
Category	O
"	O
I	O
like	O
to	O
apply	O
to	O
the	O
dataset	O
.	O

I	O
think	O
I	O
got	O
the	O
idea	O
.	O

I	O
have	O
to	O
create	O
a	O
csv	O
and	O
apply	O
the	O
the2nd	O
step	O
of	O
this	O
[	O
link	O
]	O
(	O
#URL	O
)	O
.	O

Once	O
I	O
have	O
the	O
dict	O
,	O
I	O
have	O
to	O
map	O
the	O
df	O
with	O
.map	B-API
(	O
category_list.get	O
)	O

I	O
do	O
this	O
quite	O
a	O
lot	O
.	O

I	O
would	O
create	O
a	O
dictionary	O
and	O
use	O
`	O
apply	O
`	O
and	O
`	O
lambda	O
`	O
.	O

#CODE	O

I	O
am	O
trying	O
to	O
read	O
a	O
certain	O
DF	O
from	O
file	O
and	O
add	O
to	O
it	O
two	O
more	O
columns	O
containing	O
,	O
say	O
,	O
the	O
year	O
and	O
the	O
week	O
from	O
other	O
columns	O
in	O
DF	O
.	O

When	O
i	O
apply	O
the	O
code	O
to	O
generate	O
a	O
single	O
new	O
column	O
,	O
all	O
works	O
great	O
.	O

But	O
when	O
there	O
are	O
few	O
columns	O
to	O
be	O
created	O
,	O
the	O
change	O
does	O
not	O
apply	O
.	O

Specifically	O
,	O
new	O
columns	O
are	O
created	O
but	O
their	O
values	O
are	O
not	O
what	O
they	O
are	O
supposed	O
to	O
be	O
.	O

it	O
has	O
to	O
do	O
with	O
not	O
changing	O
all	O
data	O
values	O
,	O
but	O
i	O
don't	O
understand	O
why	O
the	O
change	O
does	O
not	O
apply	O
-	O
after	O
all	O
,	O
before	O
the	O
second	O
iteration	O
begins	O
,	O
the	O
DF	O
seems	O
to	O
be	O
updated	O
and	O
then	O
`	O
tbl	O
[	O
tmp_col_name	O
]	O
=	O
'	O
No	O
Week	O
'`	O
for	O
the	O
second	O
iteration	O
"	O
deletes	O
"	O
the	O
changes	O
made	O
in	O
the	O
first	O
iteration	O
,	O
but	O
only	O
partially	O
-	O
it	O
leaves	O
the	O
new	O
column	O
created	O
but	O
filled	O
with	O
'	O
No	O
Week	O
'	O
values	O
...	O

I'm	O
struggling	O
to	O
find	O
a	O
way	O
to	O
iterate	O
over	O
Df	O
,	O
and	O
for	O
each	O
row	O
,	O
apply	O
a	O
definition	O
that	O
iterates	O
to	O
search	O
for	O
the	O
nearest	O
match	O
in	O
Df1	O
(	O
with	O
the	O
aim	O
to	O
add	O
data	O
from	O
Df1	O
to	O
Df	O
)	O
.	O

Read	O
and	O
tried	O
a	O
lot	O
of	O
methods	O
found	O
here	O
,	O
but	O
not	O
winning	O
.	O

Would	O
appreciate	O
some	O
pointers	O
,	O
especially	O
if	O
I'm	O
going	O
the	O
wrong	O
route	O
:	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
call	O
a	O
lambda	O
function	O
that	O
splits	O
the	O
string	O
and	O
then	O
joins	O
on	O
the	O
unique	O
values	O
:	O
#CODE	O

Basically	O
we	O
can	O
drop	O
the	O
`	O
NaN	O
`	O
rows	O
first	O
and	O
then	O
call	O
`	O
apply	O
`	O
and	O
use	O
`	O
datetime.strftime	O
`	O
to	O
apply	O
a	O
new	O
format	O
:	O
#CODE	O

Can	O
you	O
post	O
what	O
the	O
final	O
df	O
values	O
should	O
be	O
and	O
give	O
examples	O
of	O
the	O
calculations	O
you	O
are	O
trying	O
to	O
apply	O
,	O
thanks	O

@USER	O
,	O
unfortunately	O
I	O
think	O
there	O
is	O
no	O
general	O
answer	O
that	O
I	O
know	O
of	O
for	O
which	O
option	O
to	O
opt	O
for	O
.	O

It	O
really	O
depends	O
on	O
both	O
your	O
data	O
and	O
the	O
specific	O
machine	O
learning	O
/	O
statistical	O
algorithm	O
you	O
would	O
like	O
to	O
apply	O
.	O

However	O
;	O
I	O
would	O
generally	O
suggest	O
opting	O
for	O
1	O
)	O
as	O
base	O
case	O
unless	O
you	O
have	O
specific	O
concerns	O
about	O
correlations	O
between	O
your	O
features	O
and	O
how	O
your	O
ML	O
algorithm	O
deals	O
with	O
that	O
.	O

One	O
method	O
is	O
to	O
apply	O
a	O
function	O
to	O
your	O
df	O
to	O
split	O
the	O
'	O
cc	O
'	O
column	O
and	O
create	O
a	O
new	O
dict	O
that	O
contains	O
each	O
split	O
country	O
and	O
their	O
associated	O
count	O
,	O
you	O
can	O
then	O
construct	O
a	O
new	O
df	O
from	O
this	O
,	O
groupby	B-API
the	O
country	O
and	O
perform	O
the	O
sum	O
on	O
the	O
count	O
:	O
#CODE	O

Python	O
PANDAS	O
:	O
New	O
Column	O
,	O
Apply	O
Unique	O
Value	O
To	O
All	O
Rows	O

My	O
confusion	O
seems	O
to	O
be	O
about	O
which	O
function	O
to	O
utilize	O
(	O
apply	O
,	O
mapapply	O
,	O
etc	O
.	O
)	O
,	O
if	O
I	O
need	O
to	O
reference	O
an	O
index	O
value	O
in	O
the	O
original	O
df	O
to	O
apply	O
a	O
completely	O
unrelated	O
value	O
to	O
the	O
initial	O
df	O
,	O
and	O
the	O
most	O
optimized	O
,	O
pythonic	O
way	O
to	O
accomplish	O
this	O
.	O

`	O
monthrange	O
`	O
returns	O
a	O
tuple	O
with	O
the	O
first	O
and	O
last	O
days	O
of	O
the	O
month	O
,	O
so	O
`	O
[	O
1	O
]`	O
references	O
the	O
last	O
day	O
of	O
the	O
month	O
.	O

You	O
can	O
also	O
use	O
@USER	O
'	O
s	O
method	O
for	O
finding	O
the	O
date	O
of	O
the	O
last	O
day	O
,	O
and	O
assign	O
it	O
directly	O
to	O
the	O
column	O
instead	O
of	O
`	O
apply	O
`	O
ing	O
it	O
.	O

Columns	O
are	O
fixed	O
I	O
would	O
extract	O
the	O
column	O
calculations	O
and	O
vectorize	B-API
the	O
real	O
,	O
child	O
and	O
other	O
normalizations	O
.	O

Use	O
apply	O
rather	O
than	O
iterating	O
(	O
for	O
zfill	B-API
)	O
.	O

#CODE	O

Looks	O
like	O
it	O
did	O
in	O
first	O
test	O
@USER	O
.	O

I'm	O
doing	O
some	O
more	O
tests	O
for	O
confirmation	O
so	O
I	O
can	O
apply	O
the	O
bounty	O
with	O
a	O
fair	O
judgement	O
.	O

You	O
could	O
define	O
a	O
function	O
and	O
call	O
`	O
apply	O
`	O
passing	O
the	O
function	O
name	O
,	O
this	O
will	O
create	O
a	O
df	O
with	O
min	O
and	O
max	O
as	O
the	O
index	O
names	O
:	O
#CODE	O

Use	O
the	O
datetime	O
attribute	O
to	O
filter	O
on	O
date	O
and	O
then	O
`	O
apply	O
`	O
a	O
function	O
to	O
replace	O
just	O
the	O
day	O
component	O
:	O
#CODE	O

I've	O
found	O
apply	O
and	O
map	O
great	O
for	O
speeding	O
up	O
calculations	O
on	O
particular	O
rows	O
in	O
a	O
DataFrame	B-API
.	O

The	O
question	O
I've	O
got	O
is	O
:	O
Is	O
it	O
possible	O
to	O
return	O
a	O
value	O
with	O
apply	O
or	O
map	O
functions	O
which	O
refer	O
to	O
a	O
previous	O
row	O
?	O

Apply	O
and	O
map	O
are	O
great	O
at	O
vectorising	O
row	O
by	O
row	O
calculations	O
-	O
is	O
it	O
possible	O
to	O
refer	O
to	O
the	O
previous	O
row	O
so	O
I	O
can	O
make	O
that	O
calculation	O
?	O

My	O
second	O
suggestion	O
to	O
specify	O
this	O
in	O
the	O
groupby	B-API
call	O
with	O
`	O
as_index=False	O
`	O
,	O
seems	O
not	O
to	O
work	O
as	O
desired	O
in	O
this	O
case	O
with	O
`	O
apply	O
`	O
(	O
but	O
it	O
does	O
work	O
when	O
using	O
`	O
aggregate	O
`)	O

Apply	O
function	O
row	O
wise	O
on	O
pandas	O
data	O
frame	O
on	O
columns	O
with	O
numerical	O
values	O

To	O
apply	O
an	O
arbitrary	O
function	O
,	O
`	O
func	O
`	O
,	O
to	O
each	O
row	O
:	O
#CODE	O

So	O
you	O
see	O
here	O
that	O
apply	O
as	O
it	O
is	O
iterating	O
row-wise	O
scales	O
poorly	O
compared	O
to	O
the	O
other	O
two	O
methods	O
which	O
are	O
vectorised	O
but	O
`	O
map	O
`	O
is	O
still	O
the	O
fastest	O
.	O

I	O
would	O
like	O
to	O
have	O
the	O
company	O
symbols	O
in	O
their	O
own	O
seperate	O
column	O
instead	O
of	O
inside	O
the	O
Company	O
Name	O
column	O
.	O

Right	O
now	O
I	O
just	O
have	O
it	O
iterate	O
over	O
the	O
company	O
names	O
,	O
and	O
a	O
RE	O
pulls	O
the	O
symbols	O
,	O
puts	O
it	O
into	O
a	O
list	O
,	O
and	O
then	O
I	O
apply	O
it	O
to	O
the	O
new	O
column	O
,	O
but	O
I'm	O
wondering	O
if	O
there	O
is	O
a	O
cleaner	O
/	O
easier	O
way	O
.	O

but	O
it	O
will	O
be	O
faster	O
to	O
use	O
the	O
inbuilt	O
`	O
to_datetime	B-API
`	O
rather	O
than	O
call	O
`	O
apply	O
`	O
which	O
essentially	O
just	O
loops	O
over	O
your	O
series	O
.	O

Using	O
apply	O
will	O
be	O
substantially	O
slower	O
than	O
your	O
first	O
method	O
by	O
the	O
way	O

Not	O
at	O
the	O
moment	O
,	O
cumsum	B-API
is	O
a	O
vectorised	O
method	O
apply	O
will	O
not	O
beat	O
this	O
.	O

Here's	O
a	O
one-liner	O
,	O
but	O
with	O
cumsum	B-API
:	O
```	O
(	O
df.Volume	O
*	O
(	O
df.High	O
+	O
df.Low	O
+	O
df.Close	O
)	O
/	O
3	O
)	O
.cumsum()	B-API
/	O
df.Volume.cumsum()	O
```	O
.	O

As	O
@USER	O
notes	O
,	O
cumsum	B-API
is	O
going	O
to	O
beat	O
apply	O
.	O

I	O
doubt	O
you're	O
going	O
to	O
improve	O
speed	O
by	O
avoiding	O
cumsum	B-API
in	O
pandas	O
.	O

Why	O
do	O
you	O
want	O
to	O
avoid	O
cumsum	B-API
?	O

Beyond	O
this	O
,	O
I'd	O
guess	O
you	O
can	O
improve	O
speed	O
slightly	O
by	O
doing	O
in	O
numpy	O
,	O
and	O
even	O
more	O
by	O
doing	O
in	O
numba	O
.	O

Now	O
,	O
suppose	O
I	O
have	O
multiple	O
data	O
frames	O
outside	O
the	O
function	O
,	O
say	O
`	O
df1	O
`	O
,	O
`	O
df2	O
`	O
,	O
`	O
df3	O
`	O
on	O
which	O
I	O
want	O
to	O
apply	O
`	O
myfunc	O
`	O
.	O

I	O
want	O
to	O
ensure	O
that	O
the	O
function	O
`	O
myfunc	O
`	O
uses	O
a	O
local	O
copy	O
of	O
the	O
dataframe	B-API
-	O
I	O
want	O
to	O
avoid	O
the	O
situation	O
that	O
the	O
`	O
df1	O
`	O
outside	O
the	O
function	O
doesn't	O
get	O
changed	O
/	O
modified	O
by	O
the	O
operations	O
inside	O
the	O
dataframe	B-API
.	O

Apply	O
Across	O
Dynamic	O
Number	O
of	O
Columns	O

In	O
order	O
to	O
solve	O
this	O
big	O
problem	O
,	O
I	O
find	O
read_fwf	B-API
in	O
pandas	O
module	O
and	O
apply	O
it	O
but	O
failed	O
.	O

#CODE	O

Then	O
I	O
want	O
apply	O
fill_between()	B-API
on	O
area	O
between	O
A	O
and	O
B	O
series	O
:	O
#CODE	O

@USER	O
use	O
`	O
pd.to_datetime	B-API
`	O
rather	O
than	O
apply	O
.	O

If	O
you	O
use	O
the	O
apply	O
it	O
may	O
not	O
create	O
a	O
Datetime	O
column	O
.	O

I	O
think	O
you	O
may	O
have	O
to	O
update	O
to	O
0.15.X	O
for	O
the	O
dt	O
accessor	O
.	O

If	O
you	O
want	O
month-year	O
then	O
use	O
the	O
`	O
to_period	B-API
`	O
part	O
of	O
the	O
answer	O
above	O
?	O

Whether	O
this	O
is	O
more	O
efficient	O
than	O
a	O
groupby	B-API
/	O
resample	O
apply	O
solution	O
will	O
depend	O
on	O
the	O
data	O
.	O

For	O
very	O
sparse	O
data	O
(	O
with	O
lots	O
of	O
starting	O
up	O
NaN	O
,	O
assuming	O
you	O
want	O
to	O
drop	O
these	O
)	O
I	O
suspect	O
it	O
won't	O
be	O
as	O
fast	O
.	O

If	O
the	O
data	O
is	O
dense	O
(	O
or	O
you	O
want	O
to	O
keep	O
the	O
initial	O
NaN	O
)	O
I	O
suspect	O
this	O
solution	O
should	O
be	O
faster	O
.	O

Python	O
Pandas	O
'	O
apply	O
'	O
returns	O
series	O
;	O
can't	O
convert	O
to	O
dataframe	B-API

OK	O
,	O
I'm	O
at	O
half-wit	O
'	O
s	O
end	O
.	O

I'm	O
geocoding	O
a	O
dataframe	B-API
with	O
geopy	O
.	O

I've	O
written	O
a	O
simple	O
function	O
to	O
take	O
an	O
input	O
-	O
country	O
name	O
-	O
and	O
return	O
the	O
latitude	O
and	O
longitude	O
.	O

I	O
use	O
apply	O
to	O
run	O
the	O
function	O
and	O
it	O
returns	O
a	O
Pandas	O
series	O
object	O
.	O

I	O
can't	O
seem	O
to	O
convert	O
it	O
to	O
a	O
dataframe	B-API
.	O

I'm	O
sure	O
I'm	O
missing	O
something	O
obvious	O
,	O
but	O
I'm	O
new	O
to	O
python	O
and	O
still	O
RTFMing	O
.	O

BTW	O
,	O
the	O
geocoder	O
function	O
works	O
great	O
.	O

#CODE	O

The	O
goal	O
is	O
to	O
geocode	O
166	O
unique	O
countries	O
,	O
then	O
join	O
it	O
back	O
to	O
the	O
188K	O
addresses	O
in	O
df_addr	O
.	O

I'm	O
trying	O
to	O
be	O
pandas-y	O
in	O
my	O
code	O
and	O
not	O
write	O
loops	O
if	O
possible	O
.	O

But	O
I	O
haven't	O
found	O
the	O
magic	O
to	O
convert	O
series	O
into	O
dataframes	O
and	O
this	O
is	O
the	O
first	O
time	O
I've	O
tried	O
to	O
use	O
apply	O
.	O

Thanks	O
Ed	O
!	O

What	O
if	O
I	O
would	O
like	O
to	O
filter	O
Users	O
with	O
occurrences	O
only	O
in	O
some	O
months	O
?	O

Can	O
I	O
apply	O
some	O
dt.month	B-API
==	O
june	O
conditions	O
?	O

If	O
you	O
actually	O
have	O
strings	O
that	O
look	O
like	O
tuples	O
,	O
you	O
can	O
parse	O
them	O
first	O
and	O
then	O
apply	O
the	O
same	O
pattern	O
as	O
above	O
:	O
#CODE	O

If	O
it	O
is	O
actually	O
strings	O
,	O
you	O
can	O
first	O
convert	O
it	O
to	O
lists	O
like	O
so	O
,	O
then	O
apply	O
the	O
above	O
operation	O
:	O
#CODE	O

To	O
create	O
multiple	O
columns	O
when	O
using	O
`	O
apply	O
`	O
,	O
I	O
think	O
it's	O
best	O
to	O
return	O
a	O
`	O
Series	O
`	O
rather	O
than	O
a	O
list	O
.	O

You	O
can	O
set	O
the	O
column	O
names	O
by	O
setting	O
them	O
as	O
the	O
index	O
for	O
the	O
`	O
Series	O
`	O
.	O

So	O
you	O
can	O
do	O
:	O
#CODE	O

I	O
have	O
a	O
pandas	O
TimeSeries	O
and	O
would	O
like	O
to	O
apply	O
the	O
argmax	B-API
function	O
to	O
a	O
rolling	O
window	O
.	O

However	O
,	O
due	O
to	O
casting	O
to	O
float	O
from	O
rolling_apply	B-API
,	O
if	O
I	O
apply	O
`	O
numpy.argmax()	B-API
`	O
,	O
I	O
only	O
obtain	O
the	O
index	O
of	O
the	O
slice	O
of	O
the	O
ndarray	B-API
.	O

Is	O
there	O
a	O
way	O
to	O
apply	O
a	O
rolling	O
argmax	B-API
to	O
a	O
Series	O
/	O
DataFrame	B-API
?	O

Here	O
is	O
a	O
work-around	O
,	O
essentially	O
doing	O
the	O
apply	O
'	O
manually	O
'	O
,	O
should	O
be	O
pretty	O
efficient	O
actually	O
.	O

#CODE	O

You	O
can	O
also	O
use	O
the	O
`	O
apply	O
`	O
method	O
for	O
a	O
one-liner	O
,	O
which	O
is	O
simpler	O
and	O
clearer	O
but	O
also	O
slower	O
even	O
than	O
your	O
approach	O
:	O
#CODE	O

Apply	O
formula	O
to	O
Multi-index	O
column	O
Python	O

Want	O
to	O
apply	O
formula	O
and	O
label	O
result	O
to	O
multi-index	O
dataframe	B-API
.	O

Gut	O
tells	O
me	O
I	O
need	O
to	O
group-by	O
and	O
then	O
apply	O
formula	O
,	O
I	O
can	O
handle	O
that	O
(	O
I	O
think	O
)	O
,	O
but	O
how	O
do	O
I	O
bring	O
label	O
(	O
'	O
pattern	O
')	O
along	O
?	O

Apply	O
where	O
function	O
[	O
SQL	O
like	O
]	O
on	O
datatime	O
Pandas	O

pandas	O
-	O
apply	O
datetime	O
functions	O

Optimizing	O
pandas	O
filter	O
inside	O
apply	O
function	O

I	O
now	O
need	O
to	O
apply	O
this	O
function	O
to	O
several	O
million	O
rows	O
and	O
it's	O
impossibly	O
slow	O
so	O
I'm	O
trying	O
to	O
figure	O
out	O
the	O
best	O
way	O
to	O
speed	O
it	O
up	O
.	O

I've	O
heard	O
that	O
Cython	O
can	O
increase	O
the	O
speed	O
of	O
functions	O
but	O
I	O
have	O
no	O
experience	O
with	O
it	O
(	O
and	O
I'm	O
new	O
to	O
both	O
pandas	O
and	O
python	O
)	O
.	O

Is	O
it	O
possible	O
to	O
pass	O
two	O
rows	O
of	O
a	O
dataframe	B-API
as	O
arguments	O
to	O
the	O
function	O
and	O
then	O
use	O
Cython	O
to	O
speed	O
it	O
up	O
or	O
would	O
it	O
be	O
necessary	O
to	O
create	O
new	O
columns	O
with	O
"`	O
diff	O
`"	O
values	O
in	O
them	O
so	O
that	O
the	O
function	O
only	O
reads	O
from	O
and	O
writes	O
to	O
one	O
row	O
of	O
the	O
dataframe	B-API
at	O
a	O
time	O
,	O
in	O
order	O
to	O
benefit	O
from	O
using	O
Cython	O
?	O

Any	O
other	O
speed	O
tricks	O
would	O
be	O
greatly	O
appreciated	O
!	O

Geopy	O
error	O
:	O
GeocoderServiceError	O
:	O
HTTP	O
Error	O
500	O
:	O
Internal	O
Server	O
Error	O
using	O
pandas	O
apply	O
function	O
with	O
str	O
concat	O

Working	O
function	O
(	O
see	O
code	O
Python	O
Pandas	O
apply	O
returns	O
series	O
;	O
cant	O
convert	O
to	O
dataframe	B-API
)	O
has	O
stopped	O
working	O
.	O

Only	O
difference	O
is	O
I'm	O
passing	O
it	O
a	O
string	O
concatenation	O
.	O

#CODE	O

Ed	O
,	O
I	O
see	O
what	O
you	O
are	O
saying	O
-	O
that	O
I'm	O
passing	O
a	O
series	O
-	O
but	O
am	O
not	O
sure	O
how	O
to	O
fix	O
it	O
.	O

Short	O
of	O
ditching	O
apply	O
and	O
iterating	O
through	O
the	O
table	O
,	O
or	O
passing	O
5	O
parameters	O
and	O
then	O
iterating	O
through	O
the	O
table	O
.	O

I	O
thought	O
apply()	B-API
did	O
this	O
for	O
me	O
-	O
calling	O
the	O
function	O
once	O
for	O
each	O
row	O
.	O

The	O
debug	O
code	O
seems	O
to	O
indicate	O
this	O
as	O
it	O
says	O
that	O
x	O
is	O
a	O
str	O
type	O
,	O
not	O
series	O
.	O

Hmmm	O
...	O

I	O
believe	O
you	O
,	O
I'm	O
just	O
trying	O
to	O
wrap	O
my	O
head	O
around	O
it	O
and	O
decide	O
what	O
to	O
do	O
next	O
.	O

And	O
I	O
manually	O
confirmed	O
the	O
geocoder	O
is	O
insensitive	O
to	O
white	O
spaces	O
.	O

Any	O
Further	O
advice	O
?	O

What	O
you're	O
doing	O
is	O
a	O
little	O
perverse	O
to	O
be	O
honest	O
,	O
you're	O
calling	O
`	O
apply	O
`	O
on	O
a	O
series	O
and	O
then	O
trying	O
to	O
construct	O
a	O
str	O
from	O
lots	O
of	O
columns	O
,	O
this	O
is	O
the	O
wrong	O
way	O
to	O
go	O
about	O
this	O
,	O
you	O
can	O
call	O
apply	O
on	O
the	O
df	O
and	O
pass	O
`	O
axis=1	O
`	O
so	O
that	O
the	O
row	O
is	O
passed	O
and	O
either	O
access	O
each	O
column	O
in	O
a	O
lambda	O
func	O
and	O
pass	O
them	O
to	O
`	O
locate	O
`	O
or	O
in	O
`	O
locate	O
`	O
extract	O
each	O
column	O
value	O
,	O
or	O
just	O
create	O
a	O
series	O
from	O
the	O
concatenation	O
of	O
all	O
the	O
columns	O
and	O
call	O
apply	O
on	O
this	O
:	O
#CODE	O

Your	O
DataFrame	B-API
column	O
contains	O
a	O
mixture	O
of	O
strings	O
and	O
tuples	O
.	O

I	O
don't	O
think	O
you	O
can	O
avoid	O
iterating	O
the	O
column	O
.	O

But	O
you	O
can	O
iterate	O
efficiently	O
with	O
the	O
apply	O
method	O
.	O

Example	O
code	O
follows	O
.	O

#CODE	O

Then	O
I	O
am	O
able	O
to	O
process	O
it	O
using	O
apply	O
,	O
for	O
example	O
:	O
#CODE	O

The	O
solution	O
to	O
this	O
problem	O
is	O
to	O
apply	O
`	O
reset_index()	B-API
`	O
to	O
"	O
end	O
"	O
the	O
group-by	O
operation	O
.	O

Just	O
apply	O
a	O
`	O
filter	O
`	O
:	O
#CODE	O

The	O
point	O
is	O
that	O
I	O
don't	O
think	O
I've	O
understood	O
it	O
,	O
sorry	O
.	O

Ok	O
,	O
no	O
ANOVA	O
.	O

But	O
then	O
,	O
you	O
will	O
run	O
24x2	O
t-tests	O
??	O

Maybe	O
I	O
still	O
haven't	O
understood	O
...	O

Anyway	O
,	O
if	O
you	O
want	O
to	O
apply	O
a	O
value	O
to	O
a	O
multiindex	O
,	O
it	O
would	O
be	O
something	O
like	O
`	O
df.loc	B-API
[	O
'	O
0hr	O
']	O
.loc	B-API
[	O
'	O
0.01um	O
']	O
[	O
'	O
t	B-API
']	O
=	O
xxx	O
`	O
,	O
assuming	O
that	O
'	O
t	B-API
'	O
is	O
a	O
column	O
.	O

For	O
your	O
dataframe	B-API
,	O
I've	O
tried	O
it	O
straight	O
in	O
ipython	O
as	O
`	O
df.loc	B-API
[	O
'	O
0hr	O
']	O
.loc	B-API
[	O
'	O
0.01um	O
']	O
.loc	B-API
[	O
0	O
]	O
[	O
'	O
a	O
']	O
=	O
3	O
`	O
.	O

But	O
if	O
again	O
I	O
haven't	O
understood	O
,	O
just	O
tell	O
me	O
!	O

apply	O
sort	O
to	O
a	O
pandas	O
groupby	B-API
operation	O

How	O
do	O
I	O
apply	O
sort	O
to	O
a	O
pandas	O
groupby	B-API
operation	O
?	O

The	O
command	O
below	O
returns	O
an	O
error	O
saying	O
that	O
'	O
bool	O
'	O
object	O
is	O
not	O
callable	O
#CODE	O

Normally	O
the	O
sort	O
is	O
performed	O
on	O
the	O
groupby	B-API
keys	O
and	O
as	O
you've	O
found	O
out	O
you	O
can't	O
call	O
`	O
sort	O
`	O
on	O
a	O
groupby	B-API
object	O
,	O
what	O
you	O
could	O
do	O
is	O
call	O
`	O
apply	O
`	O
and	O
pass	O
the	O
`	O
DataFrame.sort	O
`	O
function	O
and	O
pass	O
the	O
column	O
as	O
the	O
kwarg	O
param	O
:	O
#CODE	O

It	O
doesn't	O
matter	O
for	O
your	O
mean	O
calculation	O
because	O
you're	O
just	O
generating	O
a	O
boolean	O
that	O
pandas	O
interprets	O
as	O
0	O
/	O
1	O
.	O

But	O
for	O
the	O
correlation	O
coeffient	O
you	O
need	O
to	O
provide	O
numbers	O
.	O

You	O
also	O
need	O
to	O
use	O
`	O
apply	O
`	O
rather	O
than	O
`	O
agg	O
`	O
here	O
:	O
#CODE	O

Thanks	O
Ed	O
and	O
Alex	O
,	O
never	O
used	O
'	O
.gt	B-API
'	O
before	O
.	O

Just	O
out	O
of	O
curiosity	O
,	O
is	O
it	O
possible	O
to	O
use	O
'	O
apply	O
'	O
to	O
realize	O
the	O
same	O
function	O
?	O

Yes	O
you	O
could	O
but	O
I'd	O
advise	O
against	O
it	O
because	O
apply	O
is	O
slow	O
whilst	O
this	O
will	O
be	O
vectorised	O
,	O
apply	O
should	O
be	O
a	O
last	O
resort	O
always	O

thank	O
you	O
John	O
,	O
I	O
was	O
very	O
curious	O
about	O
how	O
to	O
use	O
apply	O
to	O
realize	O
it	O
.	O

Python	O
How	O
to	O
find	O
average	O
of	O
columns	O
using	O
dataframes	O
apply	O
method	O

Using	O
the	O
dataframe's	O
apply	O
method	O
,	O
create	O
a	O
new	O
Series	O
called	O
`	O
avg_medal_count	O
`	O
that	O
indicates	O
the	O
average	O
number	O
of	O
gold	O
,	O
silver	O
,	O
and	O
bronze	O
medals	O
earned	O
amongst	O
countries	O
who	O
earned	O
at	O
least	O
one	O
medal	O
of	O
any	O
kind	O
at	O
the	O
2014	O
Sochi	O
Olympics	O
.	O

I	O
played	O
around	O
with	O
this	O
for	O
a	O
couple	O
of	O
minutes	O
.	O

I	O
think	O
v1	O
/	O
v2	O
are	O
empty	O
for	O
some	O
data	O
values	O
,	O
in	O
line	O
with	O
what	O
Andy	O
suggests	O
.	O

Also	O
coef	O
doesn't	O
seem	O
to	O
have	O
any	O
purpose	O
in	O
the	O
code	O
,	O
just	O
fyi	O
.	O

Anyway	O
,	O
your	O
groupby	B-API
/	O
apply	O
is	O
probably	O
OK	O
,	O
you	O
just	O
have	O
something	O
wrong	O
with	O
the	O
function	O
itself	O
.	O

And	O
,	O
Now	O
,	O
let's	O
see	O
what	O
was	O
the	O
error	O
that	O
was	O
happening	O
,	O
when	O
you	O
apply	O
np.argsort()	B-API
after	O
first	O
group	O
on	O
series	O
object	O
.	O

Lets	O
take	O
the	O
second	O
group	O
values	O
.	O

Which	O
is	O
-	O
#CODE	O

Ok	O
,	O
it	O
solves	O
the	O
example	O
.	O

The	O
problem	O
is	O
that	O
I	O
do	O
not	O
have	O
a	O
string	O
of	O
data	O
as	O
"	O
data	O
"	O
in	O
your	O
example	O
.	O

I	O
only	O
have	O
csv-file	O
,	O
and	O
i	O
tried	O
to	O
apply	O
your	O
solution	O
but	O
could	O
not	O
make	O
it	O
work	O
.	O

Do	O
I	O
have	O
to	O
convert	O
the	O
csv-file	O
to	O
a	O
string	O
of	O
data	O
first	O
maby	O
?	O

Alternatively	O
,	O
you	O
can	O
represent	O
`	O
sym	O
`	O
column	O
as	O
a	O
q	O
generic	O
list	O
containing	O
strings	O
.	O

You	O
can	O
also	O
apply	O
type	O
conversion	O
to	O
other	O
columns	O
:	O
#CODE	O

How	O
can	O
I	O
apply	O
a	O
search	O
,	O
such	O
that	O
the	O
result	O
would	O
be	O
the	O
index	O
for	O
each	O
value	O
,	O
if	O
it	O
exists	O
,	O
in	O
an	O
efficient	O
way	O
(	O
since	O
I	O
know	O
the	O
column	O
`'	O
A	O
'`	O
has	O
uniqu	O
values	O
)	O
to	O
get	O
the	O
following	O
results	O
:	O
#CODE	O

Yeah	O
the	O
euclidian	O
approximation	O
will	O
work	O
fine	O
for	O
small	O
enough	O
distances	O
.	O

You	O
shouldn't	O
even	O
need	O
to	O
do	O
an	O
`	O
apply	O
`	O
for	O
that	O
,	O
can	O
directly	O
just	O
use	O
the	O
columns	O
in	O
the	O
dataframe	B-API
.	O

You	O
can	O
do	O
this	O
by	O
`	O
apply	O
(	O
pd.Series	B-API
)`	O
on	O
that	O
column	O
:	O
#CODE	O

That's	O
quite	O
a	O
long	O
lambda	O
function	O
in	O
your	O
apply	O
,	O
I	O
recommend	O
writing	O
as	O
a	O
function	O
.	O

For	O
one	O
thing	O
it'll	O
be	O
easier	O
to	O
debug	O
(	O
clearer	O
which	O
line	O
is	O
causing	O
the	O
error	O
)	O
.	O

I	O
could	O
be	O
wrong	O
but	O
it	O
looks	O
like	O
`	O
search	O
(	O
Origin_Zip	O
,	O
stop=stop	O
,	O
pause=	O
5.0	O
)`	O
doesn't	O
always	O
return	O
a	O
list	O
(	O
but	O
an	O
int	O
)	O
.	O

I'd	O
reset	O
the	O
index	O
so	O
that	O
it	O
becomes	O
a	O
column	O
,	O
this	O
allows	O
you	O
to	O
call	O
`	O
apply	O
`	O
on	O
it	O
,	O
then	O
for	O
each	O
datetime	O
apply	O
a	O
lambda	O
which	O
calls	O
`	O
replace	O
`	O
and	O
null	O
the	O
minute	O
and	O
seconds	O
attributes	O
,	O
then	O
drop	O
the	O
duplicates	O
and	O
set	O
the	O
index	O
back	O
:	O
#CODE	O

Something	O
like	O
this	O
should	O
work	O
.	O

It	O
will	O
be	O
faster	O
than	O
`	O
apply	O
`	O
since	O
it	O
uses	O
vectorized	O
operations	O
.	O

Further	O
,	O
rather	O
than	O
hard-coding	O
the	O
`	O
apple	O
`	O
result	O
,	O
it	O
gives	O
you	O
counts	O
and	O
percentages	O
for	O
all	O
purchases	O
,	O
no	O
matter	O
how	O
many	O
you	O
might	O
have	O
.	O

#CODE	O

@USER	O
,	O
right	O
off	O
my	O
head	O
I	O
will	O
say	O
filter	O
the	O
selection	O
of	O
the	O
columns	O
,	O
then	O
apply	O
the	O
same	O
on	O
the	O
values	O
copy	O

simply	O
multiply	O
the	O
number	O
by	O
100	O
to	O
scale	O
it	O
in	O
the	O
range	O
(	O
1	O
,	O
100	O
)	O
,	O
and	O
then	O
apply	O
the	O
same	O
algo	O
,	O
however	O
you	O
can	O
play	O
with	O
numbers	O
and	O
find	O
out	O
your	O
own	O
way	O
of	O
doing	O
the	O
same	O
.	O

I	O
have	O
a	O
time-series	O
data	O
in	O
"	O
stacked	O
"	O
format	O
and	O
would	O
like	O
to	O
compute	O
a	O
rolling	O
function	O
based	O
on	O
two	O
columns	O
.	O

However	O
,	O
as	O
shown	O
in	O
my	O
example	O
below	O
,	O
the	O
`	O
groupby	B-API
`	O
is	O
concatenating	O
my	O
results	O
horizontally	O
instead	O
of	O
vertically	O
.	O

I	O
can	O
apply	O
`	O
stack	O
`	O
at	O
the	O
end	O
to	O
get	O
back	O
to	O
tall	O
format	O
.	O

However	O
,	O
I	O
thought	O
the	O
correct	O
behavior	O
should	O
be	O
to	O
concatenate	O
vertically	O
to	O
allow	O
assignment	O
back	O
to	O
the	O
original	O
dataframe	B-API
(	O
something	O
like	O
`	O
x	O
[	O
'	O
res	O
']	O
=	O
df.groupby	B-API
(	O
...	O
)	O
.apply	B-API
(	O
func	O
)`)	O
.	O

Does	O
anyone	O
know	O
why	O
`	O
groupby	B-API
`	O
is	O
not	O
behaving	O
as	O
expected	O
or	O
am	O
I	O
doing	O
something	O
wrong	O
?	O

#CODE	O

@USER	O
Also	O
calling	O
`	O
apply	O
`	O
should	O
be	O
the	O
last	O
resort	O
when	O
working	O
with	O
arrays	O
,	O
it	O
is	O
not	O
vectorised	O
and	O
therefore	O
will	O
not	O
scale	O
well	O

apologies	O
if	O
this	O
is	O
a	O
silly	O
question	O
,	O
but	O
I	O
am	O
not	O
quite	O
sure	O
as	O
to	O
why	O
this	O
behavior	O
is	O
the	O
case	O
,	O
and	O
/	O
or	O
whether	O
I	O
am	O
misunderstanding	O
it	O
.	O

I	O
was	O
trying	O
to	O
create	O
a	O
function	O
for	O
the	O
'	O
apply	O
'	O
method	O
,	O
and	O
noticed	O
that	O
if	O
you	O
run	O
apply	O
on	O
a	O
series	O
the	O
series	O
is	O
passed	O
as	O
a	O
np.array	B-API
and	O
if	O
you	O
pass	O
the	O
same	O
series	O
within	O
a	O
dataframe	B-API
of	O
1	O
column	O
,	O
the	O
series	O
is	O
passed	O
as	O
a	O
series	O
to	O
the	O
(	O
u	O
)	O
func	O
.	O

mode	O
isn't	O
a	O
groupby	B-API
method	O
,	O
though	O
it	O
is	O
a	O
Series	O
(	O
and	O
DataFrame	B-API
)	O
method	O
,	O
so	O
you	O
have	O
to	O
pass	O
it	O
to	O
apply	O
:	O
#CODE	O

For	O
each	O
set_up	O
in	O
set_ups	O
I	O
want	O
to	O
apply	O
'	O
value	O
'	O
to	O
'	O
set_up	O
'	O
and	O
groupby	B-API
(	O
level=0	O
)	O
or	O
df.A	O
and	O
df.B	O
.	O

#CODE	O

First	O
,	O
we	O
can	O
perform	O
a	O
groupby	B-API
/	O
apply	O
operation	O
to	O
obtain	O
the	O
Protein	O
/	O
Peptide	O
pairs	O
with	O
the	O
two	O
largest	O
Peptide	O
counts	O
for	O
each	O
Protein	O
:	O
#CODE	O

Apply	O
function	O
to	O
multilevel	O
columns	O

I	O
renamed	O
your	O
columns	O
to	O
'	O
author	O
'	O
and	O
'	O
citations	O
'	O
here	O
,	O
we	O
can	O
groupby	B-API
the	O
authors	O
and	O
then	O
apply	O
a	O
lambda	O
,	O
here	O
the	O
lambda	O
is	O
comparing	O
the	O
number	O
of	O
citations	O
against	O
the	O
value	O
,	O
this	O
will	O
generate	O
a	O
1	O
or	O
0	O
if	O
true	O
,	O
we	O
can	O
then	O
sum	O
this	O
:	O
#CODE	O

Pandas	O
:	O
column	O
of	O
type	O
str	O
converted	O
to	O
tslib.Timestamp	O
after	O
using	O
apply	O
function	O

Thank	O
you	O
.	O

That	O
worked	O
!	O

Is	O
this	O
a	O
implementation	O
problem	O
of	O
pandas	O
or	O
the	O
apply	O
function	O
that	O
I	O
was	O
using	O
?	O

You	O
can	O
apply	O
multiple	O
functions	O
to	O
multiple	O
fields	O
:	O
#CODE	O

So	O
what	O
are	O
you	O
trying	O
to	O
achieve	O
here	O
?	O
for	O
squaring	O
the	O
values	O
this	O
is	O
trivial	O
to	O
perform	O
and	O
doesn't	O
require	O
the	O
use	O
of	O
`	O
apply	O
`	O
in	O
this	O
case	O

I	O
am	O
trying	O
to	O
create	O
arbitrarily	O
many	O
fields	O
and	O
assign	O
them	O
values	O
simultaneously	O
using	O
the	O
apply	O
method	O
.	O

The	O
simple	O
functions	O
in	O
the	O
example	O
just	O
represent	O
any	O
arbitraryfunction	O
I	O
may	O
want	O
to	O
use	O
for	O
generating	O
a	O
new	O
field	O
.	O

The	O
issue	O
is	O
when	O
trying	O
to	O
create	O
more	O
than	O
1	O
field	O
in	O
the	O
above	O
example	O
it	O
errors	O
.	O

Once	O
I	O
can	O
do	O
this	O
I	O
can	O
replace	O
the	O
trivial	O
function	O
with	O
any	O
value	O
.	O

This	O
will	O
certainly	O
fix	O
the	O
problem	O
.	O

But	O
it	O
will	O
involve	O
having	O
the	O
apply	O
return	O
only	O
a	O
single	O
field	O
at	O
once	O
.	O

What	O
I	O
was	O
curious	O
about	O
was	O
being	O
able	O
to	O
use	O
apply	O
to	O
return	O
arbritrarily	O
many	O
fields	O
.	O

By	O
being	O
able	O
to	O
do	O
this	O
it	O
should	O
allow	O
for	O
cleaner	O
code	O
.	O

The	O
original	O
approach	O
you	O
suggested	O
is	O
correct	O
,	O
although	O
you	O
have	O
to	O
use	O
a	O
`	O
transform	O
`	O
on	O
the	O
groups	O
(	O
by	O
`	O
date	O
`	O
AND	O
`	O
source	O
`)	O
instead	O
of	O
an	O
`	O
apply	O
`	O
.	O

`	O
transform	O
`	O
return	O
the	O
group	O
information	O
with	O
the	O
same	O
structure	O
of	O
the	O
original	O
dataframe	B-API
.	O

#CODE	O

It	O
splits	O
up	O
the	O
DataFrame	B-API
by	O
store_nbr	O
,	O
calls	O
is_good	O
on	O
each	O
each	O
group	O
(	O
apply	O
)	O
to	O
determine	O
the	O
rows	O
you	O
want	O
to	O
keep	O
,	O
puts	O
everything	O
back	O
together	O
in	O
the	O
right	O
order	O
,	O
and	O
then	O
takes	O
a	O
subset	O
of	O
rows	O
from	O
the	O
original	O
frame	O
.	O

If	O
you	O
want	O
to	O
apply	O
it	O
on	O
a	O
full	O
column	O
,	O
you	O
can	O
also	O
do	O
:	O
#CODE	O

Yes	O
there	O
is	O
a	O
concise	O
and	O
efficient	O
way	O
to	O
solve	O
this	O
.	O

You	O
were	O
on	O
the	O
right	O
track	O
with	O
`	O
df.dropna()	B-API
`	O
,	O
just	O
that	O
you	O
need	O
to	O
`	O
unstack	O
`	O
your	O
data	O
before	O
you	O
apply	O
it	O
.	O

#CODE	O

The	O
last	O
expression	O
would	O
apply	O
to	O
your	O
case	O
if	O
`	O
res_tmp.fittedvalues	O
`	O
are	O
the	O
predicted	O
or	O
fitted	O
values	O
of	O
your	O
winsorized	O
model	O
,	O
and	O
`	O
y_orig	O
`	O
is	O
your	O
original	O
unchanged	O
response	O
variable	O
.	O

This	O
definition	O
of	O
R	O
squared	O
applies	O
if	O
there	O
is	O
a	O
constant	O
in	O
the	O
model	O
.	O

By	O
now	O
,	O
you'd	O
have	O
a	O
sense	O
of	O
the	O
pattern	O
.	O

Create	O
a	O
`	O
distance	O
`	O
method	O
.	O

Then	O
apply	O
it	O
pairwise	O
to	O
every	O
column	O
using	O
#CODE	O

Since	O
`	O
count_dic	O
`	O
is	O
actually	O
a	O
`	O
dict	O
`	O
,	O
then	O
you	O
can	O
apply	O
`	O
len	O
`	O
to	O
get	O
the	O
number	O
of	O
keys	O
,	O
eg	O
:	O
#CODE	O

Python	O
DataFrame	B-API
-	O
apply	O
different	O
calculations	O
due	O
to	O
a	O
column's	O
value	O

I	O
am	O
setting	O
the	O
values	O
to	O
NaN	O
and	O
then	O
apply	O
the	O
fillna	B-API
method	O
.	O

I	O
think	O
the	O
main	O
problem	O
here	O
,	O
is	O
because	O
I'm	O
trying	O
to	O
apply	O
the	O
`	O
pool.map	O
`	O
to	O
`	O
rpy2	O
`	O
function	O
and	O
not	O
a	O
Python	O
predefined	O
function	O
.	O

Probably	O
there	O
is	O
some	O
workaround	O
solution	O
for	O
this	O
without	O
using	O
the	O
multiprocessing	O
library	O
,	O
but	O
I	O
can't	O
see	O
any	O
.	O

maybe	O
the	O
.map()	B-API
was	O
trying	O
to	O
apply	O
both	O
the	O
mask	O
and	O
the	O
operation	O
:	O
#CODE	O

You	O
can	O
use	O
the	O
apply	O
function	O
:	O
#CODE	O

And	O
,	O
then	O
`	O
apply	O
`	O
`	O
split_cumsum	O
`	O
over	O
`	O
df.groupby	B-API
(	O
'	O
Group	O
')`	O
#CODE	O

Thanks	O
John	O
,	O
I	O
didn't	O
quite	O
appreciate	O
what	O
circumstances	O
would	O
make	O
sense	O
to	O
create	O
a	O
function	O
and	O
apply	O
it	O
to	O
a	O
DataFrame	B-API
,	O
but	O
this	O
solution	O
is	O
definitely	O
a	O
cleaner	O
approach	O
.	O

That	O
is	O
not	O
so	O
surprising	O
but	O
`	O
apply	O
`	O
does	O
not	O
scale	O
well	O
,	O
I	O
just	O
did	O
timings	O
on	O
a	O
600	O
row	O
df	O
and	O
the	O
timings	O
were	O
6.24ms	O
vs	O
33.3ms	O
comparing	O
my	O
method	O
against	O
yours	O
,	O
I	O
expect	O
the	O
performance	O
difference	O
to	O
increase	O
significantly	O
on	O
much	O
larger	O
datasets	O

@USER	O
Absolutely	O
,	O
`	O
apply	O
`	O
doesn't	O
perform	O
well	O
on	O
larger	O
datasets	O
.	O

So	O
,	O
I	O
mentioned	O
*	O
expensive	O
for	O
this	O
smaller	O
data	O
.	O

*	O
=)	O

Is	O
there	O
some	O
sort	O
of	O
`	O
apply	O
`	O
equivalent	O
(	O
like	O
in	O
`	O
pandas	O
`)	O
that	O
would	O
make	O
this	O
more	O
efficient	O
?	O

Pandas	O
Apply	O
(	O
axis=1	O
):	O
produce	O
more	O
than	O
one	O
row	O

I	O
have	O
a	O
function	O
I	O
want	O
to	O
apply	O
by	O
row	O
like	O
so	O
:	O
#CODE	O

As	O
you	O
can	O
tell	O
,	O
this	O
function	O
is	O
meant	O
to	O
take	O
a	O
list	O
of	O
items	O
and	O
create	O
a	O
row	O
for	O
each	O
item	O
that	O
duplicates	O
the	O
rest	O
of	O
the	O
remaining	O
data	O
.	O

Unfortunately	O
,	O
my	O
current	O
method	O
isn't	O
the	O
correct	O
usage	O
of	O
the	O
apply	O
method	O
:	O
#CODE	O

This	O
question	O
is	O
similar	O
to	O
pandas	O
:	O
apply	O
function	O
to	O
DataFrame	B-API
that	O
can	O
return	O
multiple	O
rows	O
that	O
Wes	O
McKinney	O
has	O
answered	O
.	O

Let	O
,	O
`	O
df	O
`	O
the	O
dataframe	B-API
with	O
two	O
columns	O
,	O
apply	O
conditional	O
absolute	O
minimum	O
over	O
rows	O
using	O
`	O
axis=1	O
`	O

OK	O
,	O
after	O
reading	O
and	O
understanding	O
your	O
question	O
and	O
not	O
being	O
able	O
to	O
find	O
a	O
vectorised	O
approach	O
,	O
we	O
can	O
define	O
a	O
custom	O
function	O
and	O
call	O
`	O
apply	O
`	O
and	O
pass	O
each	O
row	O
.	O

`	O
df.values	B-API
`	O
returns	O
a	O
NumPy	O
array	O
containing	O
the	O
values	O
in	O
`	O
df	O
`	O
.	O

You	O
could	O
then	O
apply	O
`	O
np.std	B-API
`	O
to	O
that	O
array	O
:	O
#CODE	O

I	O
believe	O
I	O
can	O
achieve	O
this	O
by	O
using	O
apply	O
on	O
the	O
first	O
to	O
filter	O
the	O
second	O
based	O
on	O
these	O
criterion	O
and	O
then	O
combining	O
the	O
results	O
but	O
apply	O
has	O
in	O
practice	O
been	O
a	O
horribly	O
slow	O
way	O
to	O
go	O
about	O
things	O
.	O

Set	O
column	O
name	O
for	O
apply	O
result	O
over	O
groupby	B-API

What	O
I'd	O
like	O
to	O
do	O
is	O
assign	O
a	O
name	O
to	O
the	O
result	O
of	O
`	O
apply	O
`	O
(	O
or	O
`	O
lambda	O
`)	O
.	O

Is	O
there	O
anyway	O
to	O
do	O
this	O
without	O
moving	O
`	O
lambda	O
`	O
to	O
a	O
named	O
function	O
or	O
renaming	O
the	O
column	O
after	O
running	O
the	O
last	O
line	O
?	O

Yes	O
,	O
that	O
was	O
what	O
I	O
was	O
planning	O
to	O
do	O
.	O

However	O
,	O
I	O
know	O
realize	O
it	O
is	O
not	O
the	O
correct	O
way	O
to	O
do	O
it	O
since	O
they	O
are	O
not	O
independent	O
.	O

Your	O
answer	O
give	O
me	O
a	O
better	O
understanding	O
how	O
to	O
use	O
pandas	O
groupby	B-API
and	O
apply	O
.	O

Thank	O
you	O
very	O
much	O
!	O

What	O
you	O
want	O
to	O
do	O
is	O
`	O
groupby	B-API
`	O
on	O
the	O
index	O
levels	O
and	O
apply	O
a	O
function	O
that	O
calls	O
`	O
mannwhitneyu	O
`	O
,	O
passing	O
the	O
two	O
columns	O
`	O
course1	O
`	O
and	O
`	O
course2	O
`	O
.	O

Suppose	O
this	O
is	O
your	O
data	O
:	O
#CODE	O

Yeah	O
.	O
this	O
works	O
.	O

I	O
wrongly	O
assumed	O
sum()	B-API
would	O
not	O
apply	O
to	O
lists	O
.	O

Thanks	O
a	O
lot	O

apply	O
if	O
statement	O
within	O
sort.head()	O

Am	O
I	O
not	O
allowed	O
to	O
use	O
a	O
series	O
in	O
a	O
pd.apply	O
function	O
?	O

If	O
so	O
how	O
can	O
I	O
apply	O
a	O
function	O
row	O
by	O
row	O
and	O
assign	O
the	O
output	O
to	O
a	O
new	O
column	O
?	O

You	O
don't	O
need	O
to	O
use	O
apply	O
when	O
calling	O
the	O
function	O
.	O

Just	O
use	O
:	O
#CODE	O

I	O
reworked	O
the	O
formulae	O
to	O
apply	O
to	O
series	O
:	O
#CODE	O

Because	O
the	O
parameters	O
lon2	O
and	O
lat2	O
are	O
Pandas	O
Series	O
,	O
dlon	O
and	O
dlat	O
will	O
both	O
be	O
Series	O
objects	O
as	O
well	O
.	O

You	O
then	O
need	O
to	O
use	O
apply	O
on	O
the	O
series	O
to	O
apply	O
the	O
function	O
to	O
each	O
element	O
in	O
the	O
list	O
.	O

Okay	O
,	O
I	O
just	O
restarted	O
the	O
kernel	O
in	O
my	O
ipython	O
notebook	O
and	O
now	O
with	O
the	O
above	O
i	O
get	O
this	O
error	O
-	O
`	O
AttributeError	O
:	O
'	O
numpy.float64	O
'	O
object	O
has	O
no	O
attribute	O
'	O
apply	O
'`	O
for	O
the	O
a=	O
code	O
that	O
you	O
gave	O
above	O

Do	O
you	O
just	O
want	O
to	O
print	O
it	O
or	O
actually	O
DO	O
something	O
with	O
it	O
or	O
to	O
it	O
?	O

E.g.	O

if	O
you	O
want	O
to	O
apply	O
a	O
function	O
to	O
every	O
element	O
,	O
see	O
```	O
applymap()	B-API
```	O

When	O
I	O
apply	O
`	O
plt.xcorr	B-API
(	O
df.Val1	O
,	O
df.Val2	O
)`	O

Note	O
:	O
Before	O
you	O
apply	O
`	O
factorize()	B-API
`	O
you	O
need	O
to	O
`	O
fill	O
`	O
your	O
`	O
NaNs	O
`	O

And	O
I	O
want	O
to	O
calculate	O
the	O
following	O
information	O
"	O
How	O
many	O
days	O
was	O
each	O
account	O
active	O
?	O

"	O
,	O
I	O
understand	O
that	O
I	O
could	O
simply	O
do	O
a	O
count	O
to	O
get	O
this	O
information	O
,	O
but	O
I	O
want	O
to	O
apply	O
the	O
following	O
restriction	O
,	O
"	O
If	O
there	O
are	O
n	O
days	O
between	O
activity	O
dates	O
,	O
only	O
count	O
the	O
days	O
before	O
that	O
gap	O
"	O
.	O

It	O
seems	O
more	O
logical	O
to	O
apply	O
the	O
filter	O
to	O
the	O
time	O
column	O
as	O
it	O
is	O
being	O
read	O
in	O
then	O
to	O
operate	O
on	O
it	O
later	O
.	O

Is	O
there	O
a	O
way	O
to	O
do	O
this	O
by	O
telling	O
the	O
read	O
function	O
what	O
function	O
to	O
call	O
as	O
it	O
reads	O
the	O
column	O
,	O
before	O
storing	O
the	O
object	O
in	O
memory	O
?	O

Below	O
,	O
john-galt	O
gives	O
an	O
extremely	O
helpful	O
answer	O
.	O

However	O
,	O
I've	O
found	O
one	O
case	O
where	O
it's	O
not	O
immediately	O
obviously	O
how	O
to	O
apply	O
his	O
solution	O
:	O
using	O
a	O
custom	O
grouping	O
function	O
.	O

But	O
unlike	O
most	O
Pandas	O
Cython	O
tutorials	O
or	O
examples	O
I	O
am	O
not	O
apply	O
functions	O
so	O
to	O
speak	O
,	O
more	O
manipulating	O
data	O
using	O
slices	O
,	O
sums	O
and	O
division	O
(	O
etc	O
)	O
.	O

@USER	O
in	O
apply	O
/	O
agg	O
the	O
function	O
needs	O
to	O
take	O
the	O
subDataFrame	O
/	O
each	O
group	O
.	O
tbh	O
I'm	O
a	O
little	O
confused	O
at	O
what	O
you're	O
trying	O
to	O
do	O
:	O
s	O

You	O
could	O
all	O
`	O
df.filter	B-API
(	O
regex=	O
'	O
HW	O
')`	O
to	O
return	O
column	O
names	O
like	O
'	O
HW	O
'	O
and	O
then	O
apply	O
sum	O
row-wise	O
via	O
`	O
sum	O
(	O
axis-1	O
)`	O
#CODE	O

I	O
have	O
a	O
big	O
`	O
DataFrame	B-API
`	O
in	O
pandas	O
with	O
three	O
columns	O
:	O
`'	O
col1	O
'`	O
is	O
string	O
,	O
`'	O
col2	O
'`	O
and	O
`'	O
col3	O
'`	O
are	O
`	O
numpy.int64	O
`	O
.	O

I	O
need	O
to	O
do	O
a	O
`	O
groupby	B-API
`	O
,	O
then	O
apply	O
a	O
custom	O
aggregation	O
function	O
using	O
`	O
apply	O
`	O
,	O
as	O
follows	O
:	O
#CODE	O

If	O
you	O
want	O
the	O
values	O
themselves	O
,	O
you	O
can	O
`	O
groupby	B-API
`	O
'	O
Column1	O
'	O
and	O
then	O
call	O
`	O
apply	O
`	O
and	O
pass	O
the	O
`	O
list	O
`	O
method	O
to	O
apply	O
to	O
each	O
group	O
.	O

You	O
could	O
`	O
groupby	B-API
`	O
on	O
`	O
Column1	O
`	O
and	O
then	O
take	O
`	O
Column3	O
`	O
to	O
`	O
apply	O
(	O
list	O
)`	O
and	O
call	O
`	O
to_dict	B-API
`	O
?	O

#CODE	O

@USER	O
this	O
is	O
incredible	O
..	O
clever	O
use	O
of	O
apply	O
!	O

what	O
a	O
great	O
principle	O
..	O
can	O
be	O
applied	O
as	O
a	O
function	O
for	O
any	O
kind	O
of	O
dict	O
look	O
up	O
.	O

Same	O
code	O
should	O
also	O
apply	O
to	O
a	O
binary	O
confusion	O
matrix	O
like	O
:	O
#CODE	O

Don't	O
use	O
`	O
apply	O
`	O
you	O
can	O
achieve	O
the	O
same	O
result	O
much	O
faster	O
using	O
3	O
`	O
.loc	B-API
`	O
calls	O
:	O
#CODE	O

df	O
[	O
'	O
column_of_ints	O
']	O
is	O
a	O
Series	O
not	O
a	O
DataFrame	B-API
,	O
there	O
is	O
no	O
`	O
axis=1	O
`	O
for	O
`	O
apply	O
`	O
method	O
for	O
a	O
Series	O
,	O
you	O
can	O
force	O
this	O
to	O
a	O
DataFrame	B-API
using	O
double	O
square	O
brackets	O
:	O
#CODE	O

@USER	O
No	O
it	O
gives	O
me	O
the	O
same	O
warning	O
even	O
on	O
using	O
apply	O
instead	O
of	O
map	O

One	O
way	O
to	O
do	O
this	O
apply	O
`	O
clip_upper()	B-API
`	O
on	O
90	O
percentile	O
value	O
`	O
np.percentile	B-API
(	O
x	O
,	O
90	O
)`	O
for	O
each	O
column	O
#CODE	O

I	O
had	O
imagined	O
@USER	O
elegant	O
solution	O
would	O
faster	O
than	O
`	O
apply	O
`	O
.	O

But	O
,	O

Thanks	O
for	O
the	O
timings	O
!	O

I	O
had	O
thought	O
the	O
same	O
thing	O
but	O
,	O
having	O
just	O
checked	O
timings	O
on	O
my	O
machine	O
,	O
it	O
appears	O
`	O
apply	O
`	O
can	O
be	O
surprising	O
sometimes	O
:-)	O

Not	O
sure	O
why	O
,	O
but	O
you	O
would	O
notice	O
that	O
in	O
the	O
benchmarks	O
posted	O
,	O
this	O
method	O
seems	O
slower	O
than	O
apply	O
method	O
.	O

+1	O
for	O
cleaner	O
single-liner	O
.	O

Note	O
that	O
these	O
days	O
you	O
can	O
use	O
`	O
expand=True	O
`	O
instead	O
of	O
`	O
apply	O
(	O
pd.Series	B-API
)`	O
:	O
#CODE	O

You	O
can't	O
pass	O
a	O
Series	O
as	O
a	O
param	O
to	O
a	O
function	O
unless	O
it	O
understands	O
what	O
a	O
pandas	O
Series	O
or	O
the	O
array	O
type	O
is	O
so	O
you	O
can	O
instead	O
call	O
`	O
apply	O
`	O
and	O
pass	O
the	O
function	O
as	O
the	O
param	O
which	O
will	O
call	O
that	O
function	O
for	O
every	O
value	O
in	O
the	O
Series	O
as	O
shown	O
above	O
.	O

You	O
could	O
call	O
`	O
apply	O
`	O
and	O
use	O
`	O
datetime.strptime	O
`	O
:	O
#CODE	O

A	O
function	O
can	O
be	O
applied	O
to	O
a	O
`	O
groupby	B-API
`	O
with	O
the	O
`	O
apply	O
`	O
function	O
.	O

The	O
passed	O
function	O
in	O
this	O
case	O
`	O
linregress	O
`	O
.	O

Please	O
see	O
below	O
:	O
#CODE	O

How	O
do	O
I	O
iterate	O
over	O
each	O
row	O
and	O
column	O
in	O
`	O
rectangle	O
`	O
to	O
run	O
my	O
function	O
`	O
MakeBoolDictOfSearchTermsAndProducts()	O
`	O
on	O
it	O
and	O
fill	O
in	O
the	O
correct	O
element	O
with	O
the	O
result	O
?	O

Should	O
I	O
use	O
apply	O
?	O
or	O
map	O
?	O
or	O
perhaps	O
apply_map	O
?	O

You	O
can	O
use	O
groupby	B-API
and	O
apply	O
:	O
#CODE	O

You	O
could	O
`	O
apply	O
`	O
on	O
dataframe	B-API
and	O
get	O
`	O
argmax()	B-API
`	O
of	O
each	O
row	O
via	O
`	O
axis=1	O
`	O
#CODE	O

Here's	O
a	O
benchmark	O
to	O
compare	O
how	O
slow	O
`	O
apply	O
`	O
method	O
is	O
to	O
`	O
idxmax()	B-API
`	O
for	O
`	O
len	O
(	O
df	O
)	O
~	O
20K	O
`	O
#CODE	O

Pandas	O
DataFrame	B-API
apply	O
function	O
doubling	O
size	O
of	O
DataFrame	B-API

I	O
am	O
trying	O
to	O
create	O
this	O
boolean	O
mask	O
using	O
the	O
`	O
apply	O
`	O
method	O
,	O
where	O
`	O
df	O
`	O
is	O
a	O
DataFrame	B-API
with	O
numeric	O
data	O
of	O
size	O
a	O
*	O
b	O
,	O
as	O
follows	O
.	O

#CODE	O

Why	O
is	O
the	O
`	O
apply	O
`	O
method	O
doubling	O
the	O
size	O
of	O
the	O
DataFrame	B-API
?	O

Unfortunately	O
,	O
the	O
Pandas	O
apply	O
documentation	O
does	O
not	O
offer	O
helpful	O
clues	O
.	O

Ability	O
to	O
apply	O
different	O
stats	O
to	O
different	O
columns	O
(	O
for	O
now	O
just	O
count	O
,	O
sum	O
,	O
mean	O
,	O
weighted	O
mean	O
)	O

`	O
data.apply	O
(	O
math.log10	O
)`	O
did	O
not	O
work	O
because	O
`	O
apply	O
`	O
tries	O
to	O
pass	O
an	O
entire	O
column	O
(	O
a	O
Series	O
)	O
of	O
values	O
to	O
`	O
math.log10	O
`	O
.	O

`	O
math.log10	O
`	O
expects	O
a	O
scalar	O
value	O
only	O
.	O

And	O
can	O
I	O
apply	O
tight_layout	B-API
to	O
data.hist	O
somehow	O
?	O

I'm	O
not	O
sure	O
I	O
can	O
give	O
you	O
a	O
great	O
explanation	O
for	O
that	O
warning	O
beyond	O
what's	O
in	O
the	O
documentation	O
,	O
but	O
it	O
appears	O
what	O
you	O
did	O
works	O
fine	O
and	O
that	O
warning	O
doesn't	O
always	O
apply	O
even	O
when	O
it	O
appears	O
.	O

Call	O
`	O
apply	O
`	O
on	O
'	O
B	O
'	O
and	O
pass	O
a	O
lambda	O
which	O
just	O
accesses	O
the	O
single	O
key	O
in	O
the	O
dict	O
:	O
#CODE	O

Wow	O
this	O
works	O
for	O
all	O
cases	O
unless	O
I	O
use	O
`	O
apply	O
`	O
and	O
a	O
lambda	O
function	O

Apply	O
a	O
weighted	O
average	O
function	O
to	O
a	O
dataframe	B-API
without	O
grouping	O
it	O
,	O
as	O
if	O
it	O
was	O
a	O
single	O
group	O

I	O
want	O
to	O
apply	O
a	O
function	O
that	O
computes	O
something	O
similar	O
to	O
a	O
weighted	O
average	O
absolute	O
deviation	O
of	O
all	O
the	O
elements	O
of	O
my	O
data	O
frame	O
.	O

If	O
I	O
don't	O
use	O
groupby	B-API
,	O
pandas	O
would	O
apply	O
this	O
function	O
to	O
every	O
row	O
of	O
the	O
dataframe	B-API
,	O
which	O
is	O
not	O
my	O
goal	O
.	O

Okay	O
,	O
so	O
in	O
your	O
post	O
when	O
you	O
say	O
"	O
If	O
I	O
don't	O
use	O
groupby	B-API
,	O
pandas	O
would	O
apply	O
this	O
function	O
to	O
every	O
row	O
of	O
the	O
dataframe	B-API
"	O
,	O
that's	O
not	O
necessarily	O
true	O
.	O

You	O
should	O
try	O
to	O
read	O
up	O
on	O
the	O
way	O
operations	O
on	O
`	O
numpy	O
`	O
arrays	O
are	O
"	O
vectorized	O
"	O
.	O

So	O
,	O
like	O
people	O
have	O
pointed	O
out	O
in	O
the	O
comments	O
,	O
your	O
function	O
works	O
fine	O
without	O
having	O
to	O
do	O
the	O
groupby	B-API
:	O
#CODE	O

Use	O
the	O
older	O
`	O
openpyxl	O
`	O
engine	O
to	O
apply	O
formats	O
one	O
cell	O
at	O
a	O
time	O
.	O

This	O
is	O
the	O
approach	O
with	O
which	O
I've	O
had	O
the	O
most	O
success	O
.	O

But	O
it	O
means	O
writing	O
loops	O
to	O
apply	O
formats	O
cell-by-cell	O
,	O
remembering	O
offsets	O
,	O
etc	O
.	O

This	O
is	O
currently	O
not	O
possible	O
in	O
openpyxl	O
.	O

As	O
you	O
rightly	O
point	O
out	O
applying	O
formats	O
to	O
individual	O
cells	O
is	O
extremely	O
inefficient	O
.	O

This	O
will	O
hopefully	O
improve	O
in	O
forthcoming	O
releases	O
when	O
we	O
add	O
support	O
for	O
named	O
styles	O
you'll	O
still	O
have	O
to	O
apply	O
these	O
individually	O
as	O
resolving	O
all	O
the	O
possible	O
styles	O
for	O
an	O
individual	O
cell	O
(	O
built-in	O
,	O
row	O
,	O
column	O
,	O
individual	O
)	O
is	O
an	O
expensive	O
operation	O
which	O
will	O
be	O
much	O
less	O
complex	O
than	O
it	O
currently	O
is	O
.	O

A	O
single-liner	O
-	O
you	O
could	O
extract	O
numbers	O
from	O
via	O
regex	O
and	O
`	O
apply	O
`	O
on	O
the	O
`	O
duration	O
`	O
column	O
like	O
split	O
into	O
multilines	O
for	O
readability	O
#CODE	O

And	O
,	O
then	O
apply	O
on	O
#CODE	O

What's	O
REALLY	O
confusing	O
me	O
is	O
,	O
when	O
I	O
try	O
to	O
step	O
through	O
the	O
function	O
(	O
not	O
using	O
apply	O
)	O
with	O
just	O
one	O
row	O
,	O
I	O
get	O
the	O
DataFrames	O
that	O
I	O
expect	O
i.e.	O
,	O
not	O
the	O
Series	O
and	O
then	O
Timestamp	O
.	O

Really	O
appreciate	O
any	O
insight	O
into	O
what's	O
going	O
on	O
!	O

Is	O
there	O
a	O
way	O
to	O
have	O
a	O
counter	O
variable	O
in	O
the	O
function	O
called	O
through	O
a	O
pandas	O
groupby	B-API
apply	O
?	O

#CODE	O

Note	O
:	O
this	O
is	O
an	O
implementation	O
detail	O
,	O
the	O
number	O
of	O
times	O
the	O
function	O
in	O
an	O
apply	O
is	O
called	O
may	O
depend	O
on	O
the	O
return	O
type	O
/	O
whether	O
the	O
apply	O
takes	O
the	O
slow	O
or	O
fast	O
path	O
...	O

Isn't	O
the	O
first	O
call	O
to	O
apply	O
the	O
initialisation	O
of	O
the	O
groups	O
though	O
,	O
I	O
thought	O
I	O
saw	O
this	O
as	O
an	O
explanation	O
in	O
a	O
previous	O
answer	O
somewhere	O
...	O

Oops	O
didn't	O
see	O
this	O
answer	O
was	O
the	O
first	O
.	O

Great	O
I	O
should	O
have	O
thought	O
of	O
using	O
apply	O
.	O

I	O
ended	O
up	O
having	O
a	O
few	O
issues	O
with	O
integers	O
and	O
special	O
character	O
(	O
like	O
spanish	O
letters	O
)	O
.	O

The	O
answer	O
bellow	O
solves	O
my	O
issue	O
with	O
integers	O
but	O
waiting	O
for	O
an	O
answer	O
on	O
how	O
to	O
deal	O
with	O
special	O
characters	O
like	O
`	O
u	O
'	O
\xf3	O
'`	O
.	O

We	O
then	O
apply	O
another	O
function	O
to	O
this	O
that	O
converts	O
the	O
str	O
numbers	O
to	O
ints	O
,	O
puts	O
these	O
in	O
a	O
list	O
and	O
returns	O
the	O
smallest	O
value	O
:	O
#CODE	O

Thanks	O
!	O

this	O
is	O
an	O
approach	O
that	O
I	O
hadn't	O
thought	O
about	O
and	O
one	O
that	O
I'm	O
likely	O
to	O
employ	O
down	O
the	O
road	O
.	O
for	O
age	O
,	O
I	O
wanted	O
the	O
series	O
[	O
62	O
,	O
55	O
,	O
67	O
]	O
at	O
the	O
end	O
,	O
and	O
the	O
problem	O
I'm	O
having	O
now	O
is	O
that	O
I	O
can't	O
target	O
just	O
row2	O
when	O
I	O
apply	O
split	O
(	O
'	O
')	O
.	O

I	O
can't	O
pick	O
the	O
values	O
from	O
the	O
list	O
based	O
on	O
min	O
and	O
max	O
because	O
the	O
expression	O
format	O
from	O
which	O
they	O
came	O
matters	O
(	O
I	O
think	O
it's	O
not	O
very	O
clear	O
from	O
the	O
examples	O
I	O
gave	O
for	O
sake	O
of	O
simplicity	O
)	O
.	O

I	O
want	O
to	O
apply	O
df	O
[	O
'	O
age	O
']	O
=d	O
f	O
[	O
'	O
e0	O
']	O
[(	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
str	O
(	O
x	O
)	O
.split	B-API
(	O
'	O
')	O
[	O
1	O
])	O
to	O
only	O
rows	O
for	O
which	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)	O
so	O
as	O
to	O
not	O
overwrite	O
what	O
was	O
already	O
in	O
the	O
age	O
column	O
...	O

If	O
you	O
make	O
these	O
a	O
list	O
you	O
can	O
apply	O
loc	O
(	O
which	O
gets	O
you	O
the	O
desired	O
result	O
):	O
#CODE	O

You	O
could	O
use	O
`	O
apply	O
`	O
like	O
this	O
:	O
#CODE	O

Surprisingly	O
,	O
applying	O
`	O
str	O
`	O
seem	O
to	O
be	O
taking	O
longer	O
than	O
`	O
apply	O
`	O
:	O
#CODE	O

Alternatively	O
,	O
you	O
could	O
also	O
use	O
`	O
apply	O
`	O
#CODE	O

The	O
thing	O
that	O
I'm	O
wanting	O
to	O
do	O
is	O
take	O
the	O
actual	O
score	O
value	O
and	O
apply	O
a	O
color	O
map	O
to	O
it	O
.	O

So	O
that	O
worse	O
scores	O
are	O
more	O
blue	O
and	O
good	O
scores	O
are	O
more	O
red	O
.	O

Is	O
there	O
any	O
way	O
to	O
do	O
this	O
within	O
a	O
radviz	O
graph	O
?	O

How	O
would	O
you	O
input	O
the	O
score	O
values	O
into	O
the	O
equation	O
?	O

Summarizing	O
Dataframes	O
with	O
ambiguous	O
columns	O
with	O
apply	O
function	O

The	O
code	O
works	O
for	O
almost	O
all	O
cases	O
except	O
for	O
`	O
apply	O
`	O
functions	O
that	O
count	O
specific	O
cases	O
inside	O
a	O
column	O
:	O
#CODE	O

Is	O
there	O
a	O
way	O
to	O
incorporate	O
the	O
apply	O
function	O
into	O
the	O
dictionary	O
`	O
sumdict	O
`	O
?	O

As	O
an	O
alternative	O
,	O
you	O
can	O
create	O
`	O
gene	O
`	O
in	O
pure	O
python	O
(	O
rather	O
than	O
using	O
apply	O
):	O
#CODE	O

Apply	O
the	O
function	O
.	O

pandas	O
-	O
apply	O
UTM	O
function	O
to	O
dataframe	B-API
columns	O

I'm	O
working	O
with	O
this	O
python	O
package	O
called	O
UTM	O
,	O
which	O
converts	O
WGS84	O
coordinates	O
to	O
UTM	O
and	O
vice	O
versa	O
.	O

I	O
would	O
like	O
to	O
apply	O
this	O
function	O
to	O
a	O
pandas	O
dataframe	B-API
.	O

The	O
function	O
works	O
as	O
follows	O
:	O
#CODE	O

You	O
could	O
use	O
`	O
apply	O
`	O
method	O
over	O
the	O
columns	O
like	O

You	O
can	O
do	O
this	O
by	O
`	O
apply	O
`	O
ing	O
a	O
`	O
rolling_sum	B-API
`	O
after	O
we	O
`	O
groupby	B-API
`	O
the	O
Type	O
.	O

For	O
example	O
:	O
#CODE	O

AttributeError	O
:	O
Cannot	O
access	O
attribute	O
'	O
index	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

Here's	O
on	O
approach	O
to	O
do	O
it	O
using	O
one	O
`	O
apply	O
`	O

And	O
,	O
`	O
apply	O
`	O
and	O
store	O
the	O
result	O
to	O
`	O
df	O
[[	O
'	O
hour	O
'	O
,	O
'	O
weekday	B-API
'	O
,	O
'	O
weeknum	O
']]`	O
#CODE	O

Depending	O
on	O
the	O
task	O
that	O
is	O
performed	O
by	O
`	O
lambdafun	O
`	O
,	O
you	O
may	O
get	O
some	O
speedup	O
by	O
storing	O
the	O
result	O
of	O
`	O
apply	O
`	O
in	O
a	O
new	O
`	O
DataFrame	B-API
`	O
and	O
then	O
joining	O
with	O
the	O
original	O
:	O
#CODE	O

One	O
way	O
is	O
to	O
groupby	B-API
and	O
apply	O
function	O
to	O
take	O
list	O
,	O
and	O
then	O
convert	O
to	O
dict	O
.	O

#CODE	O

Pandas	O
dataframe	B-API
apply	O
function	O

3	O
)	O
How	O
to	O
use	O
apply	O
function	O
on	O
the	O
above	O
dataframe	B-API
`	O
temp	O
`	O
?	O

Then	O
`	O
apply	O
`	O
lambda	O
function	O
.	O

#CODE	O

It's	O
not	O
the	O
most	O
elegant	O
,	O
but	O
life	O
is	O
short	O
,	O
so	O
I'd	O
apply	O
`	O
list	O
`	O
to	O
get	O
the	O
values	O
and	O
then	O
`	O
pd.Series	B-API
`	O
to	O
expand	O
them	O
into	O
columns	O
:	O
#CODE	O

Thanks	O
.	O

Is	O
there	O
a	O
way	O
I	O
can	O
apply	O
this	O
to	O
all	O
values	O
in	O
a	O
column	O
?	O

Then	O
I	O
want	O
to	O
save	O
that	O
factorization	O
and	O
apply	O
it	O
to	O
other	O
`	O
DataFrame	B-API
`	O
(	O
look	O
input	O
doesn't	O
have	O
c	O
values	O
in	O
column	O
A	O
):	O

As	O
wroted	O
in	O
the	O
question	O
-	O
I	O
know	O
about	O
`	O
get_dummies	B-API
`	O
-	O
but	O
this	O
doesn't	O
resolve	O
my	O
problem	O
to	O
apply	O
the	O
same	O
mapping	O
to	O
the	O
other	O
series	O
object	O
.	O

You	O
don't	O
need	O
to	O
use	O
`	O
map	O
`	O
on	O
columns	O
-	O
`	O
get_dummies	B-API
`	O
have	O
an	O
optional	O
parameter	O
`	O
prefix	O
`	O

(	O
Although	O
this	O
doesn't	O
apply	O
to	O
the	O
question	O
,	O
it	O
may	O
help	O
someone	O
searching	O
later	O
:	O
If	O
you're	O
using	O
Python	O
2.x	O
,	O
make	O
sure	O
to	O
explicitly	O
use	O
pickle	O
format	O
2	O
;	O
IIRC	O
,	O
NumPy	O
is	O
very	O
bad	O
at	O
the	O
default	O
pickle	O
format	O
0	O
.	O
In	O
Python	O
3.0	O
+	O
,	O
this	O
isn't	O
relevant	O
,	O
because	O
the	O
default	O
format	O
is	O
at	O
least	O
3	O
.	O
)	O

Apply	O
function	O
with	O
pandas	O
dataframe	B-API
-	O
POS	O
tagger	O
computation	O
time	O

I'm	O
very	O
confused	O
on	O
the	O
apply	O
function	O
for	O
pandas	O
.	O

I	O
have	O
a	O
big	O
dataframe	B-API
where	O
one	O
column	O
is	O
a	O
column	O
of	O
strings	O
.	O

I'm	O
then	O
using	O
a	O
function	O
to	O
count	O
part-of-speech	O
occurrences	O
.	O

I'm	O
just	O
not	O
sure	O
the	O
way	O
of	O
setting	O
up	O
my	O
apply	O
statement	O
or	O
my	O
function	O
.	O

#CODE	O

So	O
basically	O
I	O
have	O
a	O
function	O
similar	O
to	O
the	O
above	O
where	O
I	O
use	O
a	O
POS	O
tagger	O
on	O
a	O
column	O
that	O
outputs	O
a	O
single	O
number	O
(	O
number	O
of	O
nouns	O
)	O
.	O

I	O
may	O
possibly	O
rewrite	O
it	O
to	O
output	O
multiple	O
numbers	O
for	O
different	O
parts	O
of	O
speech	O
,	O
but	O
I	O
can't	O
wrap	O
my	O
head	O
around	O
`	O
apply	O
`	O
.	O

I'm	O
pretty	O
sure	O
I	O
don't	O
really	O
have	O
either	O
part	O
arranged	O
correctly	O
.	O

For	O
instance	O
,	O
I	O
can	O
run	O
`	O
noun_count	O
[	O
row	O
]`	O
and	O
get	O
the	O
correct	O
value	O
for	O
any	O
index	O
but	O
I	O
can't	O
figure	O
out	O
how	O
to	O
make	O
it	O
work	O
with	O
apply	O
how	O
I	O
have	O
it	O
set	O
up	O
.	O

Basically	O
I	O
don't	O
know	O
how	O
to	O
pass	O
the	O
row	O
value	O
to	O
the	O
function	O
within	O
the	O
apply	O
statement	O
.	O

#CODE	O

How	O
do	O
I	O
apply	O
a	O
function	O
designed	O
for	O
one	O
number	O
to	O
an	O
entire	O
dataframe	B-API
in	O
pandas	O
?	O

Seems	O
like	O
there	O
might	O
be	O
an	O
easier	O
way	O
but	O
this	O
isn't	O
too	O
bad	O
.	O

Mostly	O
the	O
work	O
is	O
done	O
by	O
`	O
reindex	O
`	O
but	O
I	O
had	O
to	O
loop	O
with	O
a	O
groupby	B-API
rather	O
than	O
apply	O
directly	O
due	O
to	O
the	O
index	O
not	O
being	O
unique	O
.	O

#CODE	O

What	O
should	O
I	O
use	O
if	O
I	O
want	O
to	O
update	O
`	O
some_series	O
`	O
in	O
place	O
from	O
`	O
other_series	O
`	O
,	O
but	O
also	O
have	O
the	O
NA	O
values	O
apply	O
?	O

The	O
reason	O
I'm	O
not	O
sure	O
if	O
this	O
is	O
the	O
best	O
way	O
is	O
because	O
`	O
apply	O
`	O
tends	O
to	O
be	O
slow	O
.	O

Something	O
like	O
#CODE	O

maybe	O
show	O
a	O
timeit	O
for	O
apply	O
vs	O
using	O
the	O
str	O
ops	O
:)	O

Series	O
(	O
and	O
dictionaries	O
)	O
can	O
be	O
used	O
just	O
like	O
functions	O
with	O
map	O
and	O
apply	O
:	O
#CODE	O

Ok	O
,	O
from	O
what	O
I	O
understand	O
,	O
the	O
problem	O
at	O
its	O
most	O
simple	O
is	O
that	O
you	O
have	O
a	O
`	O
pd.Series	B-API
`	O
of	O
values	O
(	O
i.e.	O
`	O
a	O
[	O
"	O
key	O
"]`	O
,	O
which	O
let's	O
just	O
call	O
`	O
keys	O
`)	O
,	O
which	O
correspond	O
to	O
the	O
rows	O
of	O
a	O
`	O
pd.DataFrame	B-API
`	O
(	O
the	O
df	O
called	O
`	O
b	O
`)	O
,	O
such	O
that	O
`	O
set	O
(	O
b	O
[	O
"	O
key	O
"])	O
.issuperset	O
(	O
set	O
(	O
keys	O
))`	O
.	O

You	O
then	O
want	O
to	O
apply	O
some	O
function	O
to	O
each	O
group	O
of	O
rows	O
in	O
`	O
b	O
`	O
where	O
the	O
`	O
b	O
[	O
"	O
key	O
"]`	O
is	O
one	O
of	O
the	O
values	O
in	O
`	O
keys	O
`	O
.	O

There	O
are	O
a	O
few	O
built	O
in	O
methods	O
on	O
the	O
`	O
groupby	B-API
`	O
object	O
that	O
are	O
useful	O
.	O

For	O
example	O
,	O
check	O
out	O
`	O
valid_rows.groupby	O
(	O
"	O
key	O
")	O
.sum()	B-API
`	O
or	O
`	O
valid_rows.groupby	O
(	O
"	O
key	O
")	O
.describe()	B-API
`	O
.	O

Under	O
the	O
covers	O
,	O
these	O
are	O
really	O
similar	O
uses	O
of	O
`	O
apply	O
`	O
.	O

The	O
shape	O
of	O
the	O
returned	O
`	O
summary	O
`	O
is	O
determined	O
by	O
the	O
applied	O
function	O
.	O

The	O
unique	O
grouped-by	O
values	O
--	O
those	O
of	O
`	O
b	O
[	O
"	O
key	O
"]`	O
--	O
always	O
constitute	O
the	O
index	O
,	O
but	O
if	O
the	O
applied	O
function	O
returns	O
a	O
scalar	O
,	O
`	O
summary	O
`	O
is	O
a	O
`	O
Series	O
`	O
;	O
if	O
the	O
applied	O
function	O
returns	O
a	O
`	O
Series	O
`	O
,	O
then	O
`	O
summary	O
`	O
constituted	O
of	O
the	O
return	O
`	O
Series	O
`	O
as	O
rows	O
;	O
if	O
the	O
applied	O
function	O
returns	O
a	O
`	O
DataFrame	B-API
`	O
,	O
then	O
the	O
result	O
is	O
a	O
multiindex	O
`	O
DataFrame	B-API
`	O
.	O

This	O
is	O
a	O
core	O
pattern	O
in	O
Pandas	O
,	O
and	O
there's	O
a	O
whole	O
,	O
whole	O
lot	O
to	O
explore	O
here	O
.	O

How	O
do	O
you	O
check	O
a	O
condition	O
of	O
several	O
pandas	O
DataFrame.Series	O
element-wise	O
and	O
apply	O
the	O
result	O
to	O
a	O
new	O
column	O
?	O

I	O
have	O
managed	O
to	O
do	O
this	O
,	O
but	O
it's	O
slower	O
than	O
I	O
would	O
like	O
(	O
takes	O
2	O
mins	O
for	O
a	O
single	O
60mb	O
file	O
;	O
mostly	O
in	O
the	O
apply	O
part	O
as	O
seen	O
below	O
)	O
and	O
I'm	O
thinking	O
that	O
there	O
must	O
be	O
a	O
better	O
way	O
of	O
doing	O
it	O

There	O
is	O
no	O
`	O
str	O
`	O
accessor	O
for	O
datetimes	O
and	O
you	O
can't	O
do	O
`	O
dates.astype	O
(	O
str	O
)`	O
either	O
,	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
use	O
`	O
datetime.strftime	O
`	O
:	O
#CODE	O

To	O
apply	O
the	O
same	O
condition	O
to	O
to	O
dozens	O
of	O
columns	O
I	O
could	O
use	O
`	O
isin	B-API
`	O
,	O
but	O
it	O
seems	O
not	O
to	O
work	O
if	O
I	O
need	O
to	O
substitute	O
`'	O
first	O
'`	O
with	O
a	O
regex	O
,	O
as	O
in	O
`	O
regex	O
=	O
'	O
(	O
?	O
=	O
.	O
*first	O
)	O
(	O
?	O
=	O
.	O
*second	O
)'`	O
.	O

Why	O
don't	O
we	O
use	O
`	O
applymap	B-API
`	O
on	O
the	O
entire	O
data	O
frame	O
.	O

This	O
will	O
be	O
different	O
than	O
working	O
the	O
columns	O
but	O
would	O
make	O
it	O
easier	O
for	O
your	O
to	O
apply	O
if-else	O
conditions	O
to	O
(	O
I	O
hope	O
):	O
#CODE	O

The	O
whole	O
point	O
of	O
`	O
applymap	B-API
`	O
is	O
that	O
you	O
can	O
apply	O
a	O
function	O
on	O
every	O
cell	O
of	O
the	O
data	O
frame	O
.	O

So	O
,	O
I	O
think	O
your	O
two	O
drawbacks	O
are	O
covered	O
if	O
you	O
expand	O
the	O
function	O
further	O
.	O

Need	O
help	O
with	O
that	O
?	O

But	O
how	O
do	O
I	O
apply	O
this	O
function	O
on	O
each	O
element	O
of	O
a	O
pandas	O
data	O
frame	O
?	O

Pass	O
the	O
`	O
hash	O
`	O
function	O
to	O
`	O
apply	O
`	O
on	O
the	O
`	O
str	O
`	O
column	O
:	O
#CODE	O

I	O
then	O
try	O
using	O
apply	O
to	O
run	O
it	O
on	O
a	O
dataframe	B-API
to	O
create	O
a	O
new	O
column	O
.	O

#CODE	O

For	O
a	O
start	O
there	O
is	O
a	O
built	O
in	O
`	O
str.split()	B-API
`	O
which	O
is	O
vectorised	O
so	O
you	O
could	O
eliminate	O
that	O
from	O
your	O
code	O
so	O
`	O
df	O
[	O
'	O
word_split	O
']	O
=	O
df	O
[	O
'	O
string	O
']	O
.str	B-API
.split()	B-API
`	O
and	O
then	O
call	O
apply	O
on	O
this	O
column	O
and	O
change	O
your	O
line	O
in	O
your	O
func	O
to	O
this	O
`	O
listoflists	O
=	O
st.tag	O
(	O
x	O
)`	O

You	O
could	O
iterate	O
through	O
them	O
and	O
apply	O
the	O
`	O
to_datetime	B-API
`	O
function	O
OR	O

It's	O
generally	O
expensive	O
to	O
do	O
it	O
this	O
way	O
,	O
as	O
you're	O
losing	O
the	O
vector	O
speed	O
advantage	O
when	O
you	O
`	O
apply	O
`	O
a	O
user	O
defined	O
function	O
.	O

Instead	O
,	O
how	O
about	O
using	O
the	O
numpy	O
version	O
of	O
the	O
ternary	O
operator	O
:	O
#CODE	O

I	O
have	O
long	O
list	O
of	O
date	O
in	O
dataframe	B-API
that	O
need	O
to	O
be	O
converted	O
into	O
datetime	O
,	O
the	O
date	O
is	O
in	O
the	O
form	O
"	O
%d%m%Y	O
"	O
,	O
and	O
I	O
apply	O
`	O
datetime.strptime	O
(	O
x	O
,	O
'	O
%d%m%Y	O
')`	O
,	O
which	O
works	O
fine	O
until	O
meet	O
the	O
date	O
"	O
3122012	O
"	O
,	O
which	O
should	O
be	O
datetime.datetime	O
(	O
2012	O
,	O
12	O
,	O
3	O
,	O
0	O
,	O
0	O
)	O
,	O
but	O
instead	O
it	O
throw	O
the	O
error	O
message	O
:	O
#CODE	O

This	O
type	O
of	O
thing	O
always	O
feels	O
somewhat	O
clunky	O
to	O
me	O
.	O

Is	O
there	O
a	O
preferred	O
way	O
to	O
apply	O
a	O
function	O
to	O
only	O
the	O
nonnull	O
rows	O
of	O
a	O
column	O
?	O

Thank	O
you	O
for	O
this	O
,	O
I	O
had	O
initially	O
tried	O
something	O
like	O
this	O
but	O
didn't	O
realise	O
that	O
you	O
only	O
have	O
to	O
apply	O
the	O
filter	O
on	O
the	O
RHS	O
of	O
the	O
assignment	O
and	O
not	O
the	O
LHS	O
.	O

Pandas	O
:	O
How	O
to	O
use	O
apply	O
to	O
create	O
new	O
dataframe	B-API

and	O
appy	O
that	O
function	O
using	O
apply	O
to	O
the	O
created	O
DataFrame	B-API
using	O
#CODE	O

Can	O
you	O
reconstruct	O
this	O
problem	O
?	O

Did	O
I	O
get	O
anything	O
wrong	O
regarding	O
the	O
use	O
of	O
the	O
apply	O
function	O
?	O

Because	O
you're	O
passing	O
your	O
`	O
data	O
`	O
df	O
as	O
a	O
reference	O
and	O
assigning	O
directly	O
to	O
it	O
each	O
time	O
by	O
calling	O
`	O
apply	O
`	O
in	O
your	O
func	O
then	O
it	O
overwrites	O
with	O
the	O
last	O
operation	O
:	O
#CODE	O

@USER	O
:	O
You'll	O
have	O
to	O
explain	O
what	O
you	O
mean	O
.	O

Each	O
column	O
has	O
only	O
one	O
dtype	B-API
.	O

You	O
can	O
subset	O
based	O
on	O
any	O
criterion	O
you	O
can	O
apply	O
to	O
each	O
item	O
in	O
the	O
column	O
.	O

You	O
can	O
use	O
`	O
df	O
.	O
column	O
.map	B-API
`	O
to	O
apply	O
a	O
function	O
to	O
each	O
element	O
in	O
a	O
column	O
:	O
#CODE	O

Why	O
don't	O
you	O
use	O
`	O
apply	O
`	O
and	O
on	O
a	O
modified	O
dictionary	O
lookup	O
:	O
#CODE	O

And	O
,	O
apply	O
it	O
like	O
this	O
-	O
#CODE	O

And	O
use	O
it	O
with	O
apply	O
#CODE	O

Once	O
this	O
is	O
created	O
,	O
you	O
can	O
create	O
a	O
function	O
to	O
split	O
the	O
categories	O
column	O
by	O
the	O
"	O
,	O
"	O
and	O
count	O
the	O
length	O
of	O
the	O
resulting	O
list	O
.	O

Use	O
lambda	O
and	O
apply	O
.	O

Assuming	O
that	O
Category	O
is	O
actually	O
a	O
list	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
(	O
per	O
@USER	O
'	O
s	O
suggestion	O
):	O
#CODE	O

You	O
can	O
groupy	O
the	O
'	O
ITEM	O
'	O
and	O
'	O
CATEGORY	O
'	O
columns	O
and	O
then	O
call	O
`	O
apply	O
`	O
on	O
the	O
df	O
groupby	B-API
object	O
and	O
pass	O
the	O
function	O
`	O
mode	O
`	O
.	O

We	O
can	O
then	O
call	O
`	O
reset_index	B-API
`	O
and	O
pass	O
param	O
`	O
drop=True	O
`	O
so	O
that	O
the	O
multi-index	O
is	O
not	O
added	O
back	O
as	O
a	O
column	O
as	O
you	O
already	O
have	O
those	O
columns	O
:	O
#CODE	O

How	O
to	O
reference	O
groupby	B-API
index	O
when	O
using	O
apply	O
,	O
transform	O
,	O
agg	O
-	O
Python	O
Pandas	O
?	O

The	O
question	O
is	O
that	O
neither	O
aggregate	O
,	O
apply	O
,	O
nor	O
transform	O
can	O
reference	O
to	O
the	O
index	O
.	O

Any	O
idea	O
how	O
to	O
work	O
around	O
this	O
?	O

After	O
some	O
tinkering	O
around	O
,	O
I	O
wrote	O
a	O
function	O
that	O
can	O
be	O
used	O
with	O
the	O
`	O
apply	O
`	O
method	O
on	O
a	O
`	O
groupby	B-API
`	O
.	O

#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
extract	O
the	O
numerical	O
values	O
,	O
and	O
do	O
the	O
counting	O
there	O
:	O
#CODE	O

If	O
not	O
already	O
you	O
need	O
to	O
convert	O
to	O
datetime	O
,	O
then	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
use	O
`	O
datetime.strftime	O
`	O
to	O
do	O
the	O
formatting	O
:	O
#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

When	O
I	O
try	O
to	O
plot	O
a	O
histogram	O
,	O
I	O
apply	O
:	O
#CODE	O

But	O
indexing	O
with	O
your	O
boolean	O
can't	O
be	O
summarized	O
in	O
those	O
few	O
numbers	O
.	O

Either	O
it	O
has	O
to	O
carry	O
the	O
`	O
index	O
`	O
array	O
all	O
the	O
way	O
through	O
,	O
or	O
copy	O
selected	O
items	O
from	O
the	O
`	O
x	O
`	O
data	O
buffer	O
.	O

`	O
numpy	O
`	O
chooses	O
to	O
copy	O
.	O

You	O
have	O
choice	O
of	O
when	O
to	O
apply	O
the	O
`	O
index	O
`	O
,	O
now	O
or	O
further	O
down	O
the	O
calling	O
stack	O
.	O

I	O
also	O
tried	O
with	O
apply	O
and	O
I	O
think	O
it	O
works	O
,	O
but	O
I	O
need	O
to	O
reset	O
the	O
index	O
,	O
which	O
is	O
something	O
I'd	O
rather	O
avoid	O
(	O
I	O
have	O
a	O
large	O
dataset	O
and	O
I	O
need	O
to	O
do	O
this	O
repeatedly	O
)	O
#CODE	O

Trying	O
to	O
create	O
a	O
new	O
column	O
with	O
the	O
groupby	B-API
calculation	O
.	O

In	O
the	O
code	O
below	O
,	O
I	O
get	O
the	O
correct	O
calculated	O
values	O
for	O
each	O
date	O
(	O
see	O
group	O
below	O
)	O
but	O
when	O
I	O
try	O
to	O
create	O
a	O
new	O
column	O
(	O
df	O
[	O
'	O
Data4	O
'])	O
with	O
it	O
I	O
get	O
NaN	O
.	O

So	O
I	O
am	O
trying	O
to	O
create	O
a	O
new	O
column	O
in	O
the	O
dataframe	B-API
with	O
the	O
sum	O
of	O
'	O
Data3	O
'	O
for	O
the	O
all	O
dates	O
and	O
apply	O
that	O
to	O
each	O
date	O
row	O
.	O

For	O
example	O
,	O
2015-05-08	O
is	O
in	O
2	O
rows	O
(	O
total	O
is	O
50+5	O
=	O
55	O
)	O
and	O
in	O
this	O
new	O
column	O
I	O
would	O
like	O
to	O
have	O
55	O
in	O
both	O
of	O
the	O
rows	O
.	O

#CODE	O

Pandas	O
groupby	B-API
:	O
apply	O
vs	O
agggregate	O
with	O
missing	O
categories	O

I'm	O
running	O
into	O
an	O
issue	O
where	O
panda's	O
`	O
GroupBy.apply	B-API
`	O
and	O
`	O
GroupBy.aggregate	B-API
`	O
give	O
different-shaped	O
results	O
when	O
categorical	B-API
data	O
has	O
missing	O
values	O
.	O

`	O
aggregate	O
`	O
retains	O
all	O
"	O
known	O
"	O
categories	O
,	O
but	O
`	O
apply	O
`	O
only	O
keeps	O
the	O
categories	O
that	O
are	O
present	O
in	O
the	O
data	O
.	O

Note	O
that	O
the	O
last	O
data	O
frame	O
is	O
missing	O
the	O
`	O
NaN	O
`	O
rows	O
where	O
`	O
missing	O
=	O
b	O
`	O
.	O

I	O
understand	O
why	O
`	O
apply	O
`	O
might	O
do	O
this	O
(	O
it	O
chooses	O
not	O
to	O
pass	O
a	O
group	O
full	O
of	O
`	O
NaN	O
`	O
s	O
to	O
the	O
reduction	O
function	O
)	O
.	O

The	O
above	O
snippet	O
is	O
just	O
a	O
toy	O
example	O
:	O
I	O
actually	O
need	O
to	O
use	O
`	O
apply	O
`	O
to	O
get	O
the	O
result	O
I	O
want	O
.	O

Question	O
:	O
What's	O
the	O
best	O
way	O
to	O
use	O
`	O
apply	O
`	O
but	O
create	O
an	O
output	O
shape	O
matching	O
the	O
one	O
returned	O
by	O
`	O
aggregate	O
`	O
?	O

Here's	O
a	O
fairly	O
general	O
solution	O
you	O
can	O
apply	O
to	O
multiple	O
columns	O
.	O

The	O
'	O
To	O
'	O
column	O
doesn't	O
need	O
to	O
be	O
rounded	O
,	O
I	O
just	O
included	O
it	O
for	O
the	O
generality	O
of	O
two	O
columns	O
rather	O
than	O
one	O
:	O
#CODE	O

Use	O
this	O
`	O
func	O
`	O
and	O
apply	O
over	O
the	O
the	O
`	O
dff.groupby	O
(	O
'	O
Group	O
')`	O
#CODE	O

With	O
the	O
`	O
func	O
`	O
function	O
you	O
wrote	O
in	O
your	O
updated	O
answer	O
(	O
i.e.	O
your	O
solution	O
)	O
,	O
you	O
should	O
be	O
able	O
to	O
use	O
the	O
`	O
DataFrame.apply	B-API
`	O
method	O
with	O
parameter	O
`	O
axis=1	O
`	O
.	O

(	O
I	O
haven't	O
tested	O
it	O
,	O
but	O
perhaps	O
you	O
could	O
try	O
to	O
apply	O
it	O
and	O
report	O
the	O
error	O
message	O
,	O
if	O
any	O
)	O

The	O
key	O
to	O
this	O
answer	O
is	O
that	O
the	O
`	O
apply	O
`	O
method	O
accepts	O
arbitrary	O
positional	O
keyword	O
arguments	O
and	O
passes	O
them	O
to	O
the	O
function	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
with	O
option	O
`	O
axis=1	O
`	O
.	O

Then	O
your	O
solution	O
is	O
pretty	O
concise	O
.	O

#CODE	O

How	O
to	O
apply	O
Cython	O
to	O
Pandas	O
DataFrame	B-API

After	O
reading	O
the	O
whole	O
Dataframe	B-API
,	O
I	O
tried	O
to	O
apply	O
function	O
on	O
one	O
Serie	O
:	O
#CODE	O

While	O
doing	O
preprocessing	O
of	O
data	O
,	O
I	O
first	O
try	O
to	O
remove	O
all	O
the	O
punctuations	O
and	O
also	O
the	O
most	O
common	O
stop	O
words	O
.	O

After	O
doing	O
that	O
,	O
I	O
want	O
to	O
apply	O
the	O
Porter	O
Stemming	O
algorithm	O
which	O
is	O
readily	O
available	O
in	O
nltk.stem	O
.	O

You	O
could	O
`	O
apply	O
`	O
and	O
construct	O
the	O
datetime	O
using	O
your	O
desired	O
date	O
values	O
and	O
then	O
copying	O
the	O
time	O
portion	O
to	O
the	O
constructor	O
:	O
#CODE	O

Use	O
the	O
`	O
apply	O
`	O
method	O
.	O

#CODE	O

With	O
Pandas	O
it's	O
often	O
a	O
good	O
idea	O
to	O
try	O
and	O
use	O
`	O
apply	O
`	O
together	O
with	O
an	O
anonymous	O
function	O
to	O
perform	O
your	O
calculation	O
on	O
every	O
row	O
.	O

Does	O
this	O
work	O
for	O
you	O
?	O

:	O
#CODE	O

@USER	O
The	O
problem	O
is	O
that	O
the	O
`	O
ExcelWriter	O
`	O
isn't	O
created	O
by	O
`	O
pd.ExcelWriter()	O
`	O
,	O
but	O
through	O
`	O
xlsxwriter.Workbook()	O
`	O
to	O
just	O
write	O
some	O
arbitrary	O
(	O
non-pandas	O
)	O
data	O
.	O

Unfortunately	O
,	O
the	O
approach	O
from	O
your	O
link	O
doesn't	O
apply	O
here	O
.	O

when	O
you	O
open	O
csv	O
file	O
from	O
excel	O
,	O
it	O
will	O
convert	O
your	O
data	O
to	O
any	O
type	O
it	O
should	O
be	O
in	O
this	O
case	O
your	O
data	O
converted	O
to	O
date	O
type	O
then	O
excel	O
apply	O
default	O
date	O
format	O
to	O
that	O
data	O
.	O

Also	O
,	O
you	O
can't	O
control	O
the	O
date	O
format	O
of	O
excel	O
file	O
since	O
csv	O
files	O
is	O
only	O
a	O
text	O
file	O
,	O
no	O
meta	O
or	O
hidden	O
data	O
to	O
advise	O
excel	O
to	O
proceed	O
.	O

Using	O
`	O
apply	O
`	O

You	O
could	O
use	O
`	O
pandas	O
`'	O
s	O
`	O
apply	O
`	O
for	O
this	O
.	O

#CODE	O

How	O
can	O
I	O
now	O
apply	O
this	O
test	O
on	O
a	O
slice	O
of	O
the	O
dataframe	B-API
?	O

#CODE	O

Hi	O
@USER	O
!	O

Thanks	O
for	O
your	O
help	O
.	O

I	O
upvoted	O
your	O
answer	O
because	O
it	O
was	O
helping	O
me	O
getting	O
the	O
job	O
done	O
.	O

Thanks	O
a	O
lot	O
for	O
it	O
!	O

I	O
am	O
not	O
sure	O
whether	O
it	O
is	O
really	O
the	O
answer	O
to	O
my	O
question	O
,	O
though	O
(	O
How	O
to	O
apply	O
the	O
test	O
to	O
the	O
dataframe	B-API
)	O
.	O

Perhaps	O
someone	O
else	O
can	O
answer	O
that	O
question	O
?	O

One	O
follow-up	O
question	O
:	O
while	O
this	O
works	O
great	O
for	O
"	O
year	O
"	O
,	O
I	O
would	O
like	O
to	O
do	O
a	O
similar	O
thing	O
for	O
"	O
yearmonth	O
"	O
,	O
i.e.	O
a	O
combination	O
of	O
YYYYMM	O
values	O
(	O
so	O
that	O
each	O
month	O
of	O
each	O
year	O
gets	O
a	O
specific	O
label	O
)	O
,	O
As	O
there	O
is	O
no	O
attribute	O
to	O
directly	O
extract	O
"	O
yearmonth	O
"	O
from	O
index	O
,	O
what	O
can	O
I	O
do	O
in	O
this	O
case	O
?	O

Could	O
I	O
define	O
a	O
lambda	O
function	O
and	O
apply	O
this	O
to	O
the	O
index	O
values	O
,	O
for	O
example	O
?	O

How	O
to	O
avoid	O
return	O
twice	O
the	O
first	O
groupby	B-API
object	O
after	O
to	O
apply	O
it	O
in	O
other	O
function	O
?	O

In	O
this	O
case	O
,	O
I'm	O
just	O
printing	O
,	O
but	O
python	O
return	O
the	O
first	O
group	O
twice	O
(	O
see	O
'	O
word	O
'	O
=	O
'	O
a	O
')	O
.	O

This	O
occur	O
with	O
other	O
function	O
more	O
elaborated	O
too	O
.	O

Why	O
?	O

There	O
are	O
any	O
solution	O
for	O
this	O
?	O

I	O
would	O
continue	O
to	O
use	O
DataFrame()	B-API
+	O
groupby()	B-API
+	O
apply()	B-API
+	O
def	O
f()	B-API
if	O
possible	O
.	O

You	O
need	O
to	O
avoid	O
for-loops	O
and	O
use	O
the	O
'	O
apply	O
'	O
methods	O
.	O

See	O
#URL	O

but	O
when	O
I	O
try	O
to	O
write	O
a	O
function	O
in	O
pandas	O
to	O
apply	O
this	O
to	O
every	O
cell	O
of	O
a	O
column	O
,	O
it	O
either	O
fails	O
because	O
of	O
an	O
attribute	O
error	O
or	O
I	O
get	O
a	O
warning	O
that	O
a	O
value	O
is	O
trying	O
to	O
be	O
set	O
on	O
a	O
copy	O
of	O
a	O
slice	O
from	O
a	O
DataFrame	B-API
#CODE	O

how	O
can	O
I	O
apply	O
this	O
code	O
to	O
each	O
element	O
of	O
a	O
Series	O
?	O

The	O
problem	O
seems	O
like	O
you	O
are	O
trying	O
to	O
access	O
and	O
alter	O
`	O
row	O
[	O
'	O
text	O
']`	O
and	O
return	O
the	O
row	O
itself	O
when	O
doing	O
the	O
apply	O
function	O
,	O
when	O
you	O
do	O
`	O
apply	O
`	O
on	O
a	O
`	O
DataFrame	B-API
`	O
,	O
it's	O
applying	O
to	O
each	O
Series	O
,	O
so	O
if	O
changed	O
to	O
this	O
should	O
help	O
:	O
#CODE	O

Alternatively	O
you	O
might	O
use	O
`	O
lambda	O
`	O
as	O
below	O
,	O
and	O
directly	O
apply	O
to	O
only	O
`	O
text	O
`	O
column	O
:	O
#CODE	O

You	O
can	O
apply	O
on	O
`	O
df.groupby	B-API
(	O
'	O
Sym	O
')	O
[	O
'	O
close	O
']`	O
using	O
`	O
pd.rolling_max	B-API
(	O
x	O
,	O
2	O
)`	O
instead	O
#CODE	O

We	O
do	O
it	O
with	O
an	O
apply	O
on	O
axis=1	O
::	O
#CODE	O

Well	O
this	O
works	O
`	O
df.assign	B-API
(	O
ts4=	O
np.where	B-API
(	O
df.a	O
*	O
df.b	O
-	O
df.c	O
>	O
1	O
,	O
'	O
XS	B-API
'	O
,	O
'	O
L	O
'))`	O
,	O
the	O
problem	O
with	O
expression	O
`	O
ts4=lambda	O
x	O
:	O
'	O
XS	B-API
'	O
if	O
x.a	O
*	O
x.b	O
-	O
x.c	O
>	O
1	O
else	O
'	O
L	O
'`	O
is	O
that	O
it	O
wonly	O
works	O
in	O
the	O
apply	O
because	O
you're	O
using	O
`	O
axis=1	O
`	O
so	O
you're	O
comparing	O
single	O
scalar	O
values	O
,	O
your	O
expression	O
isn't	O
so	O
it's	O
not	O
valid	O

What	O
I	O
am	O
hoping	O
to	O
achieve	O
,	O
is	O
to	O
apply	O
the	O
logic	O
of	O
`	O
conditions	O
`	O
to	O
`	O
indicators	O
`	O
in	O
order	O
to	O
produce	O
a	O
new	O
dataframe	B-API
called	O
`	O
signals	O
`	O
.	O

To	O
give	O
you	O
an	O
idea	O
of	O
what	O
I'm	O
looking	O
for	O
,	O
see	O
below	O
.	O

This	O
looks	O
only	O
at	O
the	O
first	O
condition	O
in	O
`	O
conditions	O
`	O
and	O
the	O
fifth	O
value	O
in	O
`	O
indicator	O
`	O
(	O
because	O
it	O
evaluates	O
to	O
True	O
):	O
#CODE	O

Just	O
define	O
a	O
function	O
that	O
fits	O
your	O
needs	O
then	O
apply	O
it	O
.	O

It	O
can	O
be	O
quite	O
complicated	O
as	O
well	O
:	O
#CODE	O

This	O
would	O
apply	O
the	O
desired	O
operation	O
to	O
all	O
the	O
rows	O
and	O
is	O
considerably	O
faster	O

This	O
gives	O
`	O
AttributeError	O
:	O
'	O
list	O
'	O
object	O
has	O
no	O
attribute	O
'	O
apply	O
'`	O

Use	O
`	O
apply	O
`	O
and	O
pass	O
your	O
func	O
to	O
it	O
:	O
#CODE	O

The	O
correct	O
way	O
as	O
EdChum	O
pointed	O
out	O
is	O
to	O
use	O
`	O
apply	O
`	O
on	O
the	O
'	O
location	O
'	O
column	O
.	O

You	O
could	O
compress	O
that	O
code	O
in	O
one	O
line	O
:	O
#CODE	O

I	O
then	O
apply	O
the	O
following	O
filter	O
to	O
`	O
ORD_ticks	O
`	O
to	O
get	O
`	O
ORD_prices	O
`	O
:	O
#CODE	O

possible	O
duplicate	O
of	O
[	O
Parallelize	O
apply	O
after	O
pandas	O
groupby	B-API
]	O
(	O
#URL	O
)	O

No	O
it	O
won't	O
see	O
my	O
edit	O
,	O
when	O
you	O
call	O
`	O
dropna()	B-API
`	O
on	O
a	O
series	O
(	O
which	O
is	O
what	O
we're	O
doing	O
here	O
when	O
calling	O
`	O
apply	O
`	O
on	O
a	O
df	O
)	O
it	O
drops	O
an	O
entry	O
in	O
the	O
series	O
not	O
an	O
entire	O
row	O

For	O
the	O
expanding	O
product	O
,	O
there's	O
`	O
cumprod()	B-API
`	O
.	O

For	O
the	O
rolling	O
version	O
,	O
I	O
think	O
you'll	O
have	O
to	O
use	O
`	O
rolling_apply	B-API
`	O
to	O
apply	O
`	O
prod()	B-API
`	O
to	O
each	O
window	O
.	O

Hello	O
.	O

Great	O
:	O
adopted	O
to	O
the	O
"	O
real	O
"	O
dataframe	B-API
where	O
I	O
have	O
to	O
apply	O
this	O
loop	O
,	O
it	O
worked	O
out	O
perfectly	O
!	O

To	O
groupby	B-API
w.r.t	O
the	O
first	O
groupby	B-API
object	O
in	O
that	O
way	O
is	O
something	O
I	O
should	O
have	O
figured	O
out	O
myself	O
.	O

Apologize	O
for	O
my	O
ignorance	O
;-)	O

I	O
normally	O
use	O
`	O
apply	O
`	O
for	O
this	O
kind	O
of	O
thing	O
;	O
it's	O
basically	O
the	O
DataFrame	B-API
version	O
of	O
map	O
(	O
the	O
axis	O
parameter	O
lets	O
you	O
decide	O
whether	O
to	O
apply	O
your	O
function	O
to	O
rows	O
or	O
columns	O
):	O
#CODE	O

To	O
do	O
that	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
.	O

However	O
,	O
instead	O
of	O
being	O
called	O
with	O
three	O
separate	O
arguments	O
(	O
one	O
for	O
each	O
column	O
)	O
your	O
specified	O
function	O
will	O
then	O
be	O
called	O
with	O
a	O
single	O
argument	O
for	O
each	O
row	O
,	O
and	O
that	O
argument	O
will	O
be	O
a	O
Series	O
containing	O
the	O
data	O
for	O
that	O
row	O
.	O

You	O
can	O
either	O
account	O
for	O
this	O
in	O
your	O
function	O
:	O
#CODE	O

Note	O
the	O
double	O
brackets	O
.	O

(	O
This	O
doesn't	O
really	O
have	O
anything	O
to	O
do	O
with	O
`	O
apply	O
`	O
;	O
indexing	O
with	O
a	O
list	O
is	O
the	O
normal	O
way	O
to	O
access	O
multiple	O
columns	O
from	O
a	O
DataFrame	B-API
.	O
)	O

However	O
,	O
it's	O
important	O
to	O
note	O
that	O
in	O
many	O
cases	O
you	O
don't	O
need	O
to	O
use	O
`	O
apply	O
`	O
,	O
because	O
you	O
can	O
just	O
use	O
vectorized	O
operations	O
on	O
the	O
columns	O
themselves	O
.	O

The	O
`	O
combine	O
`	O
function	O
above	O
can	O
simply	O
be	O
called	O
with	O
the	O
DataFrame	B-API
columns	O
themselves	O
as	O
the	O
arguments	O
:	O
#CODE	O

As	O
above	O
,	O
there	O
are	O
two	O
basic	O
ways	O
to	O
do	O
this	O
:	O
a	O
general	O
but	O
non-vectorized	O
way	O
using	O
`	O
apply	O
`	O
,	O
and	O
a	O
faster	O
vectorized	O
way	O
.	O

Suppose	O
you	O
have	O
a	O
DataFrame	B-API
like	O
this	O
:	O
#CODE	O

You	O
can	O
define	O
a	O
function	O
that	O
returns	O
a	O
Series	O
for	O
each	O
value	O
,	O
and	O
then	O
`	O
apply	O
`	O
it	O
to	O
the	O
column	O
:	O
#CODE	O

data	O
=	O
ascii.read	O
(	O
table	O
)	O
(	O
and	O
apply	O
the	O
formatters	O
)	O

Id	O
assume	O
you	O
want	O
to	O
keep	O
the	O
mapping	O
dictionaries	O
around	O
for	O
later	O
use	O
,	O
which	O
you	O
would	O
loose	O
with	O
function	O
calls	O
..	O

But	O
that	O
depends	O
on	O
the	O
overall	O
purpose	O
and	O
extent	O
of	O
the	O
code	O
.	O

You	O
can	O
use	O
use	O
```	O
enumerate	O
```	O
to	O
eliminate	O
the	O
need	O
to	O
have	O
the	O
```	O
u_rows	O
```	O
and	O
```	O
u_cols	O
```	O
variables	O
.	O

Also	O
,	O
you	O
can	O
apply	O
the	O
mappings	O
directly	O
in	O
the	O
argument	O
of	O
```	O
coo_matrix	O
```	O
to	O
save	O
space	O
,	O
but	O
that	O
is	O
a	O
bit	O
messy	O
.	O

The	O
series	O
produced	O
by	O
`	O
(	O
df	O
[	O
"	O
a	O
"]	O
|	O
df	O
[	O
"	O
b	O
"])`	O
is	O
of	O
type	O
`	O
bool	O
`	O
.	O

This	O
surprised	O
me	O
because	O
`	O
|	O
`	O
is	O
a	O
bitwise	O
operator	O
,	O
so	O
I	O
expected	O
the	O
series	O
to	O
be	O
of	O
type	O
`	O
int	O
`	O
.	O

Thus	O
,	O
I	O
have	O
to	O
do	O
the	O
`	O
apply	O
(	O
lambda	O
...	O
)`	O
to	O
get	O
the	O
desired	O
`	O
int	O
`	O
column	O
.	O

I	O
have	O
been	O
trying	O
with	O
a	O
function	O
and	O
apply	O
.	O
here	O
is	O
my	O
data	O
set	O
and	O
code	O
#CODE	O

An	O
alternative	O
would	O
be	O
to	O
apply	O
strip	O
to	O
the	O
columns	O
to	O
ensure	O
they	O
don't	O
have	O
leading	O
spaces	O
:	O
#CODE	O

Then	O
apply	O
`	O
maxminbid	O
`	O
function	O
on	O
`	O
Auction_id	O
`	O
grouped	O
objects	O
#CODE	O

And	O
I	O
apply	O
the	O
following	O
group-by	O
code	O
#CODE	O

This	O
is	O
on	O
a	O
Windows	O
7	O
Enterprise	O
Service	O
Pack	O
1	O
machine	O
and	O
it	O
seems	O
to	O
apply	O
to	O
every	O
CSV	O
file	O
I	O
create	O
.	O

In	O
this	O
particular	O
case	O
the	O
binary	O
from	O
location	O
55	O
is	O
00101001	O
and	O
location	O
54	O
is	O
01110011	O
,	O
if	O
that	O
matters	O
.	O

How	O
to	O
apply	O
group	O
by	O
on	O
data	O
frame	O
with	O
neglecting	O
NaN	O
values	O
in	O
Pandas	O
?	O

You	O
may	O
also	O
choose	O
to	O
use	O
`	O
map	O
`	O
instead	O
of	O
`	O
apply	O
`	O
since	O
upon	O
accessing	O
a	O
column	O
,	O
you'll	O
be	O
working	O
with	O
a	O
Series	O
object	O
.	O

works	O
great	O
thanks	O
,	O
but	O
why	O
would	O
I	O
use	O
applymap	B-API
and	O
apply	O
the	O
function	O
on	O
all	O
the	O
df	O
cells	O
,	O
there	O
is	O
different	O
types	O
of	O
data	O
and	O
all	O
other	O
stuff	O
?	O

I	O
expanded	O
a	O
bit	O
in	O
the	O
middle	O
to	O
highlight	O
why	O
simply	O
creating	O
a	O
new	O
column	O
of	O
data	O
makes	O
more	O
sense	O
here	O
than	O
using	O
`	O
join	O
`	O
.	O

On	O
the	O
other	O
part	O
,	O
note	O
that	O
I'm	O
not	O
suggesting	O
to	O
use	O
`	O
applymap	B-API
`	O
which	O
is	O
a	O
DataFrame	B-API
method	O
,	O
rather	O
to	O
use	O
plain	O
`	O
map	O
`	O
which	O
is	O
a	O
Series	O
method	O
.	O

`	O
Series.map	B-API
`	O
is	O
meant	O
specifically	O
for	O
element-wise	O
operations	O
,	O
whereas	O
`	O
apply	O
`	O
has	O
some	O
extra	O
checking	O
for	O
functions	O
that	O
can	O
vectorially	O
operate	O
on	O
the	O
whole	O
`	O
.values	B-API
`	O
data	O
object	O
in	O
one	O
go	O
.	O

You	O
can	O
use	O
any	O
function	O
within	O
the	O
`	O
apply	O
`	O
.	O

More	O
examples	O
here	O
-	O
#URL	O

df.applymap()	B-API
dont	O
apply	O
.map()	B-API
on	O
each	O
Series	O
of	O
the	O
DataFrame	B-API
,	O
put	O
map	O
.apply()	B-API
on	O
each	O
Series	O
.	O

See	O
Series	O
.apply()	B-API
here	O
:	O
[	O
link	O
]	O
(	O
#URL	O
)	O

Thanks	O
!	O

The	O
example	O
showing	O
how	O
map	O
produces	O
a	O
series	O
and	O
apply	O
produces	O
a	O
dataframe	B-API
also	O
explains	O
some	O
results	O
I'd	O
gotten	O
in	O
the	O
past	O
and	O
not	O
understood	O
.	O

My	O
understanding	O
of	O
all	O
this	O
is	O
still	O
a	O
bit	O
less	O
than	O
100%	O
,	O
but	O
this	O
helps	O
.	O

I	O
am	O
trying	O
to	O
apply	O
this	O
related	O
topic	O
[	O
Merge	O
pandas	O
DataFrames	O
based	O
on	O
irregular	O
time	O
intervals	O
]	O
by	O
adding	O
start_time	O
and	O
end_time	O
columns	O
to	O
df1	O
denoting	O
3	O
months	O
(	O
start_time	O
)	O
to	O
6	O
months	O
(	O
end_time	O
)	O
after	O
DATADATE	O
,	O
then	O
using	O
np.searchsorted()	B-API
,	O
but	O
this	O
case	O
is	O
a	O
bit	O
trickier	O
because	O
I'd	O
like	O
to	O
merge	O
on	O
a	O
company-by-company	O
basis	O
.	O

Apply	O
condition	O
of	O
opposite	O
values	O
...	O

So	O
anyone	O
who	O
wants	O
to	O
assign	O
values	O
in	O
the	O
column	O
of	O
one	O
dataframe	B-API
based	O
on	O
values	O
from	O
another	O
.	O

I	O
used	O
.ix	B-API
[	O
]	O
to	O
drill	O
down	O
to	O
the	O
value	O
,	O
then	O
.apply()	B-API
to	O
apply	O
a	O
function	O
across	O
each	O
row	O
(	O
axis=1	O
)	O
finding	O
the	O
line's	O
values	O
just	O
as	O
you	O
would	O
a	O
dataframe	B-API
.	O

(	O
'	O
line.element	O
'	O
/	O
line	O
[	O
'	O
element	O
'])	O

You	O
could	O
do	O
a	O
transpose	O
of	O
the	O
df	O
and	O
then	O
using	O
`	O
apply	O
`	O
call	O
`	O
nunique	B-API
`	O
row-wise	O
:	O
#CODE	O

You	O
`	O
groupby	B-API
`	O
first	O
on	O
the	O
feature	O
,	O
and	O
second	O
on	O
the	O
Iteration	O
variable	O
.	O

On	O
each	O
group	O
you	O
apply	O
the	O
`	O
mean()	B-API
`	O
function	O
,	O
and	O
you	O
get	O
the	O
group	O
whose	O
index	O
is	O
`	O
1	O
`	O
,	O
which	O
correspond	O
to	O
the	O
`	O
Feature	O
Active	O
==	O
1	O
`	O
group	O
.	O

So	O
a	O
span	O
of	O
60	O
obviously	O
wouldn't	O
apply	O
here	O
,	O
as	O
Pandas	O
would	O
just	O
interpret	O
that	O
as	O
every	O
60	O
datapoints	O
rather	O
than	O
every	O
60	O
seconds	O
.	O

Are	O
there	O
any	O
solutions	O
beyond	O
the	O
obvious	O
?	O

The	O
"	O
obvious	O
"	O
being	O
inserting	O
datapoints	O
for	O
every	O
second	O
in	O
the	O
gaps	O
,	O
and	O
extrapolating	O
the	O
values	O
.	O

I	O
should	O
note	O
that	O
the	O
Date	O
column	O
is	O
a	O
proper	O
Python	O
datetime64	O
object	O
.	O

You	O
could	O
add	O
an	O
ordinal	O
variable	O
for	O
which	O
group-of-60-seconds	O
each	O
row	O
belongs	O
to	O
,	O
then	O
group	O
by	O
that	O
ordinal	O
value	O
and	O
apply	O
the	O
averaging	O
function	O
across	O
the	O
entire	O
group	O
,	O
on	O
a	O
group-by-group	O
basis	O
.	O

An	O
easy	O
way	O
to	O
do	O
this	O
would	O
be	O
to	O
convert	O
the	O
datetime	O
value	O
to	O
a	O
number	O
of	O
seconds	O
since	O
the	O
minimum	O
datetime	O
value	O
,	O
then	O
do	O
integer	O
division	O
by	O
60	O
.	O

Pandas	O
:	O
Get	O
grouping-index	O
in	O
apply	O
function	O

What	O
are	O
you	O
actually	O
trying	O
to	O
do	O
with	O
"	O
mytest	O
"	O
,	O
it	O
looks	O
like	O
what	O
you're	O
looking	O
for	O
is	O
actually	O
a	O
df.groupby	B-API
and	O
then	O
an	O
agg	O
which	O
can	O
view	O
the	O
index	O
,	O
or	O
a	O
df.resample	B-API
and	O
then	O
an	O
apply	O
which	O
can	O
also	O
reference	O
the	O
index	O

I	O
want	O
to	O
apply	O
the	O
mapping	O
to	O
df1	O
.	O

The	O
working	O
version	O
I	O
have	O
is	O
this	O
one	O
,	O
but	O
I	O
feel	O
there	O
is	O
potential	O
for	O
improvement	O
,	O
as	O
I	O
find	O
my	O
solution	O
unreadable	O
and	O
I	O
am	O
unsure	O
about	O
how	O
it	O
would	O
generalize	O
to	O
multiindexes	O
#CODE	O

My	O
purpose	O
is	O
to	O
apply	O
two	O
functions	O
at	O
the	O
same	O
time	O
.	O

Basically	O
,	O
I	O
want	O
to	O
cut	O
my	O
dataset	O
for	O
extreme	O
values	O
by	O
looking	O
for	O
the	O
5%	O
quantile	O
at	O
the	O
lowest	O
part	O
of	O
the	O
dataset	O
and	O
the	O
top	O
%	O
at	O
the	O
other	O
end	O
.	O

#CODE	O

So	O
here	O
is	O
a	O
mask	O
that	O
ought	O
to	O
solve	O
the	O
problem	O
.	O

Just	O
`	O
interpolate	O
`	O
and	O
then	O
apply	O
the	O
mask	O
to	O
reset	O
appropriate	O
values	O
to	O
NaN	O
.	O

Honestly	O
,	O
this	O
was	O
a	O
bit	O
more	O
work	O
than	O
I	O
realized	O
it	O
would	O
be	O
because	O
I	O
had	O
to	O
loop	O
through	O
each	O
column	O
but	O
then	O
groupby	B-API
didn't	O
quite	O
work	O
without	O
me	O
providing	O
some	O
dummy	O
columns	O
like	O
'	O
ones	O
'	O
.	O

Let's	O
say	O
you	O
have	O
a	O
list	O
of	O
`	O
datetime	O
`	O
objects	O
and	O
you	O
want	O
to	O
group	O
them	O
by	O
the	O
`	O
.month	B-API
`	O
attribute	O
.	O

So	O
,	O
First	O
of	O
all	O
you	O
need	O
to	O
sort	O
them	O
,	O
then	O
you	O
can	O
apply	O
`	O
itertools.groupby()	O
`	O
function	O
which	O
returns	O
:	O
a	O
group	O
value	O
and	O
an	O
iterator	O
.	O

#CODE	O

This	O
avoids	O
apply	O
.	O

Link	O
to	O
docs	O

This	O
is	O
briefly	O
mentioned	O
in	O
the	O
docs	O
on	O
multi-indexing	O
,	O
although	O
obviously	O
that	O
doesn't	O
quite	O
apply	O
in	O
your	O
case	O
,	O
I'm	O
not	O
sure	O
where	O
to	O
go	O
for	O
a	O
good	O
overview	O
of	O
how	O
slicing	O
works	O
for	O
sorted	O
/	O
unsorted	O
indices	O
.	O

How	O
to	O
apply	O
multiple	O
formats	O
to	O
one	O
column	O
with	O
XlsxWriter	O

In	O
the	O
below	O
code	O
I	O
apply	O
number	O
formatting	O
to	O
each	O
of	O
the	O
columns	O
in	O
my	O
excel	O
sheet	O
.	O

However	O
,	O
I	O
can't	O
seem	O
to	O
figure	O
out	O
to	O
apply	O
multiple	O
formattings	O
to	O
a	O
specific	O
column	O
,	O
either	O
the	O
centering	O
or	O
the	O
numbering	O
end	O
up	O
being	O
over	O
written	O
.	O

Is	O
it	O
even	O
possible	O
to	O
apply	O
two	O
types	O
of	O
formatting	O
to	O
one	O
column	O
?	O

#CODE	O

Is	O
it	O
even	O
possible	O
to	O
apply	O
two	O
types	O
of	O
formatting	O
to	O
one	O
column	O
?	O

I	O
then	O
call	O
`	O
apply	O
`	O
on	O
that	O
list	O
to	O
turn	O
it	O
into	O
a	O
Series	O
,	O
this	O
will	O
auto	O
generate	O
the	O
names	O
of	O
the	O
columns	O
0	O
..	O

4	O
.	O

Are	O
there	O
modules	O
to	O
do	O
something	O
like	O
this	O
hourly	O
without	O
human	O
intervention	O
?	O

I	O
would	O
read	O
all	O
of	O
the	O
files	O
in	O
a	O
directory	O
,	O
append	O
them	O
into	O
a	O
single	O
file	O
,	O
drop	O
duplicates	O
,	O
apply	O
some	O
changes	O
(	O
add	O
some	O
columns	O
,	O
perform	O
some	O
calculations	O
on	O
timestamps	O
)	O
,	O
and	O
then	O
save	O
the	O
consolidated	O
new	O
file	O
in	O
another	O
directory	O
.	O

I	O
ended	O
up	O
doing	O
it	O
using	O
a	O
groupby	B-API
apply	O
as	O
follows	O
(	O
and	O
coded	O
to	O
work	O
forwards	O
or	O
backwards	O
):	O
#CODE	O

You	O
can	O
use	O
`	O
DataFrame.apply	B-API
`	O
with	O
`	O
axis=0	O
`	O
to	O
apply	O
a	O
function	O
to	O
every	O
column	O
of	O
a	O
dataframe	B-API
.	O

In	O
your	O
case	O
you	O
want	O
to	O
check	O
whether	O
`	O
all	O
(	O
col	O
==	O
1	O
)`	O
for	O
each	O
column	O
.	O

I	O
would	O
suggest	O
using	O
`	O
all	O
`	O
on	O
the	O
boolean	O
condition	O
on	O
the	O
entire	O
df	O
rather	O
than	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

Although	O
maxymoo's	O
answer	O
is	O
correct	O
generally	O
one	O
should	O
avoid	O
using	O
`	O
apply	O
`	O
if	O
there	O
is	O
a	O
method	O
that	O
is	O
vectorised	O
and	O
can	O
operate	O
on	O
the	O
entire	O
df	O
which	O
this	O
does	O

But	O
when	O
I	O
tried	O
to	O
do	O
something	O
like	O
this	O
on	O
my	O
`	O
DataFrameGroupBy	B-API
`	O
object	O
,	O
it	O
threw	O
an	O
error	O
:	O
`	O
Cannot	O
access	O
callable	O
attribute	O
'	O
astype	B-API
'	O
of	O
'	O
SeriesGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
`	O

@USER	O
I	O
think	O
he	O
needs	O
to	O
unstack	O
the	O
``	O
industry	O
``	O
column	O
in	O
order	O
to	O
apply	O
``	O
rolling_corr	B-API
``	O
on	O
the	O
result	O
.	O

@USER	O
if	O
you	O
apply	O
df.corr()	B-API
to	O
the	O
current	O
structure	O
,	O
all	O
you	O
get	O
is	O
a	O
correlation	O
of	O
all	O
the	O
columns	O
,	O
eg	O
:	O
correlation	O
between	O
mean	O
and	O
max	O
.	O

That	O
is	O
not	O
what	O
is	O
required	O
.	O

I	O
need	O
to	O
find	O
the	O
correlation	O
between	O
each	O
industry	O
.	O

In	O
other	O
words	O
the	O
industries	O
need	O
to	O
become	O
columns	O
(	O
along	O
with	O
the	O
existing	O
columns	O
)	O
,	O
and	O
the	O
rows	O
will	O
be	O
dates	O
.	O

I	O
haven't	O
had	O
any	O
luck	O
doing	O
that	O
.	O

Then	O
I'd	O
`	O
groupby	B-API
`	O
df1	O
on	O
name	O
and	O
apply	O
a	O
`	O
transform	O
`	O
to	O
calculate	O
the	O
total	O
weight	O
change	O
for	O
each	O
person	O
.	O

`	O
transform	O
`	O
returns	O
a	O
Series	O
aligned	O
to	O
the	O
orig	O
df	O
so	O
you	O
can	O
add	O
an	O
aggregated	O
column	O
back	O
to	O
the	O
df	O
.	O

I	O
have	O
tried	O
using	O
groupby	B-API
and	O
apply	O
in	O
several	O
different	O
ways	O
but	O
I	O
cant	O
get	O
it	O
to	O
work	O
.	O

Though	O
I	O
was	O
wondering	O
if	O
you	O
could	O
do	O
it	O
immediately	O
using	O
lambda	O
,	O
apply	O
and	O
groupby	B-API
.	O

This	O
function	O
is	O
mapped	O
on	O
every	O
row	O
of	O
the	O
(	O
Pandas	O
?	O
)	O
dataframe	B-API
(	O
actually	O
,	O
only	O
on	O
filtered	O
columns	O
`'	O
humidity	O
'`	O
and	O
`'	O
workingday	O
'`)	O
and	O
the	O
result	O
is	O
stored	O
in	O
`'	O
sticky	O
'`	O
column	O
.	O

That	O
said	O
,	O
you	O
can	O
translate	O
the	O
same	O
expression	O
in	O
R	O
using	O
an	O
anonymous	O
`	O
function	O
`	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

I	O
have	O
to	O
say	O
this	O
is	O
weird	O
way	O
to	O
apply	O
a	O
function	O
to	O
a	O
pandas	O
df	O
,	O
anyway	O
this	O
is	O
an	O
example	O
which	O
shows	O
what	O
it	O
does	O
:	O
#CODE	O

The	O
lambda	O
expression	O
is	O
calling	O
`	O
apply	O
`	O
and	O
passing	O
`	O
axis=1	O
`	O
which	O
means	O
row-wise	O
and	O
test	O
each	O
named	O
column	O
for	O
whether	O
the	O
expression	O
is	O
True	O
or	O
False	O
,	O
the	O
`	O
(	O
0	O
,	O
1	O
)`	O
casts	O
this	O
to	O
an	O
`	O
int	O
`	O
,	O
otherwise	O
you'd	O
get	O
a	O
boolean	O
dtype	B-API
returned	O
.	O

#CODE	O

I	O
then	O
apply	O
this	O
#CODE	O

and	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
:	O
#CODE	O

As	O
to	O
why	O
your	O
method	O
failed	O
,	O
you	O
were	O
calling	O
`	O
apply	O
`	O
on	O
a	O
Series	O
(	O
`	O
df	O
[	O
'	O
ID	O
']`	O
is	O
a	O
Series	O
and	O
not	O
a	O
df	O
)	O
and	O
there	O
is	O
no	O
`	O
axis	O
`	O
param	O
so	O
the	O
following	O
works	O
:	O
#CODE	O

Working	O
on	O
the	O
database	O
of	O
matches	O
I	O
would	O
like	O
to	O
retrive	O
the	O
rating	O
of	O
both	O
players	O
and	O
apply	O
two	O
functions	O
(	O
i	O
already	O
have	O
them	O
defined	O
)	O
predicted_result	O
(	O
rating1	O
,	O
rating2	O
)	O
,	O
and	O
updated_rating	O
(	O
rating1	O
,	O
rating2	O
)	O
.	O

The	O
first	O
one	O
gives	O
me	O
the	O
expected	O
result	O
of	O
the	O
match	O
given	O
the	O
ratings	O
,	O
the	O
second	O
one	O
gives	O
me	O
the	O
updated	O
ratings	O
.	O

Finally	O
I	O
need	O
to	O
record	O
the	O
updated	O
ratings	O
in	O
the	O
player	O
database	O
.	O

It	O
looks	O
like	O
it's	O
binding	O
the	O
function	O
object	O
as	O
the	O
column	O
value	O
rather	O
than	O
unpacking	O
it	O
to	O
a	O
dict	O
,	O
what	O
I'm	O
doing	O
above	O
is	O
to	O
return	O
the	O
`	O
value_counts	B-API
`	O
as	O
a	O
list	O
and	O
then	O
call	O
`	O
apply	O
`	O
again	O
to	O
unpack	O
the	O
single	O
element	O
list	O
.	O

This	O
forces	O
the	O
dict	O
to	O
be	O
unpacked	O
into	O
a	O
single	O
element	O
list	O
in	O
the	O
initial	O
`	O
apply	O
`	O
call	O
:	O
#CODE	O

I'm	O
trying	O
to	O
do	O
apply	O
simple	O
functions	O
to	O
mostly	O
numeric	O
data	O
in	O
pandas	O
.	O
the	O
data	O
is	O
a	O
set	O
of	O
matrices	O
indexed	O
by	O
time	O
.	O

I	O
wanted	O
to	O
use	O
hierarchical	O
/	O
multilevel	O
indices	O
to	O
represent	O
this	O
and	O
then	O
use	O
a	O
split-apply-combine	O
like	O
operation	O
to	O
group	O
the	O
data	O
,	O
apply	O
an	O
operation	O
,	O
and	O
summarize	O
the	O
result	O
as	O
a	O
dataframe	B-API
.	O

I'd	O
like	O
the	O
result	O
of	O
these	O
operations	O
to	O
be	O
dataframes	O
and	O
not	O
Series	O
objects	O
.	O

1	O
)	O
`	O
groupby	B-API
`	O
on	O
'	O
id	O
'	O
and	O
call	O
`	O
apply	O
`	O
on	O
the	O
'	O
vehicle	O
'	O
column	O
and	O
pass	O
method	O
`	O
nunique	B-API
`	O
,	O
you	O
have	O
to	O
subtract	O
1	O
as	O
you	O
are	O
looking	O
for	O
changes	O
rather	O
than	O
just	O
an	O
overall	O
unique	O
count	O
:	O
#CODE	O

2	O
)	O
`	O
apply	O
`	O
a	O
lambda	O
that	O
tests	O
whether	O
the	O
current	O
vehicle	O
does	O
not	O
equal	O
the	O
previous	O
vehicle	O
using	O
`	O
shift	O
`	O
,	O
this	O
is	O
more	O
semantically	O
correct	O
as	O
this	O
detects	O
changes	O
rather	O
than	O
just	O
the	O
overall	O
unique	O
count	O
,	O
calling	O
`	O
sum	O
`	O
on	O
booleans	O
will	O
convert	O
`	O
True	O
`	O
and	O
`	O
False	O
`	O
to	O
`	O
1	O
`	O
and	O
`	O
0	O
`	O
respectively	O
:	O
#CODE	O

Are	O
just	O
for	O
ilustrate	O
the	O
use	O
of	O
map	O
function	O
:	O
`	O
l	O
`	O
is	O
a	O
list	O
containing	O
the	O
integer	O
values	O
1	O
,	O
2	O
and	O
3	O
and	O
`	O
ml	O
`	O
is	O
a	O
list	O
we	O
have	O
obtained	O
as	O
the	O
result	O
of	O
apply	O
the	O
`	O
set_negative	O
`	O
lambda	O
to	O
`	O
l	O
`	O
.	O

In	O
others	O
words	O
we	O
have	O
applied	O
a	O
function	O
to	O
each	O
element	O
of	O
the	O
sequence	O
`	O
l	O
`	O
without	O
using	O
a	O
`	O
for	O
`	O
o	O
`	O
while	O
`	O
loop	O
.	O

It	O
seems	O
like	O
pandas	O
either	O
expects	O
apply	O
to	O
return	O
a	O
scalar	O
for	O
each	O
column	O
,	O
or	O
a	O
vector	O
of	O
the	O
same	O
length	O
as	O
the	O
column	O
.	O

Is	O
there	O
a	O
way	O
to	O
return	O
vectors	O
of	O
different	O
length	O
to	O
the	O
original	O
data	O
?	O

Another	O
version	O
that	O
works	O
the	O
same	O
as	O
EdChum's	O
answer	O
,	O
but	O
splits	O
within	O
`	O
apply	O
`	O
,	O
instead	O
of	O
within	O
`	O
np.percentile	B-API
`	O
:	O
#CODE	O

You	O
can	O
pass	O
param	O
`	O
axis=1	O
`	O
to	O
`	O
apply	O
`	O
so	O
that	O
it	O
process	O
each	O
row	O
rather	O
than	O
the	O
entire	O
column	O
:	O
#CODE	O

In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O
first	O
column	O
/	O
row	O
to	O
decide	O
whether	O
it	O
can	O
take	O
a	O
fast	O
or	O
slow	O
code	O
path	O
.	O

In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O
first	O
group	O
to	O
decide	O
whether	O
it	O
can	O
take	O
a	O
fast	O
or	O
slow	O
code	O
path	O
.	O

This	O
can	O
lead	O
to	O
unexpected	O
behavior	O
if	O
func	O
has	O
side-effects	O
,	O
as	O
they	O
will	O
take	O
effect	O
twice	O
for	O
the	O
first	O
group	O
.	O

In	O
my	O
opinion	O
you	O
should	O
read	O
the	O
entire	O
csv	O
as	O
a	O
df	O
,	O
then	O
`	O
apply	O
`	O
your	O
crawl	O
method	O
on	O
column2	O
and	O
create	O
the	O
new	O
column	O
and	O
then	O
write	O
the	O
df	O
to	O
your	O
output	O
:	O
#CODE	O

using	O
apply	O
.	O

#CODE	O

apply	O
pandas	O
qcut	B-API
function	O
to	O
subgroups	O

Python	O
Pandas	O
DataFrame	B-API
If	O
Index	O
Contains	O
Any	O
String	O
Values	O
,	O
Apply	O
Label	O
,	O
Else	O
Apply	O
Different	O
Label	O

If	O
the	O
'	O
Search	O
term	O
'	O
(	O
index	O
)	O
CONTAINS	O
`'	O
american	O
brewing	O
'`	O
or	O
`'	O
americanbrewing	O
'`	O
,	O
apply	O
the	O
label	O
`'	O
Brand	O
'`	O
,	O
else	O
apply	O
`'	O
Non-brand	O
'`	O
to	O
a	O
column	O
with	O
the	O
header	O
`	O
Label	O
`	O
.	O

#CODE	O

How	O
do	O
I	O
output	O
the	O
`	O
Label	O
`	O
column	O
in	O
the	O
`	O
result	O
`	O
`	O
dataframe	B-API
`	O
based	O
on	O
if	O
the	O
`	O
Search	O
term	O
`	O
(	O
index	O
)	O
contains	O
any	O
of	O
several	O
possible	O
string	O
values	O
?	O

Where	O
`	O
True	O
`	O
,	O
apply	O
`	O
Brand	O
`	O
,	O
Else	O
,	O
apply	O
`	O
Non-brand	O
`	O
to	O
the	O
`	O
Label	O
`	O
column	O
.	O

You	O
could	O
convert	O
the	O
`	O
index	O
`	O
to	O
`	O
Series	O
`	O
and	O
apply	O
transformations	O
.	O

#CODE	O

No	O
matter	O
which	O
of	O
the	O
given	O
alternatives	O
I	O
apply	O
-	O
it	O
just	O
doesn't	O
work	O
.	O

Do	O
you	O
have	O
any	O
ideas	O
?	O

#CODE	O

I	O
can't	O
figure	O
out	O
a	O
way	O
to	O
do	O
this	O
in	O
a	O
single	O
loop	O
,	O
the	O
problem	O
here	O
is	O
that	O
you	O
want	O
some	O
kind	O
of	O
rolling	O
apply	O
that	O
can	O
then	O
look	O
at	O
the	O
previous	O
row	O
,	O
the	O
problem	O
here	O
is	O
that	O
the	O
previous	O
row	O
update	O
will	O
not	O
be	O
observable	O
until	O
the	O
`	O
apply	O
`	O
finishes	O
so	O
for	O
instance	O
the	O
following	O
works	O
because	O
we	O
in	O
run	O
the	O
apply	O
3	O
times	O
.	O

This	O
isn't	O
great	O
IMO	O
:	O
#CODE	O

Hi	O
Many	O
thanks	O
for	O
all	O
the	O
answers	O
,	O
I	O
have	O
tried	O
to	O
apply	O
the	O
df.ix	B-API
[:	O
,	O
:	O
'	O
4	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x.isin	O
(	O
df	O
[	O
'	O
1	O
']))	O
.all	B-API
(	O
axis=1	O
)	O
.sum()	B-API
to	O
the	O
last	O
4	O
columns	O
of	O
my	O
example	O
(	O
columns	O
2	O
,	O
3	O
,	O
4	O
and	O
5	O
)	O
by	O
using	O
df.ix	B-API
[:	O
,	O
:	O
'	O
5	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x.isin	O
(	O
df	O
[	O
'	O
2	O
']))	O
.all	B-API
(	O
axis=1	O
)	O
.sum()	B-API
and	O
have	O
checked	O
by	O
hand	O
(	O
with	O
a	O
dataset	O
that	O
provides	O
me	O
an	O
answer	O
greater	O
than	O
0	O
,	O
but	O
keep	O
getting	O
a	O
different	O
result	O
.	O

Have	O
I	O
applied	O
the	O
logic	O
correctly	O
please	O
?	O

In	O
a	O
Python	O
Pandas	O
`	O
DataFrame	B-API
`	O
,	O
I'm	O
trying	O
to	O
apply	O
a	O
specific	O
label	O
to	O
a	O
row	O
if	O
a	O
'	O
Search	O
terms	O
'	O
column	O
contains	O
any	O
possible	O
strings	O
from	O
a	O
joined	O
,	O
pipe-delimited	O
list	O
.	O

How	O
can	O
I	O
do	O
conditional	O
if	O
,	O
elif	O
,	O
else	O
statements	O
with	O
Pandas	O
?	O

It	O
doesn't	O
look	O
like	O
`	O
str.contains	B-API
`	O
supports	O
multiple	O
patterns	O
,	O
so	O
you	O
may	O
just	O
have	O
to	O
apply	O
over	O
the	O
rows	O
:	O
#CODE	O

Apply	O
a	O
lambda	O
function	O
on	O
the	O
rows	O
and	O
test	O
if	O
A	O
is	O
in	O
B	O
.	O

#CODE	O

If	O
you're	O
looking	O
to	O
perform	O
some	O
kind	O
of	O
timestamp	O
calculation	O
using	O
your	O
index	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
access	O
the	O
index	O
using	O
the	O
`	O
name	O
`	O
attribute	O
:	O
#CODE	O

Is	O
there	O
a	O
way	O
to	O
apply	O
to	O
a	O
pandas	O
dataframe	B-API
while	O
threading	O
state	O
?	O

My	O
goal	O
is	O
to	O
be	O
ably	O
to	O
do	O
an	O
apply	O
,	O
but	O
one	O
which	O
maintains	O
some	O
state	O
.	O

Now	O
,	O
I	O
know	O
that	O
I	O
can	O
just	O
have	O
a	O
variable	O
(	O
and	O
be	O
aware	O
that	O
apply	O
is	O
called	O
twice	O
,	O
I	O
believe	O
)	O
,	O
but	O
I'm	O
wondering	O
if	O
there	O
is	O
a	O
more	O
idiomatic	O
way	O
to	O
do	O
this	O
?	O

"	O
maintains	O
some	O
state	O
"	O
<---	O
what	O
does	O
this	O
mean	O
and	O
how	O
does	O
`	O
apply	O
`	O
not	O
currently	O
achieve	O
this	O
?	O

post	O
some	O
more	O
code	O
showing	O
what	O
you're	O
trying	O
to	O
accomplish	O
(	O
and	O
example	O
output	O
)	O

How	O
to	O
apply	O
different	O
aggregation	O
functions	O
to	O
same	O
column	O
by	O
using	O
pandas	O
Groupby	B-API

@USER	O
I'd	O
say	O
that	O
question	O
is	O
different	O
,	O
the	O
OP	O
here	O
is	O
asking	O
how	O
to	O
apply	O
multiple	O
different	O
functions	O
at	O
once	O
,	O
not	O
to	O
generate	O
multiple	O
columns	O
from	O
a	O
single	O
function	O

What	O
I	O
got	O
so	O
far	O
is	O
the	O
code	O
below	O
and	O
it	O
works	O
fine	O
and	O
brings	O
the	O
results	O
it	O
should	O
:	O
It	O
fills	O
`	O
df	O
[	O
'	O
c	O
']`	O
with	O
the	O
calculation	O
`	O
previous	O
c	O
*	O
b	O
`	O
if	O
there	O
is	O
no	O
`	O
c	O
`	O
given	O
.	O

The	O
problem	O
is	O
that	O
I	O
have	O
to	O
apply	O
this	O
to	O
a	O
bigger	O
data	O
set	O
`	O
len	O
(	O
df.index	O
)	O
=	O
ca	O
.	O

10.000	O
`	O
,	O
so	O
the	O
function	O
I	O
have	O
so	O
far	O
is	O
inappropriate	O
since	O
I	O
would	O
have	O
to	O
write	O
a	O
couple	O
of	O
thousand	O
times	O
:	O
`	O
df	O
[	O
'	O
c	O
']	O
=	O
df.apply	B-API
(	O
func	O
,	O
axis	O
=1	O
)`	O
.	O

A	O
`	O
while	O
`	O
loop	O
is	O
no	O
option	O
in	O
`	O
pandas	O
`	O
for	O
this	O
size	O
of	O
dataset	O
.	O

Any	O
ideas	O
?	O

#CODE	O

@USER	O
Cunningham	O
:	O
How	O
would	O
I	O
apply	O
this	O
?	O

But	O
I'm	O
a	O
bit	O
stumped	O
at	O
how	O
to	O
do	O
this	O
pandas	O
.	O

As	O
far	O
as	O
I	O
can	O
tell	O
,	O
aggregate	O
only	O
applies	O
a	O
function	O
on	O
a	O
given	O
grouped	O
column	O
,	O
and	O
I	O
don't	O
know	O
how	O
to	O
get	O
it	O
to	O
apply	O
a	O
function	O
that	O
involves	O
multiple	O
columns	O
.	O

This	O
operation	O
will	O
only	O
apply	O
to	O
groups	O
that	O
are	O
larger	O
that	O
2	O
in	O
the	O
original	O
dataframe	B-API
.	O

I	O
tried	O
an	O
alternate	O
solution	O
which	O
involved	O
`	O
apply	O
`	O
ing	O
a	O
`	O
lambda	O
`	O
function	O
to	O
each	O
element	O
of	O
the	O
`	O
Series	O
`	O
but	O
that	O
took	O
longer	O
.	O

Now	O
get	O
the	O
distance	O
from	O
points	O
to	O
lines	O
and	O
only	O
save	O
the	O
minimum	O
distance	O
for	O
each	O
point	O
(	O
see	O
below	O
for	O
a	O
version	O
with	O
apply	O
)	O
#CODE	O

(	O
taken	O
from	O
a	O
github	O
issue	O
)	O
Using	O
`	O
apply	O
`	O
is	O
nicer	O
and	O
more	O
consistent	O
with	O
how	O
you'd	O
do	O
it	O
in	O
`	O
pandas	O
`	O
:	O
#CODE	O

2	O
)	O
How	O
do	O
I	O
apply	O
a	O
function	O
to	O
a	O
set	O
of	O
columns	O
to	O
remove	O
SettingWithCopyWarning	O
when	O
reformatting	O
DATA	O
columns	O
.	O

I	O
know	O
I	O
can	O
do	O
it	O
with	O
a	O
custom	O
apply	O
,	O
but	O
I'm	O
wondering	O
if	O
anyone	O
has	O
any	O
fun	O
ideas	O
?	O

(	O
Also	O
this	O
is	O
slow	O
when	O
there	O
are	O
many	O
groups	O
.	O
)	O
Here's	O
one	O
solution	O
:	O
#CODE	O

@USER	O
all	O
of	O
this	O
soln	O
is	O
completely	O
vectorized	O
or	O
in	O
cython	O
.	O

Using	O
an	O
apply	O
(	O
even	O
with	O
a	O
fast	O
lambda	O
)	O
will	O
be	O
orders	O
of	O
magnitude	O
slower	O
on	O
any	O
real	O
dataset	O
.	O

As	O
the	O
apply	O
is	O
essentially	O
a	O
python	O
loop	O
.	O

The	O
problem	O
is	O
,	O
that	O
I	O
am	O
getting	O
this	O
error	O
form	O
the	O
last	O
line	O
of	O
code	O
,	O
where	O
I	O
try	O
to	O
apply	O
the	O
function	O
with	O
`	O
df.apply	B-API
(	O
flex_relative	O
,	O
axis	O
=1	O
)`	O

The	O
only	O
thing	O
I	O
found	O
so	O
far	O
was	O
the	O
link	O
below	O
,	O
but	O
calling	O
a	O
R	O
function	O
won't	O
work	O
for	O
me	O
because	O
I	O
need	O
to	O
apply	O
that	O
to	O
quite	O
big	O
datasets	O
and	O
I	O
may	O
also	O
implement	O
an	O
optimization	O
in	O
this	O
function	O
,	O
so	O
it	O
definitely	O
needs	O
to	O
be	O
built	O
in	O
python	O
.	O

Here	O
is	O
the	O
link	O
anyway	O
:	O
Finance	O
Lib	O
with	O
portfolio	O
optimization	O
method	O
in	O
python	O

The	O
following	O
should	O
be	O
more	O
optimised	O
,	O
basically	O
I'd	O
`	O
groupby	B-API
`	O
on	O
the	O
team	O
,	O
apply	O
a	O
boolean	O
test	O
of	O
whether	O
the	O
difference	O
in	O
the	O
datetime	O
is	O
equal	O
to	O
a	O
timedelta	O
of	O
1	O
day	O
.	O

Then	O
for	O
where	O
this	O
is	O
True	O
then	O
apply	O
a	O
`	O
cumsum	B-API
`	O
on	O
this	O
and	O
add	O
1	O
.	O

Background-	O
I'm	O
trying	O
to	O
extract	O
unsynchronised	O
dual-doppler	O
measurements	O
from	O
a	O
scanning	O
`	O
LiDAR	O
`	O
which	O
is	O
taking	O
PPI	O
scans	O
.	O

I	O
have	O
the	O
data	O
(	O
from	O
MySQL	O
)	O
loaded	O
into	O
pandas	O
dataframes	O
,	O
and	O
now	O
need	O
to	O
apply	O
some	O
matching	O
function	O
where	O
the	O
rows	O
are	O
matched	O
if	O
the	O
time	O
of	O
measurement	O
is	O
within	O
some	O
limit	O
(	O
time	O
8s	O
apart	O
)	O
.	O

So	O
it	O
seems	O
to	O
have	O
collapsed	O
the	O
groups	O
,	O
but	O
I've	O
now	O
lost	O
data	O
?	O

Or	O
how	O
is	O
the	O
object	O
now	O
stored	O
?	O

I	O
realize	O
I	O
haven't	O
done	O
the	O
apply	O
stage	O
,	O
which	O
is	O
probably	O
how	O
I	O
will	O
generate	O
new	O
rows	O
and	O
new	O
columns	O
,	O
but	O
I	O
don't	O
know	O
the	O
next	O
step	O
or	O
if	O
there's	O
a	O
cookbook	O
example	O
for	O
something	O
like	O
this	O
.	O

One	O
method	O
would	O
be	O
to	O
convert	O
the	O
time	O
strings	O
to	O
datetime	O
but	O
only	O
take	O
the	O
time	O
portion	O
and	O
then	O
call	O
`	O
apply	O
`	O
and	O
call	O
`	O
datetime.combine	O
`	O
to	O
produce	O
your	O
datetime	O
for	O
both	O
columns	O
:	O
#CODE	O

Return	O
multiple	O
objects	O
from	O
an	O
apply	O
function	O
in	O
Pandas	O

I'm	O
practicing	O
with	O
using	O
`	O
apply	O
`	O
with	O
Pandas	O
dataframes	O
.	O

So	O
,	O
I'd	O
like	O
to	O
use	O
the	O
2nd	O
dataframe	B-API
,	O
`	O
DFa	O
`	O
,	O
and	O
get	O
the	O
dates	O
from	O
each	O
row	O
(	O
using	O
apply	O
)	O
,	O
and	O
then	O
find	O
and	O
sum	O
up	O
any	O
dates	O
in	O
the	O
original	O
dataframe	B-API
,	O
that	O
came	O
earlier	O
:	O
#CODE	O

Obviously	O
I'm	O
new	O
to	O
`	O
apply	O
`	O
and	O
I'm	O
eager	O
to	O
get	O
away	O
from	O
loops	O
.	O

I	O
just	O
don't	O
understand	O
how	O
to	O
return	O
values	O
from	O
apply	O
.	O

I	O
don't	O
think	O
apply	O
is	O
best	O
option	O
for	O
this	O
.	O

If	O
I	O
understand	O
correctly	O
why	O
not	O
DFa	O
[	O
DF.index	O
]	O
.sum()	B-API
?	O

I	O
agree	O
,	O
it's	O
a	O
pretty	O
lousy	O
example	O
.	O

My	O
main	O
problem	O
is	O
trying	O
to	O
return	O
from	O
the	O
apply	O
.	O

I	O
would	O
really	O
like	O
to	O
see	O
how	O
I	O
could	O
return	O
3	O
different	O
dataframes	O
,	O
and	O
sum	O
them	O
up	O
elsewhere	O
(	O
but	O
I	O
didn't	O
mention	O
that	O
in	O
the	O
question	O
appropriately	O
)	O
.	O

@USER	O
'	O
Brien	O
:	O
The	O
performance	O
of	O
DF.apply	B-API
(	O
func	O
,	O
axis=1	O
)	O
is	O
comparable	O
to	O
calling	O
func	O
in	O
a	O
loop	O
.	O
apply	O
is	O
useful	O
when	O
you	O
want	O
to	O
align	O
the	O
output	O
into	O
a	O
single	O
DataFrame	B-API
.	O

If	O
you	O
need	O
to	O
return	O
3	O
disparate	O
DataFrames	O
,	O
go	O
ahead	O
and	O
loop	O
over	O
DF.iterrows()	B-API
.	O

For	O
better	O
performance	O
you'll	O
have	O
to	O
think	O
of	O
a	O
better	O
way	O
to	O
calculate	O
the	O
result	O
(	O
such	O
as	O
doing	O
a	O
sorted	O
cumsum	B-API
for	O
the	O
toy	O
example	O
above	O
)	O
or	O
perhaps	O
use	O
Cython	O
.	O

Also	O
,	O
note	O
that	O
`	O
apply	O
`	O
returns	O
a	O
`	O
DataFrame	B-API
`	O
.	O

So	O
your	O
current	O
function	O
would	O
return	O
a	O
`	O
DataFrame	B-API
`	O
for	O
each	O
row	O
in	O
`	O
DFa	O
`	O
,	O
so	O
you	O
would	O
end	O
up	O
with	O
a	O
`	O
DataFrame	B-API
`	O
of	O
`	O
DataFrames	O
`	O

There's	O
a	O
bit	O
of	O
a	O
mixup	O
the	O
way	O
you're	O
using	O
`	O
apply	O
`	O
.	O

With	O
`	O
axis=1	O
`	O
,	O
`	O
foo	O
`	O
will	O
be	O
applied	O
to	O
each	O
row	O
(	O
see	O
the	O
docs	O
)	O
,	O
and	O
yet	O
your	O
code	O
implies	O
(	O
by	O
the	O
parameter	O
name	O
)	O
that	O
its	O
first	O
parameter	O
is	O
a	O
DataFrame	B-API
.	O

Once	O
you	O
make	O
the	O
changes	O
,	O
as	O
`	O
foo	O
`	O
returns	O
a	O
scalar	O
,	O
then	O
`	O
apply	O
`	O
will	O
return	O
a	O
series	O
:	O
#CODE	O

Is	O
there	O
a	O
faster	O
/	O
more	O
elegant	O
way	O
to	O
accomplish	O
this	O
?	O

For	O
example	O
,	O
is	O
there	O
a	O
way	O
to	O
apply	O
`	O
dateParser	O
`	O
directly	O
to	O
the	O
index	O
(	O
perhaps	O
inplace	O
)	O
so	O
I	O
don't	O
have	O
to	O
`	O
reset_index	B-API
`	O
first	O
?	O

My	O
current	O
approach	O
is	O
to	O
create	O
an	O
array	O
of	O
the	O
indices	O
where	O
the	O
markers	O
occur	O
,	O
iterating	O
over	O
this	O
array	O
using	O
the	O
values	O
to	O
slice	O
the	O
dataframe	B-API
,	O
and	O
then	O
appending	O
these	O
slices	O
to	O
a	O
list	O
.	O

I	O
end	O
up	O
with	O
a	O
list	O
of	O
numpy	O
arrays	O
that	O
I	O
can	O
then	O
apply	O
a	O
function	O
to	O
:	O
#CODE	O

Apply	O
a	O
value	O
to	O
a	O
`	O
sold_at_same_place	O
`	O
column	O
base	O
on	O
the	O
value	O
in	O
`	O
place	O
`	O
:	O
#CODE	O

apply	O
custom	O
function	O
on	O
pandas	O
dataframe	B-API
on	O
a	O
rolling	O
window	O

You	O
want	O
to	O
apply	O
a	O
risk	O
calculation	O
function	O
(	O
let's	O
say	O
VaR	O
)	O
named	O
compute_var()	O
on	O
last	O
90	O
closing	O
prices	O
,	O
on	O
a	O
rolling	O
basis	O

Wait	O
,	O
are	O
both	O
functions	O
meant	O
to	O
apply	O
to	O
individual	O
strings	O
instead	O
of	O
a	O
whole	O
row	O
,	O
or	O
just	O
`	O
perform_function1	O
`	O
?	O

Maybe	O
it	O
would	O
help	O
to	O
include	O
your	O
functions	O
(	O
if	O
they're	O
not	O
too	O
complicated	O
)	O
.	O

The	O
functions	O
are	O
kind	O
of	O
complicated	O
.	O

They're	O
meant	O
to	O
apply	O
to	O
individual	O
strings	O
.	O

If	O
you	O
want	O
to	O
apply	O
function	O
to	O
certain	O
columns	O
in	O
a	O
dataframe	B-API
#CODE	O

How	O
to	O
apply	O
a	O
function	O
to	O
the	O
elements	O
of	O
a	O
pandas	O
dataframe	B-API

I	O
want	O
to	O
apply	O
a	O
lambda	O
function	O
to	O
the	O
elements	O
of	O
a	O
dataframe	B-API
,	O
in	O
the	O
same	O
way	O
as	O
np.sqrt	B-API
returns	O
a	O
dataframe	B-API
with	O
the	O
sqrt	O
of	O
each	O
element	O
.	O

However	O
pd.DataFrame.apply	B-API
apply	O
the	O
function	O
to	O
an	O
row	O
or	O
an	O
column	O
.	O

Is	O
there	O
a	O
similar	O
comand	O
that	O
apply	O
a	O
lambda	O
function	O
on	O
each	O
element	O
?	O

This	O
is	O
really	O
quite	O
similar	O
to	O
what	O
you	O
are	O
doing	O
except	O
that	O
the	O
loop	O
is	O
replaced	O
by	O
`	O
apply	O
`	O
.	O

The	O
`	O
pd.Series	B-API
(	O
x.values	O
)`	O
has	O
an	O
index	O
which	O
by	O
default	O
ranges	O
over	O
integers	O
starting	O
at	O
`	O
0	O
`	O
.	O

The	O
index	O
values	O
become	O
the	O
column	O
names	O
(	O
above	O
)	O
.	O

It	O
doesn't	O
matter	O
that	O
the	O
various	O
groups	O
may	O
have	O
different	O
lengths	O
.	O

The	O
`	O
apply	O
`	O
method	O
aligns	O
the	O
various	O
indices	O
for	O
you	O
(	O
and	O
fills	O
missing	O
values	O
with	O
`	O
NaN	O
`)	O
.	O

What	O
a	O
convenience	O
!	O

I'm	O
trying	O
to	O
apply	O
one	O
function	O
`	O
f1	O
`	O
to	O
rows	O
`	O
[	O
'	O
Utah	O
,	O
'	O
Texas	O
']`	O
and	O
`	O
f2	O
`	O
to	O
other	O
rows	O
.	O

I	O
don't	O
want	O
to	O
create	O
separate	O
DF	O
for	O
each	O
function	O
.	O

Apply	O
function	O
to	O
column	O
in	O
pandas	O
dataframe	B-API
that	O
takes	O
two	O
arguments	O

You	O
can	O
do	O
this	O
with	O
the	O
`	O
map	O
`	O
method	O
without	O
writing	O
a	O
function	O
or	O
using	O
`	O
apply	O
`	O
at	O
all	O
:	O
#CODE	O

then	O
the	O
syntax	O
would	O
be	O
`	O
df.apply	B-API
(	O
func	O
,	O
axis	O
=	O
1	O
)`	O
to	O
apply	O
the	O
function	O
func	O
to	O
each	O
row	O
.	O

Apply	O
function	O
to	O
each	O
row	O
of	O
pandas	O
dataframe	B-API
to	O
create	O
two	O
new	O
columns	O

Because	O
NaT	O
is	O
technically	O
a	O
datetime	O
this	O
condition	O
wasn't	O
covered	O
by	O
that	O
function	O
.	O

Since	O
isnull	O
will	O
handle	O
this	O
,	O
I	O
wrote	O
this	O
function	O
to	O
apply	O
to	O
data	O
[	O
col_name	O
]:	O
#CODE	O

pandas	O
find	O
max	O
value	O
in	O
groupby	B-API
and	O
apply	O
function	O

How	O
may	O
I	O
set	O
my	O
maximum	O
H	O
value	O
(	O
4	O
for	O
Dublin	O
and	O
5	O
for	O
Madrid	O
)	O
as	O
a	O
constant	O
/	O
city	O
in	O
order	O
to	O
apply	O
the	O
function	O
all	O
over	O
the	O
DataFrame	B-API
?	O

The	O
expected	O
df	O
would	O
appear	O
as	O
:	O
#CODE	O

Many	O
thanks	O
for	O
your	O
answer	O
:)	O
Just	O
wondering	O
what	O
the	O
sub_df.columns	O
=	O
range	O
(	O
12	O
)	O
does	O
?	O

Does	O
it	O
just	O
rename	O
the	O
columns	O
1	O
to	O
12	O
or	O
apply	O
some	O
sort	O
of	O
indexing	O
?	O

How	O
to	O
apply	O
functions	O
with	O
multiple	O
arguments	O
on	O
Pandas	O
selected	O
columns	O
data	O
frame	O

What	O
I	O
want	O
to	O
do	O
is	O
to	O
apply	O
a	O
function	O
:	O
#CODE	O

The	O
`	O
DataFrame.apply	B-API
`	O
method	O
takes	O
a	O
parameter	O
`	O
axis	O
`	O
which	O
when	O
set	O
to	O
1	O
sends	O
the	O
whole	O
row	O
into	O
the	O
apply	O
function	O
.	O

This	O
makes	O
it	O
a	O
lot	O
slower	O
than	O
a	O
normal	O
apply	O
function	O
since	O
it	O
is	O
no	O
longer	O
a	O
proper	O
monoid	O
lambda	O
function	O
.	O

But	O
it	O
does	O
work	O
.	O

The	O
error	O
message	O
is	O
telling	O
you	O
that	O
you	O
cannot	O
cast	O
a	O
pandas	O
Series	O
to	O
a	O
`	O
float	O
`	O
,	O
whilst	O
you	O
could	O
call	O
`	O
apply	O
`	O
to	O
call	O
your	O
method	O
row-wise	O
.	O

You	O
should	O
look	O
at	O
rewriting	O
your	O
method	O
so	O
that	O
it	O
can	O
work	O
on	O
the	O
entire	O
`	O
Series	O
`	O
,	O
this	O
will	O
be	O
vectorised	O
and	O
be	O
much	O
faster	O
than	O
calling	O
`	O
apply	O
`	O
which	O
is	O
essentially	O
a	O
`	O
for	O
`	O
loop	O
.	O

I	O
guess	O
I	O
will	O
have	O
to	O
`	O
apply	O
`	O
or	O
map	O
a	O
`	O
split	O
(	O
"	O
,	O
")`	O
to	O
the	O
`	O
Term	O
`	O
column	O
,	O
but	O
what	O
do	O
I	O
do	O
after	O
that	O
?	O

#CODE	O

You	O
can	O
use	O
`	O
str.split	B-API
`	O
to	O
do	O
the	O
splitting	O
(	O
instead	O
of	O
apply	O
and	O
split	O
approach	O
,	O
but	O
similar	O
):	O
#CODE	O

To	O
filter	O
out	O
some	O
rows	O
,	O
we	O
need	O
the	O
'	O
filter	O
'	O
function	O
instead	O
of	O
'	O
apply	O
'	O
.	O

#CODE	O

in	O
excel	O
what	O
I'm	O
trying	O
to	O
do	O
would	O
be	O
"	O
=IF	O
(	O
AND	O
(	O
A2=0	O
,	O
B1=-1	O
)	O
,	O
-1	O
,	O
A2	O
)	O
so	O
that	O
I	O
could	O
then	O
drag	O
down	O
column	O
'	O
B	O
'	O
and	O
that	O
would	O
apply	O
.	O

In	O
essence	O
,	O
based	O
on	O
the	O
prior	O
data	O
point	O
of	O
column	O
B	O
,	O
and	O
the	O
current	O
value	O
of	O
column	O
A	O
,	O
I	O
need	O
to	O
update	O
the	O
current	O
value	O
of	O
B	O
.	O

I	O
have	O
to	O
do	O
that	O
for	O
15	O
columns	O
though	O
.	O

I	O
have	O
read	O
that	O
lambda	O
is	O
a	O
'	O
throwaway	O
'	O
function	O
.	O

Is	O
it	O
better	O
to	O
define	O
a	O
function	O
(	O
to	O
split	O
and	O
then	O
to	O
turn	O
the	O
values	O
into	O
minutes	O
)	O
and	O
apply	O
it	O
to	O
each	O
column	O
instead	O
?	O

Would	O
I	O
loop	O
through	O
the	O
columns	O
(	O
not	O
all	O
columns	O
,	O
but	O
15	O
of	O
about	O
30	O
)	O
?	O

I	O
am	O
hoping	O
someone	O
will	O
provide	O
a	O
function	O
I	O
can	O
use	O
to	O
apply	O
/	O
map	O
everything	O
to	O
several	O
columns	O
at	O
once	O
efficiently	O
.	O

I	O
am	O
not	O
too	O
familiar	O
with	O
def	O
and	O
return	O
functions	O
(	O
I	O
learned	O
basic	O
pandas	O
before	O
I	O
learned	O
basic	O
python	O
,	O
just	O
for	O
practical	O
purposes	O
..	O
slowly	O
learning	O
though	O
)	O
.	O

Need	O
to	O
turn	O
those	O
timestamps	O
into	O
minutes	O

You	O
could	O
just	O
measure	O
this	O
but	O
generally	O
`	O
apply	O
`	O
should	O
be	O
the	O
last	O
resort	O
as	O
it	O
doesn't	O
scale	O
as	O
well	O
as	O
its	O
a	O
for	O
loop	O
and	O
if	O
called	O
on	O
a	O
series	O
it	O
executes	O
per	O
row	O
.	O

With	O
respect	O
to	O
turning	O
it	O
into	O
a	O
function	O
so	O
you	O
can	O
apply	O
to	O
15	O
columns	O
you	O
put	O
your	O
code	O
for	O
you	O
last	O
method	O
into	O
a	O
function	O
and	O
then	O
call	O
`	O
apply	O
`	O
on	O
a	O
df	O
,	O
this	O
will	O
call	O
it	O
for	O
each	O
column	O
but	O
it	O
will	O
try	O
to	O
execute	O
the	O
function	O
on	O
the	O
whole	O
Series	O

Also	O
,	O
what	O
about	O
.map	B-API
vs	O
.apply	B-API
?	O

And	O
is	O
it	O
better	O
to	O
have	O
a	O
separate	O
line	O
of	O
code	O
for	O
each	O
column	O
I	O
am	O
doing	O
this	O
to	O
,	O
or	O
is	O
it	O
better	O
to	O
define	O
a	O
function	O
and	O
apply	O
that	O
to	O
each	O
column	O
?	O

It	O
looks	O
a	O
bit	O
messy	O
to	O
have	O
this	O
split	O
lambda	O
function	O
15	O
times	O
in	O
a	O
row	O
(	O
15	O
timestamp	O
columns	O
to	O
be	O
converted	O
to	O
minutes	O
)	O

just	O
wrap	O
it	O
up	O
in	O
a	O
small	O
function	O
,	O
and	O
either	O
apply	O
it	O
across	O
the	O
columns	O
,	O
or	O
since	O
you	O
prob	O
don't	O
have	O
too	O
many	O
of	O
these	O
,	O
just	O
do	O
it	O
per	O
column	O
.	O

Note	O
:	O
executing	O
the	O
cubic	O
spline	O
interpolation	O
via	O
the	O
apply	O
function	O
takes	O
quite	O
a	O
mount	O
of	O
time	O
(	O
about	O
2	O
minutes	O
in	O
my	O
PC	O
)	O
.	O

It	O
interpolates	O
from	O
about	O
100	O
points	O
to	O
300	O
points	O
,	O
row	O
by	O
row	O
(	O
2638	O
in	O
total	O
)	O
.	O

#CODE	O

I'm	O
trying	O
to	O
apply	O
a	O
weighted	O
filter	O
on	O
data	O
rather	O
the	O
use	O
raw	O
data	O
before	O
calculating	O
stats	O
,	O
mu	O
,	O
std	O
and	O
covar	O
.	O

But	O
the	O
results	O
clearly	O
need	O
adjusting	O
.	O

#CODE	O

pd.DataFrame.groupby.apply	O
really	O
gives	O
us	O
a	O
lot	O
of	O
flexibility	O
(	O
unlike	O
agg	O
/	O
filter	O
/	O
transform	O
,	O
it	O
allows	O
you	O
to	O
reshape	O
each	O
subgroup	O
to	O
any	O
shape	O
,	O
in	O
your	O
case	O
,	O
from	O
538	O
x	O
122	O
to	O
N_categories	O
x	O
122	O
)	O
.	O

But	O
it	O
indeed	O
comes	O
with	O
a	O
cost	O
:	O
apply	O
your	O
flexible	O
function	O
one-by-one	O
and	O
lacks	O
of	O
vectorization	O
.	O

But	O
I'm	O
not	O
sure	O
how	O
to	O
proceed	O
.	O

How	O
do	O
I	O
apply	O
the	O
date	O
subtraction	O
operation	O
,	O
then	O
combine	O
?	O

You	O
can	O
use	O
apply	O
like	O
this	O
:	O
#CODE	O

FWIW	O
,	O
using	O
`	O
transform	O
`	O
can	O
often	O
be	O
simpler	O
(	O
and	O
usually	O
faster	O
)	O
than	O
`	O
apply	O
`	O
.	O

`	O
transform	O
`	O
takes	O
the	O
results	O
of	O
a	O
groupby	B-API
operation	O
and	O
broadcasts	O
it	O
up	O
to	O
the	O
original	O
index	O
:	O
#CODE	O

@USER	O
-	O
I	O
referenced	O
the	O
post	O
you	O
suggest	O
as	O
duplicative	O
,	O
and	O
tried	O
to	O
apply	O
the	O
.map()	B-API
function	O
it	O
recommends	O
.	O

My	O
results	O
from	O
doing	O
so	O
are	O
listed	O
above	O
under	O
"	O
My	O
best	O
effort	O
so	O
far	O
"	O
.	O

I	O
realize	O
I	O
must	O
be	O
missing	O
something	O
;	O
can	O
you	O
help	O
my	O
understand	O
how	O
to	O
use	O
the	O
.map()	B-API
function	O
in	O
this	O
example	O
?	O

The	O
following	O
snippet	O
should	O
work	O
after	O
your	O
`	O
apply	O
(	O
crawl	O
)`	O
.	O

#CODE	O

From	O
what	O
I	O
understand	O
I	O
am	O
following	O
the	O
steps	O
to	O
apply	O
PCA	B-API
as	O
they	O
should	O
be	O
.	O

But	O
my	O
results	O
are	O
not	O
similar	O
with	O
the	O
ones	O
in	O
the	O
tutorial	O
(	O
or	O
maybe	O
they	O
are	O
and	O
I	O
can't	O
interpret	O
them	O
right	O
?	O
)	O
.	O

With	O
n_components=4	O
I	O
obtain	O
the	O
following	O
graph	O
n_components4	O
.	O

I	O
am	O
probably	O
missing	O
something	O
somewhere	O
,	O
I've	O
also	O
added	O
the	O
code	O
I	O
have	O
so	O
far	O
.	O

If	O
you	O
have	O
too	O
many	O
levels	O
for	O
this	O
to	O
work	O
,	O
or	O
you	O
want	O
to	O
consider	O
the	O
individual	O
words	O
in	O
`	O
catB	O
`	O
as	O
well	O
as	O
the	O
bigrams	O
,	O
you	O
could	O
apply	O
your	O
`	O
CountVectorizer	O
`	O
separately	O
to	O
each	O
column	O
,	O
and	O
then	O
use	O
and	O
use	O
`	O
hstack	B-API
`	O
to	O
concatenate	O
the	O
resulting	O
output	O
matrices	O
:	O
#CODE	O

Using	O
`	O
apply	O
`	O
check	O
if	O
value	O
is	O
list	O
`	O
isinstance	O
(	O
x	O
,	O
list	O
)`	O
and	O
take	O
the	O
value	O
,	O
and	O
then	O
`	O
apply	O
(	O
pd.Series	B-API
,	O
1	O
)`	O
to	O
split	O
as	O
columns	O
#CODE	O

I	O
would	O
like	O
to	O
change	O
the	O
value	O
of	O
a	O
`	O
Pandas	O
`	O
DataFrame	B-API
based	O
on	O
index	O
and	O
column	O
.	O

I	O
am	O
getting	O
an	O
error	O
`	O
A	O
value	O
is	O
trying	O
to	O
be	O
set	O
on	O
a	O
copy	O
of	O
a	O
slice	O
from	O
a	O
DataFrame	B-API
`	O
.	O

I	O
searched	O
around	O
and	O
found	O
similar	O
questions	O
/	O
answers	O
,	O
but	O
none	O
that	O
I	O
was	O
able	O
to	O
apply	O
.	O

#CODE	O

You	O
can	O
apply	O
a	O
lambda	O
function	O
to	O
the	O
column	O
of	O
the	O
data	O
frame	O
,	O
extracting	O
the	O
date	O
from	O
the	O
dictionary	O
via	O
`	O
x	O
[	O
'	O
$date	O
']`	O
,	O
and	O
then	O
just	O
take	O
the	O
date	O
/	O
time	O
portion	O
(	O
ignoring	O
the	O
time	O
offset	O
)	O
.	O

As	O
this	O
is	O
a	O
'	O
datetime	O
naive	O
'	O
object	O
,	O
Python	O
wouldn't	O
know	O
what	O
to	O
do	O
with	O
any	O
timezone	O
adjustment	O
.	O

Use	O
this	O
stripped	O
date	O
/	O
time	O
string	O
(	O
e.g.	O
'	O
2014-11-04T17	O
:	O
27:50	O
.000	O
')	O
as	O
the	O
input	O
to	O
`	O
strptime	O
`	O
.	O

#CODE	O

apply	O
function	O
throws	O
an	O
error	O
=	O
DataFrame	B-API
'	O
object	O
has	O
no	O
attribute	O
'	O
datetime	O
'	O
Checked	O
Pandas	O
version	O
,	O
its	O
Also	O
dt.datetime	O
should	O
be	O
df.datetime	O
(	O
just	O
a	O
typo	O
)	O
right	O
?	O

What	O
the	O
`	O
apply	O
`	O
function	O
does	O
,	O
is	O
that	O
for	O
each	O
row	O
value	O
of	O
`	O
df	O
[	O
'	O
A	O
']`	O
,	O
it	O
calls	O
the	O
`	O
applyFunc	O
`	O
function	O
with	O
the	O
parameter	O
as	O
the	O
value	O
of	O
that	O
row	O
,	O
and	O
the	O
returned	O
value	O
is	O
put	O
into	O
the	O
same	O
row	O
for	O
`	O
df	O
[	O
'	O
B	O
']`	O
,	O
what	O
really	O
happens	O
behind	O
the	O
scene	O
is	O
a	O
bit	O
different	O
though	O
,	O
the	O
value	O
is	O
not	O
directly	O
put	O
into	O
`	O
df	O
[	O
'	O
B	O
']`	O
but	O
rather	O
a	O
new	O
`	O
Series	O
`	O
is	O
created	O
and	O
at	O
the	O
end	O
,	O
the	O
new	O
Series	O
is	O
assigned	O
to	O
`	O
df	O
[	O
'	O
B	O
']`	O
.	O

You	O
can	O
define	O
an	O
explicit	O
function	O
to	O
apply	O
to	O
the	O
entire	O
`	O
Name	O
`	O
Series	O
.	O

#CODE	O

@USER	O
Shouldn't	O
I	O
apply	O
`	O
split	O
`	O
as	O
:	O
`	O
df	O
[	O
'	O
Description	O
']	O
=	O
df	O
[	O
'	O
Name	O
']	O
.map	B-API
(	O
split	O
)`	O
to	O
run	O
it	O
?	O

Or	O
similar	O

Applymap	B-API
is	O
for	O
the	O
whole	O
df	O
,	O
is	O
you	O
;	O
re	O
doing	O
just	O
a	O
single	O
column	O
(	O
series	O
)	O
,	O
then	O
just	O
use	O
apply	O
.	O

Sorry	O
you're	O
trying	O
to	O
apply	O
to	O
a	O
groupby	B-API
object	O
?	O

Does	O
it	O
work	O
after	O
calling	O
`	O
reset_index()	B-API
`	O
?	O

really	O
you	O
should	O
post	O
a	O
new	O
question	O
as	O
chaning	O
the	O
requirements	O
loses	O
context	O
for	O
the	O
changes	O
.	O

Interested	O
to	O
apply	O
multivariate	O
hexagonal	O
binning	O
to	O
this	O
and	O
different	O
color	O
hexagoan	O
for	O
each	O
unique	O
column	O
"	O
ball	O
,	O
mouse	O
...	O
etc	O
"	O
.	O
scikit	O
offers	O
hexagoanal	O
binning	O
but	O
cant	O
figure	O
out	O
how	O
to	O
render	O
different	O
colors	O
for	O
each	O
hexagon	O
based	O
on	O
the	O
unique	O
data	O
point	O
.	O

Any	O
other	O
visualization	O
technique	O
would	O
also	O
help	O
in	O
this	O
.	O

interested	O
to	O
apply	O
hexagonal	O
binning	O
to	O
this	O
#URL	O

Converting	O
multiple	O
columns	O
to	O
categories	O
in	O
Pandas	O
.	O
apply	O
?	O

Why	O
does	O
`	O
apply	O
`	O
(	O
`	O
axis=0	O
`)	O
return	O
a	O
Series	O
even	O
though	O
it	O
is	O
supposed	O
to	O
act	O
on	O
the	O
columns	O
one	O
by	O
one	O
?	O

I'd	O
suggest	O
that	O
you	O
use	O
`	O
groupby	B-API
`	O
/	O
`	O
apply	O
`	O
returning	O
a	O
`	O
Series	O
`	O
(	O
see	O
Returning	O
Multiple	O
Values	O
From	O
Apply	O
)	O
.	O

I	O
think	O
the	O
way	O
you	O
did	O
it	O
is	O
probably	O
best	O
.	O

I'm	O
not	O
sure	O
'	O
vectorized	O
'	O
has	O
any	O
real	O
meaning	O
in	O
your	O
situation	O
.	O

To	O
the	O
extent	O
where	O
you	O
would	O
gain	O
speed	O
,	O
I	O
think	O
you'd	O
have	O
to	O
already	O
have	O
a	O
square	O
dataframe	B-API
with	O
rows	O
and	O
column	O
in	O
the	O
same	O
order	O
.	O

Given	O
that	O
neither	O
of	O
those	O
conditions	O
apply	O
here	O
,	O
I	O
don't	O
see	O
a	O
reason	O
to	O
change	O
what	O
you	O
have	O
.	O

You	O
could	O
also	O
do	O
it	O
with	O
apply	O
,	O
but	O
it	O
will	O
be	O
slower	O
than	O
the	O
`	O
np.where	B-API
`	O
approach	O
(	O
but	O
approximately	O
the	O
same	O
speed	O
as	O
what	O
you	O
are	O
currently	O
doing	O
)	O
,	O
though	O
much	O
simpler	O
.	O

That's	O
probably	O
a	O
good	O
example	O
of	O
why	O
you	O
should	O
always	O
avoid	O
`	O
apply	O
`	O
if	O
possible	O
,	O
when	O
you	O
care	O
about	O
speed	O
.	O

#CODE	O

You	O
could	O
also	O
do	O
this	O
,	O
which	O
is	O
faster	O
than	O
`	O
apply	O
`	O
but	O
slower	O
than	O
`	O
np.where	B-API
`	O
:	O
#CODE	O

Pandas	O
Apply	O
function	O
on	O
Column	O

You	O
don't	O
have	O
to	O
call	O
`	O
grouped	O
[	O
'	O
B	O
']`	O
`	O
grouped	O
[	O
'	O
C	O
']`	O
one	O
by	O
one	O
,	O
simply	O
pass	O
your	O
entire	O
groupby	B-API
object	O
and	O
pandas	O
will	O
apply	O
the	O
aggregate	O
functions	O
to	O
all	O
columns	O
.	O

#CODE	O

This	O
is	O
a	O
little	O
messed	O
up	O
,	O
firstly	O
split	O
the	O
'	O
codes	O
'	O
column	O
on	O
the	O
separator	O
and	O
`	O
apply	O
`	O
`	O
map	O
`	O
to	O
each	O
element	O
and	O
pass	O
the	O
other	O
df	O
with	O
the	O
index	O
set	O
to	O
'	O
code	O
'	O
,	O
this	O
will	O
perform	O
a	O
lookup	O
,	O
we	O
reduce	O
this	O
to	O
just	O
the	O
codes	O
that	O
match	O
.	O

Is	O
this	O
really	O
what	O
you	O
want	O
to	O
do	O
?	O

Ideally	O
you	O
want	O
to	O
avoid	O
using	O
`	O
apply	O
`	O
if	O
there	O
is	O
a	O
vectorised	O
method	O
,	O
so	O
just	O
`	O
df	O
[	O
'	O
x	O
']	O
+	O
df	O
[	O
'	O
y	O
']`	O
would	O
work	O

You	O
can	O
apply	O
a	O
function	O
row-wise	O
by	O
setting	O
`	O
axis=1	O
`	O
#CODE	O

`	O
groupby	B-API
/	O
apply	O
`	O
to	O
a	O
columns	O
of	O
`	O
df	O
`	O
unless	O
the	O
columns	O
or	O
levels	O
you	O
group	O
by	O

Select	O
your	O
columns	O
from	O
the	O
DataFrame	B-API
and	O
then	O
apply	O
your	O
function	O
(	O
possibly	O
a	O
`	O
lambda	O
`	O
expression	O
depending	O
on	O
usage	O
)	O
.	O

#CODE	O

If	O
you	O
have	O
pandas	O
version	O
>	O
=	O
`	O
0.17.0	O
`	O
you	O
could	O
try	O
to	O
apply	O
`	O
pandas.to_numeric	B-API
`	O
for	O
each	O
column	O
(	O
or	O
may	O
be	O
you	O
know	O
suspicious	O
columns	O
):	O
#CODE	O

We	O
could	O
see	O
that	O
it's	O
slower	O
then	O
convert_object	O
.	O

Let's	O
pass	O
`	O
raw=True	O
`	O
for	O
`	O
apply	O
`	O
:	O
#CODE	O

`	O
apply	O
`	O
might	O
work	O
well	O
for	O
you	O
here	O
:	O
#CODE	O

I	O
have	O
a	O
list	O
of	O
servers	O
,	O
and	O
each	O
server	O
has	O
a	O
number	O
of	O
patches	O
that	O
apply	O
to	O
that	O
server	O
.	O

The	O
excel	O
looks	O
a	O
bit	O
like	O
this	O
:	O
#CODE	O

I	O
realise	O
there	O
have	O
been	O
a	O
lot	O
of	O
similar	O
questions	O
on	O
here	O
,	O
but	O
I	O
am	O
new	O
to	O
pandas	O
and	O
can't	O
seem	O
to	O
apply	O
the	O
right	O
syntax	O
to	O
my	O
problem	O
using	O
the	O
documentation	O
-	O
can	O
anyone	O
help	O
?	O

I'm	O
trying	O
to	O
figure	O
out	O
how	O
to	O
apply	O
a	O
lambda	O
function	O
to	O
multiple	O
dataframes	O
simultaneously	O
,	O
without	O
first	O
merging	O
the	O
data	O
frames	O
together	O
.	O

I	O
am	O
working	O
with	O
large	O
data	O
sets	O
(	O
>	O
60MM	O
records	O
)	O
and	O
I	O
need	O
to	O
be	O
extra	O
careful	O
with	O
memory	O
management	O
.	O

My	O
hope	O
is	O
that	O
there	O
is	O
a	O
way	O
to	O
apply	O
lambda	O
to	O
just	O
the	O
underlying	O
dataframes	O
so	O
that	O
I	O
can	O
avoid	O
the	O
cost	O
of	O
stitching	O
them	O
together	O
first	O
,	O
and	O
then	O
dropping	O
that	O
intermediary	O
dataframe	B-API
from	O
memory	O
before	O
I	O
move	O
on	O
to	O
the	O
next	O
step	O
in	O
the	O
process	O
.	O

However	O
,	O
it	O
is	O
slower	O
since	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
is	O
doing	O
an	O
addition	O
and	O
division	O
once	O
for	O
each	O
group	O
,	O
whereas	O
#CODE	O

However	O
,	O
it	O
is	O
slower	O
since	O
the	O
`	O
groupby	B-API
/	O
apply	O
`	O
is	O
doing	O
an	O
addition	O
and	O
division	O
once	O
for	O
each	O
group	O
,	O
whereas	O
#CODE	O

So	O
far	O
I	O
can	O
think	O
of	O
`	O
apply	O
`	O
followed	O
by	O
`	O
itertools.chain	O
`	O
,	O
but	O
I	O
am	O
wondering	O
if	O
there	O
is	O
a	O
one-step	O
solution	O
.	O

Group	O
by	O
uid	O
and	O
apply	O
`	O
value_counts	B-API
`	O
to	O
the	O
msg	O
column	O
:	O
#CODE	O

Apply	O
`	O
groupby	B-API
`	O
on	O
both	O
`	O
id	O
`	O
and	O
`	O
msg	O
`	O
,	O
and	O
then	O
sum	O
the	O
`	O
count	O
`	O
of	O
each	O
:	O
#CODE	O

How	O
did	O
you	O
check	O
if	O
anything	O
was	O
written	O
?	O

The	O
`	O
if	O
os.path.isfile()	O
`	O
is	O
not	O
going	O
to	O
cause	O
much	O
overhead	O
and	O
is	O
easy	O
to	O
apply	O
the	O
logic	O

I	O
am	O
not	O
sure	O
what	O
I	O
am	O
doing	O
wrong	O
here	O
,	O
I	O
am	O
simply	O
trying	O
to	O
call	O
a	O
function	O
with	O
a	O
if-then-else	O
filter	O
in	O
it	O
and	O
apply	O
to	O
a	O
dataframe	B-API
.	O

#CODE	O

You	O
want	O
to	O
apply	O
it	O
to	O
each	O
row	O
,	O
this	O
will	O
do	O
what	O
you	O
want	O
using	O
apply	O
and	O
a	O
lambda	O
:	O
#CODE	O

`	O
df.apply	B-API
`	O
has	O
performance	O
comparable	O
to	O
a	O
Python	O
`	O
for-loop	O
`	O
.	O

Sometimes	O
using	O
apply	O
or	O
a	O
for-loop	O
to	O
compute	O
row-by-row	O
is	O
unavoidable	O
,	O
but	O
in	O
this	O
case	O
a	O
quicker	O
alternative	O
would	O
be	O
express	O
the	O
calculation	O
as	O
one	O
done	O
on	O
whole	O
columns	O
.	O

thanks	O
for	O
the	O
added	O
color	O
.	O

.	O
.	O

.I	O
just	O
checked	O
,	O
in	O
my	O
application	O
,	O
this	O
is	O
5.3	O
times	O
faster	O
than	O
my	O
"	O
def	O
"	O
solution	O
and	O
2.8	O
times	O
faster	O
than	O
the	O
df	O
,	O
apply	O
approach	O
.	O

Thank	O
you	O

Apply	O
curve_fit	O
within	O
a	O
loop	O

Now	O
,	O
I	O
would	O
like	O
to	O
apply	O
a	O
fit	O
to	O
each	O
frequency	O
group	O
(	O
400	O
,	O
800	O
and	O
1200	O
)	O
and	O
do	O
this	O
efficiently	O
within	O
a	O
loop	O
.	O

The	O
first	O
attempt	O
is	O
:	O
#CODE	O

I	O
hope	O
,	O
that	O
there	O
is	O
someone	O
,	O
who	O
could	O
explain	O
,	O
if	O
it	O
is	O
possible	O
to	O
apply	O
the	O
curv_fit	O
routine	O
within	O
a	O
loop	O
and	O
if	O
so	O
-	O
how	O
.	O

You	O
should	O
be	O
able	O
to	O
do	O
this	O
using	O
`	O
apply	O
`	O
which	O
is	O
for	O
applying	O
a	O
function	O
to	O
every	O
row	O
or	O
every	O
column	O
of	O
a	O
data	O
frame	O
.	O

#CODE	O

I	O
am	O
completely	O
new	O
to	O
python	O
and	O
Pandas	O
of	O
course	O
.	O

I	O
am	O
trying	O
to	O
run	O
a	O
function	O
"	O
get	O
url	O
"	O
which	O
is	O
function	O
to	O
get	O
the	O
complete	O
extended	O
url	O
from	O
small	O
Url	O
.	O

I	O
have	O
a	O
data	O
frame	O
in	O
python	O
consists	O
all	O
the	O
short	O
URLs	O
.	O

Now	O
I	O
am	O
trying	O
to	O
do	O
with	O
following	O
ways	O
.	O

One	O
is	O
to	O
use	O
"	O
for	O
"	O
loop	O
which	O
loops	O
and	O
apply	O
function	O
on	O
all	O
the	O
elements	O
and	O
will	O
create	O
a	O
another	O
series	O
of	O
extended	O
URL	O
but	O
I	O
am	O
not	O
able	O
to	O
,	O
dont	O
know	O
why	O
,	O
I	O
tried	O
to	O
write	O
it	O
like	O
#CODE	O

If	O
the	O
short	O
urls	O
are	O
a	O
column	O
in	O
the	O
pandas	O
dataFrame	B-API
,	O
you	O
can	O
use	O
the	O
`	O
apply	O
`	O
function	O
(	O
though	O
I	O
am	O
not	O
sure	O
if	O
they	O
would	O
resume	O
on	O
error	O
,	O
most	O
probably	O
not	O
)	O
.	O

Hi	O
Anand	O
-	O
Thanks	O
for	O
help	O
.	O
but	O
it	O
is	O
working	O
same	O
as	O
apply	O
function	O
.	O
as	O
soon	O
as	O
it	O
faces	O
a	O
error	O
it	O
pass	O
completely	O
.	O
error	O
is	O
like	O
HTTPError	O
:	O
HTTP	O
Error	O
404	O
:	O
Not	O
Found	O
....	O

@USER	O
"	O
Misses	O
the	O
point	O
"	O
is	O
a	O
little	O
harsh	O
!	O

;-)	O
I	O
guess	O
if	O
you	O
want	O
me	O
to	O
explicitly	O
state	O
it	O
,	O
I	O
don't	O
believe	O
it	O
is	O
possible	O
to	O
do	O
what	O
you	O
want	O
without	O
making	O
a	O
copy	O
.	O

Btw	O
you	O
might	O
mean	O
*	O
set	O
*	O
rather	O
than	O
*	O
select	O
*	O
in	O
your	O
question	O
title	O
?	O

Anyway	O
,	O
you're	O
trying	O
to	O
apply	O
a	O
numpy	O
concept	O
to	O
pandas	O
and	O
it	O
doesn't	O
work	O
like	O
that	O
.	O

My	O
edit	O
was	O
merely	O
an	O
attempt	O
to	O
find	O
something	O
faster	O
.	O

I'll	O
edit	O
the	O
answer	O
to	O
make	O
this	O
more	O
obvious	O
.	O

The	O
following	O
works	O
but	O
this	O
really	O
is	O
a	O
loop	O
as	O
it	O
uses	O
`	O
apply	O
`	O
:	O
#CODE	O

That's	O
correct	O
`	O
apply	O
`	O
will	O
not	O
scale	O
well	O
,	O
one	O
thing	O
you	O
could	O
do	O
is	O
assuming	O
that	O
all	O
values	O
are	O
not	O
unique	O
you	O
could	O
create	O
a	O
dict	O
of	O
the	O
unique	O
values	O
as	O
keys	O
and	O
the	O
row	O
position	O
values	O
as	O
the	O
values	O
and	O
merge	O
this	O
,	O
this	O
should	O
perform	O
slightly	O
better	O
,	O
your	O
issue	O
here	O
is	O
that	O
you	O
are	O
trying	O
to	O
compare	O
a	O
scalar	O
against	O
the	O
entire	O
df	O
for	O
every	O
row	O
value	O
,	O
there	O
isn't	O
a	O
built	O
in	O
method	O
for	O
doing	O
this	O
so	O
you	O
have	O
to	O
call	O
`	O
apply	O
`	O
here	O

@USER	O
is	O
there	O
code	O
not	O
listed	O
above	O
that's	O
altering	O
the	O
data	O
frame	O
?	O

For	O
example	O
,	O
how	O
are	O
you	O
apply	O
a	O
Month	O
`	O
Series	O
`	O
to	O
the	O
table	O
?	O

I	O
think	O
you're	O
asking	O
how	O
to	O
apply	O
a	O
function	O
to	O
all	O
columns	O
of	O
a	O
Data	O
Frame	O
:	O
To	O
do	O
this	O
call	O
the	O
`	O
apply	O
`	O
method	O
of	O
your	O
dataframe	B-API
:	O
#CODE	O

Why	O
not	O
try	O
`	O
np.where	B-API
`	O
.	O

It's	O
column-wise	O
vectorized	O
operation	O
and	O
it	O
is	O
much	O
faster	O
than	O
row-wise	O
apply	O
.	O

#CODE	O

I've	O
created	O
a	O
function	O
that	O
looks	O
for	O
rows	O
that	O
have	O
a	O
set	O
of	O
column	O
values	O
that	O
are	O
the	O
same	O
.	O

It's	O
ugly	O
though	O
:	O
nested	O
apply	O
functions	O
.	O

Is	O
there	O
a	O
better	O
way	O
to	O
test	O
if	O
`	O
n	O
`	O
number	O
columns	O
have	O
the	O
same	O
value	O
,	O
and	O
if	O
so	O
apply	O
a	O
function	O
to	O
them	O
or	O
add	O
them	O
to	O
a	O
dictionary	O
?	O

#CODE	O

Ah	O
,	O
yes	O
,	O
that	O
was	O
a	O
bug	O
in	O
0.15	O
preventing	O
you	O
to	O
use	O
such	O
an	O
instantiated	O
class	O
(	O
which	O
is	O
the	O
case	O
when	O
providing	O
a	O
keyword	O
)	O
,	O
see	O
#URL	O
You	O
need	O
0.16	O
for	O
that	O
fix	O
(	O
or	O
you	O
can	O
apply	O
it	O
yourself	O
as	O
it	O
is	O
only	O
a	O
2	O
line	O
fix	O
,	O
see	O
the	O
linked	O
PR	O
)	O

An	O
easy	O
workaround	O
would	O
be	O
to	O
apply	O
`	O
.values	B-API
`	O
to	O
the	O
series	O
first	O
and	O
then	O
apply	O
`	O
std	O
`	O
to	O
these	O
values	O
;	O
in	O
this	O
case	O
`	O
numpy's	O
`	O
`	O
std	O
`	O
is	O
used	O
:	O
#CODE	O

By	O
default	O
,	O
when	O
you	O
`	O
groupby	B-API
`	O
-	O
`	O
sum	O
`	O
a	O
DataFrame	B-API
,	O
pandas	O
doesn't	O
assume	O
that	O
you	O
want	O
to	O
do	O
so	O
for	O
all	O
the	O
columns	O
that	O
are	O
not	O
of	O
the	O
classic	O
numeric	O
types	O
.	O

If	O
you'd	O
have	O
a	O
column	O
of	O
strings	O
,	O
it	O
wouldn't	O
try	O
to	O
apply	O
the	O
sum	O
to	O
them	O
too	O
.	O

Thanks	O
!	O

Was	O
the	O
error	O
with	O
my	O
code	O
because	O
datetime.date	O
works	O
on	O
a	O
single	O
row	O
,	O
and	O
with	O
functions	O
working	O
on	O
rows	O
one	O
at	O
a	O
time	O
I	O
hvae	O
to	O
do	O
apply	O
(	O
fun()	O
)	O
rather	O
than	O
fun	O
(	O
apply()	B-API
)	O
?	O

Here	O
is	O
another	O
alternative	O
that	O
might	O
appear	O
simpler	O
(	O
though	O
learning	O
to	O
apply	O
functions	O
to	O
groups	O
is	O
a	O
great	O
idea	O
!	O
)	O
#CODE	O

Here	O
is	O
one	O
way	O
to	O
do	O
it	O
by	O
defining	O
your	O
own	O
rolling	O
apply	O
function	O
.	O

#CODE	O

Here	O
is	O
one	O
way	O
of	O
approaching	O
it	O
,	O
using	O
the	O
apply	O
method	O
to	O
subtract	O
the	O
first	O
item	O
from	O
all	O
the	O
other	O
obs	O
.	O

#CODE	O

Use	O
`	O
groupby	B-API
/	O
apply	O
`	O
to	O
sort	O
each	O
group	O
individually	O
,	O
and	O
pick	O
off	O
just	O
the	O
top	O
three	O
rows	O
:	O
#CODE	O

At	O
a	O
high-level	O
,	O
this	O
indicates	O
that	O
we	O
would	O
like	O
to	O
look	O
at	O
each	O
country	O
differently	O
.	O

Now	O
our	O
goal	O
is	O
to	O
determine	O
the	O
top	O
3	O
metric	O
counts	O
and	O
report	O
the	O
corresponding	O
channel	O
.	O

To	O
do	O
this	O
,	O
we	O
will	O
apply	O
a	O
sort	O
to	O
the	O
resulting	O
data-frame	O
and	O
then	O
only	O
return	O
the	O
top	O
3	O
results	O
.	O

We	O
can	O
do	O
this	O
by	O
defining	O
a	O
sort	O
function	O
that	O
returns	O
only	O
the	O
top	O
3	O
results	O
and	O
use	O
the	O
apply	O
function	O
in	O
pandas	O
.	O

This	O
indicates	O
to	O
panda	O
that	O
"	O
I	O
want	O
to	O
apply	O
this	O
sort	O
function	O
to	O
each	O
of	O
our	O
groups	O
and	O
return	O
the	O
top	O
3	O
results	O
for	O
each	O
group	O
"	O
.	O

you	O
want	O
to	O
access	O
the	O
index	O
inside	O
the	O
`	O
apply	O
`	O
function	O
,	O
and	O
I	O
don't	O
think	O
you	O
can	O

and	O
then	O
use	O
the	O
apply	O
function	O
,	O
#CODE	O

You	O
need	O
`	O
apply	O
(	O
your_func	O
,	O
axis=1	O
)`	O
to	O
work	O
on	O
a	O
row-by-row	O
basis	O
.	O

#CODE	O

This	O
could	O
be	O
done	O
in	O
2	O
steps	O
,	O
generate	O
a	O
new	O
column	O
that	O
creates	O
the	O
expanded	O
str	O
values	O
,	O
then	O
`	O
groupby	B-API
`	O
on	O
'	O
A	O
'	O
and	O
`	O
apply	O
`	O
`	O
list	O
`	O
to	O
this	O
new	O
column	O
:	O
#CODE	O

@USER	O
sorry	O
what	O
do	O
you	O
mean	O
,	O
do	O
you	O
mean	O
the	O
fact	O
I	O
added	O
an	O
intermediate	O
column	O
?	O

The	O
intermediate	O
step	O
is	O
necessary	O
as	O
I	O
can't	O
figure	O
out	O
how	O
to	O
get	O
the	O
`	O
apply	O
`	O
and	O
`	O
lambda	O
`	O
to	O
not	O
try	O
to	O
expand	O
the	O
list	O
and	O
remain	O
1-dimensional	O

Another	O
way	O
to	O
do	O
it	O
.	O

First	O
reshape	O
the	O
`	O
df	O
`	O
using	O
`	O
pivot_table	B-API
`	O
and	O
then	O
`	O
apply	O
`	O
`	O
np.repeat()	B-API
.tolist()	B-API
`	O
.	O

#CODE	O

You	O
can	O
`	O
apply	O
`	O
`	O
round	O
`	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
apply	O
to	O
a	O
specific	O
number	O
of	O
places	O
:	O
#CODE	O

You	O
can	O
`	O
groupby	B-API
`	O
on	O
'	O
Symbol	O
'	O
and	O
then	O
call	O
`	O
apply	O
`	O
passing	O
a	O
lambda	O
and	O
use	O
`	O
shift	O
`	O
:	O
#CODE	O

To	O
calculate	O
the	O
new	O
'	O
Skew	O
'	O
column	O
,	O
you	O
can	O
do	O
a	O
`	O
groupby	B-API
`	O
and	O
define	O
your	O
customized	O
`	O
apply	O
`	O
function	O
.	O

To	O
calculate	O
pct_change	B-API
,	O
you	O
can	O
use	O
the	O
`	O
.shift()	B-API
`	O
operator	O
.	O

#CODE	O

I	O
am	O
using	O
scikit	O
learning's	O
StandardScaler()	O
and	O
notice	O
that	O
after	O
I	O
apply	O
a	O
transform	O
(	O
xtrain	O
)	O
or	O
fit_transform	O
(	O
xtrain	O
)	O
,	O
it	O
also	O
changes	O
my	O
xtrain	O
dataframe	B-API
.	O

Is	O
this	O
supposed	O
to	O
happen	O
?	O

How	O
can	O
I	O
avoid	O
the	O
StandardScaler	O
from	O
changing	O
my	O
dataframe	B-API
?	O

(	O
I	O
have	O
tried	O
using	O
copy=False	O
)	O
#CODE	O

How	O
to	O
apply	O
line	O
attribute	O
at	O
each	O
group	O
?	O

`	O
1	O
/	O
2	O
ID	O
`	O
is	O
the	O
column	O
head	O
that	O
need	O
to	O
apply	O
UPPERCASE	O
.	O

How	O
can	O
I	O
apply	O
upper	O
case	O
to	O
the	O
first	O
three	O
letters	O
in	O
the	O
column	O
of	O
the	O
DataFrame	B-API
`	O
df	O
`	O
?	O

@USER	O
It's	O
due	O
to	O
the	O
current	O
implementation	O
of	O
pandas	O
`	O
groupby	B-API
`	O
.	O

See	O
this	O
Warning	O
Message	O
:	O
`	O
Warning	O
In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O
first	O
group	O
to	O
decide	O
whether	O
it	O
can	O
take	O
a	O
fast	O
or	O
slow	O
code	O
path	O
.	O

This	O
can	O
lead	O
to	O
unexpected	O
behavior	O
if	O
func	O
has	O
side-effects	O
,	O
as	O
they	O
will	O
take	O
effect	O
twice	O
for	O
the	O
first	O
group	O
.	O

`	O
from	O
#URL	O

`	O
df	O
[	O
i	O
]`	O
gets	O
each	O
column	O
.	O

`	O
apply	O
(	O
Series	O
)`	O
applys	O
`	O
Series	O
`	O
function	O
to	O
the	O
column	O
,	O
which	O
creates	O
`	O
Series	O
`	O
from	O
the	O
inner	O
`	O
dict	O
`	O
.	O

`	O
join	O
`	O
append	O
created	O
`	O
Series	O
`	O
to	O
the	O
end	O
of	O
column	O
,	O
and	O
`	O
drop	O
`	O
deletes	O
the	O
original	O
column	O
.	O

Python	O
apply	O
a	O
func	O
to	O
two	O
lists	O
of	O
lists	O
,	O
store	O
the	O
result	O
in	O
a	O
Dataframe	B-API

I	O
am	O
trying	O
to	O
do	O
a	O
dataframe	B-API
transformation	O
that	O
I	O
cannot	O
solve	O
.	O

I	O
have	O
tried	O
multiple	O
approaches	O
from	O
stackoverflow	O
and	O
the	O
pandas	O
documentation	O
:	O
apply	O
,	O
apply	O
(	O
lambda	O
:	O
...	O
)	O
,	O
pivots	O
,	O
and	O
joins	O
.	O

Too	O
many	O
attempts	O
to	O
list	O
here	O
,	O
but	O
not	O
sure	O
which	O
approach	O
is	O
the	O
best	O
or	O
if	O
maybe	O
I	O
tried	O
the	O
right	O
approach	O
with	O
the	O
wrong	O
syntax	O
.	O

I	O
came	O
pretty	O
close	O
with	O
the	O
melt()	B-API
function	O
,	O
and	O
then	O
taking	O
the	O
former	O
column	O
numbers	O
and	O
added	O
the	O
offset	O
to	O
them	O
.	O

However	O
,	O
I've	O
had	O
a	O
lot	O
of	O
problems	O
trying	O
to	O
reform	O
the	O
dataframe	B-API
using	O
pivot	B-API
.	O

No	O
luck	O
with	O
apply	O
or	O
apply	O
(	O
lambda	O
)	O
!	O

You	O
can	O
use	O
`	O
groupby	B-API
`	O
on	O
column	O
'	O
ts	O
'	O
,	O
and	O
then	O
`	O
apply	O
`	O
using	O
`	O
.any()	B-API
`	O
to	O
determine	O
whether	O
any	O
of	O
`	O
val	O
`	O
is	O
`	O
True	O
`	O
in	O
the	O
cluster	O
/	O
group	O
.	O

#CODE	O

@USER	O
Yes	O
.	O

We	O
can	O
just	O
first	O
divide	O
the	O
full	O
dataset	O
using	O
`	O
groupby	B-API
`	O
,	O
and	O
then	O
apply	O
the	O
above	O
procedure	O
within	O
each	O
group	O
.	O

I've	O
updated	O
the	O
code	O
.	O

The	O
`	O
NaN	O
`	O
at	O
the	O
bottom	O
is	O
because	O
the	O
2nd	O
group	O
just	O
29	O
rows	O
whereas	O
1st	O
group	O
has	O
71	O
rows	O
.	O

This	O
is	O
a	O
general	O
question	O
about	O
how	O
to	O
apply	O
a	O
function	O
efficiently	O
in	O
pandas	O
.	O

I	O
often	O
encounter	O
situations	O
where	O
I	O
need	O
to	O
apply	O
a	O
function	O
to	O
a	O
`	O
pd.Series	B-API
`	O
and	O
it	O
would	O
be	O
faster	O
to	O
apply	O
the	O
function	O
only	O
to	O
unique	O
values	O
.	O

But	O
for	O
large	O
data	O
sets	O
,	O
this	O
can	O
take	O
a	O
while	O
.	O

So	O
to	O
speed	O
it	O
up	O
,	O
I'll	O
extract	O
the	O
unique	O
values	O
of	O
`	O
date	O
`	O
,	O
apply	O
the	O
function	O
to	O
those	O
,	O
and	O
then	O
merge	O
it	O
back	O
in	O
to	O
the	O
original	O
data	O
:	O
#CODE	O

And	O
,	O
would	O
it	O
make	O
sense	O
and	O
be	O
feasible	O
to	O
add	O
a	O
feature	O
to	O
pandas	O
that	O
would	O
take	O
this	O
unique	O
/	O
apply	O
/	O
merge	O
approach	O
automatically	O
?	O

(	O
It	O
wouldn't	O
work	O
for	O
certain	O
functions	O
,	O
such	O
as	O
those	O
that	O
rely	O
on	O
rolling	O
data	O
,	O
so	O
presumably	O
the	O
user	O
would	O
have	O
to	O
explicitly	O
request	O
this	O
behavior	O
.	O
)	O

@USER	O
Doesn't	O
the	O
`	O
apply	O
`	O
need	O
to	O
be	O
`	O
transform	O
`	O
if	O
you	O
are	O
going	O
to	O
be	O
back	O
to	O
your	O
full	O
size	O
data	O
and	O
not	O
a	O
collapsed	O
version	O
?	O

I.e.	O

don't	O
you	O
still	O
need	O
to	O
merge	O
here	O
?	O

Also	O
,	O
when	O
I	O
time	O
this	O
,	O
it's	O
actually	O
slower	O
than	O
either	O
of	O
the	O
original	O
methods	O
and	O
I	O
thought	O
the	O
point	O
of	O
this	O
whole	O
thing	O
was	O
speed	O
?	O

(	O
Perhaps	O
my	O
timing	O
was	O
off	O
though	O
,	O
you	O
can	O
check	O
yourself	O
,	O
of	O
course	O
)	O
But	O
to	O
be	O
clear	O
,	O
I	O
do	O
think	O
the	O
`	O
groupby	B-API
`	O
with	O
`	O
transform	O
`	O
is	O
probably	O
the	O
most	O
clear	O
and	O
readable	O
approach	O
.	O

It's	O
just	O
not	O
any	O
sort	O
of	O
speed	O
improvement	O
that	O
I	O
can	O
see	O
.	O

How	O
to	O
apply	O
a	O
function	O
on	O
a	O
Series	O

I	O
would	O
like	O
a	O
apply	O
a	O
function	O
to	O
rename	O
the	O
values	O
.	O

#CODE	O

Your	O
error	O
occurred	O
because	O
you	O
called	O
apply	O
on	O
a	O
single	O
column	O
df	O
:	O
#CODE	O

So	O
this	O
is	O
different	O
to	O
a	O
Series	O
where	O
`	O
apply	O
`	O
iterates	O
over	O
each	O
value	O
which	O
can	O
be	O
hashed	O
but	O
here	O
it's	O
passing	O
the	O
entire	O
`	O
Series	O
`	O
which	O
cannot	O
be	O
hashed	O
,	O
it	O
would	O
work	O
if	O
you	O
did	O
this	O
:	O
#CODE	O

We	O
can	O
generated	O
the	O
edge	O
list	O
using	O
`	O
groupby	B-API
/	O
apply	O
`	O
and	O

Basically	O
,	O
I	O
want	O
to	O
apply	O
the	O
same	O
transformation	O
to	O
a	O
huge	O
data	O
set	O
I'm	O
working	O
on	O
now	O
,	O
but	O
I'm	O
getting	O
an	O
error	O
message	O
:	O
#CODE	O

Why	O
do	O
I	O
get	O
an	O
object	O
type	O
when	O
apply	O
group	O
by	O
with	O
size	O
instead	O
of	O
an	O
integer	O
type	O
?	O

Since	O
you	O
want	O
to	O
retrieve	O
`	O
category	O
`	O
column	O
as	O
well	O
,	O
a	O
standard	O
`	O
.agg	B-API
`	O
on	O
column	O
`	O
val	O
`	O
won't	O
give	O
you	O
what	O
you	O
want	O
.	O

(	O
also	O
,	O
since	O
there	O
are	O
two	O
values	O
in	O
author3	O
are	O
7	O
,	O
the	O
approach	O
by	O
@USER	O
Cunningham	O
using	O
`	O
.max()	B-API
`	O
will	O
only	O
return	O
one	O
instance	O
instead	O
of	O
both	O
)	O
You	O
can	O
define	O
a	O
customized	O
`	O
apply	O
`	O
function	O
to	O
accomplish	O
your	O
task	O
.	O

#CODE	O

python	O
dask	O
DataFrame	B-API
,	O
support	O
for	O
(	O
trivially	O
parallelizable	O
)	O
row	O
apply	O
?	O

Edit	O
:	O
Thanks	O
@USER	O
for	O
the	O
map	O
function	O
.	O

It	O
seems	O
to	O
be	O
slower	O
than	O
plain	O
pandas	O
apply	O
.	O

Is	O
this	O
related	O
to	O
pandas	O
GIL	O
releasing	O
issue	O
or	O
am	O
I	O
doing	O
it	O
wrong	O
?	O

#CODE	O

You	O
can	O
apply	O
your	O
function	O
to	O
all	O
of	O
the	O
partitions	O
of	O
your	O
dataframe	B-API
with	O
the	O
`	O
map_partitions	O
`	O
function	O
.	O

#CODE	O

Note	O
that	O
func	O
will	O
be	O
given	O
only	O
part	O
of	O
the	O
dataset	O
at	O
a	O
time	O
,	O
not	O
the	O
entire	O
dataset	O
like	O
with	O
`	O
pandas	O
apply	O
`	O
(	O
which	O
presumably	O
you	O
wouldn't	O
want	O
if	O
you	O
want	O
to	O
do	O
parallelism	O
.	O
)	O

But	O
avoid	O
`	O
apply	O
`	O

However	O
,	O
you	O
should	O
really	O
avoid	O
`	O
apply	O
`	O
with	O
custom	O
Python	O
functions	O
,	O
both	O
in	O
Pandas	O
and	O
in	O
Dask	O
.	O

This	O
is	O
often	O
a	O
source	O
of	O
poor	O
performance	O
.	O

It	O
could	O
be	O
that	O
if	O
you	O
find	O
a	O
way	O
to	O
do	O
your	O
operation	O
in	O
a	O
vectorized	O
manner	O
then	O
it	O
could	O
be	O
that	O
your	O
Pandas	O
code	O
will	O
be	O
100x	O
faster	O
and	O
you	O
won't	O
need	O
dask.dataframe	O
at	O
all	O
.	O

Thanks	O
!	O

I	O
tried	O
the	O
map	O
method	O
and	O
it	O
seems	O
to	O
be	O
slower	O
than	O
pandas	O
apply	O
.	O

Could	O
you	O
comment	O
on	O
the	O
edit	O
of	O
original	O
post	O
please	O
?	O

@USER	O
Slightly	O
off	O
topic	O
regarding	O
pandas	O
;	O
i	O
try	O
to	O
use	O
map	O
over	O
apply	O
because	O
I've	O
heard	O
it's	O
faster	O
,	O
but	O
I'm	O
not	O
sure	O
why	O
it's	O
faster	O
.	O

Any	O
clarification	O
or	O
links	O
to	O
clarification	O
would	O
be	O
greatly	O
appreciated	O
.	O

Speeding	O
up	O
Pandas	O
apply	O
function	O

For	O
a	O
relatively	O
big	O
Pandas	O
DataFrame	B-API
(	O
a	O
few	O
100k	O
rows	O
)	O
,	O
I'd	O
like	O
to	O
create	O
a	O
series	O
that	O
is	O
a	O
result	O
of	O
an	O
apply	O
function	O
.	O

The	O
problem	O
is	O
that	O
the	O
function	O
is	O
not	O
very	O
fast	O
and	O
I	O
was	O
hoping	O
that	O
it	O
can	O
be	O
sped	O
up	O
somehow	O
.	O

#CODE	O

No	O
,	O
not	O
for	O
this	O
particular	O
problem	O
.	O

But	O
I	O
think	O
the	O
main	O
problem	O
is	O
the	O
number	O
of	O
calls	O
to	O
the	O
apply	O
function	O
,	O
so	O
`	O
cython	O
`	O
,	O
`	O
numba	O
`	O
,	O
`	O
numexpr	O
`	O
,	O
etc	O
.	O

won't	O
help	O
much	O
to	O
alleviate	O
this	O
.	O

The	O
trick	O
is	O
not	O
to	O
use	O
`	O
apply	O
`	O
,	O
but	O
to	O
do	O
smart	O
selections	O
.	O

#CODE	O

We	O
have	O
to	O
apply	O
the	O
`	O
map	O
(	O
func	O
)`	O
to	O
the	O
series	O
in	O
the	O
dataframe	B-API
:	O
#CODE	O

DataFrame.applymap	B-API
(	O
func	O
):	O
Apply	O
a	O
function	O
to	O
a	O
DataFrame	B-API
that	O
is	O
intended	O
to	O
operate	O
elementwise	O
,	O
i.e.	O
like	O
doing	O
map	O
(	O
func	O
,	O
series	O
)	O
for	O
each	O
series	O
in	O
the	O
DataFrame	B-API

You	O
can	O
convert	O
`	O
datetime64	O
`	O
into	O
whatever	O
string	O
format	O
you	O
like	O
using	O
the	O
`	O
strftime	B-API
`	O
method	O
.	O

In	O
your	O
case	O
you	O
would	O
apply	O
it	O
like	O
this	O
:	O
#CODE	O

@USER	O
Yes	O
,	O
it's	O
possible	O
.	O

You	O
just	O
need	O
to	O
first	O
groupby	B-API
`	O
Id	O
`	O
and	O
then	O
move	O
all	O
the	O
processing	O
into	O
an	O
apply	O
function	O
`	O
my_func	O
`	O
.	O

I've	O
updated	O
the	O
code	O
.	O

Please	O
have	O
a	O
look	O
.	O

The	O
`	O
groupby	B-API
/	O
apply	O
`	O
above	O
returns	O
a	O
`	O
pd.Series	B-API
`	O
.	O

To	O
make	O
this	O
a	O
DataFrame	B-API
,	O
we	O
can	O
make	O
the	O
index	O
level	O
values	O
into	O
columns	O
by	O
calling	O
`	O
reset_index()	B-API
`	O
,	O
and	O
then	O
assign	O
column	O
names	O
to	O
the	O
columns	O
:	O
#CODE	O

apply	O
function	O
to	O
a	O
DataFrame	B-API
GroupBy	B-API
and	O
return	O
fewer	O
columns	O

I	O
want	O
to	O
group	O
my	O
`	O
DataFrame	B-API
`	O
then	O
apply	O
a	O
function	O
of	O
several	O
columns	O
which	O
returns	O
a	O
single	O
result	O
.	O

#CODE	O

This	O
can	O
be	O
fixed	O
using	O
`	O
apply	O
`	O
rather	O
than	O
`	O
agg	O
`	O
,	O
as	O
`	O
apply	O
`	O
has	O
no	O
constraint	O
on	O
the	O
returned	O
shape	O
.	O

#CODE	O

I	O
put	O
a	O
condition	O
for	O
one	O
column	O
in	O
pandas	O
dataframe	B-API
,	O
hopefully	O
it	O
works	O
.	O

But	O
it	O
doesn't	O
work	O
when	O
I	O
apply	O
it	O
for	O
all	O
columns	O
.	O

Yes	O
that	O
works	O
when	O
we	O
are	O
looking	O
for	O
any	O
in	O
the	O
set	O
that	O
is	O
of	O
value	O
1	O
,	O
2	O
.	O

But	O
,	O
we	O
are	O
looking	O
for	O
all	O
of	O
the	O
records	O
B	O
=	O
1	O
and	O
B	O
=	O
2	O
where	O
A	O
=	O
A	O
.	O

In	O
our	O
set	O
we	O
sometimes	O
could	O
have	O
this	O
:	O
B	O
=	O
2	O
but	O
no	O
B	O
=	O
1	O
.	O

We	O
thus	O
want	O
to	O
exclude	O
these	O
.	O

As	O
such	O
the	O
isin()	B-API
doesn't	O
seem	O
to	O
apply	O
?	O

You	O
can	O
use	O
`	O
.max()	B-API
`	O
and	O
apply	O
it	O
row-wise	O
by	O
specifying	O
`	O
axis=1	O
`	O
#CODE	O

However	O
I	O
want	O
to	O
apply	O
the	O
function	O
to	O
each	O
row	O
in	O
the	O
df	O
and	O
make	O
a	O
new	O
column	O
.	O

I've	O
tried	O
the	O
following	O
#CODE	O

You	O
can	O
call	O
`	O
apply	O
`	O
and	O
pass	O
the	O
function	O
you	O
want	O
to	O
execute	O
on	O
every	O
row	O
like	O
the	O
following	O
:	O
#CODE	O

Or	O
do	O
it	O
in	O
a	O
one	O
liner	O
by	O
calling	O
`	O
apply	O
`	O
twice	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
keep	O
all	O
your	O
rows	O
,	O
`	O
group_by	O
`	O
the	O
city	O
/	O
state	O
combination	O
,	O
apply	O
geocoding	O
to	O
it	O
the	O
first	O
one	O
by	O
calling	O
`	O
head	O
(	O
1	O
)`	O
,	O
then	O
duplicate	O
to	O
the	O
remainder	O
rows	O
.	O

Thanks	O
for	O
this	O
response	O
.	O

Incredibly	O
useful	O
information	O
!	O

Although	O
when	O
I	O
did	O
look	O
at	O
[:	O
5	O
]	O
rows	O
of	O
data	O
I	O
received	O
a	O
good	O
dataframe	B-API
.	O

When	O
I	O
applied	O
the	O
function	O
to	O
all	O
(	O
200,000	O
records	O
)	O
I	O
received	O
a	O
time	O
out	O
error	O
.	O

I	O
will	O
have	O
to	O
groupby	B-API
and	O
then	O
apply	O
.	O

Thank	O
you	O
very	O
much	O
.	O

I	O
guess	O
it	O
depends	O
on	O
the	O
number	O
of	O
levels	O
for	O
small	O
number	O
of	O
levels	O
this	O
will	O
be	O
faster	O
than	O
calling	O
apply	O
but	O
code	O
wise	O
it	O
doesn't	O
scale	O
to	O
increasing	O
levels	O
well	O

You	O
can	O
use	O
apply	O
for	O
that	O
:	O
#CODE	O

Yes	O
,	O
that	O
is	O
what	O
apply	O
does	O
.	O

df	O
[	O
df	O
[	O
'	O
Q2	O
']	O
.apply	B-API
(	O
your_custom_function	O
)]	O
.	O

You	O
pass	O
a	O
function	O
into	O
the	O
**	O
column	O
**	O
of	O
the	O
data	O
frame	O
and	O
get	O
rows	O
for	O
matching	O
criteria	O
.	O

Since	O
you	O
only	O
want	O
to	O
change	O
the	O
first	O
element	O
of	O
each	O
group	O
,	O
you	O
can	O
do	O
a	O
customized	O
groupby	B-API
apply	O
function	O
to	O
do	O
this	O
.	O

#CODE	O

After	O
this	O
,	O
I	O
will	O
apply	O
the	O
resample	O
method	O
,	O
and	O
then	O
use	O
the	O
reset_index()	B-API
method	O
to	O
get	O
back	O
a	O
DataFrame	B-API
that	O
looks	O
more	O
or	O
less	O
what	O
I	O
have	O
before	O
:	O
#CODE	O

I	O
have	O
a	O
function	O
which	O
I	O
apply	O
it	O
on	O
the	O
rows	O
of	O
a	O
dataframe	B-API
.	O

This	O
function	O
returns	O
a	O
list	O
of	O
variable	O
length	O
depending	O
on	O
a	O
parameter	O
.	O

Another	O
possibility	O
could	O
be	O
to	O
create	O
dataframes	O
with	O
only	O
the	O
repeated	O
columns	O
,	O
apply	O
either	O
sum	O
or	O
max	O
and	O
then	O
merge	O
everything	O
.	O

Edit	O
:	O
Prior	O
version	O
used	O
apply	O
/	O
lambda	O
which	O
is	O
not	O
really	O
necessary	O
.	O

This	O
is	O
a	O
simpler	O
version	O
.	O

Why	O
does	O
order	O
of	O
comparison	O
matter	O
for	O
this	O
apply	O
/	O
lambda	O
inequality	O
?	O

Assuming	O
your	O
logic	O
for	O
function	O
`	O
week	O
(	O
rawdate	O
)`	O
is	O
correct	O
,	O
You	O
can	O
use	O
the	O
`	O
series.apply	B-API
`	O
function	O
to	O
apply	O
a	O
function	O
to	O
all	O
values	O
in	O
a	O
series	O
(	O
a	O
pandas	O
column	O
)	O
,	O
and	O
this	O
returns	O
a	O
new	O
series	O
,	O
which	O
you	O
can	O
assign	O
to	O
your	O
new	O
pandas	O
column	O
.	O

anyway	O
try	O
the	O
`	O
apply	O
`	O
function	O
i	O
specified	O
above	O
.	O

With	O
that	O
as	O
a	O
template	O
for	O
the	O
desired	O
output	O
,	O
we	O
can	O
just	O
loop	O
over	O
the	O
relevant	O
columns	O
of	O
the	O
original	O
dataframe	B-API
and	O
use	O
`	O
groupby	B-API
/	O
apply	O
`	O
with	O
`	O
join	O
/	O
unique	O
`	O
to	O
replace	O
the	O
values	O
in	O
the	O
existing	O
columns	O
:	O
#CODE	O

Hi	O
Thanks	O
for	O
the	O
solution	O
.	O

I	O
tried	O
to	O
apply	O
this	O
on	O
my	O
data	O
set	O
.	O

However	O
it	O
gives	O
an	O
error	O
"	O
T	B-API
#URL	O
item	O
0	O
:	O
expected	O
string	O
,	O
int	O
found	O
"	O
.Upon	O
close	O
inspection	O
..	O

my	O
data	O
set	O
has	O
dates	O
and	O
integers	O
..	O

so	O
i	O
converted	O
the	O
data	O
frame	O
to	O
strings	O
using	O
applymap	B-API
(	O
str	O
)	O
..	O
that	O
is	O
still	O
not	O
helping	O
..	O
how	O
can	O
i	O
concatenate	O
the	O
values	O
?	O

Where	O
row	O
is	O
the	O
dataframe	B-API
`	O
row	O
`	O
.	O

I	O
am	O
assuming	O
your	O
`	O
start	O
`	O
and	O
`	O
end	O
`	O
columns	O
are	O
`	O
datetime	O
`	O
objects	O
.	O

Then	O
you	O
can	O
use	O
`	O
DataFrame.apply()	B-API
`	O
function	O
to	O
apply	O
it	O
to	O
each	O
row	O
.	O

#CODE	O

Had	O
to	O
use	O
map	O
instead	O
of	O
apply	O
because	O
of	O
pandas	O
'	O
timedelda64	O
,	O
which	O
doesn't	O
allow	O
a	O
simple	O
addition	O
to	O
a	O
datetime	O
object	O
.	O

Looking	O
at	O
the	O
source	O
code	O
,	O
`	O
dropna	B-API
`	O
appears	O
to	O
only	O
only	O
apply	O
to	O
the	O
values	O
that	O
get	O
assign	O
to	O
`	O
hue	O
`	O
.	O

For	O
now	O
,	O
simply	O
drop	O
the	O
NAs	O
yourself	O
via	O
the	O
appropriate	O
pandas	O
methods	O
.	O

There	O
might	O
also	O
be	O
a	O
way	O
to	O
do	O
this	O
with	O
a	O
loop	O
or	O
`	O
apply	O
`	O
,	O
can't	O
quite	O
think	O
how	O
though	O
.	O

So	O
I	O
am	O
wondering	O
whether	O
there	O
is	O
a	O
way	O
to	O
accelerate	O
this	O
process	O
?	O

maybe	O
some	O
vectorized	O
functions	O
on	O
datetime	O
object	O
that	O
I	O
was	O
not	O
aware	O
of	O
?	O

I	O
think	O
one	O
way	O
to	O
slightly	O
improve	O
the	O
speed	O
is	O
to	O
use	O
`	O
multiprocessing	O
`	O
module	O
,	O
and	O
maybe	O
I	O
could	O
expect	O
4-6	O
time	O
faster	O
on	O
a	O
8-core	O
PC	O
.	O

Also	O
,	O
because	O
I	O
invoke	O
python	O
function	O
in	O
the	O
`	O
apply	O
`	O
,	O
cython	O
or	O
jit	O
does	O
not	O
help	O
in	O
this	O
case	O
?	O

Here	O
is	O
one	O
approach	O
where	O
you	O
`	O
apply	O
`	O
a	O
function	O
row	O
by	O
row	O
to	O
generate	O
the	O
two	O
wanted	O
columns	O
:	O
#CODE	O

yes	O
.	O
as	O
stated	O
in	O
the	O
question	O
its	O
a	O
silly	O
example	O
.	O
but	O
its	O
more	O
that	O
dplyr	O
offers	O
me	O
elegant	O
code	O
while	O
also	O
allowing	O
for	O
a	O
flexible	O
syntax	O
.	O

i	O
was	O
wondering	O
how	O
to	O
make	O
this	O
exact	O
code	O
work	O
in	O
python	O
.	O
its	O
more	O
about	O
how	O
to	O
split	O
apply	O
and	O
combine	O
in	O
a	O
similar	O
fashion	O
.	O
not	O
so	O
much	O
that	O
the	O
end	O
result	O
has	O
any	O
meaning	O
.	O

Apply	O
multiple	O
functions	O
to	O
multiple	O
groupby	B-API
columns	O

I	O
have	O
a	O
data	O
set	O
which	O
is	O
actually	O
a	O
occurrence	O
matrix	O
of	O
a	O
feature	O
vector	O
for	O
some	O
numbers	O
of	O
items	O
.	O

In	O
theory	O
,	O
this	O
type	O
of	O
representation	O
helps	O
to	O
apply	O
machine	O
learning	O
algorithms	O
to	O
data	O
set	O
as	O
its	O
normalized	O
.	O

#CODE	O

How	O
could	O
I	O
apply	O
decision	O
tree	O
algorithms	O
such	O
as	O
CART	O
and	O
Naive	O
Bayes	O
for	O
this	O
type	O
of	O
data	O
sets	O
?	O

(	O
I	O
only	O
checked	O
scikit	O
learning	O
library	O
)	O

Hi	O
!	O

Jianxun	O
!	O

Thanks	O
for	O
answering	O
the	O
question	O
!	O

But	O
I	O
cannot	O
apply	O
this	O
to	O
my	O
code	O
...	O

I	O
posted	O
another	O
question	O
..	O

It	O
would	O
be	O
great	O
if	O
you	O
could	O
please	O
check	O
it	O
..	O

This	O
you	O
should	O
do	O
a	O
groupby	B-API
on	O
option	O
and	O
apply	O
a	O
sum	O
and	O
retrieve	O
the	O
count	O
...	O

For	O
you	O
you	O
just	O
need	O
the	O
function	O
and	O
to	O
apply	O
it	O
to	O
your	O
dataframe	B-API

However	O
,	O
no	O
matter	O
how	O
I	O
banged	O
my	O
head	O
,	O
I	O
could	O
not	O
apply	O
`	O
.str	B-API
.contains()	B-API
`	O
to	O
the	O
object	O
returned	O
by	O
`	O
df.columns	O
`	O
-	O
which	O
is	O
an	O
`	O
Index	O
`	O
-	O
nor	O
the	O
one	O
returned	O
by	O
`	O
df.columns.values	O
`	O
-	O
which	O
is	O
an	O
`	O
ndarray	B-API
`	O
.	O

This	O
works	O
fine	O
for	O
what	O
is	O
returned	O
by	O
the	O
"	O
slicing	O
"	O
operation	O
`	O
df	O
[	O
column_name	O
]`	O
,	O
i.e.	O
a	O
`	O
Series	O
`	O
,	O
though	O
.	O

(	O
one	O
could	O
apply	O
any	O
of	O
the	O
`	O
str	O
`	O
functions	O
,	O
of	O
course	O
)	O

Of	O
course	O
in	O
the	O
first	O
solution	O
I	O
could	O
have	O
performed	O
the	O
same	O
kind	O
of	O
regex	O
checking	O
,	O
because	O
I	O
can	O
apply	O
it	O
to	O
the	O
`	O
str	O
`	O
data	O
type	O
returned	O
by	O
the	O
iteration	O
.	O

EDIT	O
:	O
I	O
just	O
found	O
the	O
`	O
Index	O
`	O
method	O
`	O
Index.to_series()	B-API
`	O
,	O
which	O
returns	O
-	O
ehm	O
-	O
a	O
`	O
Series	O
`	O
to	O
which	O
I	O
could	O
apply	O
`	O
.str	B-API
.contains	B-API
(	O
'	O
whatever	O
')`	O
.	O

`	O
test.max	O
(	O
columns=1	O
)`	O
finds	O
the	O
max	O
in	O
each	O
column	O
(	O
like	O
R's	O
`	O
apply	O
(	O
test	O
,	O
2	O
,	O
max	O
)`)	O

I'm	O
trying	O
to	O
replace	O
some	O
NaN	O
values	O
in	O
my	O
data	O
with	O
an	O
empty	O
list	O
[	O
]	O
.	O

However	O
the	O
list	O
is	O
represented	O
as	O
a	O
str	O
and	O
doesn't	O
allow	O
me	O
to	O
properly	O
apply	O
the	O
len()	B-API
function	O
.	O

is	O
there	O
anyway	O
to	O
replace	O
a	O
NaN	O
value	O
with	O
an	O
actual	O
empty	O
list	O
in	O
pandas	O
?	O

#CODE	O

You	O
have	O
to	O
do	O
this	O
using	O
`	O
apply	O
`	O
in	O
order	O
for	O
the	O
list	O
object	O
to	O
not	O
be	O
interpreted	O
as	O
an	O
array	O
to	O
assign	O
back	O
to	O
the	O
df	O
which	O
will	O
try	O
to	O
align	O
the	O
shape	O
back	O
to	O
the	O
original	O
series	O

But	O
then	O
I	O
try	O
to	O
apply	O
it	O
to	O
DataFrame	B-API
obtained	O
from	O
a	O
.csv	O
file	O
:	O
#CODE	O

how	O
to	O
change	O
the	O
following	O
example	O
to	O
apply	O
for	O
a	O
column	O
?	O

say	O
,	O
for	O
any	O
cell	O
in	O
A1	O
:	O
A15	O
,	O
Ai	O
,	O
if	O
the	O
cell	O
in	O
column	O
C	O
in	O
the	O
same	O
row	O
,	O
Ci	O
,	O
is	O
less	O
than	O
the	O
cell	O
in	O
A	O
,	O
we	O
put	O
red	O
color	O
in	O
the	O
cell	O
Ai	O
?	O

I	O
can	O
do	O
a	O
loop	O
but	O
it	O
seems	O
slow	O
for	O
a	O
big	O
file	O
,	O
maybe	O
due	O
to	O
too	O
many	O
I	O
/	O
O	O
in	O
loop	O
#CODE	O

Ideally	O
I	O
would	O
like	O
something	O
like	O
`	O
apply_chunk()	O
`	O
which	O
is	O
the	O
same	O
as	O
apply	O
but	O
only	O
works	O
on	O
a	O
piece	O
of	O
the	O
dataframe	B-API
.	O

I	O
thought	O
`	O
dask	O
`	O
might	O
be	O
an	O
option	O
for	O
this	O
,	O
but	O
`	O
dask	O
`	O
dataframes	O
seemed	O
to	O
have	O
other	O
issues	O
when	O
I	O
used	O
them	O
.	O

This	O
has	O
to	O
be	O
a	O
common	O
problem	O
though	O
,	O
is	O
there	O
a	O
design	O
pattern	O
I	O
should	O
be	O
using	O
for	O
adding	O
columns	O
to	O
large	O
pandas	O
dataframes	O
?	O

whats	O
about	O
using	O
the	O
apply	O
method	O
?	O

However	O
,	O
if	O
your	O
operation	O
is	O
highly	O
custom	O
(	O
as	O
it	O
appears	O
to	O
be	O
)	O
and	O
if	O
Python	O
iterators	O
are	O
fast	O
enough	O
(	O
as	O
they	O
seem	O
to	O
be	O
)	O
then	O
you	O
might	O
just	O
want	O
to	O
stick	O
with	O
that	O
.	O

Anytime	O
you	O
find	O
yourself	O
using	O
`	O
apply	O
`	O
or	O
`	O
iloc	B-API
`	O
in	O
a	O
loop	O
it's	O
likely	O
that	O
Pandas	O
is	O
operating	O
much	O
slower	O
than	O
is	O
optimal	O
.	O

You	O
need	O
to	O
modify	O
the	O
apply	O
`	O
func	O
`	O
as	O
below	O
to	O
count	O
consecutive	O
non-zero	O
values	O
.	O

#CODE	O

I'm	O
trying	O
to	O
export	O
`	O
pandas.DataFrame.describe()	B-API
`	O
to	O
`	O
LaTex	O
`	O
using	O
the	O
`	O
to_latex()	B-API
`	O
-method	O
.	O

This	O
works	O
all	O
fine	O
as	O
long	O
as	O
I	O
don't	O
apply	O
the	O
`	O
groupby()	B-API
`	O
-method	O
beforehand	O
.	O

With	O
a	O
grouped	O
DataFrame	B-API
,	O
the	O
first	O
row	O
has	O
no	O
values	O
,	O
even	O
though	O
its	O
label	O
is	O
`	O
count	O
`	O
.	O

Note	O
that	O
the	O
first	O
row	O
of	O
a	O
grouped	O
dataframe	B-API
is	O
used	O
to	O
mark	O
down	O
the	O
variable	O
used	O
for	O
grouping	O
in	O
iPython	O
notebook	O
.	O

You	O
can	O
define	O
a	O
func	O
which	O
takes	O
the	O
values	O
,	O
sorts	O
them	O
,	O
slices	O
the	O
top	O
2	O
values	O
(	O
`	O
[:	O
2	O
]`)	O
then	O
calculates	O
the	O
difference	O
and	O
returns	O
the	O
second	O
value	O
(	O
as	O
the	O
first	O
value	O
is	O
`	O
NaN	O
`)	O
.	O

You	O
`	O
apply	O
`	O
this	O
and	O
pass	O
arg	O
`	O
axis=1	O
`	O
to	O
apply	O
row-wise	O
:	O
#CODE	O

This	O
can	O
go	O
wrong	O
depending	O
on	O
the	O
column	O
names	O
.	O

It's	O
safer	O
to	O
use	O
`	O
.diff()	B-API
.iloc	B-API
[	O
1	O
]`	O
.	O

Also	O
,	O
this	O
is	O
pretty	O
inefficient	O
as	O
it	O
uses	O
sort	O
and	O
apply	O
,	O
neither	O
of	O
which	O
are	O
necessary	O
.	O

See	O
my	O
answer	O
below	O
.	O

Here's	O
an	O
elegant	O
solution	O
that	O
doesn't	O
involve	O
sorting	O
or	O
defining	O
any	O
functions	O
.	O

It's	O
also	O
fully	O
vectorized	O
as	O
it	O
avoid	O
use	O
of	O
the	O
`	O
apply	O
`	O
method	O
.	O

#CODE	O

Unfortunately	O
offsets	O
don't	O
support	O
operations	O
using	O
array	O
like	O
objects	O
so	O
you	O
have	O
to	O
`	O
apply	O
`	O
the	O
offset	O
for	O
each	O
element	O
:	O
#CODE	O

You	O
can	O
`	O
groupby	B-API
`	O
on	O
'	O
name	O
'	O
and	O
'	O
id	O
'	O
and	O
just	O
`	O
apply	O
`	O
`	O
len	O
`	O
function	O
:	O
#CODE	O

Calling	O
the	O
DataFrame's	O
`	O
any	O
`	O
method	O
will	O
perform	O
better	O
than	O
using	O
`	O
apply	O
`	O
to	O
call	O
Python's	O
builtin	O
`	O
any	O
`	O
function	O
once	O
per	O
row	O
.	O

You	O
can	O
`	O
apply	O
`	O
the	O
function	O
`	O
any	O
`	O
along	O
the	O
rows	O
of	O
`	O
df	O
`	O
by	O
using	O
`	O
axis=1	O
`	O
.	O

In	O
this	O
case	O
I'll	O
only	O
apply	O
`	O
any	O
`	O
to	O
a	O
subset	O
of	O
the	O
columns	O
:	O
#CODE	O

For	O
each	O
station	O
that	O
I'm	O
working	O
with	O
.	O

I	O
want	O
to	O
be	O
able	O
to	O
apply	O
these	O
using	O
a	O
dictionary	O
like	O
so	O
:	O
#CODE	O

Looks	O
like	O
a	O
nice	O
usecase	O
for	O
a	O
multi	O
column	O
apply	O
.	O

Just	O
write	O
a	O
function	O
with	O
your	O
mapping	O
dict	O
.	O

Apply	O
this	O
function	O
to	O
slice	O
of	O
your	O
columns	O
.	O

Finish	O
.	O

#URL	O

`	O
df2	O
[	O
'	O
Date	O
']`	O
first	O
,	O
and	O
then	O
apply	O
`	O
pd.merge	B-API
`	O
to	O
sub-DataFrames	O
of	O
`	O
df1	O
`	O
and	O
`	O
df2	O
`	O
which	O
contain	O
only	O
those	O
dates	O
:	O
#CODE	O

Call	O
`	O
apply	O
`	O
on	O
the	O
'	O
scores	O
'	O
column	O
on	O
the	O
`	O
groupby	B-API
`	O
object	O
and	O
use	O
the	O
vectorise	O
`	O
str	O
`	O
method	O
`	O
contains	O
`	O
,	O
use	O
this	O
to	O
filter	O
the	O
`	O
group	O
`	O
and	O
call	O
`	O
count	O
`	O
:	O
#CODE	O

Outer	O
join	O
will	O
still	O
apply	O
,	O
but	O
the	O
original	O
answer	O
is	O
correct	O
:	O
#CODE	O

`	O
pd.DataFrame.sort()	O
`	O
takes	O
a	O
colum	O
object	O
as	O
argument	O
,	O
which	O
does	O
not	O
apply	O
here	O
,	O
so	O
how	O
can	O
I	O
achieve	O
this	O
?	O

You	O
could	O
use	O
groupby	B-API
/	O
apply	O
with	O
a	O
custom	O
(	O
lambda	O
)	O
function	O
:	O
#CODE	O

You	O
can	O
define	O
a	O
list	O
of	O
the	O
cols	O
of	O
interest	O
and	O
pass	O
this	O
to	O
the	O
groupby	B-API
which	O
will	O
operate	O
on	O
each	O
of	O
these	O
cols	O
via	O
a	O
lambda	O
and	O
`	O
apply	O
`	O
:	O
#CODE	O

We	O
can	O
do	O
this	O
for	O
each	O
row	O
of	O
`	O
dates	O
`	O
by	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

By	O
making	O
`	O
lambda	O
`	O
,	O
above	O
,	O
return	O
a	O
Series	O
,	O
`	O
apply	O
`	O
will	O
return	O
a	O
DataFrame	B-API
,	O

How	O
can	O
I	O
accomplish	O
this	O
in	O
pandas	O
so	O
that	O
the	O
dataframe	B-API
I	O
get	O
contains	O
the	O
statistics	O
of	O
each	O
flow	O
i.e.	O
the	O
columns	O
should	O
contain	O
the	O
`	O
ip_src	O
`	O
,	O
`	O
ip_dst	O
`	O
,	O
`	O
sport	O
`	O
,	O
`	O
dport	O
`	O
,	O
`	O
ip_proto	O
`	O
,	O
`	O
service	O
`	O
,	O
and	O
the	O
mean	O
var	O
values	O
calculated	O
as	O
earlier	O
.	O

I	O
have	O
tried	O
both	O
the	O
`	O
aggr	O
`	O
and	O
`	O
apply	O
`	O
methods	O
,	O
but	O
haven't	O
been	O
able	O
to	O
do	O
it	O
.	O

Thanks	O
in	O
advance	O
!	O

Just	O
apply	O
a	O
lambda	O
function	O
on	O
the	O
groups	O
like	O
so	O
:	O
#CODE	O

You	O
can	O
apply	O
a	O
function	O
that	O
returns	O
the	O
category	O
:	O
#CODE	O

You	O
want	O
to	O
avoid	O
iterating	O
,	O
if	O
possible	O
,	O
and	O
instead	O
find	O
a	O
function	O
to	O
apply	O
,	O
such	O
as	O
this	O
:	O
#CODE	O

@USER	O
:	O
I	O
like	O
this	O
solution	O
,	O
but	O
wouldn't	O
`	O
.map	B-API
`	O
be	O
better	O
?	O

Or	O
if	O
you're	O
going	O
to	O
use	O
apply	O
on	O
a	O
single	O
series	O
,	O
you	O
need	O
to	O
include	O
an	O
`	O
axis	O
`	O
parameter	O
.	O

I	O
am	O
trying	O
to	O
delete	O
the	O
first	O
two	O
rows	O
from	O
my	O
dataframe	B-API
`	O
df	O
`	O
and	O
am	O
using	O
the	O
answer	O
suggested	O
in	O
this	O
post	O
.	O

However	O
,	O
I	O
get	O
the	O
error	O
`	O
AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
ix	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
`	O
and	O
don't	O
know	O
how	O
to	O
do	O
this	O
with	O
the	O
`	O
apply	O
`	O
method	O
.	O

I've	O
shown	O
the	O
relevant	O
lines	O
of	O
code	O
below	O
:	O
#CODE	O

If	O
that's	O
too	O
slow	O
,	O
you	O
can	O
also	O
skip	O
the	O
type	O
checking	O
and	O
just	O
apply	O
the	O
string	O
conversion	O
to	O
columns	O
matching	O
the	O
numeric	O
type	O
.	O

Python	O
pandas	O
:	O
can	O
I	O
speed	O
up	O
this	O
apply	O
statement	O
?	O

I	O
do	O
all	O
of	O
this	O
with	O
apply	O
statements	O
.	O

They	O
work	O
,	O
but	O
seem	O
slow	O
to	O
me	O
:	O
7	O
seconds	O
in	O
total	O
,	O
whereas	O
any	O
SQL	O
would	O
take	O
a	O
fraction	O
of	O
a	O
second	O
,	O
even	O
without	O
parallelisation	O
,	O
on	O
the	O
same	O
machine	O
.	O

If	O
this	O
were	O
a	O
one-off	O
I	O
wouldn't	O
invest	O
time	O
in	O
speeding	O
this	O
up	O
,	O
but	O
I	O
must	O
do	O
it	O
multiple	O
times	O
on	O
multiple	O
dataframes	O
of	O
similar	O
size	O
.	O

Thanks	O
-	O
much	O
appreciated	O
.	O

The	O
data	O
comes	O
from	O
a	O
Microsoft	O
SQL	O
Server	O
.	O

I	O
have	O
a	O
feeling	O
I	O
should	O
learn	O
LINQ	O
and	O
how	O
to	O
apply	O
it	O
to	O
SQL	O
-	O
it	O
might	O
make	O
these	O
things	O
much	O
faster	O

You	O
can	O
use	O
`	O
apply	O
`	O
,	O
iterate	O
over	O
all	O
rows	O
and	O
replace	O
0	O
by	O
the	O
maximal	O
number	O
of	O
the	O
row	O
by	O
using	O
the	O
`	O
replace	O
`	O
function	O
which	O
gives	O
you	O
the	O
expected	O
output	O
:	O
#CODE	O

Here	O
is	O
one	O
workaround	O
by	O
defining	O
customized	O
`	O
apply	O
/	O
map	O
`	O
function	O
to	O
unpack	O
the	O
list	O
.	O

#CODE	O

I	O
can't	O
solve	O
your	O
exact	O
problem	O
unless	O
you	O
include	O
demonstration	O
code	O
.	O

You	O
can't	O
apply	O
my	O
example	O
to	O
your	O
problem	O
?	O

You	O
can	O
use	O
str.split	B-API
on	O
the	O
series	O
and	O
apply	O
a	O
function	O
to	O
the	O
result	O
:	O
#CODE	O

Is	O
apply	O
as	O
efficient	O
as	O
this	O
"	O
vectorized	O
"	O
function	O
definition	O
?	O

I	O
received	O
this	O
suggestion	O
to	O
avoid	O
mapping	O
,	O
supposedly	O
doing	O
loops	O
of	O
my	O
lambda	O
functions	O
:	O
#URL	O

@USER	O
I	O
get	O
an	O
AttributeError	O
:	O
AttributeError	O
:	O
'	O
DatetimeIndex	B-API
'	O
object	O
has	O
no	O
attribute	O
'	O
apply	O
'	O

OK	O
the	O
following	O
should	O
work	O
,	O
convert	O
your	O
datetimeindex	B-API
to	O
a	O
series	O
so	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
use	O
`	O
strftime	B-API
`	O
to	O
return	O
an	O
array	O
of	O
strings	O
:	O
#CODE	O

But	O
,	O
again	O
I	O
want	O
the	O
output	O
of	O
KDE	O
of	O
original	O
X	O
not	O
positions	O
,	O
so	O
I	O
can	O
make	O
first	O
derivative	O
on	O
the	O
output	O
of	O
KDE	O
.	O

That's	O
why	O
I	O
did	O
kernel	O
(	O
X	O
)	O
.	O

I'd	O
prefer	O
if	O
you	O
could	O
write	O
an	O
answer	O
with	O
your	O
supported	O
code	O
to	O
plot	O
pdf	O
output	O
vs	O
KDE	O
of	O
original	O
data	O
and	O
save	O
the	O
output	O
of	O
KDE	O
to	O
apply	O
first	O
derivative	O
on	O
it	O

I	O
couldn't	O
find	O
an	O
answer	O
to	O
this	O
in	O
the	O
existing	O
`	O
SettingWithCopy	O
`	O
warning	O
questions	O
,	O
because	O
the	O
common	O
`	O
.loc	B-API
`	O
solution	O
doesn't	O
seem	O
to	O
apply	O
.	O

I'm	O
loading	O
a	O
table	O
into	O
pandas	O
then	O
trying	O
to	O
create	O
some	O
mask	O
columns	O
based	O
on	O
values	O
in	O
the	O
other	O
columns	O
.	O

For	O
some	O
reason	O
,	O
this	O
returns	O
a	O
`	O
SettingWithCopy	O
`	O
warning	O
even	O
when	O
I'm	O
wrapping	O
the	O
test	O
in	O
a	O
`	O
pd.Series	B-API
`	O
constructor	O
.	O

Data	O
type	O
of	O
pandas	O
column	O
changes	O
to	O
object	O
when	O
it's	O
passed	O
to	O
a	O
function	O
via	O
apply	O
?	O

I	O
need	O
to	O
use	O
the	O
`	O
dtype	B-API
`	O
of	O
a	O
pandas	O
column	O
in	O
a	O
function	O
,	O
but	O
for	O
some	O
reason	O
when	O
I	O
call	O
the	O
function	O
using	O
`	O
apply	O
`	O
,	O
the	O
`	O
dtype	B-API
`	O
is	O
changed	O
to	O
`	O
object	O
`	O
.	O

Does	O
anyone	O
know	O
what	O
is	O
happening	O
here	O
?	O

#CODE	O

It	O
appears	O
to	O
be	O
due	O
to	O
an	O
optimization	O
in	O
`	O
DataFrame._apply_standard	O
`	O
.	O

The	O
"	O
fast	O
path	O
"	O
in	O
the	O
code	O
of	O
that	O
method	O
creates	O
an	O
output	O
Series	O
whose	O
dtype	B-API
is	O
the	O
dtype	B-API
of	O
`	O
df.values	B-API
`	O
,	O
which	O
in	O
your	O
case	O
is	O
`	O
object	O
`	O
since	O
the	O
DataFrame	B-API
is	O
of	O
mixed	O
type	O
.	O

If	O
you	O
pass	O
`	O
reduce=False	O
`	O
to	O
your	O
`	O
apply	O
`	O
call	O
,	O
the	O
result	O
is	O
correct	O
:	O
#CODE	O

As	O
you're	O
trying	O
to	O
learn	O
categories	O
from	O
one	O
DataFrame	B-API
to	O
apply	O
to	O
a	O
different	O
DataFrame	B-API
,	O
using	O
scikit-learn	O
might	O
provide	O
a	O
more	O
elegant	O
solution	O
:	O
#CODE	O

Or	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

By	O
the	O
way	O
,	O
you	O
can	O
apply	O
your	O
logic	O
of	O
`	O
df	O
[	O
df	O
[	O
'	O
col_1	O
']	O
!	O
=	O
754	O
]`	O
also	O
on	O
the	O
index	O
.	O

This	O
would	O
give	O
`	O
df	O
[	O
df.index	O
!	O
=	O
754	O
]`	O
,	O
although	O
this	O
would	O
not	O
work	O
with	O
a	O
multi-index	O

I	O
know	O
that	O
I	O
can	O
simply	O
do	O
one	O
datetime	O
minus	O
the	O
other	O
to	O
find	O
the	O
timedelta	O
-	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
this	O
to	O
make	O
a	O
new	O
column	O
.	O

There	O
is	O
an	O
`	O
apply	O
`	O
for	O
that	O
:	O
#CODE	O

The	O
code	O
is	O
not	O
that	O
efficient	O
,	O
Is	O
there	O
a	O
more	O
efficient	O
way	O
to	O
do	O
this	O
?	O

I	O
would	O
assume	O
there	O
must	O
be	O
some	O
special	O
function	O
(	O
such	O
as	O
apply	O
,	O
roll_apply	O
)	O
to	O
iterate	O
through	O
these	O
values	O
,	O
but	O
I	O
couldn't	O
figure	O
that	O
out	O
.	O

Any	O
help	O
would	O
be	O
appreciated	O
.	O

how	O
do	O
I	O
apply	O
normalize	O
function	O
to	O
pandas	O
string	O
series	O
?	O

I	O
would	O
like	O
to	O
apply	O
the	O
following	O
function	O
to	O
a	O
dataframe	B-API
series	O
:	O

How	O
do	O
I	O
apply	O
the	O
`	O
normalize	O
`	O
function	O
to	O
all	O
members	O
of	O
the	O
series	O
?	O

If	O
`	O
c	O
`	O
is	O
your	O
string	O
column	O
.	O

`	O
map	O
`	O
is	O
used	O
to	O
apply	O
a	O
function	O
elementwise	O
(	O
and	O
of	O
course	O
you	O
wouldn't	O
have	O
to	O
chain	O
it	O
all	O
together	O
like	O
this	O
)	O
#CODE	O

This	O
was	O
written	O
in	O
Python	O
2	O
,	O
but	O
the	O
basic	O
idea	O
should	O
work	O
for	O
you	O
.	O

It	O
uses	O
the	O
apply	O
function	O
:	O
#CODE	O

Note	O
that	O
if	O
you	O
loaded	O
the	O
other	O
keys	O
into	O
the	O
dict	O
,	O
you	O
could	O
do	O
the	O
apply	O
without	O
the	O
swapper	O
function	O
:	O
#CODE	O

Could	O
you	O
post	O
an	O
array	O
form	O
of	O
the	O
data	O
so	O
I	O
can	O
play	O
with	O
it	O
a	O
bit	O
?	O

Also	O
,	O
consider	O
creating	O
a	O
new	O
function	O
to	O
use	O
in	O
the	O
apply	O
for	O
now	O
until	O
you	O
can	O
work	O
the	O
problem	O
out	O
.	O

Simply	O
add	O
axis	O
=	O
1	O
to	O
your	O
apply	O
function	O
and	O
it	O
will	O
work	O
:	O
#CODE	O

You	O
add	O
the	O
column	O
to	O
the	O
subgroup	O
inside	O
the	O
apply	O
function	O
,	O
and	O
then	O
when	O
you	O
return	O
that	O
subgroup	O
it	O
replaces	O
the	O
existing	O
subgroup	O
.	O

The	O
way	O
that	O
I	O
have	O
found	O
to	O
do	O
is	O
by	O
making	O
a	O
copy	O
of	O
the	O
column	O
and	O
operating	O
on	O
it	O
(	O
I	O
have	O
to	O
do	O
this	O
because	O
a	O
`	O
DateTimeIndex	B-API
`	O
has	O
no	O
`	O
apply	O
`	O
method	O
)	O
.	O

I	O
am	O
sure	O
there	O
must	O
be	O
a	O
way	O
to	O
operate	O
on	O
the	O
index	O
directly	O
though	O
but	O
I	O
could	O
not	O
find	O
it	O
:	O
#CODE	O

It	O
could	O
be	O
done	O
by	O
calling	O
`	O
apply	O
`	O
on	O
the	O
df	O
like	O
so	O
:	O
#CODE	O

This	O
uses	O
double	O
subscripts	O
`	O
[[	O
]]`	O
to	O
call	O
`	O
apply	O
`	O
on	O
a	O
df	O
with	O
a	O
single	O
column	O
,	O
this	O
allows	O
you	O
to	O
pass	O
param	O
`	O
axis=1	O
`	O
so	O
you	O
can	O
call	O
you	O
function	O
row-wise	O
,	O
you	O
then	O
have	O
access	O
to	O
the	O
index	O
attribute	O
,	O
which	O
is	O
`	O
name	O
`	O
and	O
the	O
column	O
name	O
attribute	O
,	O
which	O
is	O
`	O
index	O
`	O
,	O
this	O
allows	O
you	O
to	O
slice	O
your	O
df	O
to	O
calculate	O
a	O
rolling	O
`	O
std	O
`	O
.	O

However	O
,	O
when	O
I	O
apply	O
this	O
method	O
to	O
whole	O
length	O
of	O
data	O
,	O
I	O
couldn't	O
wait	O
until	O
the	O
operation	O
was	O
done	O
.	O

Not	O
sure	O
what	O
you	O
mean	O
by	O
your	O
comment	O
@USER	O
.	O

I	O
did	O
use	O
pd.DataFrame()	B-API
on	O
each	O
of	O
your	O
dict's	O
,	O
however	O
,	O
what	O
I	O
did	O
was	O
apply	O
a	O
dict	O
comprehension	O
using	O
each	O
of	O
them	O
to	O
strip	O
out	O
the	O
nested	O
zeros	B-API
.	O

pd.concat()	B-API
just	O
took	O
all	O
three	O
of	O
the	O
DataFrame's	O
from	O
dict's	O
and	O
concatenates	O
them	O
all	O
together	O
.	O

Python	O
pandas	O
:	O
banal	O
apply	O
statements	O
incredibly	O
slow	O

apply	O
sum	O
calculated	O
using	O
pandas	O
group	O
by	O
to	O
all	O
elements	O
of	O
group	O

Please	O
suggest	O
how	O
can	O
I	O
apply	O
sum	O
on	O
all	O
rows	O
of	O
one	O
account	O
.	O

You	O
can	O
use	O
the	O
`	O
map	O
`	O
method	O
on	O
your	O
json-text	O
column	O
to	O
apply	O
a	O
`	O
lambda	O
`	O
function	O
which	O
will	O
parse	O
the	O
json	O
using	O
`	O
json.loads	O
`	O
then	O
return	O
the	O
field	O
that	O
you	O
want	O
.	O

#CODE	O

You	O
can	O
use	O
the	O
`	O
loc	O
`	O
method	O
of	O
a	O
dataframe	B-API
to	O
select	O
certain	O
columns	O
based	O
on	O
a	O
Boolean	O
indexer	O
.	O

Create	O
the	O
indexer	O
like	O
this	O
(	O
uses	O
Numpy	O
Array	O
broadcasting	O
to	O
apply	O
the	O
condition	O
to	O
each	O
column	O
):	O
#CODE	O

I	O
can	O
see	O
from	O
your	O
output	O
that	O
this	O
is	O
exactly	O
what	O
I	O
want	O
.	O

However	O
,	O
I	O
cant	O
recreate	O
it	O
because	O
our	O
initial	O
dataframes	O
are	O
created	O
in	O
different	O
ways	O
.	O

I'm	O
using	O
a	O
groupby	B-API
to	O
set	O
the	O
initial	O
split	O
and	O
sex	O
index	O
.	O

Then	O
,	O
if	O
I	O
use	O
your	O
code	O
:	O
level_group	O
=	O
np.where	B-API
(	O
df.columns.str.contains	O
(	O
'	O
0	O
')	O
,	O
0	O
,	O
1	O
)	O
on	O
my	O
groupby	B-API
(	O
replacing	O
the	O
df	O
)	O
,	O
I	O
get	O
an	O
error	O
:	O
Cannot	O
access	O
attribute	O
'	O
columns	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

What	O
I	O
did	O
is	O
to	O
apply	O
this	O
function	O
to	O
get	O
the	O
count	O
of	O
repeating	O
elements	O
in	O
B	O
#CODE	O

Apply	O
async	O
usage	O
:	O

@USER	O
I'm	O
not	O
sure	O
in	O
this	O
case	O
,	O
you	O
could	O
use	O
`	O
%timeit	O
`	O
in	O
ipython	O
to	O
compare	O
.	O

Generally	O
speaking	O
,	O
the	O
advantage	O
of	O
pandas	O
is	O
crunching	O
numbers	O
not	O
strings	O
,	O
so	O
it	O
might	O
not	O
matter	O
too	O
much	O
.	O

But	O
generally	O
speaking	O
,	O
`	O
apply	O
/	O
lambda	O
`	O
will	O
be	O
slower	O
than	O
using	O
built	O
in	O
pandas	O
methods	O
.	O

Pandas	O
:	O
Apply	O
function	O
via	O
"	O
Column	O
A	O
"	O
,	O
simultaneously	O
reading	O
"	O
Column	O
B	O
"	O

In	O
the	O
`	O
csv	O
`	O
,	O
there	O
is	O
also	O
a	O
`"	O
Column	O
B	O
"`	O
that	O
contains	O
values	O
that	O
I	O
want	O
to	O
read	O
into	O
a	O
variable	O
`	O
x	O
`	O
within	O
the	O
function	O
.	O

It	O
should	O
not	O
`	O
apply	O
`	O
from	O
`"	O
Column	O
B	O
"`	O
this	O
should	O
still	O
be	O
done	O
from	O
`"	O
Column	O
A	O
"`	O
.	O

Is	O
this	O
possible	O
?	O

Post-edit	O
:	O
This	O
question	O
has	O
been	O
identified	O
as	O
a	O
possible	O
duplicate	O
of	O
another	O
question	O
.	O

Although	O
the	O
answer	O
may	O
be	O
the	O
same	O
,	O
the	O
question	O
is	O
not	O
the	O
same	O
.	O

For	O
future	O
readers	O
it	O
is	O
probably	O
not	O
apparent	O
that	O
`	O
apply	O
`	O
on	O
two	O
columns	O
is	O
interchangeable	O
with	O
`	O
apply	O
`	O
on	O
one	O
column	O
and	O
"	O
reading	O
"	O
another	O
column	O
at	O
the	O
same	O
time	O
.	O

The	O
question	O
should	O
therefore	O
remain	O
open	O
.	O

possible	O
duplicate	O
of	O
[	O
How	O
to	O
apply	O
a	O
function	O
to	O
two	O
columns	O
of	O
Pandas	O
dataframe	B-API
]	O
(	O
#URL	O
)	O

The	O
`	O
axis=1	O
`	O
argument	O
passed	O
to	O
the	O
apply	O
method	O
puts	O
the	O
whole	O
row	O
into	O
the	O
apply	O
method	O
as	O
a	O
single	O
tuple	O
argument	O
.	O

This	O
is	O
a	O
really	O
messy	O
way	O
to	O
do	O
this	O
,	O
first	O
use	O
`	O
first_valid_index	B-API
`	O
to	O
get	O
the	O
valid	O
columns	O
,	O
convert	O
the	O
returned	O
series	O
to	O
a	O
dataframe	B-API
so	O
we	O
can	O
call	O
`	O
apply	O
`	O
row-wise	O
and	O
use	O
this	O
to	O
index	O
back	O
to	O
original	O
df	O
:	O
#CODE	O

You	O
can	O
do	O
the	O
following	O
,	O
this	O
tests	O
each	O
row	O
for	O
membership	O
of	O
`	O
1	O
,	O
2	O
`	O
using	O
`	O
isin	B-API
`	O
and	O
if	O
so	O
this	O
generates	O
a	O
boolean	O
series	O
,	O
you	O
can	O
use	O
this	O
to	O
index	O
into	O
the	O
columns	O
by	O
calling	O
`	O
apply	O
`	O
again	O
,	O
we	O
convert	O
this	O
to	O
a	O
list	O
because	O
the	O
dimensions	O
won't	O
align	O
if	O
you	O
don't	O
do	O
this	O
:	O
#CODE	O

output	O
from	O
inner	O
`	O
apply	O
`	O
:	O
#CODE	O

performance	O
degradation	O
when	O
switching	O
from	O
pandas	O
column	O
concatenation	O
to	O
using	O
apply	O
on	O
dataframe	B-API

Generally	O
using	O
`	O
apply	O
`	O
should	O
be	O
avoided	O
it's	O
essentially	O
a	O
for	O
loop	O
and	O
not	O
vectorised	O
,	O
it	O
would	O
be	O
better	O
to	O
write	O
a	O
func	O
that	O
performed	O
vectorised	O
operations	O
rather	O
than	O
using	O
`	O
apply	O
`	O
at	O
all	O

Right	O
now	O
I	O
have	O
the	O
data	O
input	O
,	O
and	O
I	O
have	O
more	O
or	O
less	O
written	O
the	O
function	O
I	O
would	O
like	O
to	O
use	O
to	O
analyze	O
each	O
column	O
separately	O
.	O

However	O
,	O
I	O
can't	O
quite	O
understand	O
how	O
to	O
use	O
a	O
forloop	O
or	O
use	O
the	O
apply	O
function	O
through	O
all	O
of	O
the	O
columns	O
in	O
the	O
dataset	O
.	O

I	O
would	O
prefer	O
not	O
to	O
hardcode	O
the	O
columns	O
because	O
I	O
will	O
have	O
40,000	O
~	O
50,000	O
columns	O
to	O
analyze	O
.	O

I'm	O
attempting	O
to	O
use	O
the	O
apply	O
function	O
:	O
#CODE	O

`	O
axis=2	O
`	O
is	O
not	O
a	O
valid	O
param	O
for	O
`	O
apply	O
`	O

I	O
know	O
I	O
can	O
make	O
a	O
partial	O
function	O
with	O
"	O
or	O
"	O
and	O
my	O
vector	O
and	O
apply	O
it	O
to	O
the	O
df	O
,	O
but	O
this	O
is	O
probably	O
unidiomatic	O
and	O
needlessly	O
time-consuming	O
.	O

What	O
is	O
the	O
pandas	O
way	O
?	O

Apply	O
curve_fit	O
on	O
dataframe	B-API
columns	O

I	O
have	O
a	O
`	O
pandas.DataFrame	B-API
`	O
with	O
with	O
multiple	O
columns	O
and	O
I	O
would	O
like	O
to	O
apply	O
a	O
`	O
curve_fit	O
`	O
function	O
to	O
each	O
of	O
them	O
.	O

I	O
would	O
like	O
the	O
output	O
to	O
be	O
a	O
dataframe	B-API
with	O
the	O
optimal	O
values	O
fitting	O
the	O
data	O
in	O
the	O
columns	O
(	O
for	O
now	O
,	O
I	O
am	O
not	O
interested	O
in	O
their	O
covariance	O
)	O
.	O

I	O
can	O
apply	O
the	O
function	O
and	O
get	O
an	O
array	O
in	O
return	O
:	O
#CODE	O

Can	O
this	O
be	O
done	O
with	O
something	O
similar	O
to	O
`	O
apply	O
`	O
?	O

I	O
think	O
the	O
issue	O
is	O
that	O
the	O
apply	O
of	O
your	O
fitting	O
function	O
returns	O
an	O
array	O
of	O
dim	O
3x3	O
(	O
the	O
3	O
fitparameters	O
as	O
returned	O
by	O
conner	O
)	O
.	O

But	O
expected	O
is	O
something	O
in	O
the	O
shape	O
of	O
20x3	O
as	O
your	O
df	O
.	O

Well	O
all	O
you're	O
doing	O
is	O
creating	O
a	O
df	O
for	O
each	O
column	O
which	O
seems	O
unncessary	O
,	O
semantically	O
they	O
should	O
perform	O
the	O
same	O
,	O
`	O
apply	O
`	O
on	O
a	O
df	O
calls	O
the	O
function	O
on	O
each	O
column	O
in	O
turn	O
(	O
as	O
`	O
axis=0	O
`	O
is	O
the	O
default	O
param	O
value	O
)	O

Can	O
probably	O
be	O
improved	O
using	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
.	O

#CODE	O

I've	O
been	O
trying	O
to	O
figure	O
this	O
out	O
for	O
awhile	O
now	O
and	O
haven't	O
been	O
able	O
to	O
apply	O
any	O
of	O
the	O
solutions	O
I've	O
found	O
online	O
for	O
splitting	O
columns	O
in	O
pandas	O
yet	O
.	O

I	O
have	O
to	O
apply	O
the	O
column	O
split	O
to	O
90+	O
consistently	O
formatted	O
columns	O
.	O

I	O
feel	O
like	O
the	O
solution	O
should	O
be	O
trivial	O
,	O
I'm	O
just	O
too	O
new	O
to	O
programming	O
and	O
python	O
to	O
figure	O
it	O
out	O
!	O

Maybe	O
a	O
`	O
groupby	B-API
`	O
in	O
conjunction	O
with	O
`	O
apply	O
`	O
?	O

I'm	O
not	O
familiar	O
with	O
`	O
apply	O
`	O
yet	O
.	O

you	O
can	O
use	O
apply	O
on	O
the	O
groups	O
,	O
which	O
allows	O
you	O
to	O
transform	O
a	O
group	O
.	O

This	O
means	O
that	O
the	O
function	O
inside	O
returns	O
something	O
for	O
each	O
set	O
of	O
entries	O
that	O
has	O
the	O
same	O
ID	O
.	O

@USER	O
You	O
can	O
also	O
define	O
your	O
own	O
apply	O
function	O
to	O
achieve	O
the	O
goal	O
by	O
using	O
the	O
`	O
cumsum	B-API
`	O
trick	O
.	O

See	O
the	O
edited	O
part	O
.	O

The	O
extract	O
method	O
will	O
create	O
a	O
dataframe	B-API
with	O
as	O
many	O
columns	O
as	O
groups	O
specified	O
in	O
the	O
pattern	O
you	O
pass	O
,	O
in	O
this	O
case	O
two	O
.	O

Groups	O
are	O
delimited	O
by	O
brackets	O
in	O
the	O
pattern	O
.	O

I've	O
edited	O
the	O
question	O
to	O
show	O
hoe	O
to	O
apply	O
it	O
in	O
your	O
case	O
.	O

Passing	O
a	O
dataframe	B-API
as	O
an	O
an	O
argument	O
in	O
apply	O
with	O
pandas	O

Ok	O
,	O
the	O
problem	O
here	O
is	O
the	O
combination	O
of	O
`	O
func	O
`	O
and	O
`	O
apply	O
`	O
.	O

The	O
`	O
apply	O
`	O
method	O
of	O
a	O
dataframe	B-API
applies	O
the	O
given	O
function	O
to	O
each	O
COLUMN	O
in	O
the	O
data	O
frame	O
and	O
returns	O
the	O
result	O
.	O

So	O
the	O
function	O
you	O
pass	O
to	O
`	O
apply	O
`	O
should	O
expect	O
a	O
pandas	O
Series	O
or	O
an	O
array	O
as	O
input	O
,	O
not	O
a	O
dataframe	B-API
.	O

It	O
should	O
give	O
either	O
a	O
series	O
/	O
array	O
or	O
single	O
value	O
as	O
output	O
.	O

will	O
apply	O
the	O
`	O
sum	O
`	O
function	O
to	O
each	O
column	O
and	O
give	O
a	O
series	O
containing	O
the	O

Secondly	O
,	O
the	O
`	O
args	O
`	O
parameter	O
in	O
`	O
apply	O
`	O
is	O
only	O
used	O
when	O
the	O
function	O
you	O
are	O
passing	O
takes	O
additional	O
arguments	O
(	O
besides	O
the	O
series	O
,	O
which	O
should	O
be	O
the	O
first	O
argument	O
)	O
.	O

For	O
example	O
,	O
you	O
might	O
have	O
a	O
function	O
that	O
sums	O
an	O
array	O
and	O
then	O
divides	O
by	O
some	O
number	O
(	O
again	O
a	O
silly	O
example	O
):	O
#CODE	O

The	O
you	O
might	O
want	O
to	O
apply	O
this	O
to	O
each	O
column	O
of	O
a	O
dataframe	B-API
with	O
divisor	O
=	O
2	O
.	O

@USER	O
Sorry	O
that	O
I	O
misunderstood	O
your	O
question	O
.	O

For	O
your	O
case	O
,	O
just	O
apply	O
the	O
same	O
`	O
groupby.agg	O
(	O
sum	O
)`	O
logic	O
to	O
hourly	O
price	O
dataframe	B-API
,	O
and	O
then	O
calculate	O
dot	O
product	O
with	O
daily	O
volume	O
data	O
.	O

Finally	O
sum	O
over	O
`	O
axis=1	O
`	O
.	O

See	O
the	O
edit	O
.	O

You	O
should	O
use	O
`	O
resample	O
`	O
to	O
calculate	O
the	O
mean	O
price	O
for	O
the	O
day	O
,	O
and	O
then	O
apply	O
it	O
to	O
the	O
volume	O
:	O
#CODE	O

Actually	O
,	O
it	O
is	O
bad	O
to	O
use	O
`'	O
columns	O
'`	O
in	O
the	O
`	O
query	O
`	O
expression	O
like	O
this	O
.	O

In	O
the	O
first	O
example	O
,	O
it	O
is	O
just	O
happened	O
that	O
returned	O
Series	O
can	O
be	O
used	O
as	O
index	O
,	O
but	O
it	O
might	O
not	O
apply	O
to	O
the	O
general	O
case	O
.	O

The	O
problem	O
with	O
the	O
`	O
apply	O
`	O
/	O
`	O
map	O
`	O
/	O
`	O
applymap	B-API
`	O
functions	O
is	O
that	O
they	O
don't	O

Here	O
is	O
a	O
faster	O
code	O
using	O
`	O
apply	O
`	O
,	O
but	O
it	O
will	O
provide	O
wrong	O
result	O
in	O
case	O
there	O
are	O
2	O
or	O
more	O
months	O
in	O
the	O
same	O
column	O
with	O
the	O
same	O
value	O
,	O
because	O
`	O
np.where	B-API
`	O
returns	O
an	O
`	O
np.array	B-API
`	O
of	O
the	O
indexes	O
that	O
it	O
found	O
the	O
value	O
of	O
`	O
x	O
`	O
in	O
,	O
but	O
there's	O
no	O
way	O
to	O
store	O
it	O
and	O
use	O
the	O
next	O
index	O
the	O
next	O
time	O
we	O
encounter	O
the	O
same	O
`	O
x	O
`	O
value	O
:	O
#CODE	O

Sorry	O
,	O
that's	O
my	O
fault	O
and	O
this	O
is	O
not	O
due	O
to	O
date	O
conversion	O
.	O

I	O
was	O
working	O
with	O
a	O
much	O
larger	O
`	O
DataFrame	B-API
`	O
containing	O
other	O
columns	O
.	O

In	O
this	O
context	O
,	O
it	O
was	O
a	O
bad	O
idea	O
to	O
use	O
the	O
`	O
apply	O
`	O
function	O
.	O

After	O
this	O
correction	O
,	O
it	O
works	O
fine	O
and	O
I	O
obtain	O
the	O
same	O
result	O
in	O
less	O
time	O
.	O

Thanks	O
for	O
the	O
solution	O
and	O
for	O
the	O
reply	O
.	O

Below	O
is	O
the	O
code	O
I	O
apply	O
to	O
get	O
the	O
fitted	O
volatility	O
from	O
the	O
regression	O
equation	O
y	O
=	O
ax^2	O
+	O
x	O
+	O
c	O
and	O
the	O
results	O
are	O
great	O
.	O

.	O
.	O

#CODE	O

I	O
need	O
to	O
have	O
the	O
regression	O
variables	O
and	O
FitVol	O
apply	O
to	O
all	O
of	O
the	O
original	O
data	O
,	O
not	O
the	O
data	O
that	O
was	O
filtered	O
to	O
have	O
the	O
abs	O
(	O
Delta	O
)	O
be	O
between	O
0.01	O
and	O
0.5	O

You	O
haven't	O
to	O
apply	O
`	O
for	O
`	O
loop	O
or	O
`	O
iterrows()	B-API
`	O
at	O
all	O
in	O
pandas	O
:	O
#CODE	O

Group	O
by	O
then	O
apply	O
function	O
then	O
flatten	O
back	O
to	O
dataframe	B-API
in	O
Pandas	O
Python	O

pick	O
the	O
columns	O
you	O
want	O
to	O
diff	O
,	O
and	O
apply	O
`	O
pd.DataFrame.diff	B-API
`	O

Now	O
apply	O
the	O
logic	O
described	O
above	O
:	O
#CODE	O

And	O
I	O
want	O
an	O
expanding	O
apply	O
function	O
that	O
identifies	O
whether	O
we	O
reach	O
a	O
new	O
maximum	O
value	O
for	O
a	O
given	O
id	O
.	O

The	O
resulting	O
dataframe	B-API
should	O
look	O
like	O
this	O
:	O
#CODE	O

I	O
can't	O
seem	O
to	O
pass	O
two	O
columns	O
to	O
the	O
expanding	O
apply	O
function	O
.	O

Its	O
been	O
a	O
long	O
time	O
since	O
I	O
worked	O
with	O
`	O
apply	O
`	O
like	O
a	O
couple	O
releases	O
ago	O
minimum	O
,	O
so	O
my	O
recollection	O
may	O
be	O
bad	O
,	O
or	O
things	O
may	O
have	O
changed	O
.	O

However	O
,	O
as	O
I	O
remember	O
it	O
the	O
grouped	O
data	O
is	O
passed	O
automatically	O
as	O
the	O
first	O
argument	O
.	O

The	O
temptation	O
when	O
passing	O
your	O
own	O
function	O
to	O
`	O
apply	O
`	O
is	O
to	O
do	O
this	O
:	O
#CODE	O

In	O
example	O
data	O
above	O
,	O
this	O
works	O
great	O
but	O
when	O
I	O
apply	O
this	O
concept	O
to	O
my	O
real	O
datasets	O
,	O
I	O
get	O
`	O
Exception	O
:	O
cannot	O
handle	O
a	O
non-unique	O
multi-index	O
!	O

`	O
.	O

I	O
verified	O
that	O
`	O
df1	O
`	O
and	O
`	O
df2	O
`	O
have	O
the	O
exact	O
same	O
columns	O
.	O

Any	O
ideas	O
of	O
the	O
cause	O
and	O
how	O
to	O
fix	O
?	O

In	O
which	O
columns	O
4	O
,	O
5	O
and	O
6	O
are	O
actually	O
the	O
components	O
of	O
a	O
vector	O
.	O

I	O
want	O
to	O
apply	O
a	O
matrix	O
multiplication	O
in	O
these	O
columns	O
,	O
that	O
is	O
to	O
replace	O
columns	O
4	O
,	O
5	O
and	O
6	O
with	O
the	O
vector	O
resulting	O
of	O
a	O
the	O
multiplication	O
of	O
the	O
previous	O
vector	O
with	O
a	O
matrix	O
.	O

if	O
so	O
i	O
would	O
gest	O
that	O
the	O
apply	O
method	O
is	O
a	O
good	O
hint	O
here	O
but	O
like	O
@USER	O
-sc	O
i	O
would	O
suggest	O
you	O
to	O
restructure	O
your	O
data	O
model	O
or	O
have	O
a	O
look	O
at	O
pytables	O
etc	O

You	O
can	O
create	O
a	O
column	O
with	O
the	O
mutation	O
type	O
(	O
A	O
->	O
T	B-API
,	O
G	O
->	O
C	O
)	O
with	O
a	O
regular	O
expression	O
substitution	O
then	O
apply	O
pandas	O
groupby	B-API
to	O
count	O
.	O

#CODE	O

You	O
can	O
transpose	O
the	O
df	O
and	O
apply	O
a	O
lambda	O
that	O
drops	O
the	O
NaN	O
rows	O
,	O
slices	O
from	O
4th	O
value	O
onwards	O
and	O
returns	O
the	O
first	O
valid	O
index	O
:	O
#CODE	O

@USER	O
then	O
may	O
be	O
you	O
can	O
use	O
the	O
idea	O
and	O
apply	O
to	O
panda	O
DataFrame	B-API

In	O
case	O
you	O
need	O
to	O
convert	O
existing	O
columns	O
in	O
a	O
dataframe	B-API
here	O
the	O
solution	O
using	O
a	O
helper	O
function	O
`	O
conv	O
`	O
and	O
the	O
`	O
apply	O
`	O
method	O
.	O

#CODE	O

I	O
believe	O
your	O
data	O
structure	O
isn't	O
appropriate	O
for	O
your	O
problem	O
.	O

Especially	O
the	O
`	O
list	O
`	O
in	O
fields	O
of	O
a	O
`	O
DataFrame	B-API
`	O
,	O
they	O
make	O
loops	O
or	O
`	O
apply	O
`	O
almost	O
unavoidable	O
.	O

Could	O
you	O
in	O
principle	O
re-structure	O
the	O
data	O
?	O

(	O
For	O
example	O
one	O
`	O
df	O
`	O
per	O
solar	O
panel	O
with	O
columns	O
`	O
date	O
`	O
,	O
`	O
time	O
`	O
,	O
`	O
energy	O
`)	O

I	O
believe	O
your	O
data	O
structure	O
isn't	O
appropriate	O
for	O
your	O
problem	O
.	O

Especially	O
the	O
list	O
in	O
fields	O
of	O
a	O
DataFrame	B-API
,	O
they	O
make	O
loops	O
or	O
apply	O
almost	O
unavoidable	O
.	O

Could	O
you	O
in	O
principle	O
re-structure	O
the	O
data	O
?	O

(	O
For	O
example	O
one	O
df	O
per	O
solar	O
panel	O
with	O
columns	O
date	O
,	O
time	O
,	O
energy	O
)	O

Python	O
pandas	O
:	O
retrieve	O
the	O
field	O
associated	O
to	O
the	O
min	O
of	O
another	O
(	O
cross	O
apply	O
equivalent	O
)	O

In	O
SQL	O
I	O
was	O
used	O
to	O
doing	O
this	O
with	O
a	O
cross	O
apply	O
.	O

If	O
you	O
want	O
to	O
apply	O
an	O
arbitrary	O
Python	O
function	O
,	O
you	O
will	O
have	O
to	O
loop	O
it	O
.	O

Can	O
you	O
write	O
out	O
the	O
formula	O
you	O
want	O
to	O
apply	O
?	O

Based	O
on	O
the	O
latest	O
suggestion	O
of	O
Firelynx	O
I	O
have	O
a	O
small	O
update	O
which	O
makes	O
it	O
a	O
bit	O
cleaner	O
.	O

Still	O
,	O
you	O
need	O
to	O
keep	O
a	O
list	O
in	O
order	O
to	O
prevent	O
double	O
counts	O
of	O
the	O
label	O
,	O
because	O
unique	O
apply	O
only	O
to	O
a	O
unique	O
(	O
label	O
,	O
side	O
)	O
combination	O
.	O

So	O
I	O
now	O
have	O
#CODE	O

Is	O
it	O
possible	O
to	O
have	O
unique()	B-API
apply	O
on	O
the	O
label	O
alone	O
?	O

Then	O
I	O
could	O
remove	O
the	O
label_list	O
to	O
keep	O
track	O
of	O
which	O
label	O
has	O
been	O
processed	O
already	O

tom's	O
answer	O
looks	O
good	O
.	O

On	O
a	O
column	O
you	O
could	O
also	O
do	O
`	O
.map	B-API
(	O
lambda	O
x	O
:	O
min	O
(	O
x	O
,	O
0	O
)	O
)`	O
to	O
apply	O
the	O
standard	O
python	O
`	O
min	O
`	O
to	O
each	O
cell	O
,	O
but	O
`	O
np.minimum	B-API
`	O
is	O
probably	O
going	O
to	O
be	O
the	O
fastest	O
way	O
.	O

OR	O
you	O
can	O
apply	O
over	O
two	O
columns	O
:	O
#CODE	O

Further	O
,	O
it	O
is	O
possible	O
to	O
select	O
automatically	O
all	O
columns	O
with	O
a	O
certain	O
dtype	B-API
in	O
a	O
dataframe	B-API
using	O
`	O
select_dtypes	B-API
`	O
.	O

This	O
way	O
,	O
you	O
can	O
apply	O
above	O
operation	O
on	O
multiple	O
and	O
automatically	O
selected	O
columns	O
.	O

Export	O
pandas	O
DataFrame	B-API
to	O
LaTeX	O
and	O
apply	O
formatters	O
by	O
row	O

Is	O
there	O
any	O
way	O
to	O
hack	O
this	O
functionality	O
?	O

Only	O
thing	O
I	O
thought	O
about	O
was	O
to	O
manually	O
apply	O
the	O
formats	O
converting	O
all	O
my	O
columns	O
to	O
strings	O
before	O
transposing	O
and	O
exporting	O

To	O
all	O
the	O
answerers	O
:	O
as	O
the	O
OP	O
mentions	O
pandas	O
,	O
it	O
may	O
be	O
desirable	O
to	O
enclose	O
in	O
apply	O
/	O
lambda	O
.	O

E.g.	O

`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
your_code	O
)`	O
.	O

It	O
would	O
also	O
be	O
good	O
for	O
the	O
OP	O
to	O
be	O
more	O
explicit	O
:	O
`	O
df	O
=p	O
d.DataFrame	O
(	O
[	O
0.5	O
,	O
4.6	O
,	O
7.2	O
]	O
)`	O

Thanks	O
!	O

one	O
more	O
question	O
,	O
will	O
I	O
manually	O
`	O
e	O
=	O
re.sub	O
(	O
'	O
/	O
'	O
,	O
'	O
-	O
'	O
,	O
c	O
)`	O
and	O
apply	O
`	O
to_datetime	B-API
(	O
e	O
)`	O
that	O
can	O
improve	O
the	O
performance	O
?	O

you	O
already	O
accessed	O
the	O
column	O
before	O
calling	O
the	O
`	O
.apply()	B-API
`	O
method	O
on	O
it	O
,	O
notice	O
that	O
you	O
call	O
the	O
apply	O
function	O
as	O
-	O
`	O
df	O
[	O
0	O
]	O
.apply	B-API
`	O
,	O
which	O
means	O
apply	O
it	O
in	O
0th	O
column	O
of	O
`	O
df	O
`	O
dataframe	B-API
.	O

if	O
I	O
apply	O
a	O
groupy	O
say	O
with	O
column	O
col2	O
and	O
col3	O
this	O
way	O
#CODE	O

One	O
option	O
is	O
to	O
use	O
groupby	B-API
and	O
apply	O
to	O
end	O
with	O
a	O
pandas	O
Series	O
:	O
#CODE	O

As	O
far	O
as	O
numpy	O
is	O
concerned	O
,	O
a	O
`	O
list	O
`	O
counts	O
as	O
an	O
arbitrary	O
Python	O
object	O
.	O
numpy	O
can	O
only	O
efficiently	O
deal	O
with	O
arrays	O
that	O
have	O
regular	O
dimensions	O
and	O
contain	O
elements	O
of	O
a	O
constant	O
size	O
in	O
memory	O
(	O
this	O
all	O
has	O
to	O
do	O
with	O
numpy's	O
[	O
internal	O
representation	O
]	O
(	O
#URL	O
)	O
of	O
the	O
array	O
)	O
.	O

This	O
doesn't	O
apply	O
to	O
Python	O
lists	O
,	O
since	O
the	O
length	O
and	O
item	O
size	O
can	O
vary	O
arbitrarily	O
.	O

Ha	O
,	O
that	O
would	O
be	O
too	O
easy	O
:)	O
.	O

That's	O
the	O
result	O
of	O
the	O
grouping	O
operation	O
that	O
I	O
want	O
to	O
apply	O
.	O

This	O
column	O
is	O
unpopulated	O
until	O
I	O
run	O
the	O
code	O
above	O
.	O

Another	O
option	O
where	O
you	O
can	O
control	O
the	O
format	O
is	O
using	O
the	O
`	O
strftime	B-API
`	O
method	O
in	O
an	O
apply	O
(	O
this	O
would	O
actually	O
be	O
equivalent	O
to	O
writing	O
a	O
loop	O
,	O
but	O
shorter	O
):	O
#CODE	O

However	O
,	O
when	O
I	O
apply	O
this	O
to	O
my	O
full	O
dataset	O
,	O
with	O
multiple	O
dates	O
in	O
utctime	O
,	O
the	O
x-axis	O
remains	O
a	O
time	O
-	O
I	O
want	O
it	O
to	O
show	O
the	O
dates	O
in	O
this	O
case	O
.	O

Groupby	B-API
on	O
level	O
0	O
(	O
parameter1	O
)	O
and	O
apply	O
`	O
idxmax()	B-API
`	O
and	O
get	O
the	O
values	O
:	O
#CODE	O

Go	O
through	O
the	O
matrix	O
line	O
by	O
line	O
,	O
than	O
apply	O
in	O
each	O
element	O
`	O
ord()	B-API
-	O
65	O
`	O
if	O
it	O
is	O
an	O
alphabet	O
else	O
use	O
it	O
as	O
it	O
is	O
.	O

`	O
64	O
`	O
is	O
`	O
ord	B-API
(	O
"	O
A	O
")	O
-1	O
`	O
.	O

Use	O
`	O
groupby	B-API
/	O
agg	O
`	O
to	O
aggregate	O
the	O
groups	O
.	O

For	O
each	O
group	O
,	O
apply	O
`	O
set	O
`	O
to	O
find	O
the	O
unique	O
strings	O
,	O
and	O
`''	O
.join	B-API
`	O
to	O
concatenate	O
the	O
strings	O
:	O
#CODE	O

convert	O
the	O
dtype	B-API
of	O
the	O
df	O
to	O
a	O
`	O
bool	O
`	O
,	O
then	O
call	O
`	O
apply	O
`	O
and	O
use	O
the	O
boolean	O
mask	O
to	O
mask	O
the	O
columns	O
,	O
you	O
need	O
to	O
pass	O
param	O
`	O
axis=1	O
`	O
to	O
`	O
apply	O
`	O
the	O
column	O
mask	O
row-wise	O
:	O
#CODE	O

Your	O
code	O
`	O
my_df.apply	O
(	O
lambda	O
x	O
:	O
colnames	O
[	O
x	O
])`	O
won't	O
work	O
because	O
firstly	O
when	O
calling	O
`	O
apply	O
`	O
on	O
a	O
df	O
without	O
specifying	O
the	O
`	O
axis	O
`	O
will	O
call	O
the	O
lambda	O
on	O
each	O
column	O
in	O
turn	O
,	O
secondly	O
the	O
`	O
1	O
/	O
0	O
`	O
will	O
interpret	O
this	O
as	O
an	O
index	O
value	O
rather	O
than	O
a	O
boolean	O
flag	O
.	O

The	O
issue	O
occurs	O
because	O
you	O
have	O
three	O
columns	O
with	O
only	O
`	O
NaT	O
`	O
values	O
,	O
which	O
is	O
causing	O
those	O
columns	O
to	O
be	O
treated	O
as	O
objects	O
when	O
you	O
do	O
apply	O
your	O
condition	O
on	O
it	O
.	O

You	O
should	O
put	O
some	O
kind	O
of	O
condition	O
in	O
your	O
`	O
apply	O
`	O
part	O
,	O
to	O
default	O
to	O
some	O
timedelta	O
in	O
case	O
of	O
`	O
NaT	O
`	O
.	O

Example	O
-	O
#CODE	O

Or	O
a	O
simpler	O
way	O
to	O
change	O
the	O
`	O
apply	O
`	O
part	O
to	O
directly	O
get	O
what	O
you	O
want	O
would	O
be	O
-	O
#CODE	O

@USER	O
I	O
am	O
applying	O
customized	O
functions	O
with	O
APPLY	O
function	O
.	O

It	O
seems	O
to	O
me	O
that	O
resample	O
or	O
TimeGrouper	O
fills	O
in	O
the	O
gap	O
automatically	O
,	O
even	O
there	O
is	O
a	O
time	O
gap	O
of	O
one	O
year	O
.	O

Is	O
there	O
a	O
way	O
to	O
prevent	O
from	O
this	O
?	O

Thanks	O
a	O
lot	O

@USER	O
thanks	O
for	O
the	O
suggestion	O
.	O

I	O
have	O
switched	O
to	O
resample	O
and	O
it	O
almost	O
works	O
.	O

Only	O
resample	O
takes	O
the	O
first	O
column	O
of	O
df	O
,	O
does	O
it	O
apply	O
to	O
multiple	O
columns	O
of	O
df	O
at	O
the	O
same	O
time	O
?	O

I	O
would	O
reedit	O
my	O
function	O
into	O
the	O
question	O
.	O
thx	O
again	O

I	O
think	O
you	O
want	O
to	O
`	O
agg	O
`	O
(	O
aggregate	O
)	O
,	O
not	O
`	O
apply	O
`	O
,	O
as	O
for	O
each	O
of	O
your	O
group	O
,	O
you	O
want	O
1	O
returning	O
value	O
:	O
#CODE	O

Apply	O
the	O
daily	O
frequency	O
to	O
weekly	O
frequency	O
(	O
eg	O
.	O
Monday	O
to	O
Sunday	O
)	O

Apply	O
daily	O
frequency	O
to	O
monthly	O
frequency	O
(	O
eg	O
.	O
how	O
many	O
times	O
I	O
see	O
"	O
2012-01	O
-**	O
"	O
in	O
my	O
column	O
)	O

Last	O
apply	O
to	O
get	O
annotation	O
#CODE	O

Pandas	O
has	O
an	O
efficient	O
`	O
nlargest	B-API
`	O
operation	O
you	O
can	O
use	O
that	O
is	O
faster	O
than	O
a	O
full	O
sort	O
.	O

It	O
will	O
still	O
take	O
awhile	O
to	O
apply	O
across	O
500,000	O
columns	O
.	O

#CODE	O

This	O
should	O
be	O
faster	O
than	O
a	O
temporary	O
sort	O
+1	O
,	O
the	O
problem	O
here	O
is	O
that	O
the	O
`	O
apply	O
`	O
is	O
trying	O
to	O
return	O
a	O
df	O
with	O
the	O
same	O
shape	O
as	O
the	O
original	O
df	O
which	O
is	O
not	O
what	O
can	O
be	O
achieved	O
unless	O
you	O
take	O
the	O
raw	O
values	O
and	O
return	O
some	O
other	O
data	O
structure	O
like	O
in	O
your	O
answer	O

How	O
to	O
apply	O
a	O
condition	O
to	O
a	O
large	O
number	O
of	O
columns	O
in	O
a	O
pandas	O
dataframe	B-API

What	O
I	O
would	O
like	O
to	O
do	O
now	O
is	O
apply	O
a	O
function	O
that	O
takes	O
in	O
two	O
strings	O
and	O
produces	O
a	O
score	O
of	O
the	O
similarity	O
between	O
them	O
.	O

For	O
now	O
,	O
I	O
am	O
using	O
the	O
`	O
difflib	O
`	O
library	O
.	O

You	O
can	O
use	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
scheme	O
.	O

#CODE	O

Generally	O
your	O
idea	O
of	O
trying	O
to	O
apply	O
`	O
astype	B-API
`	O
to	O
each	O
column	O
is	O
fine	O
.	O

#CODE	O

Note	O
:	O
While	O
using	O
`	O
pandas.DataFrame	B-API
`	O
avoid	O
using	O
iteration	O
using	O
loop	O
as	O
this	O
much	O
slower	O
than	O
performing	O
the	O
same	O
operation	O
using	O
`	O
apply	O
`	O
.	O

You	O
can	O
`	O
groupby	B-API
`	O
on	O
'	O
id	O
'	O
and	O
then	O
`	O
apply	O
`	O
`	O
list	O
`	O
to	O
`	O
value	O
`	O
column	O
and	O
then	O
call	O
`	O
reset_index	B-API
`	O
:	O
#CODE	O

I	O
resolved	O
this	O
error	O
by	O
creating	O
list	O
of	O
tuples	O
(	O
i.e.	O
apply	O
(	O
tuples	O
))	O
instead	O
of	O
list	O
.	O

But	O
i	O
am	O
not	O
able	O
to	O
explain	O
why	O
tuples	O
works	O
here	O
&	O
when	O
to	O
use	O
tuples	O
vs	O
list	O
.	O

Please	O
advise	O
.	O

For	O
your	O
reference	O
the	O
`	O
apply	O
`	O
method	O
automatically	O
passes	O
the	O
data	O
frame	O
as	O
the	O
first	O
argument	O
.	O

Also	O
,	O
as	O
you	O
are	O
always	O
going	O
to	O
be	O
reducing	O
each	O
group	O
of	O
data	O
to	O
a	O
single	O
observation	O
you	O
could	O
also	O
use	O
the	O
`	O
agg	O
`	O
method	O
(	O
aggregate	O
)	O
.	O

`	O
apply	O
`	O
is	O
more	O
flexible	O
in	O
terms	O
of	O
the	O
length	O
of	O
the	O
sequences	O
that	O
can	O
be	O
returned	O
whereas	O
`	O
agg	O
`	O
must	O
reduce	O
the	O
data	O
to	O
a	O
single	O
value	O
.	O

#CODE	O

I	O
found	O
also	O
this	O
question	O
related	O
to	O
a	O
similar	O
issues	O
,	O
but	O
I	O
can't	O
figured	O
out	O
how	O
to	O
apply	O
that	O
method	O
in	O
my	O
case	O
.	O

You	O
can	O
apply	O
the	O
same	O
logic	O
,	O
just	O
keep	O
the	O
rows	O
that	O
have	O
the	O
first	O
elements	O
the	O
start	O
with	O
"	O
AN	O
using	O
a	O
generator	O
expression	O

You	O
could	O
apply	O
a	O
lambda	O
on	O
each	O
column	O
group	O
:	O
#CODE	O

I've	O
tried	O
to	O
use	O
`	O
apply	O
`	O
like	O
this	O
,	O
but	O
can't	O
figure	O
out	O
the	O
correct	O
syntax	O
:	O
#CODE	O

Pass	O
param	O
`	O
axis=1	O
`	O
to	O
`	O
apply	O
`	O
to	O
iterate	O
row-wise	O
:	O
#CODE	O

I'm	O
trying	O
to	O
convert	O
a	O
Pandas	O
dataframe	B-API
series	O
to	O
float	O
.	O

I	O
do	O
`	O
locale.setlocale	O
(	O
locale.LC_NUMERIC	O
,	O
'')`	O
and	O
then	O
`	O
df.idh.apply	O
(	O
locale.atof	O
)`	O
,	O
but	O
it	O
gives	O
me	O
the	O
above	O
mentioned	O
error	O
:	O
`	O
AttributeError	O
:	O
'	O
float	O
'	O
object	O
has	O
no	O
attribute	O
'	O
replace	O
'`	O
.	O

I	O
assume	O
at	O
some	O
point	O
it's	O
getting	O
something	O
like	O
a	O
NaN	O
,	O
maybe	O
or	O
some	O
other	O
string	O
and	O
it	O
does	O
not	O
recognize	O
it	O
.	O

How	O
do	O
I	O
tell	O
`	O
apply	O
`	O
to	O
skip	O
those	O
?	O

Firstly	O
the	O
conversion	O
to	O
decimal	O
is	O
really	O
`	O
float	O
`	O
dtype	B-API
due	O
to	O
the	O
resampling	O
as	O
this	O
will	O
introduce	O
`	O
NaN	O
`	O
values	O
for	O
missing	O
values	O
,	O
you	O
can	O
fix	O
this	O
using	O
`	O
astype	B-API
`	O
,	O
you	O
can	O
then	O
restore	O
your	O
'	O
timeline	O
'	O
column	O
which	O
get	O
lost	O
as	O
it	O
can't	O
figure	O
out	O
how	O
to	O
resample	O
a	O
`	O
str	O
`	O
so	O
we	O
can	O
apply	O
`	O
strftime	B-API
`	O
to	O
the	O
index	O
:	O
#CODE	O

You	O
can	O
`	O
groupby	B-API
`	O
on	O
'	O
col1	O
'	O
and	O
then	O
`	O
apply	O
`	O
a	O
lambda	O
that	O
joins	O
the	O
values	O
:	O
#CODE	O

but	O
this	O
will	O
start	O
the	O
index	O
from	O
`	O
0	O
`	O
.	O

I	O
want	O
to	O
start	O
it	O
from	O
`	O
1	O
`	O
.	O

How	O
do	O
I	O
do	O
that	O
without	O
creating	O
any	O
extra	O
columns	O
and	O
by	O
keeping	O
the	O
index	O
/	O
reset_index	B-API
functionality	O
and	O
options	O
?	O

I	O
do	O
not	O
want	O
to	O
create	O
a	O
new	O
dataframe	B-API
,	O
so	O
`	O
inplace=True	O
`	O
should	O
still	O
apply	O
.	O

You	O
can	O
`	O
apply	O
`	O
a	O
lambda	O
to	O
your	O
dates	O
and	O
call	O
`	O
datetime.strftime	O
`	O
:	O
#CODE	O

referring	O
to	O
this	O
link	O
:	O
implementing	O
R	O
scale	O
function	O
in	O
pandas	O
in	O
Python	O
?	O

I	O
used	O
the	O
function	O
for	O
def	O
scale	O
and	O
want	O
to	O
apply	O
for	O
it	O
,	O
like	O
this	O
fashion	O
:	O
#CODE	O

Apply	O
a	O
func	O
to	O
generate	O
a	O
new	O
colum	O
based	O
on	O
value	O
of	O
other	O
colums	O
in	O
Pandas	O

When	O
I	O
'	O
apply	O
'	O
that	O
function	O
to	O
both	O
'	O
Time	O
on	O
Page	O
'	O
'	O
Pageviews	O
'	O
columns	O
,	O
wouldn't	O
it	O
take	O
the	O
value	O
from	O
both	O
columns	O
as	O
the	O
argument	O
and	O
return	O
one	O
value	O
,	O
which	O
is	O
'	O
AvgTimeOnPage	O
'	O
,	O
as	O
the	O
output	O
?	O

I	O
don't	O
quite	O
understand	O
the	O
error	O
msg	O
saying	O
'	O
1	O
'	O
arg	O
is	O
given	O
,	O
instead	O
of	O
'	O
2	O
'	O

@USER	O
Ah	O
,	O
I	O
see	O
,	O
apply	O
takes	O
ONE	O
argument	O
(	O
which	O
is	O
a	O
row	O
/	O
Series	O
)	O
and	O
you	O
access	O
the	O
column	O
as	O
`	O
x	O
[	O
'	O
Time	O
on	O
Page	O
']`	O
inside	O
the	O
apply	O
.	O

Passing	O
as	O
(	O
x	O
,	O
y	O
)	O
doesn't	O
work	O
-	O
I	O
suspect	O
the	O
second	O
argument	O
is	O
used	O
as	O
some	O
kind	O
of	O
flag	O
.	O

Using	O
apply	O
on	O
a	O
column	O

I'd	O
like	O
to	O
somehow	O
apply	O
a	O
function	O
to	O
each	O
column	O
,	O
converting	O
it	O
to	O
a	O
list	O
and	O
placing	O
it	O
in	O
a	O
new	O
DataFrame	B-API
.	O

However	O
,	O
apply	O
only	O
operates	O
on	O
individual	O
entries	O
.	O

Managed	O
to	O
figure	O
this	O
out	O
from	O
what	O
you	O
gave	O
me	O
.	O

I	O
simply	O
needed	O
to	O
apply	O
a	O
split	O
function	O
to	O
each	O
string	O
in	O
the	O
dataframe	B-API
!	O

:D	O
Thank	O
you	O
!	O

but	O
there	O
is	O
no	O
pandas	O
method	O
that	O
allows	O
you	O
to	O
return	O
the	O
minimum	O
like	O
`	O
np.miniumum	O
`	O
,	O
also	O
`	O
np.minimum	B-API
`	O
does	O
not	O
care	O
about	O
aligning	O
columns	O
and	O
indices	O
here	O
.	O

You'd	O
have	O
to	O
define	O
a	O
func	O
yourself	O
and	O
`	O
apply	O
`	O
it	O
,	O
also	O
you	O
need	O
to	O
add	O
all	O
this	O
information	O
to	O
your	O
question	O
and	O
to	O
pose	O
representative	O
code	O
to	O
show	O
your	O
desired	O
output	O
including	O
a	O
series	O
with	O
an	O
index	O
in	O
a	O
different	O
order	O
to	O
your	O
df	O

And	O
then	O
apply	O
it	O
to	O
some	O
function	O
that	O
returns	O
a	O
series	O
like	O
so	O
:	O
#CODE	O

Essentially	O
this	O
performs	O
a	O
reverse	O
lookup	O
,	O
we	O
iterate	O
over	O
the	O
ingredients	O
series	O
using	O
`	O
apply	O
`	O
and	O
then	O
test	O
for	O
membership	O
of	O
this	O
ingredient	O
in	O
the	O
whole	O
df	O
using	O
`	O
contains	O
`	O
this	O
will	O
handle	O
plurals	O
in	O
this	O
case	O
.	O

I	O
have	O
a	O
dataframe	B-API
with	O
sporadic	O
dates	O
as	O
the	O
index	O
,	O
and	O
columns	O
=	O
'	O
id	O
'	O
and	O
'	O
num	O
'	O
.	O

I	O
would	O
like	O
to	O
`	O
pd.groupby	O
`	O
the	O
'	O
id	O
'	O
column	O
,	O
and	O
apply	O
the	O
reindex	O
to	O
each	O
group	O
in	O
the	O
dataframe	B-API
.	O

Which	O
returns	O
error	O
:	O
`	O
AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
reindex	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
`	O

This	O
appears	O
to	O
be	O
successful	O
.	O

Now	O
I	O
want	O
to	O
apply	O
functions	O
based	O
on	O
metadata	O
criteria	O
:	O
#CODE	O

You	O
can	O
use	O
apply	O
,	O
like	O
this	O
.	O

#CODE	O

I	O
need	O
to	O
apply	O
this	O
calculation	O
to	O
every	O
cell	O
.	O

But	O
then	O
I	O
am	O
struggling	O
to	O
find	O
a	O
way	O
to	O
apply	O
this	O
function	O
to	O
each	O
cell	O
in	O
the	O
dataframe	B-API
.	O

I	O
tried	O
`	O
iterrows	B-API
`	O
but	O
it	O
was	O
very	O
slow	O
as	O
the	O
actual	O
dataset	O
is	O
very	O
large	O
.	O

If	O
you	O
have	O
trends	O
in	O
your	O
serie	O
,	O
you	O
may	O
rather	O
apply	O
it	O
on	O
time	O
moving	O
window	O
instead	O
of	O
the	O
whole	O
serie	O
.	O

@USER	O
you	O
mean	O
to	O
apply	O
the	O
function	O
as	O
follows	O
?	O

This	O
produced	O
me	O
an	O
error	O
.	O

`	O
results=	O
ingredients.apply	O
(	O
lambda	O
x	O
:	O
where	O
(	O
df	O
[	O
0	O
]	O
.str	B-API
.lower()	B-API
.str	B-API
.contains	B-API
(	O
x.lower()	O
)	O
,	O
True	O
))`	O

Now	O
apply	O
a	O
ffill	B-API
lambda	O
as	O
follows	O
:	O
#CODE	O

More	O
elegant	O
than	O
the	O
apply	O
function	O
is	O
to	O
use	O
`	O
result	O
[	O
xstring	O
]	O
=	O
tst.bla.str.contains	O
(	O
xstring	O
)`	O

So	O
,	O
I	O
truncated	O
my	O
data	O
set	O
in	O
the	O
question	O
to	O
make	O
it	O
easier	O
to	O
read	O
and	O
thinking	O
that	O
whatever	O
solution	O
came	O
would	O
also	O
apply	O
..	O

In	O
actuality	O
,	O
the	O
groupings	O
are	O
34	O
rows	O
long	O
,	O
and	O
replacing	O
the	O
`	O
3	O
`	O
with	O
`	O
34	O
`	O
does	O
not	O
seem	O
to	O
work	O
-	O
any	O
thoughts	O
?	O

If	O
you	O
want	O
to	O
change	O
the	O
display	O
format	O
then	O
you	O
need	O
to	O
parse	O
as	O
a	O
datetime	O
and	O
then	O
`	O
apply	O
`	O
`	O
datetime.strftime	O
:	O
#CODE	O

`	O
apply	O
`	O
a	O
lambda	O
to	O
convert	O
to	O
timedelta	O
and	O
then	O
subtract	O
:	O
#CODE	O

That	O
now	O
leaves	O
me	O
with	O
$23	O
to	O
spend	O
on	O
extra	O
presents	O
that	O
birthday	O
;	O
the	O
same	O
rules	O
as	O
above	O
apply	O
on	O
any	O
additional	O
presents	O
.	O

apply	O
`	O
df.str.contains()	O
`	O
to	O
`	O
s2	O
`	O
using	O
the	O
contents	O
of	O
`	O
s1	O
`	O
as	O
the	O
matching	O
pattern	O

The	O
best	O
I	O
could	O
come	O
up	O
with	O
is	O
to	O
use	O
`	O
apply	O
`	O
instead	O
of	O
manual	O
iterations	O
:	O
#CODE	O

sorry	O
to	O
break	O
this	O
to	O
you	O
but	O
`	O
apply	O
`	O
is	O
essentially	O
a	O
`	O
for	O
`	O
loop	O
,	O
the	O
code	O
just	O
looks	O
cleaner	O

My	O
understanding	O
in	O
pandas	O
is	O
to	O
use	O
a	O
pd.rolling_sum()	B-API
function	O
but	O
i'm	O
not	O
quite	O
sure	O
how	O
to	O
groupby	B-API
and	O
apply	O
it	O
while	O
setting	O
a	O
condition	O
.	O

I've	O
also	O
tried	O
using	O
cumcount()	B-API
to	O
no	O
avail	O
#CODE	O

See	O
comment	O
@USER	O
In	O
short	O
,	O
can	O
I	O
"	O
universalize	O
"	O
this	O
to	O
make	O
it	O
apply	O
to	O
every	O
car	O
?	O

Thanks	O
.	O

You	O
can	O
apply	O
the	O
recipe	O
from	O
here	O
#CODE	O

That	O
loop	O
works	O
fine	O
,	O
but	O
I	O
trying	O
to	O
see	O
how	O
I	O
could	O
use	O
map	O
and	O
apply	O
to	O
make	O
this	O
look	O
cleaner	O
.	O

From	O
reading	O
,	O
apply	O
is	O
a	O
loop	O
function	O
underneath	O
,	O
so	O
I'm	O
not	O
sure	O
whether	O
I	O
will	O
get	O
any	O
speed	O
from	O
doing	O
this	O
.	O

But	O
,	O
it	O
could	O
shrink	O
the	O
code	O
by	O
a	O
lot	O
.	O

Do	O
you	O
know	O
of	O
a	O
more	O
general	O
method	O
?	O

This	O
works	O
fine	O
with	O
basic	O
addition	O
,	O
but	O
I	O
was	O
trying	O
to	O
find	O
a	O
way	O
to	O
apply	O
a	O
more	O
general	O
function	O
.	O

I've	O
updated	O
the	O
question	O
to	O
show	O
a	O
more	O
complicated	O
example	O
.	O

I	O
cannot	O
understand	O
the	O
error	O
I	O
see	O
when	O
using	O
apply	O
or	O
transform	O
:	O

1	O
2	O
)	O
`	O
transform	O
`	O
expects	O
something	O
"	O
like-indexed	O
"	O
,	O
while	O
`	O
apply	O
`	O
is	O
flexible	O
.	O

The	O
two	O
failing	O
functions	O
are	O
adding	O
additional	O
columns	O
.	O

4	O
)	O
The	O
first	O
two	O
functions	O
take	O
a	O
`	O
DataFrame	B-API
`	O
with	O
two	O
parameters	O
and	O
returns	O
data	O
.	O

`	O
InnerFoo	O
`	O
actually	O
returns	O
another	O
function	O
,	O
so	O
it	O
needs	O
to	O
be	O
called	O
before	O
being	O
passed	O
into	O
`	O
apply	O
`	O
.	O

Hi	O
Tom	O
,	O
it	O
doesn't	O
look	O
like	O
this	O
works	O
.	O

It	O
outputs	O
just	O
one	O
array	O
and	O
is	O
equivalent	O
to	O
df2	O
[	O
'	O
array	O
']	O
.sum()	B-API
.	O

But	O
you	O
have	O
given	O
me	O
an	O
idea	O
with	O
apply	O
.	O

Let	O
me	O
see	O
if	O
I	O
can	O
figure	O
something	O
out	O
.	O

Apply	O
string.format()	O
to	O
row	O
in	O
Pandas	O
DataFrame	B-API

can	O
be	O
used	O
to	O
apply	O
the	O
format	O
string	O
using	O
the	O
column	O
data	O
.	O

and	O
then	O
apply	O
the	O
method	O
over	O
it	O
.	O

You	O
can	O
create	O
a	O
boolean	O
mask	O
by	O
calling	O
`	O
apply	O
`	O
on	O
'	O
type	O
'	O
column	O
to	O
create	O
your	O
new	O
df	O
:	O
#CODE	O

Apply	O
a	O
function	O
to	O
translate	O
a	O
column	O
in	O
pandas	O
dataframe	B-API
with	O
condition	O
on	O
other	O
columns	O

Why	O
not	O
just	O
convert	O
the	O
whole	O
column	O
to	O
English	O
,	O
then	O
use	O
a	O
mask	O
of	O
non-english	O
rows	O
to	O
replace	O
only	O
the	O
ones	O
you	O
need	O
to	O
?	O

That	O
is	O
a	O
bit	O
easier	O
than	O
using	O
apply	O
with	O
your	O
conditionals	O
happening	O
in	O
each	O
step	O
.	O

and	O
that	O
the	O
function	O
inside	O
`	O
apply	O
`	O
should	O
make	O
use	O
of	O
the	O
`	O
isin	B-API
`	O
method	O
.	O

probably	O
but	O
calling	O
`	O
apply	O
`	O
will	O
also	O
be	O
very	O
slow	O
as	O
this	O
is	O
just	O
a	O
`	O
for	O
`	O
loop	O

Then	O
apply	O
your	O
method	O
:	O
#CODE	O

apply	O
conditional	O
if	O
loop	O
over	O
groups	O

I	O
think	O
it	O
apply	O
the	O
function	O
to	O
the	O
index	O
instead	O
of	O
the	O
value	O
.	O

OK	O
,	O
I'd	O
`	O
reindex	O
`	O
using	O
your	O
time_series	O
,	O
then	O
`	O
groupby	B-API
`	O
on	O
your	O
index	O
and	O
then	O
apply	O
`	O
isnull	O
`	O
and	O
call	O
`	O
sum	O
`	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
add	O
the	O
values	O
then	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
use	O
the	O
`	O
new_df	O
`	O
values	O
to	O
perform	O
a	O
lookup	O
from	O
`	O
cos	O
`	O
df	O
:	O
#CODE	O

This	O
is	O
by	O
far	O
the	O
most	O
efficient	O
solution	O
to	O
this	O
problem	O
.	O

The	O
hard	O
part	O
was	O
realizing	O
that	O
I	O
could	O
`	O
sort	O
`	O
`	O
df	O
`	O
by	O
the	O
`	O
Type	O
Rank	O
`	O
so	O
the	O
`	O
Criterion	O
Type	O
`	O
rows	O
were	O
ordered	O
by	O
their	O
rank	O
.	O

This	O
meant	O
I	O
wanted	O
the	O
highest	O
`	O
Max	O
CPC	O
`	O
to	O
apply	O
to	O
the	O
first	O
,	O
the	O
second	O
highest	O
`	O
Max	O
CPC	O
`	O
to	O
the	O
second	O
,	O
and	O
so	O
on	O
.	O

You	O
can	O
use	O
`	O
str.split	B-API
`	O
,	O
followed	O
by	O
a	O
`	O
apply	O
(	O
pd.Series	B-API
)	O
.stack()	B-API
`	O
(	O
the	O
`	O
apply	O
(	O
pd.Series	B-API
)`	O
makes	O
different	O
columns	O
of	O
the	O
elements	O
,	O
`	O
stack	O
`	O
is	O
for	O
turning	O
this	O
to	O
rows	O
):	O
#CODE	O

I	O
have	O
tried	O
to	O
apply	O
your	O
answers	O
but	O
I	O
do	O
not	O
get	O
good	O
results	O
as	O
you	O
can	O
see	O
below	O
:	O
I	O
just	O
have	O
the	O
same	O
value	O
1970	O
-	O
01-01	O
instead	O
of	O
having	O
a	O
column	O
with	O
the	O
same	O
value	O
stored	O
in	O
datetime	O
column	O
.	O

Arrival	O
column	O
is	O
empty	O
instead	O
of	O
having	O
the	O
count	O
of	O
arrivals	O
as	O
needed	O
(	O
from	O
df1	O
)	O
#CODE	O

@USER	O
has	O
a	O
pretty	O
good	O
answer	O
.	O

Thinking	O
outside	O
the	O
box	O
,	O
you	O
could	O
groupby	B-API
school	O
and	O
set	O
indexes	O
on	O
the	O
date	O
columns	O
one	O
at	O
a	O
time	O
.	O

Then	O
you	O
can	O
use	O
the	O
rolling	O
counts	O
because	O
it	O
will	O
be	O
sorted	O
by	O
date	O
.	O

That	O
will	O
be	O
much	O
faster	O
than	O
using	O
the	O
apply	O
method	O
and	O
checking	O
len	O
for	O
each	O
row	O
.	O

Check	O
out	O
cumcount	O
#URL	O

Pandas	O
dataframe	B-API
apply	O
function	O
to	O
entire	O
column	O

`	O
.apply()	B-API
`	O
is	O
the	O
method	O
to	O
apply	O
a	O
function	O
to	O
a	O
`	O
Series	O
`	O
on	O
a	O
row-by-row	O
basis	O
.	O

Other	O
than	O
that	O
you	O
haven't	O
given	O
much	O
information	O
to	O
work	O
with	O
.	O

apply	O
a	O
function	O
that	O
return	O
a	O
list	O

I	O
know	O
how	O
to	O
split	O
a	O
string	O
,	O
but	O
I	O
could	O
not	O
find	O
a	O
way	O
to	O
apply	O
it	O
to	O
a	O
series	O
,	O
or	O
a	O
Data	O
Frame	O
column	O
.	O

For	O
all	O
but	O
the	O
last	O
names	O
you	O
can	O
apply	O
`"	O
"	O
.join	B-API
(	O
..	O
)`	O
to	O
all	O
but	O
the	O
last	O
element	O
(	O
`	O
[:	O
-1	O
]`)	O
of	O
each	O
row	O
:	O
#CODE	O

Without	O
knowing	O
the	O
format	O
of	O
your	O
csv	O
files	O
this	O
question	O
is	O
hard	O
to	O
answer	O
.	O

Yes	O
,	O
you	O
can	O
probably	O
use	O
much	O
less	O
RAM	O
than	O
the	O
3.8gb	O
text	O
file	O
-	O
No	O
you	O
cannot	O
use	O
the	O
same	O
strategies	O
as	O
you	O
would	O
apply	O
to	O
a	O
file	O
on	O
your	O
disk	O
.	O

On	O
the	O
disk	O
you	O
only	O
have	O
to	O
store	O
the	O
information	O
,	O
in	O
memory	O
you	O
often	O
have	O
to	O
keep	O
this	O
information	O
in	O
a	O
form	O
which	O
is	O
easy	O
to	O
manipulate	O
.	O

The	O
`	O
args	O
`	O
argument	O
given	O
to	O
apply	O
function	O
is	O
passed	O
`	O
func	O
`	O
argument	O
(	O
lambda	O
function	O
given	O
)	O
.	O

You	O
are	O
getting	O
this	O
error	O
since	O
two	O
arguments	O
are	O
given	O
but	O
lambda	O
function	O
only	O
accepts	O
one	O
argument	O
.	O

You	O
could	O
take	O
advantage	O
of	O
the	O
vectorized	O
string	O
operations	O
available	O
under	O
`	O
.str	B-API
`	O
,	O
instead	O
of	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

`	O
pd.read_table	B-API
(	O
filename	O
,	O
usecols	O
=[	O
0	O
,	O
8	O
,	O
9	O
,	O
11	O
]	O
,	O
parse_dates	O
=[	O
1	O
,	O
2	O
]	O
,	O
dtype={	O
'	O
LopNr	O
'	O
:	O
np.uint32	O
,	O
'	O
INDATUMA	O
'	O
:	O
np.uint32	O
,	O
'	O
UTDATUMA	O
'	O
:	O
np.uint32	O
,	O
'	O
DIAGNOS	O
'	O
:	O
np.object	O
}	O
)`	O
,	O
assuming	O
the	O
dtype	B-API
would	O
apply	O
to	O
the	O
data	O
before	O
it	O
enters	O
the	O
converter	O
,	O
hiccups	O
on	O
a	O
string	O
in	O
some	O
of	O
the	O
rows	O
:	O
`	O
ValueError	O
:	O
invalid	O
literal	O
for	O
long()	O
with	O
base	O
10	O
:	O
'	O
string	O
'`	O

This	O
can	O
be	O
done	O
with	O
`	O
groupby	B-API
`	O
and	O
using	O
`	O
apply	O
`	O
to	O
run	O
a	O
simple	O
function	O
on	O
each	O
group	O
:	O
#CODE	O

and	O
if	O
you	O
want	O
to	O
apply	O
your	O
custom	O
function	O
you	O
can	O
use	O
apply	O
where	O
it	O
takes	O
your	O
custom	O
function	O
as	O
a	O
parameter	O
,	O
and	O
it	O
passes	O
each	O
group	O
to	O
your	O
custom	O
function	O
#CODE	O

Just	O
to	O
compare	O
against	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

If	O
you	O
had	O
not	O
called	O
`	O
apply	O
`	O
on	O
the	O
`	O
groupby	B-API
`	O
object	O
then	O
you	O
could	O
access	O
the	O
`	O
groups	O
`	O
:	O
#CODE	O

Including	O
the	O
group	O
name	O
in	O
the	O
apply	O
function	O
pandas	O
python	O

Is	O
there	O
away	O
to	O
specify	O
the	O
groupby	B-API
call	O
to	O
use	O
the	O
group	O
name	O
in	O
the	O
apply	O
lambda	O
function	O
.	O

is	O
there	O
away	O
to	O
get	O
the	O
group	O
name	O
in	O
the	O
apply	O
function	O
,	O
such	O
as	O
:	O
#CODE	O

How	O
can	O
I	O
get	O
the	O
group	O
name	O
as	O
an	O
argument	O
for	O
the	O
apply	O
lambda	O
function	O
?	O

This	O
is	O
difficult	O
to	O
do	O
in	O
place	O
as	O
pandas	O
will	O
expand	O
the	O
structure	O
after	O
the	O
`	O
apply	O
`	O

If	O
you	O
want	O
to	O
apply	O
values	O
from	O
other	O
parts	O
of	O
the	O
df	O
you	O
could	O
put	O
those	O
in	O
a	O
dict	O
and	O
then	O
pass	O
that	O
into	O
your	O
apply	O
function	O
.	O

#CODE	O

But	O
I	O
recognise	O
that	O
my	O
expressions	O
contain	O
sub-expressions	O
that	O
consist	O
of	O
only	O
scalar	O
values	O
.	O

Do	O
the	O
documented	O
rules	O
apply	O
to	O
sub-expressions	O
as	O
well	O
then	O
?	O

The	O
code	O
does	O
run	O
,	O
but	O
the	O
result	O
isn't	O
correct	O
.	O

The	O
problem	O
with	O
`	O
apply	O
`	O
is	O
that	O
you	O
need	O
to	O
return	O
mulitple	O
rows	O
and	O
it	O
expects	O
only	O
one	O
.	O

A	O
possible	O
solution	O
:	O
#CODE	O

Thanks	O
for	O
the	O
advice	O
hellpanderrr	O
.	O

I	O
think	O
what	O
I	O
needed	O
to	O
know	O
is	O
that	O
it's	O
not	O
possible	O
to	O
reassign	O
different	O
dimensions	O
in	O
an	O
apply	O
function	O
.	O

I	O
also	O
needed	O
a	O
way	O
to	O
generically	O
assign	O
the	O
remaining	O
columns	O
to	O
the	O
new	O
groups	O
.	O

In	O
the	O
end	O
I	O
came	O
up	O
with	O
the	O
technique	O
shown	O
in	O
my	O
answer	O
.	O

Cheers	O

The	O
`	O
groupby	B-API
`	O
version	O
of	O
`	O
apply	O
`	O
supports	O
`	O
DataFrame	B-API
`	O
as	O
return	O
value	O
in	O
the	O
way	O
which	O
you	O
intended	O
:	O
#CODE	O

Just	O
call	O
`	O
apply	O
`	O
and	O
call	O
`	O
tuple	O
`	O
:	O
#CODE	O

How	O
do	O
I	O
apply	O
a	O
regex	O
substitution	O
in	O
a	O
string	O
column	O
of	O
a	O
data	O
frame	O
?	O

You	O
should	O
assign	O
another	O
DataFrame	B-API
to	O
hold	O
the	O
index	O
and	O
value	O
of	O
such	O
,	O
and	O
apply	O
to	O
the	O
original	O
DataFrame	B-API
base	O
on	O
the	O
groupby	B-API
field	O
(	O
as	O
index	O
)	O
.	O

Then	O
apply	O
and	O
perform	O
the	O
lookup	O
:	O
#CODE	O

For	O
each	O
of	O
the	O
new	O
data	O
frames	O
I	O
then	O
apply	O
this	O
logic	O
:	O
#CODE	O

A	O
hack	O
is	O
to	O
set	O
the	O
dtype	B-API
to	O
object	O
before	O
doing	O
the	O
apply	O
:	O
#CODE	O

This	O
solution	O
worked	O
if	O
i	O
apply	O
group	O
by	O
column	O
only	O
on	O
Sex	O
field	O
.	O

Howver	O
another	O
requirement	O
says	O
the	O
below	O
format	O
:	O
Date	O
Sex	O
weight	O
hight	O
Salary	O

How	O
to	O
apply	O
cubic	O
spline	O
interpolation	O
over	O
long	O
Pandas	O
Series	O
?	O

This	O
approach	O
is	O
very	O
slow	O
as	O
it	O
involves	O
iteration	O
and	O
invoking	O
the	O
apply	O
method	O
for	O
each	O
group	O
.	O

Re	O
transform	O
vs	O
apply	O
:	O
generally	O
speaking	O
you	O
use	O
transform	O
to	O
keep	O
the	O
same	O
number	O
of	O
rows	O
when	O
the	O
function	O
would	O
otherwise	O
reduce	O
the	O
number	O
of	O
rows	O
.	O

It's	O
not	O
clear	O
to	O
me	O
why	O
it	O
is	O
needed	O
here	O
as	O
expanding_mean	B-API
should	O
not	O
be	O
reducing	O
anyway	O
...	O

You	O
need	O
to	O
apply	O
your	O
function	O
to	O
a	O
data	O
frame	O
,	O
not	O
a	O
series	O
#CODE	O

I	O
would	O
apply	O
your	O
operations	O
to	O
a	O
copy	O
of	O
the	O
`	O
DataFrame	B-API
`	O
and	O
stack	O
back	O
together	O
-	O
something	O
like	O
this	O
:	O
#CODE	O

You	O
could	O
use	O
`	O
apply	O
`	O
to	O
generate	O
the	O
values	O
for	O
each	O
range	O
,	O
then	O
`	O
melt	B-API
`	O
to	O
reshape	O
the	O
data	O
into	O
long	O
form	O
.	O

#CODE	O

Apply	O
two	O
operations	O
on	O
the	O
sub	O
`	O
DataFrame	B-API
`	O
obtained	O
by	O
the	O
`	O
groupby	B-API
`	O
(	O
one	O
for	O
each	O
year	O
)	O

Alexander	O
,	O
this	O
was	O
extraordinarily	O
helpful	O
!	O

It	O
may	O
take	O
me	O
some	O
time	O
to	O
evaluate	O
and	O
apply	O
.	O

I	O
will	O
report	O
back	O
.	O

I	O
am	O
proactively	O
calling	O
this	O
question	O
answered	O
.	O

Please	O
let	O
me	O
know	O
if	O
there	O
are	O
other	O
methods	O
for	O
up	O
voting	O
and	O
giving	O
positive	O
feedback	O
!	O

I	O
am	O
new	O
to	O
python	O
and	O
pandas	O
.	O

How	O
can	O
we	O
apply	O
a	O
groupby	B-API
and	O
an	O
aggregate	O
on	O
multiple	O
columns	O
ignoring	O
the	O
blank	O
/	O
None	O
/	O
NaN	O
values	O
?	O

I	O
am	O
trying	O
to	O
apply	O
a	O
groupby	B-API
and	O
count	O
agregation	O
function	O
on	O
these	O
values	O
as	O
:	O

Because	O
your	O
are	O
updating	O
the	O
same	O
set	O
of	O
values	O
in	O
that	O
dataframe	B-API
at	O
the	O
same	O
time	O
,	O
you	O
can	O
try	O
to	O
use	O
a	O
temp	O
variable	O
to	O
hold	O
the	O
result	O
and	O
apply	O
back	O
to	O
the	O
column	O
,	O
see	O
if	O
this	O
helps	O
ridding	O
of	O
the	O
warning	O
message	O
.	O

Here	O
is	O
the	O
feedback	O
I	O
get	O
from	O
plugging	O
that	O
in	O
:	O
AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
unstack	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O

I	O
see	O
you	O
can	O
do	O
two	O
conditions	O
on	O
one	O
line	O
,	O
but	O
I	O
don't	O
see	O
how	O
to	O
apply	O
it	O
.	O

The	O
second	O
line	O
is	O
perfect	O
,	O
but	O
how	O
do	O
you	O
implement	O
the	O
first	O
stage	O
,	O
where	O
location	O
id	O
can	O
be	O
specified	O
for	O
the	O
group	O
by	O
to	O
apply	O
to	O
the	O
subset	O
?	O

Discretization	O
of	O
continuous	O
attributes	O
using	O
np.histogram	B-API
-	O
how	O
to	O
apply	O
on	O
a	O
new	O
data	O
point	O
?	O

After	O
I	O
"	O
learned	O
"	O
my	O
bins	O
from	O
train	O
data	O
,	O
using	O
`	O
np.histogram	B-API
(	O
A	O
[	O
'	O
my_var	O
'])`	O
how	O
do	O
I	O
apply	O
it	O
on	O
my	O
test	O
set	O
?	O
as	O
in	O
which	O
bin	O
is	O
the	O
my_var	O
attribute	O
of	O
each	O
data	O
point	O
?	O

Both	O
my	O
train	O
and	O
test	O
data	O
are	O
in	O
pandas	O
data	O
frames	O
,	O
if	O
it	O
matters	O
.	O

Pandas	O
:	O
How	O
to	O
apply	O
a	O
function	O
to	O
different	O
columns	O

I	O
want	O
to	O
apply	O
the	O
function	O
to	O
just	O
columns	O
`	O
B	O
`	O
and	O
`	O
D	O
`	O
.	O

(	O
Applying	O
it	O
to	O
the	O
full	O
DataFrame	B-API
isn't	O
the	O
answer	O
as	O
that	O
produces	O
NaN	O
values	O
in	O
the	O
numeric	O
columns	O
)	O
.	O

But	O
I	O
cannot	O
fathom	O
how	O
to	O
select	O
distinct	O
columns	O
to	O
apply	O
the	O
function	O
to	O
.	O

I've	O
tried	O
all	O
manner	O
of	O
indexing	O
by	O
numeric	O
position	O
,	O
name	O
,	O
etc	O
.	O

How	O
to	O
apply	O
a	O
function	O
to	O
two	O
columns	O
of	O
Pandas	O
dataframe	B-API

Pandas	O
:	O
How	O
to	O
use	O
apply	O
function	O
to	O
multiple	O
columns	O

Pandas	O
:	O
apply	O
different	O
functions	O
to	O
different	O
columns	O

Python	O
Pandas	O
:	O
Using	O
apply	O
to	O
apply	O
1	O
function	O
to	O
multiple	O
columns	O

Apply	O
isn't	O
inplace	O
,	O
it	O
returns	O
a	O
new	O
dataframe	B-API
,	O
so	O
the	O
question	O
is	O
can	O
you	O
return	O
the	O
complete	O
dataframe	B-API
in	O
one	O
go	O
.	O

None	O
of	O
them	O
seem	O
to	O
apply	O
to	O
this	O
problem	O
,	O
and	O
all	O
of	O
them	O
say	O
that	O
in	O
order	O
to	O
generate	O
unique	O
values	O
from	O
every	O
column	O
,	O
you	O
should	O
either	O
use	O
a	O
groupby	B-API
function	O
,	O
or	O
select	O
individual	O
columns	O
.	O

I	O
have	O
a	O
very	O
large	O
number	O
of	O
columns	O
(	O
over	O
20	O
)	O
,	O
so	O
it	O
doesn't	O
really	O
make	O
sense	O
to	O
group	O
them	O
together	O
just	O
by	O
writing	O
out	O
df.unique	O
[	O
'	O
col1	O
'	O
,	O
'	O
col2	O
'	O
...	O
'	O
col20	O
']	O

I	O
have	O
tried	O
.unique()	B-API
,	O
.value_counts()	B-API
,	O
and	O
.count	B-API
,	O
but	O
I	O
can't	O
figure	O
out	O
how	O
to	O
apply	O
any	O
of	O
those	O
to	O
work	O
across	O
multiple	O
columns	O
,	O
rather	O
than	O
a	O
groupby	B-API
function	O
or	O
anything	O
that	O
was	O
suggested	O
in	O
the	O
above	O
links	O
.	O

Just	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`	O
pd.Series.value_counts	B-API
`	O
:	O
#CODE	O

I	O
had	O
understood	O
'	O
converters	O
'	O
specified	O
a	O
function	O
to	O
apply	O
to	O
the	O
column	O
.	O
evidently	O
I	O
was	O
wrong	O
-	O
thank	O
you	O
for	O
pointing	O
this	O
out	O
,	O
it's	O
very	O
useful	O
!	O

The	O
read_excel()	B-API
function	O
has	O
a	O
converters	O
argument	O
,	O
where	O
you	O
can	O
apply	O
functions	O
to	O
input	O
in	O
certain	O
columns	O
.	O

You	O
can	O
use	O
this	O
to	O
keep	O
them	O
as	O
strings	O
.	O

It	O
won't	O
be	O
super-performant	O
,	O
but	O
you	O
should	O
be	O
able	O
to	O
`	O
apply	O
(	O
pd.Series	B-API
)`	O
:	O
#CODE	O

I	O
think	O
you	O
may	O
have	O
to	O
apply	O
the	O
operation	O
to	O
each	O
column	O
individually	O
since	O
`	O
factorize	O
`	O
only	O
takes	O
a	O
1D	O
array	O
as	O
input	O
.	O

Accordingly	O
,	O
I	O
followed	O
the	O
guidance	O
provided	O
elsewhere	O
on	O
stack	O
overflow	O
,	O
but	O
pertaining	O
to	O
`	O
re.sub	O
`	O
,	O
and	O
attempted	O
to	O
apply	O
it	O
to	O
`	O
pandas.DataFrame.replace	B-API
`	O
(	O
using	O
replace	O
with	O
`	O
regex=True	O
,	O
inplace=True	O
`	O
and	O
with	O
`	O
to_replace	O
`	O
set	O
as	O
either	O
a	O
nested	O
dictionary	O
,	O
if	O
specifying	O
a	O
specific	O
column	O
,	O
or	O
otherwise	O
as	O
two	O
lists	O
,	O
per	O
its	O
documentation	O
)	O
.	O

My	O
code	O
works	O
find	O
without	O
using	O
a	O
function	O
call	O
,	O
but	O
fails	O
if	O
I	O
try	O
to	O
provide	O
a	O
function	O
as	O
one	O
of	O
the	O
replacement	O
values	O
,	O
despite	O
doing	O
so	O
in	O
the	O
same	O
manner	O
as	O
works	O
with	O
`	O
re.sub	O
`	O
(	O
this	O
was	O
tested	O
and	O
worked	O
correctly	O
)	O
.	O

I	O
realize	O
that	O
the	O
function	O
is	O
expected	O
to	O
accept	O
a	O
match	O
object	O
its	O
only	O
required	O
parameter	O
and	O
return	O
a	O
string	O
.	O

@USER	O
That	O
logic	O
is	O
not	O
correct	O
in	O
the	O
operational	O
sense	O
that	O
```	O
re.sub	O
```	O
allows	O
for	O
my	O
expected	O
notion	O
of	O
function	O
interpolation	O
.	O

I	O
am	O
using	O
apply	O
right	O
now	O
,	O
but	O
this	O
really	O
should	O
work	O
with	O
```	O
pandas.DataFrame.replace	B-API
```	O
.	O

regardless	O
,	O
you	O
should	O
use	O
apply	O
or	O
#URL	O

if	O
you	O
don't	O
want	O
to	O
merge	O
both	O
frames	O
,	O
you	O
can	O
apply	O
the	O
same	O
logic	O
on	O
`	O
dfV	O
`	O

Thanks	O
@USER	O
.	O
how	O
can	O
we	O
apply	O
the	O
function	O
to	O
only	O
the	O
rows	O
missing	O
values	O
in	O
C	O
and	O
D	O
?	O

Once	O
you	O
have	O
that	O
,	O
you	O
can	O
apply	O
it	O
to	O
every	O
row	O
using	O
the	O
`	O
apply	O
`	O
method	O
on	O
dataframes	O
:	O
#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
to	O
make	O
the	O
code	O
more	O
concise	O
.	O

For	O
example	O
,	O
given	O
this	O
DataFrame	B-API
:	O
#CODE	O

The	O
`	O
apply	O
`	O
function	O
applies	O
the	O
`	O
contains	O
`	O
function	O
on	O
each	O
column	O
(	O
since	O
by	O
default	O
`	O
axis=0	O
`)	O
.	O

The	O
`	O
any	O
`	O
function	O
returns	O
a	O
Boolean	O
mask	O
,	O
with	O
element	O
True	O
indicating	O
that	O
at	O
least	O
one	O
of	O
the	O
columns	O
met	O
the	O
search	O
criteria	O
.	O

This	O
can	O
then	O
be	O
used	O
to	O
perform	O
selection	O
on	O
the	O
original	O
DataFrame	B-API
.	O

You	O
can	O
make	O
use	O
of	O
the	O
DataFrame's	O
`	O
apply	O
`	O
method	O
.	O

#CODE	O

@USER	O
This	O
not	O
a	O
duplicate	O
,	O
the	O
OP	O
does	O
not	O
even	O
use	O
apply	O
here	O
.	O

Pandas	O
:	O
How	O
to	O
structure	O
row-wise	O
apply	O
which	O
requires	O
previous	O
output	O
as	O
input	O

Alternatively	O
,	O
you	O
can	O
also	O
apply	O
a	O
function	O
based	O
on	O
the	O
column	O
`	O
col1	O
`	O
:	O
#CODE	O

The	O
`	O
apply	O
`	O
approach	O
should	O
be	O
preferred	O
in	O
this	O
case	O
as	O
it	O
is	O
much	O
faster	O
:	O
#CODE	O

Sadly	O
Tom	O
I'm	O
at	O
a	O
loss	O
of	O
where	O
to	O
start	O
.	O

I	O
was	O
looking	O
at	O
this	O
example	O
#URL	O
but	O
couldn't	O
apply	O
it	O
to	O
my	O
own	O

You	O
can	O
`	O
import	O
json	O
`	O
and	O
apply	O
`	O
json.loads	O
`	O
to	O
convert	O
the	O
string	O
data	O
in	O
your	O
`	O
geojson	O
`	O
column	O
to	O
`	O
dict	O
`	O
.	O

Then	O
,	O
you	O
can	O
extract	O
data	O
from	O
`	O
dict	O
`	O
directly	O
,	O
or	O
use	O
one	O
of	O
many	O
Python	O
modules	O
that	O
deal	O
with	O
GIS	O
data	O
.	O

I	O
find	O
`	O
shapely	O
`	O
easy	O
to	O
use	O
and	O
helpful	O
in	O
many	O
cases	O
.	O

Pivot	B-API
table	O
from	O
a	O
pandas	O
dataframe	B-API
without	O
an	O
apply	O
function	O

I	O
thought	O
using	O
the	O
pivot	B-API
function	O
to	O
the	O
dataframe	B-API
(	O
df_pivot	O
=	O
df.pivot	B-API
(	O
index=	O
'	O
ID	O
'	O
,	O
columns=	O
...,	O
values=	O
'	O
count	O
')	O
but	O
I	O
am	O
missing	O
the	O
columns	O
index	O
list	O
.	O

I	O
thought	O
applying	O
a	O
lambda	O
function	O
to	O
the	O
df	O
to	O
generate	O
an	O
additional	O
column	O
with	O
the	O
missing	O
column	O
names	O
but	O
I	O
have	O
800M	O
IDs	O
and	O
the	O
apply	O
function	O
to	O
a	O
grouped	O
dataframe	B-API
is	O
painfully	O
slow	O
.	O

Is	O
there	O
a	O
quick	O
approach	O
you	O
might	O
be	O
aware	O
off	O
?	O

Then	O
apply	O
the	O
pivot	B-API
method	O
setting	O
the	O
new	O
`	O
subindex	O
`	O
as	O
columns	O
and	O
fill	O
`	O
NaN	O
`	O
values	O
with	O
0	O
:	O
#CODE	O

Does	O
this	O
work	O
only	O
on	O
the	O
index	O
of	O
the	O
dataframe	B-API
?	O

I'd	O
like	O
the	O
option	O
to	O
specify	O
the	O
field	O
(	O
s	O
)	O
to	O
apply	O
this	O
to	O

Sorry	O
,	O
I	O
want	O
to	O
simply	O
identify	O
the	O
column	O
that	O
contains	O
the	O
text	O
'	O
Measure	O
'	O
in	O
it	O
,	O
which	O
I	O
then	O
apply	O
the	O
filter	O
measure_filter	O
too	O
using	O
.isnin	O
.	O

Sorry	O
for	O
not	O
being	O
as	O
clear	O
cut	O
,	O
I've	O
attempted	O
to	O
update	O
my	O
question	O
to	O
be	O
more	O
concise	O
.	O

I'm	O
wanting	O
to	O
apply	O
the	O
logic	O
to	O
just	O
identify	O
the	O
word	O
'	O
measure	O
'	O
within	O
the	O
following	O
code	O
`	O
(	O
df	O
[	O
'	O
hereisalltherandomtextmeasure	O
']	O
.isin	B-API
(	O
measure_filter	O
))`	O

What	O
is	O
a	O
concise	O
way	O
to	O
split	O
col3	O
into	O
new	O
,	O
named	O
columns	O
?	O

(	O
perhaps	O
using	O
lambda	O
and	O
apply	O
)	O

You	O
could	O
apply	O
a	O
join	O
to	O
the	O
list	O
elements	O
to	O
make	O
a	O
comma	O
separated	O
string	O
and	O
then	O
call	O
the	O
vectorised	O
`	O
str.split	B-API
`	O
with	O
`	O
expand=True	O
`	O
to	O
create	O
the	O
new	O
columns	O
:	O
#CODE	O

A	O
cleaner	O
method	O
would	O
be	O
to	O
apply	O
the	O
`	O
pd.Series	B-API
`	O
ctor	O
which	O
will	O
turn	O
each	O
list	O
into	O
a	O
Series	O
:	O
#CODE	O

You	O
could	O
use	O
`	O
apply	O
`	O
to	O
remove	O
the	O
nulls	O
and	O
take	O
the	O
integer	O
location	O
like	O
this	O
.	O

#CODE	O

If	O
you	O
change	O
'	O
transform	O
'	O
to	O
'	O
apply	O
'	O
,	O
you'll	O
get	O
:	O
#CODE	O

Then	O
what	O
you'll	O
need	O
is	O
to	O
index	O
each	O
column	O
using	O
then	O
apply	O
`	O
df.resample()	B-API
`	O
#CODE	O

Are	O
you	O
trying	O
to	O
set	O
the	O
value	O
of	O
an	O
existing	O
column	O
by	O
applying	O
a	O
scalar	O
function	O
to	O
each	O
row	O
?	O

If	O
that's	O
the	O
case	O
,	O
instead	O
of	O
iterating	O
over	O
the	O
rows	O
you	O
can	O
consider	O
apply	O
,	O
map	O
,	O
or	O
applymap	B-API
methods	O
based	O
on	O
your	O
need	O
.	O

This	O
is	O
a	O
pretty	O
good	O
summary	O
#URL	O

Assuming	O
you	O
have	O
a	O
unique-indexed	O
dataframe	B-API
(	O
and	O
if	O
you	O
don't	O
,	O
you	O
can	O
simply	O
do	O
`	O
.reset_index()	B-API
`	O
,	O
apply	O
this	O
,	O
and	O
then	O
`	O
set_index	B-API
`	O
after	O
the	O
fact	O
)	O
,	O
you	O
could	O
use	O
`	O
DataFrame.sample	B-API
`	O
.	O

[	O
Actually	O
,	O
you	O
should	O
be	O
able	O
to	O
use	O
`	O
sample	O
`	O
even	O
if	O
the	O
frame	O
didn't	O
have	O
a	O
unique	O
index	O
,	O
but	O
you	O
couldn't	O
use	O
the	O
below	O
method	O
to	O
get	O
`	O
df2	O
`	O
.	O
]	O

You	O
can	O
do	O
this	O
with	O
groupby	B-API
and	O
apply	O
:	O
#CODE	O

You	O
need	O
to	O
apply	O
`	O
transform	O
`	O
to	O
the	O
`	O
groupby	B-API
`	O
,	O
which	O
preserves	O
the	O
shape	O
of	O
your	O
original	O
DataFrame	B-API
.	O

#CODE	O

Because	O
that	O
fft	O
function	O
changes	O
the	O
shape	O
of	O
the	O
input	O
you	O
can't	O
just	O
apply	O
it	O
directly	O
.	O

Here	O
would	O
be	O
one	O
way	O
to	O
wrap	O
it	O
.	O

#CODE	O

We	O
want	O
to	O
remove	O
rows	O
whose	O
values	O
show	O
up	O
in	O
all	O
columns	O
,	O
or	O
in	O
other	O
words	O
the	O
values	O
are	O
equal	O
=>	O
their	O
minimums	O
and	O
maximums	O
are	O
equal	O
.	O

This	O
is	O
method	O
works	O
on	O
a	O
`	O
DataFrame	B-API
`	O
with	O
any	O
number	O
of	O
columns	O
.	O

If	O
we	O
apply	O
the	O
above	O
,	O
we	O
remove	O
rows	O
0	O
and	O
2	O
.	O

Pandas	O
apply	O
to	O
multiple	O
rows	O
with	O
missing	O
dates	O

For	O
a	O
Pandas	O
DataFrame	B-API
I	O
am	O
looking	O
for	O
a	O
vectorized	O
way	O
to	O
calculate	O
the	O
cumulative	O
sum	O
of	O
the	O
number	O
of	O
views	O
per	O
given	O
group	O
,	O
except	O
the	O
views	O
from	O
more	O
than	O
a	O
week	O
ago	O
.	O

I	O
have	O
tried	O
all	O
kinds	O
apply	O
functions	O
,	O
but	O
I	O
can't	O
seem	O
to	O
go	O
up	O
and	O
down	O
7	O
days	O
to	O
collect	O
the	O
data	O
I	O
need	O
.	O

I	O
am	O
also	O
not	O
sure	O
how	O
to	O
pass	O
`	O
.year	B-API
`	O
argument	O
after	O
I	O
successfully	O
convert	O
the	O
strings	O
into	O
datetimes	O
.	O

I	O
could	O
write	O
a	O
wrapper	O
function	O
that	O
takes	O
each	O
row	O
as	O
input	O
and	O
then	O
extracts	O
the	O
year	O
,	O
but	O
I	O
think	O
it	O
s	O
useful	O
to	O
know	O
how	O
to	O
apply	O
pandas	O
syntax	O
for	O
future	O
reference	O
.	O

Thanks	O
!	O

Classic	O
case	O
of	O
pivot	B-API
.	O

First	O
,	O
let's	O
introduce	O
a	O
count	O
column	O
,	O
then	O
create	O
a	O
pivot	B-API
table	O
.	O

Let's	O
ignore	O
your	O
regex	O
,	O
since	O
that	O
is	O
not	O
the	O
issue	O
;	O
just	O
apply	O
it	O
to	O
the	O
column	O
beforehand	O
.	O

#CODE	O

What	O
is	O
the	O
Pythonic	O
way	O
to	O
apply	O
a	O
function	O
to	O
multi-index	O
multi-columns	O
dataFrame	B-API
?	O

Given	O
a	O
multi-index	O
multi-column	O
dataframe	B-API
below	O
,	O
I	O
want	O
to	O
apply	O
LinearRegression	O
to	O
each	O
block	O
of	O
this	O
dataframe	B-API
,	O
for	O
example	O
,	O
"	O
index	O
(	O
X	O
,	O
1	O
)	O
,	O
column	O
A	O
"	O
.	O

And	O
compute	O
the	O
predicted	O
dataframe	B-API
as	O
df_result	O
.	O

#CODE	O

Some	O
columns	O
of	O
the	O
original	O
data	O
can	O
contain	O
missing	O
value	O
,	O
and	O
we	O
cannot	O
apply	O
regression	O
directly	O
on	O
them	O
.	O

For	O
example	O
,	O
#CODE	O

`	O
df	O
[	O
df	O
[	O
'	O
A	O
']	O
1.0	O
]`	O
:	O
this	O
works	O
-	O
But	O
I	O
want	O
to	O
apply	O
the	O
filter	O
condition	O
to	O
all	O
columns	O
.	O

what	O
filter	O
condition	O
do	O
you	O
want	O
to	O
apply	O
,	O
what	O
is	O
an	O
example	O
`	O
df	O
`	O
and	O
what	O
are	O
you	O
expecting	O
as	O
output	O
?	O

When	O
trying	O
it	O
for	O
whole	O
df	O
,	O
there	O
would	O
surely	O
be	O
some	O
rows	O
where	O
only	O
some	O
columns	O
meet	O
the	O
condition	O
(	O
and	O
vice-versa	O
)	O
,	O
so	O
for	O
places	O
where	O
the	O
condition	O
is	O
not	O
met	O
,	O
it	O
is	O
substituted	O
with	O
`	O
NaN	O
`	O
.	O

B	O
.	O

Create	O
a	O
function	O
which	O
transforms	O
the	O
"	O
refund	O
"	O
orders	O
into	O
negative	O
values	O
and	O
,	O
then	O
,	O
apply	O
it	O
on	O
the	O
Series	O
:	O
#CODE	O

Why	O
not	O
just	O
use	O
an	O
`	O
apply	O
`	O
on	O
the	O
column	O
,	O
and	O
do	O
something	O
like	O
`	O
lambda	O
lst	O
:	O
'	O
'	O
.join	B-API
(	O
lst	O
)`	O

what	O
does	O
'	O
'	O
mean	O
in	O
the	O
apply	O
function	O
?	O

I	O
think	O
actually	O
it's	O
better	O
to	O
test	O
for	O
each	O
value	O
and	O
apply	O
`	O
any	O
`	O
:	O
#CODE	O

lol	O
..	O

my	O
apologies	O
I	O
didn't	O
notice	O
you	O
have	O
"	O
2200	O
"	O
columns	O
,	O
I	O
jumped	O
too	O
quick	O
to	O
a	O
conclusion	O
.	O
but	O
hey	O
same	O
rules	O
apply	O
you	O
can	O
do	O
:	O
`	O
df	O
[[	O
col	O
for	O
col	O
in	O
df.columns	O
if	O
col.endswith	O
(	O
"	O
_x	O
")]]`	O
.	O

But	O
hey	O
just	O
follow	O
unutbu's	O
solution	O
,	O
he's	O
GOD	O
of	O
pandas	O

Python	O
Pandas	O
Apply	O
Formatting	O
to	O
Each	O
Column	O
in	O
Dataframe	B-API
Using	O
a	O
Dict	O
Mapping	O

I	O
want	O
to	O
apply	O
very	O
specific	O
formatting	O
to	O
each	O
column	O
in	O
the	O
dataframe	B-API
using	O
a	O
dict	O
like	O
the	O
following	O
:	O
#CODE	O

I	O
know	O
I	O
can	O
use	O
applymap	B-API
for	O
multiple	O
columns	O
or	O
apply	O
on	O
a	O
single	O
column	O
:	O
#CODE	O

How	O
can	O
I	O
iterate	O
through	O
each	O
column	O
in	O
a	O
dataframe	B-API
and	O
apply	O
formatting	O
using	O
a	O
dictionary	O
where	O
the	O
`	O
dict	O
`	O
`	O
key	O
`	O
is	O
the	O
`	O
column	O
`	O
and	O
the	O
`	O
value	O
`	O
is	O
the	O
`	O
string	O
`	O
formatting	O
?	O

The	O
easiest	O
way	O
would	O
be	O
to	O
iterate	O
through	O
the	O
`	O
format_mapping	O
`	O
dictionary	O
and	O
then	O
apply	O
on	O
the	O
column	O
(	O
denoted	O
by	O
the	O
key	O
)	O
the	O
formatting	O
denoted	O
by	O
the	O
`	O
value	O
`	O
.	O

Example	O
-	O
#CODE	O

With	O
the	O
hopes	O
of	O
x	O
being	O
a	O
series	O
with	O
the	O
values	O
I	O
want	O
that	O
I	O
can	O
column	O
bind	O
to	O
my	O
DF	O
.	O

What	O
actually	O
happens	O
is	O
that	O
it	O
errors	O
out	O
with	O
an	O
IndexError	O
.	O

In	O
that	O
case	O
I	O
made	O
a	O
function	O
to	O
apply	O
,	O
in	O
place	O
of	O
the	O
lambda	O
function	O
,	O
so	O
that	O
it	O
could	O
except	O
the	O
error	O
,	O
but	O
this	O
returned	O
all	O
nulls	O
.	O

I	O
don't	O
have	O
mongo	O
installed	O
.	O

Is	O
the	O
1st	O
box	O
you	O
show	O
the	O
first	O
rows	O
of	O
`	O
data	O
`	O
in	O
your	O
code	O
?	O

If	O
it	O
is	O
,	O
I	O
think	O
it	O
would	O
be	O
more	O
or	O
less	O
easy	O
to	O
solve	O
with	O
`	O
apply	O
`	O
,	O
there's	O
many	O
questions	O
around	O
but	O
probably	O
[	O
this	O
one	O
]	O
(	O
#URL	O
)	O
will	O
help	O
you	O
.	O

If	O
you	O
find	O
issues	O
please	O
post	O
them	O
.	O

Hope	O
it	O
helps	O
.	O

To	O
get	O
exactly	O
what	O
you	O
hoped	O
to	O
see	O
,	O
included	O
the	O
other	O
columns	O
in	O
the	O
group	O
by	O
,	O
and	O
apply	O
sums	O
to	O
the	O
Y	O
variables	O
in	O
the	O
frame	O
:	O
#CODE	O

The	O
issue	O
is	O
that	O
you	O
have	O
some	O
columns	O
that	O
are	O
int	O
,	O
hence	O
when	O
trying	O
to	O
apply	O
the	O
regex	O
on	O
those	O
int	O
values	O
it	O
fails	O
with	O
the	O
error	O
-	O
#CODE	O

You	O
can	O
convert	O
your	O
columns	O
to	O
`	O
str	O
`	O
and	O
then	O
apply	O
the	O
`	O
DataFrame.filter	B-API
`	O
-	O
#CODE	O

You	O
will	O
need	O
to	O
convert	O
to	O
`	O
str	O
`	O
before	O
you	O
can	O
apply	O
regex	O
on	O
the	O
column	O
name	O
,	O
a	O
way	O
(	O
not	O
sure	O
if	O
the	O
most	O
efficient	O
)	O
to	O
not	O
convert	O
the	O
column	O
names	O
to	O
`	O
str	O
`	O
permanently	O
and	O
still	O
get	O
the	O
required	O
data	O
is	O
-	O
#CODE	O

yes	O
-	O
however	O
,	O
I	O
should	O
have	O
said	O
that	O
I	O
want	O
to	O
apply	O
the	O
new	O
series	O
the	O
requests.post	O
method	O
,	O
in	O
order	O
to	O
practice	O
passing	O
functions	O
to	O
series	O
items	O
..	O
for	O
instance	O
,	O
I	O
could	O
have	O
100	O
columns	O
that	O
I	O
would	O
not	O
want	O
to	O
write	O
out	O
.	O

The	O
same	O
principles	O
would	O
apply	O
if	O
you	O
are	O
using	O
excel	O
reader	O
.	O

Note	O
:	O
I	O
thought	O
you	O
used	O
to	O
be	O
able	O
to	O
return	O
a	O
list	O
in	O
an	O
apply	O
(	O
to	O
create	O
a	O
DataFrame	B-API
which	O
has	O
list	O
elements	O
)	O
this	O
no	O
longer	O
appears	O
to	O
be	O
the	O
case	O
.	O

How	O
to	O
get	O
the	O
index	O
and	O
column	O
name	O
when	O
apply	O
transform	O
to	O
a	O
Pandas	O
dataframe	B-API
?	O

My	O
version	O
always	O
replaces	O
the	O
positive	O
values	O
with	O
999	O
.	O

It	O
does	O
'	O
apply	O
'	O
over	O
the	O
rows	O
,	O
but	O
I	O
can't	O
quite	O
get	O
how	O
you	O
could	O
do	O
this	O
without	O
that	O
.	O

2	O
)	O
There	O
is	O
a	O
much	O
better	O
way	O
to	O
apply	O
a	O
function	O
than	O
map	O
to	O
validate	O
urls	O
?	O

I	O
might	O
do	O
this	O
with	O
apply	O
rather	O
than	O
eval	O
(	O
especially	O
if	O
I	O
didn't	O
trust	O
the	O
source	O
):	O
#CODE	O

I	O
would	O
like	O
to	O
apply	O
something	O
like	O
'	O
text	O
to	O
columns	O
'	O
function	O
in	O
excel	O
.	O

You	O
compared	O
the	O
result	O
of	O
groupby	B-API
`	O
upper_bound	O
`	O
to	O
`	O
df	O
[	O
'	O
C	O
']`	O
,	O
but	O
they	O
have	O
different	O
number	O
of	O
elements	O
.	O

Use	O
`	O
transform	O
`	O
to	O
have	O
the	O
mean	O
for	O
each	O
line	O
existing	O
witin	O
each	O
group	O
and	O
compare	O
it	O
to	O
`	O
df	O
[	O
'	O
C	O
']`	O
.	O

Apply	O
this	O
mask	O
with	O
`	O
loc	O
`	O
:	O
#CODE	O

If	O
you	O
really	O
must	O
remove	O
the	O
`	O
microsecond	O
`	O
part	O
of	O
the	O
datetime	O
,	O
you	O
can	O
use	O
the	O
`	O
Timestamp.replace	O
`	O
method	O
along	O
with	O
`	O
Series.apply	B-API
`	O
method	O
to	O
apply	O
it	O
across	O
the	O
series	O
,	O
to	O
replace	O
the	O
`	O
microsecond	O
`	O
part	O
with	O
`	O
0	O
`	O
.	O

Example	O
-	O
#CODE	O

and	O
got	O
this	O
error	O
:	O
`	O
AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
drop	O
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
`	O

but	O
when	O
I	O
apply	O
it	O
to	O
a	O
for	O
loop	O
,	O
it	O
shows	O
integer	O
type	O
values	O
.	O

#CODE	O

You	O
can	O
call	O
`	O
apply	O
`	O
with	O
a	O
lambda	O
that	O
calls	O
the	O
vectorise	O
`	O
str	O
`	O
methods	O
to	O
slice	O
your	O
strings	O
:	O
#CODE	O

Whilst	O
this	O
answer	O
is	O
correct	O
we	O
should	O
actively	O
discourage	O
using	O
`	O
apply	O
`	O
where	O
a	O
vectorised	O
solution	O
exists	O
,	O
of	O
course	O
if	O
the	O
version	O
of	O
pandas	O
is	O
so	O
old	O
that	O
the	O
`	O
.str	B-API
`	O
methods	O
don't	O
exist	O
then	O
this	O
would	O
be	O
a	O
valid	O
answer	O

I	O
wrote	O
the	O
function	O
that	O
will	O
compare	O
those	O
2	O
strings	O
and	O
return	O
True	O
or	O
False	O
,	O
the	O
problem	O
is	O
I	O
fail	O
to	O
see	O
how	O
to	O
apply	O
/	O
applymap	B-API
to	O
the	O
consecutive	O
rows	O
:	O
#CODE	O

First	O
`	O
NaN	O
`	O
are	O
converted	O
to	O
`	O
0	O
`	O
,	O
then	O
apply	O
function	O
above	O
and	O
it	O
return	O
NaN	O
instead	O
of	O
problematic	O
values	O
.	O

So	O
you	O
have	O
to	O
find	O
rows	O
with	O
NaN	O
values	O
and	O
return	O
subset	O
of	O
original	O
`	O
df	O
`	O
.	O

#CODE	O

Note	O
that	O
`	O
copy()	B-API
`	O
is	O
required	O
if	O
you	O
wish	O
to	O
later	O
apply	O
changes	O
to	O
that	O
new	O
dataframe	B-API
`	O
dfa	O
`	O
.	O

Otherwise	O
,	O
if	O
I	O
remember	O
correctly	O
,	O
you	O
would	O
be	O
applying	O
changes	O
by	O
pointer	O
,	O
much	O
like	O
when	O
using	O
dictionaries	O
.	O

Function	O
np.unique	B-API
with	O
parameter	O
`	O
return_index=True	O
`	O
return	O
unique	O
indexes	O
of	O
array	O
.	O

But	O
I	O
need	O
indexes	O
inverted	O
,	O
so	O
firstly	O
I	O
inverted	O
array	O
and	O
then	O
subtracting	O
them	O
by	O
index	O
.	O

Function	O
apply	O
cannot	O
access	O
to	O
index	O
link	O
,	O
so	O
it	O
is	O
count	O
from	O
length	O
of	O
columns	O
`	O
colD	O
`	O
minus	O
1	O
.	O

Last	O
values	O
of	O
column	O
`	O
colB	O
`	O
are	O
summed	O
by	O
indexes	O
from	O
list	O
of	O
column	O
`	O
colF	O
`	O
.	O

#CODE	O

You	O
can	O
see	O
that	O
the	O
`	O
apply	O
`	O
approach	O
is	O
not	O
working	O
:	O
#CODE	O

what	O
version	O
?	O

your	O
apply	O
code	O
worked	O
for	O
me	O
in	O
`	O
0.16.2	O
`	O

I	O
tried	O
this	O
approach	O
,	O
however	O
I	O
don't	O
know	O
how	O
to	O
apply	O
`	O
concat	O
`	O
inside	O
the	O
for	O
loop	O
.	O

#CODE	O

First	O
,	O
apply	O
`	O
isinstance	O
`	O
to	O
determine	O
which	O
elements	O
are	O
floats	O
,	O
then	O
slice	O
your	O
series	O
to	O
get	O
the	O
elements	O
back	O
.	O

Then	O
just	O
apply	O
`	O
str	O
`	O
and	O
you're	O
good	O
.	O

#CODE	O

I	O
can	O
do	O
the	O
proportion	O
using	O
group	O
/	O
apply	O
:	O
#CODE	O

sorting	O
is	O
slow	O
,	O
it's	O
O	O
(	O
n*log	O
(	O
n	O
))	O
.	O

I	O
think	O
this	O
may	O
also	O
be	O
doing	O
an	O
apply	O
,	O
which	O
is	O
also	O
slow	O
.	O

What's	O
the	O
reason	O
you	O
have	O
to	O
do	O
this	O
?	O

For	O
a	O
40,000	O
0	O
row	O
df	O
using	O
`	O
str.replace	B-API
`	O
is	O
faster	O
than	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

I	O
am	O
trying	O
to	O
apply	O
something	O
like	O
this	O
....	O

#CODE	O

After	O
that	O
I	O
can	O
easily	O
count	O
the	O
occurrences	O
per	O
column	O
.	O

But	O
currently	O
I	O
am	O
stuck	O
in	O
achieving	O
one	O
of	O
the	O
two	O
given	O
results	O
.	O

I	O
know	O
it	O
should	O
work	O
somehow	O
with	O
`	O
apply	O
`	O
or	O
`	O
transform	O
`	O
,	O
but	O
I	O
have	O
no	O
precise	O
idea	O
unfortunately	O
.	O

Here's	O
one	O
way	O
,	O
with	O
`	O
apply	O
`	O
and	O
`	O
first_valid_index	B-API
`	O
:	O
#CODE	O

Then	O
,	O
apply	O
`	O
get	O
`	O
to	O
the	O
column	O
,	O
returning	O
the	O
original	O
value	O
if	O
it	O
is	O
not	O
in	O
the	O
dictionary	O
:	O
#CODE	O

I	O
have	O
the	O
jaccard	O
similarity	O
function	O
defined	O
as	O
`	O
jaccard()	O
`	O
I	O
only	O
want	O
to	O
know	O
how	O
to	O
apply	O
it	O
to	O
`	O
df	O
`	O
so	O
that	O
I	O
can	O
have	O
this	O
type	O
of	O
representation	O
matrix	O
by	O
the	O
end	O
.	O

Thank	O
You	O
!	O

So	O
you	O
need	O
apply	O
`	O
jaccard	O
`	O
function	O
to	O
`	O
df	O
`	O
?	O

What	O
is	O
input	O
and	O
output	O
of	O
`	O
jaccard()	O
`	O
?	O

Can	O
you	O
use	O
function	O
df.apply	B-API
or	O
df.applymap	B-API
?	O

[	O
src	O
]	O
(	O
#URL	O
)	O
Or	O
you	O
need	O
create	O
`	O
jaccard_custom()	O
`	O
?	O

use	O
data	O
from	O
two	O
or	O
more	O
columns	O
when	O
using	O
.map	B-API
to	O
apply	O
a	O
function	O

Thanks	O
.	O

Ideally	O
I'd	O
like	O
to	O
add	O
a	O
`	O
lambda	O
`	O
in	O
the	O
`	O
cumsum	B-API
`	O
.	O

So	O
to	O
get	O
to	O
`	O
y	O
`	O
I	O
take	O
`	O
x	O
`	O
and	O
apply	O
some	O
function	O
.	O

...	O
and	O
then	O
cast	O
the	O
result	O
of	O
"	O
apply	O
"	O
to	O
a	O
list	O
.	O

#CODE	O

I	O
have	O
the	O
dtaaframe	O
above	O
,	O
where	O
the	O
index	O
is	O
the	O
column	O
datetime	O
.	O

I	O
would	O
like	O
to	O
decrease	O
the	O
values	O
in	O
the	O
column	O
JD	O
(	O
by	O
1	O
)	O
from	O
5th	O
Jan	O
2000	O
to	O
8th	O
Jan	O
2000	O
,	O
using	O
the	O
dates	O
(	O
and	O
not	O
merely	O
row	O
numbers	O
)	O
.	O

Is	O
there	O
a	O
pandas	O
command	O
to	O
do	O
this	O
?	O

I	O
have	O
been	O
playing	O
around	O
with	O
apply	O
,	O
but	O
not	O
sure	O
how	O
to	O
use	O
it	O

Nice	O
and	O
simple	O
,	O
no	O
need	O
for	O
apply	O
.	O

The	O
`	O
apply	O
`	O
function	O
returns	O
a	O
new	O
DataFrame	B-API
instead	O
of	O
modifying	O
the	O
input	O
in-place	O
.	O

Therefore	O
,	O
in	O
`	O
remove_leap_JD()	O
`	O
,	O
the	O
code	O
should	O
be	O
changed	O
to	O
something	O
like	O
:	O
#CODE	O

You	O
could	O
write	O
your	O
logic	O
as	O
a	O
function	O
and	O
then	O
apply	O
the	O
function	O
to	O
your	O
dataframe	B-API
using	O
applymap()	B-API
.	O

Also	O
,	O
note	O
that	O
'	O
0	O
pound	O
'	O
should	O
probably	O
read	O
'	O
0	O
pounds	O
'	O
.	O

I	O
am	O
trying	O
to	O
apply	O
a	O
function	O
which	O
returns	O
the	O
latest	O
or	O
maximum	O
date	O
for	O
a	O
stock	O
(	O
on	O
which	O
I	O
have	O
collected	O
prices	O
for	O
multiple	O
days	O
)	O
.	O

Where	O
,	O
`	O
values	O
`	O
contain	O
numpy	O
arrays	O
,	O
`	O
apply	O
`	O
,	O
`	O
lambda	O
x	O
:	O
pd.Series	B-API
(	O
x	O
)`	O
on	O
`	O
df	O
[	O
'	O
values	O
']`	O
#CODE	O

Eventually	O
,	O
I	O
think	O
having	O
the	O
distance	O
matrix	O
as	O
a	O
pandas	O
DataFrame	B-API
may	O
be	O
convenient	O
,	O
since	O
I	O
may	O
apply	O
some	O
ranking	O
and	O
ordering	O
operations	O
per	O
row	O
(	O
e.g.	O
find	O
the	O
top	O
N	O
closest	O
objects	O
to	O
object	O
`	O
first	O
`)	O
.	O

Use	O
`	O
apply	O
`	O
on	O
column	O
to	O
do	O
`	O
df	O
[	O
'	O
B	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
sum	O
(	O
map	O
(	O
int	O
,	O
x.split	O
(	O
'	O
,	O
'))))`	O
#CODE	O

If	O
I	O
understood	O
correctly	O
your	O
issue	O
,	O
maybe	O
you	O
can	O
just	O
apply	O
a	O
filter	O
like	O
:	O
#CODE	O

You	O
can	O
use	O
the	O
apply	O
method	O
:	O

A	O
dictionary	O
can	O
only	O
have	O
one	O
value	O
associated	O
with	O
a	O
key	O
,	O
so	O
that	O
syntax	O
won't	O
work	O
.	O

There	O
are	O
two	O
other	O
options	O
that	O
come	O
to	O
mind	O
to	O
get	O
a	O
similar	O
output	O
:	O
you	O
could	O
select	O
the	O
column	O
using	O
brackets	O
,	O
and	O
then	O
pass	O
a	O
list	O
of	O
the	O
reduction	O
operations	O
you	O
want	O
to	O
apply	O
:	O
#CODE	O

How	O
can	O
I	O
skip	O
(	O
don't	O
apply	O
)	O
the	O
filters	O
that	O
are	O
None	O
?	O

#CODE	O

Filtering	O
in	O
pandas	O
-	O
how	O
to	O
apply	O
a	O
custom	O
method	O
(	O
lambda	O
)	O
?	O

How	O
can	O
I	O
apply	O
`	O
df	O
[	O
'	O
column2	O
']	O
.apply	B-API
(	O
lambda	O
x	O
:	O
'	O
str2	O
'	O
in	O
x.split	O
(	O
'	O
,	O
'))`	O
to	O
#CODE	O

To	O
apply	O
this	O
,	O
simply	O
use	O
this	O
to	O
filter	O
the	O
DataFrame	B-API
.	O

Example	O
-	O
#CODE	O

ops	O
,	O
one	O
more	O
thing	O
.	O

What	O
if	O
the	O
key	O
to	O
filter	O
for	O
(	O
`	O
str2	O
`)	O
is	O
an	O
array	O
itself	O
?	O

For	O
example	O
:	O
`	O
.....	O
apply	O
(	O
lambda	O
x	O
:	O
[	O
'	O
str2	O
'	O
,	O
'	O
str4	O
']	O
in	O
x.split	O
(	O
'	O
,	O
'))]`	O
?	O

That	O
won't	O
work	O
,	O
but	O
actually	O
that's	O
what	O
I	O
need	O
--	O
the	O
filter	O
should	O
be	O
an	O
array	O
.	O

And	O
if	O
any	O
element	O
from	O
[	O
'	O
str2	O
'	O
,	O
'	O
str4	O
']	O
contains	O
in	O
x.split	O
(	O
'	O
,	O
')	O
then	O
that's	O
True	O
condition	O
.	O

My	O
Questions	O
and	O
/	O
or	O
things	O
I've	O
read	O
about	O
on	O
SO	O
but	O
haven't	O
/	O
am	O
unclear	O
on	O
how	O
to	O
apply	O
:	O

So	O
it	O
looks	O
like	O
`	O
nextday	O
`	O
is	O
already	O
vectorized	O
(	O
i.e.	O
operating	O
on	O
the	O
whole	O
frame	O
at	O
once	O
)	O
.	O

Why	O
are	O
you	O
calling	O
it	O
via	O
`	O
apply	O
`	O
?	O

@USER	O
When	O
I	O
don't	O
call	O
nextday	O
via	O
apply	O
,	O
the	O
calculations	O
don't	O
get	O
applied	O
for	O
days	O
2-last	O
day	O
.	O

I	O
end	O
up	O
with	O
a	O
bunch	O
of	O
NaN	O
values	O
in	O
the	O
output	O
.	O

I	O
tried	O
it	O
as	O
well	O
using	O
for	O
index	O
,	O
row	O
in	O
d.iterrows()	O
,	O
but	O
that's	O
about	O
the	O
same	O
speed	O
as	O
the	O
apply	O
method	O
.	O

Is	O
there	O
another	O
/	O
different	O
way	O
I	O
can	O
apply	O
the	O
calculations	O
without	O
using	O
apply	O
?	O

Can	O
you	O
reduce	O
your	O
problem	O
down	O
to	O
some	O
copy	O
paste-able	O
functions	O
/	O
data	O
?	O

Likely	O
to	O
to	O
get	O
more	O
help	O
.	O

Your	O
`	O
nextday	O
`	O
function	O
doesn't	O
seem	O
to	O
use	O
`	O
row	O
`	O
at	O
all	O
,	O
which	O
it	O
doesn't	O
make	O
sense	O
to	O
use	O
via	O
`	O
apply	O
`	O
(	O
which	O
is	O
for	O
row-by-row	O
function	O
application	O
)	O
.	O

It's	O
somewhat	O
tough	O
to	O
unpack	O
without	O
expected	O
output	O
,	O
but	O
your	O
your	O
function	O
is	O
already	O
vectorized	O
.	O

e.g.	O
when	O
you	O
have	O
`	O
d	O
[	O
'	O
ET_WL	O
']	O
-d	O
[	O
'	O
infilP	O
']`	O
that	O
subtracts	O
on	O
all	O
the	O
rows	O
in	O
`	O
d	O
`	O
,	O
so	O
there	O
isn't	O
any	O
reason	O
to	O
call	O
it	O
via	O
an	O
apply	O
.	O

In	O
essence	O
what	O
you're	O
doing	O
is	O
:	O
#CODE	O

You	O
could	O
`	O
apply	O
`	O
`	O
tuple	O
`	O
on	O
`	O
axis=1	O
`	O
#CODE	O

Apply	O
the	O
following	O
function	O
over	O
the	O
dataframe	B-API
to	O
generate	O
a	O
new	O
column	O
:	O
#CODE	O

Are	O
you	O
sure	O
you	O
are	O
replacing	O
df	O
with	O
the	O
result	O
of	O
calling	O
`	O
apply	O
`	O
?	O

Apply	O
doesn't	O
change	O
the	O
dataframe	B-API
inplace	O
,	O
rather	O
returns	O
a	O
copy	O
of	O
it	O
,	O
so	O
you	O
need	O
to	O
store	O
it	O
or	O
else	O
the	O
results	O
are	O
vacuous	O
...	O

that's	O
the	O
only	O
thing	O
that	O
comes	O
to	O
mind	O

I	O
have	O
tried	O
setting	O
a	O
new	O
df	O
to	O
the	O
results	O
of	O
apply	O
via	O
`	O
df2	O
=d	O
f.apply	O
(	O
sep_yearmonths	O
,	O
axis=1	O
)`	O
then	O
`	O
df2	O
=d	O
f2.groupby	O
(	O
'	O
month	O
')	O
.sum()	B-API
`	O

You	O
can	O
add	O
a	O
secondary	O
axis	O
by	O
specifying	O
'	O
secondary_y=True	O
'	O
when	O
you	O
apply	O
your	O
plot	O
function	O
directly	O
on	O
your	O
dataframe	B-API
.	O

Pandas	O
'	O
apply	O
method	O

You	O
should	O
consider	O
a	O
func	O
that	O
is	O
passed	O
to	O
apply	O
that	O
simply	O
makes	O
some	O
calculations	O
and	O
returns	O
either	O
a	O
scalar	O
or	O
array	O
like	O
structure	O
to	O
avoid	O
ambiguous	O
behaviour	O
,	O
using	O
apply	O
to	O
modify	O
a	O
df	O
in	O
place	O
is	O
not	O
going	O
to	O
work	O
in	O
practice	O
as	O
especially	O
if	O
you	O
iterating	O
row-wise	O
yet	O
wanting	O
to	O
mutate	O
the	O
df	O
row-wise	O

Generally	O
speaking	O
the	O
answer	O
is	O
that	O
`	O
apply	O
`	O
is	O
NOT	O
in	O
place	O
but	O
you	O
made	O
this	O
overly	O
complicated	O
.	O

Generally	O
you	O
would	O
use	O
`	O
iteritems	B-API
`	O
OR	O
`	O
apply	O
`	O
,	O
not	O
both	O
.	O

In	O
this	O
case	O
,	O
you	O
have	O
no	O
need	O
to	O
use	O
`	O
iteritems	B-API
`	O
in	O
addition	O
to	O
`	O
apply	O
`	O
.	O

In	O
fact	O
,	O
just	O
do	O
this	O
:	O
`	O
tt.iloc	O
[	O
1	O
,	O
:]	O
*	O
2	O
`	O
or	O
`	O
tt.iloc	O
[	O
1	O
,	O
:]	O
*=	O
2	O
`	O

@USER	O
:	O
above	O
is	O
a	O
simple	O
example	O
to	O
a	O
much	O
more	O
complicated	O
function	O
.	O

My	O
actual	O
function	O
is	O
not	O
a	O
simple	O
`	O
multiply	O
by	O
2	O
`	O
.	O

It	O
does	O
other	O
things	O
,	O
and	O
uses	O
the	O
`	O
index	O
`	O
of	O
the	O
`	O
Series	O
`	O
as	O
an	O
input	O
as	O
well	O
.	O

Really	O
I	O
plan	O
to	O
have	O
a	O
second	O
function	O
which	O
acts	O
on	O
every	O
element	O
in	O
the	O
`	O
iteritems()	B-API
`	O
.	O

Perhaps	O
I	O
should	O
use	O
two	O
`	O
iteritems()	B-API
`	O
instead	O
of	O
`	O
apply	O
`	O
.	O

Generally	O
speaking	O
,	O
don't	O
use	O
`	O
iteritems	B-API
`	O
or	O
`	O
iterrows	B-API
`	O
if	O
you	O
can	O
help	O
it	O
(	O
and	O
it's	O
rare	O
you	O
really	O
need	O
them	O
)	O
.	O

You're	O
almost	O
certainly	O
better	O
off	O
with	O
`	O
apply	O
`	O
than	O
any	O
of	O
the	O
`	O
iter	O
`	O
-options	O
,	O
and	O
there	O
are	O
often	O
better	O
options	O
than	O
apply	O
.	O

I	O
realize	O
it's	O
an	O
artificial	O
example	O
,	O
but	O
still	O
...	O

don't	O
do	O
it	O
!	O

And	O
consider	O
posting	O
a	O
more	O
realistic	O
(	O
but	O
still	O
simple	O
)	O
example	O
if	O
you	O
want	O
more	O
specific	O
advice	O
.	O

How	O
to	O
apply	O
tz_convert	B-API
with	O
different	O
timezones	O
to	O
different	O
rows	O
in	O
pandas	O
dataframe	B-API

You	O
can	O
`	O
groupby	B-API
`	O
on	O
'	O
userid	O
'	O
and	O
then	O
on	O
'	O
var1	O
'	O
col	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`	O
list	O
`	O
to	O
create	O
a	O
sequence	O
,	O
you	O
can	O
rename	O
/	O
reset	O
if	O
required	O
.	O

#CODE	O

Also	O
you	O
should	O
almost	O
never	O
need	O
to	O
iterate	O
row-wise	O
so	O
avoid	O
using	O
`	O
for	O
`	O
loops	O
,	O
`	O
apply	O
`	O
,	O
`	O
iterrows	B-API
`	O
etc	O
...	O

The	O
lines	O
below	O
apply	O
to	O
data	O
where	O
`	O
INDATUMA	O
`	O
and	O
`	O
UTDATUMA	O
`	O
are	O
of	O
the	O
format	O
20071231	O
,	O
e.g.	O
Date	O
parsing	O
seems	O
to	O
work	O
for	O
`	O
indate	O
`	O
and	O
`	O
outdate	O
`	O
,	O
those	O
values	O
make	O
sense	O
.	O

IIUC	O
you	O
can	O
just	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`	O
value_counts	B-API
`	O
:	O
#CODE	O

You	O
can	O
use	O
a	O
combination	O
of	O
`	O
apply	O
`	O
and	O
this	O
[	O
answer	O
]	O
(	O
#URL	O
)	O
to	O
achieve	O
this	O
but	O
why	O
is	O
this	O
an	O
issue	O
?	O

I	O
want	O
to	O
apply	O
following	O
rules	O
:	O

You	O
could	O
call	O
`	O
apply	O
`	O
and	O
pass	O
a	O
lambda	O
and	O
call	O
`	O
squeeze	O
`	O
to	O
flatten	O
the	O
Series	O
into	O
a	O
1-D	O
array	O
:	O
#CODE	O

I'm	O
not	O
sure	O
if	O
this	O
is	O
quicker	O
though	O
,	O
here	O
we're	O
applying	O
the	O
mask	O
column-wise	O
by	O
calling	O
`	O
apply	O
`	O
on	O
the	O
df	O
which	O
is	O
why	O
transposing	O
is	O
unnecessary	O

So	O
to	O
properly	O
fillback	O
by	O
date	O
I	O
can	O
use	O
groupby	B-API
(	O
level=0	O
)	O
function	O
.	O

The	O
groupby	B-API
is	O
fast	O
but	O
the	O
fill	O
function	O
apply	O
on	O
the	O
dataframe	B-API
group	O
by	O
date	O
is	O
really	O
too	O
slow	O
.	O

Then	O
I'd	O
apply	O
the	O
`	O
between_time	B-API
`	O
pandas	O
function	O
to	O
filter	O
the	O
dataframe	B-API
by	O
start	O
and	O
end	O
date	O
given	O
by	O
the	O
`	O
bounds	O
`	O
dataframe	B-API
:	O
#CODE	O

df.plot()	B-API
correctly	O
shows	O
the	O
labels	O
,	O
as	O
you	O
say	O
.	O
plot	O
(	O
df	O
)	O
was	O
what	O
I	O
was	O
doing	O
,	O
and	O
does	O
not	O
.	O

It	O
seems	O
like	O
the	O
'	O
label=	O
'	O
part	O
of	O
the	O
plot	O
(	O
...	O
)	O
call	O
ought	O
to	O
take	O
a	O
list	O
or	O
series	O
or	O
something	O
and	O
apply	O
the	O
values	O
according	O
,	O
but	O
I	O
can't	O
figure	O
out	O
how	O
.	O

I	O
probably	O
should	O
use	O
`	O
apply	O
`	O
,	O
but	O
how	O
exactly	O
?	O

Performance	O
is	O
drastically	O
improved	O
by	O
increasing	O
the	O
`	O
arraysize	O
`	O
attribute	O
of	O
the	O
Cursor	O
-	O
allowing	O
me	O
to	O
get	O
decent	O
performance	O
out	O
of	O
`	O
fetchall()	O
`	O
.	O
pandas	O
`	O
read_sql()	B-API
`	O
takes	O
a	O
`	O
Connection	O
`	O
object	O
as	O
input	O
and	O
the	O
cursor	O
is	O
created	O
within	O
the	O
function	O
,	O
therefore	O
it's	O
not	O
obvious	O
to	O
me	O
how	O
I	O
can	O
apply	O
that	O
same	O
setting	O
and	O
still	O
take	O
advantage	O
of	O
the	O
`	O
read_sql()	B-API
`	O
function	O
.	O

Have	O
I	O
missed	O
something	O
?	O

I've	O
been	O
able	O
to	O
construct	O
the	O
following	O
code	O
(	O
mostly	O
with	O
the	O
help	O
from	O
the	O
StackOverflow	O
contributors	O
)	O
to	O
calculate	O
the	O
Implied	O
Volatility	O
of	O
an	O
option	O
contract	O
using	O
Newton-Raphson	O
method	O
.	O

The	O
process	O
calculates	O
Vega	O
when	O
determining	O
the	O
Implied	O
Volatility	O
.	O

Although	O
I'm	O
able	O
to	O
create	O
a	O
new	O
DataFrame	B-API
column	O
for	O
Implied	O
Volatility	O
using	O
the	O
Pandas	O
DataFrame	B-API
apply	O
method	O
,	O
I'm	O
unable	O
to	O
create	O
a	O
second	O
column	O
for	O
Vega	O
.	O

Is	O
there	O
a	O
way	O
create	O
two	O
separate	O
DataFrame	B-API
columns	O
when	O
the	O
function	O
to	O
returns	O
IV	O
Vega	O
together	O
?	O

The	O
two	O
tricks	O
I'm	O
using	O
here	O
are	O
1	O
)	O
using	O
%i	O
in	O
the	O
format	O
string	O
to	O
signify	O
that	O
it's	O
an	O
integer	O
(	O
%f	O
means	O
a	O
float	O
,	O
but	O
it	O
renders	O
w	O
/	O
o	O
trailing	O
zeros	B-API
)	O
and	O
2	O
)	O
the	O
apply	O
function	O
on	O
df	O
.	O

Make	O
sure	O
that	O
axis=1	O
with	O
that	O
one	O
.	O

or	O
if	O
s1	O
and	O
s2	O
are	O
columns	O
in	O
a	O
pandas	O
DataFrame	B-API
df	O
,	O
then	O
we	O
can	O
use	O
similar	O
logic	O
and	O
the	O
apply	O
function	O
:	O
#CODE	O

When	O
I	O
apply	O
#CODE	O

I	O
keep	O
getting	O
the	O
following	O
error	O
when	O
I	O
apply	O
it	O
to	O
real	O
data	O
(	O
in	O
which	O
case	O
,	O
data	O
frames	O
are	O
of	O
different	O
sizes	O
):	O

Is	O
there	O
a	O
way	O
to	O
`	O
apply	O
`	O
a	O
function	O
to	O
one	O
column	O
of	O
a	O
dataframe	B-API
while	O
leaving	O
the	O
other	O
columns	O
fixed	O
?	O

If	O
`	O
apply	O
`	O
is	O
not	O
done	O
`	O
inplace	O
`	O
you	O
still	O
have	O
to	O
make	O
an	O
assignment	O
,	O
so	O
what	O
is	O
the	O
difference	O
?	O

@USER	O
my	O
point	O
is	O
that	O
if	O
I	O
want	O
to	O
compose	O
functions	O
`	O
f1	O
`	O
,	O
`	O
f2	O
`	O
and	O
`	O
f3	O
`	O
,	O
the	O
syntax	O
would	O
be	O
`	O
d.assign	O
(	O
A=f3	O
(	O
d.assign	O
(	O
A=f2	O
(	O
d.assign	O
(	O
A=f1	O
))))`	O
;	O
agree	O
that	O
this	O
is	O
better	O
than	O
in-place	O
,	O
but	O
I	O
would	O
argue	O
that	O
this	O
is	O
less	O
readable	O
than	O
a	O
"	O
forward	O
pipe	O
"	O
style	O
syntax	O
using	O
something	O
like	O
`	O
apply	O
`	O

Apply	O
a	O
value	O
to	O
all	O
instances	O
of	O
a	O
number	O
based	O
on	O
conditions	O

I	O
want	O
to	O
apply	O
a	O
5	O
to	O
any	O
ids	O
that	O
have	O
a	O
1	O
anywhere	O
in	O
the	O
number	O
column	O
and	O
a	O
zero	O
to	O
those	O
that	O
don't	O
.	O

For	O
example	O
,	O
if	O
the	O
number	O
"	O
1	O
"	O
appears	O
anywhere	O
in	O
the	O
Number	O
column	O
for	O
ID	O
1	O
,	O
I	O
want	O
to	O
place	O
a	O
5	O
in	O
the	O
total	O
column	O
for	O
every	O
instance	O
of	O
that	O
ID	O
.	O

You	O
could	O
`	O
groupby	B-API
`	O
on	O
'	O
Area	O
'	O
and	O
`	O
apply	O
`	O
`	O
list	O
`	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
split	O
the	O
values	O
out	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`	O
pd.Series	B-API
`	O
ctor	O
:	O
#CODE	O

I	O
think	O
what	O
you're	O
looking	O
for	O
is	O
a	O
`	O
groupby	B-API
`	O
followed	O
by	O
an	O
`	O
apply	O
`	O
which	O
does	O
the	O
correct	O
logic	O
for	O
each	O
user	O
.	O

For	O
example	O
:	O
#CODE	O

I	O
know	O
word_tokenize	O
can	O
for	O
it	O
for	O
a	O
string	O
,	O
but	O
how	O
to	O
apply	O
it	O
onto	O
the	O
entire	O
dataframe	B-API
?	O

You	O
can	O
use	O
apply	O
method	O
of	O
DataFrame	B-API
API	O
:	O
#CODE	O

For	O
finding	O
the	O
length	O
of	O
each	O
text	O
try	O
to	O
use	O
apply	O
and	O
lambda	O
function	O
again	O
:	O
#CODE	O

You	O
can	O
call	O
`	O
apply	O
`	O
pass	O
`	O
axis=1	O
`	O
to	O
`	O
apply	O
`	O
row-wise	O
,	O
then	O
convert	O
the	O
dtype	B-API
to	O
`	O
str	O
`	O
and	O
`	O
join	O
`	O
:	O
#CODE	O

A	O
method	O
by	O
which	O
you	O
can	O
do	O
this	O
would	O
be	O
to	O
apply	O
a	O
function	O
on	O
the	O
grouped	O
DataFrame	B-API
.	O

Strangely	O
the	O
condition	O
that	O
removed	O
all	O
the	O
`	O
nan	O
`	O
did	O
not	O
work	O
.	O

But	O
I	O
could	O
resolve	O
it	O
through	O
putting	O
the	O
output	O
of	O
the	O
condition	O
in	O
a	O
new	O
df	O
and	O
apply	O
the	O
code	O
on	O
that	O
,	O
that	O
worked	O
.	O

Thanks	O
again	O
!	O

If	O
you	O
only	O
want	O
to	O
remove	O
certain	O
rows	O
within	O
matching	O
groups	O
,	O
you	O
can	O
write	O
a	O
function	O
and	O
then	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

Anyone	O
know	O
how	O
to	O
apply	O
a	O
method	O
to	O
change	O
it	O
?	O

what	O
does	O
apply	O
(	O
floor	O
)	O
do	O
here	O
?	O

I	O
don't	O
really	O
know	O
..	O

Apply	O
unique	O
twice	O
in	O
groupby	B-API
dataframe	B-API

thank	O
you	O
!	O

I	O
guess	O
I	O
should	O
have	O
mentioned	O
my	O
real	O
df	O
has	O
about	O
300k	O
rows	O
so	O
it	O
wouldn't	O
be	O
practical	O
this	O
way	O
.	O

Also	O
,	O
what	O
I'm	O
looking	O
for	O
is	O
a	O
"	O
query	O
"	O
or	O
"	O
method	O
"	O
to	O
apply	O
to	O
the	O
whole	O
df	O
and	O
return	O
the	O
desired	O
subset	O
.	O

e.g.	O
df.method_1	O
=	O
subset_1	O
,	O
df.method_2	O
=	O
subset_2	O

I'd	O
add	O
a	O
new	O
col	O
using	O
`	O
date_range	B-API
`	O
passing	O
the	O
`	O
min	O
`	O
and	O
`	O
max	O
`	O
date	O
values	O
,	O
then	O
call	O
`	O
apply	O
`	O
on	O
a	O
df	O
with	O
a	O
single	O
column	O
passing	O
param	O
`	O
axis=1	O
`	O
to	O
`	O
apply	O
`	O
row-wise	O
,	O
you	O
can	O
then	O
count	O
the	O
number	O
of	O
rows	O
that	O
meet	O
your	O
condition	O
using	O
`	O
sum	O
`	O
(	O
as	O
this	O
will	O
convert	O
`	O
True	O
`	O
to	O
`	O
1	O
`	O
and	O
`	O
False	O
`	O
to	O
`	O
0	O
`)	O
and	O
add	O
this	O
as	O
a	O
new	O
column	O
:	O
#CODE	O

So	O
I'd	O
construct	O
a	O
new	O
df	O
with	O
a	O
date	O
range	O
,	O
you	O
can	O
just	O
call	O
apply	O
on	O
this	O
and	O
`	O
sum	O
`	O
the	O
number	O
of	O
rows	O
that	O
meet	O
your	O
condition	O
.	O

I'm	O
assuming	O
you	O
want	O
the	O
actual	O
index	O
location	O
(	O
zero-based	O
)	O
,	O
you	O
can	O
call	O
`	O
apply	O
`	O
on	O
your	O
'	O
date_time	O
'	O
column	O
and	O
call	O
`	O
np.searchsorted	B-API
`	O
to	O
find	O
the	O
index	O
location	O
of	O
where	O
in	O
`	O
bounds	O
`	O
df	O
it	O
falls	O
in	O
:	O
#CODE	O

@USER	O
has	O
pointed	O
out	O
that	O
`	O
apply	O
`	O
is	O
unnecessary	O
here	O
and	O
of	O
course	O
he's	O
right	O
,	O
this	O
will	O
be	O
much	O
faster	O
:	O
#CODE	O

No	O
need	O
to	O
use	O
apply	O
here	O
:	O
```	O
In	O
[	O
40	O
]:	O
bounds	O
[	O
'	O
date_start	O
']	O
.searchsorted	B-API
(	O
df	O
[	O
'	O
date_time	O
'])	O

yeah	O
some	O
logic	O
are	O
same	O
i	O
just	O
want	O
to	O
learn	O
how	O
to	O
make	O
these	O
simple	O
logic	O
work	O
,	O
so	O
that	O
I	O
can	O
in	O
future	O
easily	O
apply	O
different	O
things	O
.	O

Thanks	O
for	O
replying	O
.	O

You	O
should	O
use	O
apply	O
method	O
of	O
DataFrame	B-API
API	O
:	O
#CODE	O

You	O
can	O
find	O
more	O
information	O
about	O
apply	O
method	O
here	O
.	O

@USER	O
what	O
are	O
you	O
talking	O
about	O
?	O

you	O
can	O
just	O
do	O
`	O
df	O
[	O
'	O
usids	O
']	O
=	O
df	O
[	O
'	O
uids	O
']	O
.apply	B-API
(	O
set	O
)`	O
,	O
there	O
is	O
no	O
`	O
inplace	O
`	O
param	O
for	O
`	O
apply	O
`	O
anyway	O
you	O
have	O
to	O
assign	O
the	O
result	O

@USER	O
apply	O
function	O
take	O
so	O
long	O
(	O
19	O
second	O
)	O
as	O
my	O
list	O
includes	O
30,000	O
uids	O
.	O

Isn't	O
there	O
a	O
better	O
way	O
to	O
enhance	O
performance	O
?	O

`	O
apply	O
`	O
is	O
just	O
a	O
`	O
for	O
`	O
loop	O
so	O
this	O
will	O
be	O
slow	O
unfortunately	O
,	O
there	O
isn't	O
a	O
`	O
toset	O
`	O
method	O

How	O
to	O
apply	O
different	O
aggregation	O
functions	O
to	O
different	O
columns	O
and	O
give	O
the	O
results	O
different	O
names	O
?	O

Fixing	O
the	O
order	O
of	O
the	O
DataFrame	B-API
columns	O
returned	O
by	O
`	O
apply	O
`	O
:	O

I	O
did	O
change	O
it	O
before	O
I	O
apply	O
the	O
code	O
,	O
and	O
the	O
error	O
come	O
out	O

Thinking	O
about	O
it	O
,	O
you	O
can	O
remove	O
the	O
transpose	O
and	O
just	O
use	O
axis=1	O
in	O
the	O
apply	O
.	O

Glad	O
I	O
could	O
help	O
.	O

You	O
could	O
`	O
apply	O
`	O
`	O
value_counts	B-API
`	O
:	O
#CODE	O

`	O
apply	O
`	O
tends	O
to	O
be	O
slow	O
,	O
and	O
row-wise	O
operations	O
slow	O
as	O
well	O
,	O
but	O
to	O
be	O
honest	O
if	O
your	O
frame	O
isn't	O
very	O
big	O
you	O
might	O
not	O
even	O
notice	O
the	O
difference	O
.	O

You	O
can	O
create	O
a	O
mask	O
of	O
your	O
df	O
by	O
calling	O
`	O
apply	O
`	O
and	O
call	O
`	O
value_counts	B-API
`	O
,	O
this	O
will	O
produce	O
`	O
NaN	O
`	O
for	O
all	O
rows	O
except	O
one	O
,	O
you	O
can	O
then	O
call	O
`	O
dropna	B-API
`	O
column-wise	O
and	O
pass	O
param	O
`	O
thresh=2	O
`	O
so	O
that	O
there	O
must	O
be	O
2	O
or	O
more	O
non-	O
`	O
NaN	O
`	O
values	O
:	O
#CODE	O

You	O
could	O
use	O
the	O
apply	O
function	O
:	O
#CODE	O

You	O
can	O
avoid	O
loops	O
by	O
using	O
`	O
apply	O
`	O
#CODE	O

C	O
:\	O
Users\user\Anaconda\lib\	O
site-packages	O
\pandas\core\	O
groupby.pyc	O
in	O
apply	O
(	O
self	O
,	O
func	O
,	O
*	O
args	O
,	O
**	O
kwargs	O
)	O

You	O
may	O
use	O
apply	O
with	O
regex	O
:	O
#CODE	O

Btw	O
check	O
into	O
[	O
pandas	O
apply	O
/	O
ufunc	O
object	O
]	O
(	O
#URL	O
)	O
.	O

You've	O
probably	O
found	O
this	O
already	O
though	O
.	O

You	O
can	O
actually	O
put	O
a	O
numpy	O
function	O
into	O
the	O
pandas	O
apply	O
object	O
.	O

So	O
this	O
could	O
do	O
the	O
trick	O

You	O
can	O
use	O
`	O
DataFrame.apply	B-API
`	O
with	O
`	O
axis=1	O
`	O
(	O
to	O
apply	O
the	O
func	O
to	O
each	O
row	O
)	O
and	O
in	O
that	O
function	O
do	O
your	O
logic	O
.	O

Example	O
-	O
#CODE	O

So	O
if	O
we	O
apply	O
this	O
we	O
get	O
a	O
Series	O
with	O
the	O
indices	O
as	O
the	O
c3	O
keys	O
we	O
want	O
and	O
the	O
values	O
as	O
dictionaries	O
,	O
and	O
that	O
we	O
can	O
turn	O
into	O
a	O
dictionary	O
using	O
`	O
.to_dict()	B-API
`	O
:	O
#CODE	O

Which	O
is	O
the	O
answer	O
I'm	O
looking	O
for	O
.	O

The	O
problem	O
is	O
when	O
I	O
apply	O
this	O
to	O
a	O
`	O
DataFrame	B-API
`	O
with	O
a	O
large	O
dataset	O
it	O
runs	O
slow	O
.	O

Very	O
slow	O
.	O

Is	O
there	O
a	O
better	O
way	O
of	O
achieving	O
this	O
?	O

You	O
can	O
apply	O
the	O
`	O
type	O
`	O
function	O
to	O
the	O
Series	O
values	O
:	O
#CODE	O

but	O
this	O
gives	O
`	O
NameError	O
:	O
name	O
'	O
ex	O
'	O
is	O
not	O
defined	O
`	O
.	O

These	O
DataFrames	O
can	O
have	O
a	O
lot	O
of	O
rows	O
in	O
them	O
so	O
I'm	O
also	O
concerned	O
that	O
the	O
`	O
apply	O
`	O
function	O
might	O
not	O
be	O
very	O
efficient	O
.	O

How	O
can	O
I	O
apply	O
a	O
function	O
for	O
each	O
city	O
or	O
for	O
each	O
column	O
in	O
this	O
"	O
pivot	B-API
table	O
"	O
?	O

How	O
to	O
apply	O
a	O
function	O
to	O
each	O
column	O
of	O
a	O
pivot	B-API
table	O
in	O
pandas	O
?	O

You	O
should	O
use	O
`	O
apply	O
`	O
function	O
of	O
DataFrame	B-API
API	O
.	O

Demo	O
is	O
below	O
:	O
#CODE	O

Put	O
std	O
dev	O
and	O
mean	O
in	O
your	O
table	O
,	O
use	O
dictionary	O
for	O
it	O
:	O
`	O
some_dict	O
=	O
{	O
(	O
'	O
city	O
'	O
,	O
'	O
date	O
')	O
:[	O
std_dev	O
,	O
mean	O
]	O
,	O
..	O

}	O
`	O
.	O

For	O
putting	O
data	O
in	O
dataframe	B-API
use	O
apply	O
function	O
.	O

You	O
have	O
all	O
necessary	O
data	O
for	O
running	O
your	O
check	O
by	O
apply	O
function	O
.	O

Does	O
the	O
standard	O
deviation	O
and	O
the	O
rolling	O
mean	O
need	O
to	O
be	O
appended	O
to	O
the	O
original	O
data	O
frame	O
for	O
this	O
apply	O
to	O
work	O
?	O

I	O
think	O
yes	O
bc	O
this	O
is	O
applying	O
the	O
function	O
by	O
row	O
.	O

If	O
yes	O
,	O
then	O
how	O
can	O
I	O
concatenate	O
rolling	O
mean	O
and	O
std	O
dev	O
?	O

I	O
don't	O
think	O
it's	O
as	O
simple	O
as	O
adding	O
a	O
column	O
because	O
df2	O
is	O
a	O
stacked	O
table	O
/	O
pivot	B-API
table	O
.	O

How	O
to	O
pass	O
multiple	O
arguments	O
to	O
the	O
apply	O
function	O

I	O
have	O
a	O
method	O
called	O
counting	O
that	O
takes	O
2	O
arguments	O
.	O

I	O
need	O
to	O
call	O
this	O
method	O
using	O
the	O
apply()	B-API
method	O
.	O

However	O
when	O
I	O
am	O
passing	O
the	O
two	O
parameters	O
to	O
the	O
apply	O
method	O
it	O
is	O
giving	O
the	O
following	O
error	O
:	O

I	O
have	O
seen	O
the	O
following	O
thread	O
python	O
pandas	O
:	O
apply	O
a	O
function	O
with	O
arguments	O
to	O
a	O
series	O
.	O

Update	O
and	O
I	O
do	O
not	O
want	O
to	O
use	O
functool.partial	O
as	O
I	O
do	O
not	O
want	O
to	O
import	O
additional	O
classes	O
to	O
be	O
able	O
to	O
pass	O
parameters	O
.	O

#CODE	O

Modified	O
the	O
question	O
for	O
more	O
clarity	O
.	O
dic	O
is	O
the	O
column	O
value	O
that	O
would	O
come	O
by	O
default	O
via	O
the	O
apply	O
function	O
.	O

The	O
second	O
argument	O
is	O
a	O
new	O
argument	O
that	O
is	O
being	O
passed	O
using	O
logic	O
.	O

`	O
partial	O
`	O
is	O
equivalent	O
here	O
,	O
lambda	O
isn't	O
'	O
better	O
'	O
in	O
any	O
way	O
:	O
e.g.	O
`	O
countWord	O
=	O
partial	O
(	O
counting	O
,	O
strWord=	O
'	O
word	O
')`	O
and	O
then	O
`	O
apply	O
(	O
countWord	O
)`	O
.	O

And	O
yes	O
,	O
your	O
understanding	O
is	O
correct	O
.	O

How	O
to	O
apply	O
a	O
concat	O
function	O
to	O
a	O
group	O
by	O
data	O
frame	O
using	O
pandas	O
?	O

How	O
to	O
return	O
new	O
data	O
frame	O
when	O
using	O
a	O
apply	O
function	O
on	O
old	O
dataframe	B-API
?	O

How	O
to	O
return	O
new	O
data	O
frame	O
when	O
using	O
a	O
apply	O
function	O
on	O
old	O
dataframe	B-API
?	O

Currently	O
I	O
am	O
not	O
returning	O
anything	O
!	O

Which	O
is	O
why	O
the	O
output	O
confuses	O
me	O
.	O

Is	O
it	O
a	O
default	O
return	O
with	O
the	O
apply	O
function	O
?	O

I	O
want	O
to	O
return	O
a	O
new	O
dataframe	B-API
with	O
only	O
the	O
rows	O
that	O
fulfill	O
the	O
elif	O
statement	O
.	O

However	O
,	O
not	O
even	O
the	O
printing	O
works	O
in	O
the	O
elif	O
so	O
return	O
x	O
in	O
the	O
elif	O
doesn't	O
work	O
either	O
.	O

This	O
is	O
why	O
you	O
are	O
getting	O
a	O
dataframe	B-API
of	O
all	O
`	O
None	O
`	O
.	O

I	O
do	O
not	O
think	O
you	O
can	O
achieve	O
what	O
you	O
are	O
trying	O
for	O
with	O
`	O
apply	O
`	O
,	O
as	O
`	O
apply()	B-API
`	O
with	O
axis	O
`	O
1	O
`	O
actually	O
runs	O
the	O
function	O
for	O
every	O
row	O
and	O
replaces	O
the	O
row	O
with	O
the	O
returned	O
value	O
(	O
as	O
you	O
see	O
in	O
your	O
case	O
)	O
.	O

Your	O
comparison	O
func	O
won't	O
work	O
as	O
you've	O
found	O
out	O
,	O
you're	O
trying	O
to	O
compare	O
a	O
scalar	O
with	O
an	O
array	O
.	O

Anyway	O
you	O
can	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`	O
axis=1	O
`	O
to	O
process	O
the	O
df	O
row-wise	O
.	O

Convert	O
the	O
dtype	B-API
to	O
`	O
str	O
`	O
so	O
that	O
you	O
can	O
use	O
the	O
vectorised	O
`	O
str.contains	B-API
`	O
with	O
`	O
any	O
`	O
to	O
produce	O
a	O
boolean	O
series	O
and	O
use	O
this	O
as	O
the	O
arg	O
for	O
`	O
np.where	B-API
`	O
and	O
return	O
'	O
yes	O
'	O
or	O
'	O
no	O
'	O
when	O
`	O
True	O
`	O
or	O
`	O
False	O
`	O
respectively	O
:	O
#CODE	O

You	O
can	O
groupby	B-API
on	O
'	O
Column1	O
'	O
and	O
`	O
apply	O
`	O
a	O
lambda	O
that	O
calls	O
`	O
join	O
`	O
to	O
concatenate	O
all	O
the	O
string	O
values	O
and	O
then	O
if	O
you	O
desire	O
construct	O
a	O
list	O
object	O
from	O
that	O
result	O
:	O
#CODE	O

not	O
sure	O
why	O
you	O
get	O
the	O
error	O
,	O
note	O
that	O
I'm	O
using	O
a	O
double	O
subscript	O
`	O
[[	O
]]`	O
to	O
create	O
a	O
single	O
column	O
df	O
when	O
calling	O
`	O
apply	O
`	O
.	O

You	O
could	O
iterate	O
over	O
each	O
row	O
for	O
that	O
column	O
after	O
the	O
groupby	B-API
so	O
just	O
take	O
the	O
result	O
of	O
my	O
answer	O
and	O
iterate	O
over	O
'	O
Column2	O
'	O

For	O
merging	O
two	O
lists	O
use	O
`	O
apply	O
`	O
function	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
apply	O
some	O
function	O
to	O
some	O
column	O
of	O
dataframe	B-API
,	O
try	O
to	O
use	O
function	O
`	O
apply	O
`	O
function	O
of	O
DataFrame	B-API
API	O
.	O

Simple	O
demo	O
:	O
#CODE	O

By	O
passing	O
a	O
dict	O
to	O
aggregate	O
you	O
can	O
apply	O
a	O
different	O
aggregation	O
to	O
the	O
columns	O
of	O
a	O
DataFrame	B-API
.	O

You	O
could	O
`	O
apply	O
`	O
`	O
pd.Series.nunique	B-API
`	O
,	O
and	O
then	O
use	O
that	O
to	O
select	O
:	O
#CODE	O

I	O
have	O
a	O
dataframe	B-API
on	O
which	O
I'm	O
doing	O
a	O
row	O
by	O
row	O
manipulation	O
,	O
I'm	O
currently	O
using	O
iterrows()	B-API
which	O
I	O
know	O
is	O
slow	O
,	O
and	O
would	O
rather	O
use	O
apply()	B-API
.	O

However	O
I'm	O
not	O
sure	O
how	O
to	O
go	O
about	O
it	O
with	O
apply	O
(	O
if	O
at	O
all	O
possible	O
)	O
.	O

You	O
can	O
apply	O
string	O
methods	O
in	O
a	O
vectorized	O
way	O
using	O
the	O
`	O
str	O
`	O
attribute	O
of	O
`	O
Series	O
`	O
.	O

To	O
find	O
rows	O
in	O
the	O
`'	O
page_name	O
'`	O
column	O
with	O
some	O
string	O
`'	O
xxx	O
'`	O
you	O
can	O
do	O
#CODE	O

I	O
recommend	O
using	O
datetime64	O
,	O
that	O
is	O
first	O
apply	O
`	O
pd.to_datetime	B-API
`	O
on	O
the	O
index	O
.	O

If	O
you	O
set	O
this	O
as	O
an	O
index	O
then	O
you	O
can	O
use	O
resample	O
:	O
#CODE	O

Attempt	O
2	O
:	O
When	O
I	O
try	O
with	O
`	O
apply	O
`	O
I	O
almost	O
get	O
what	O
I	O
need	O
:	O
#CODE	O

Attempt	O
3	O
:	O
If	O
I	O
to	O
assign	O
the	O
result	O
of	O
`	O
apply	O
`	O
to	O
a	O
new	O
column	O
:	O
#CODE	O

weirdly	O
,	O
even	O
with	O
`	O
as_index=False	O
`	O
the	O
apply	O
version	O
doesn't	O
work	O
...	O

I	O
kindof	O
think	O
perhaps	O
it	O
should	O
work	O
(	O
modulo	O
ordering	O
)	O
...	O

Thanks	O
@USER	O
.	O

Sorry	O
,	O
not	O
sure	O
if	O
you	O
saw	O
the	O
second	O
part	O
of	O
my	O
question	O
.	O

I	O
tried	O
using	O
transform	O
and	O
apply	O
without	O
luck	O
.	O

@USER	O
-Reina	O
seen	O
them	O
thanks	O
,	O
I	O
hope	O
this	O
way	O
works	O
for	O
you	O
.	O

Will	O
have	O
a	O
little	O
think	O
if	O
I	O
can	O
get	O
this	O
with	O
an	O
apply	O
(	O
but	O
this	O
will	O
always	O
be	O
more	O
efficient	O
)	O
.	O

:)	O

Earlier	O
I	O
was	O
trying	O
len	O
(	O
filter	O
(	O
y.__contains__	O
,	O
x	O
))	O
for	O
the	O
same	O
purpose	O
but	O
was	O
not	O
able	O
to	O
apply	O
it	O
on	O
df	O

One	O
way	O
,	O
is	O
to	O
use	O
`	O
apply	O
`	O
and	O
calculate	O
len	O
#CODE	O

Typically	O
,	O
you're	O
better	O
off	O
keeping	O
DataFrame	B-API
columns	O
as	O
simple	O
types	O
rather	O
than	O
lists	O
,	O
dicts	O
,	O
etc	O
.	O

In	O
this	O
particular	O
case	O
,	O
you	O
can	O
pull	O
out	O
specific	O
elements	O
from	O
that	O
list	O
using	O
apply	O
though	O
with	O
something	O
like	O
`	O
x.apply	O
(	O
lambda	O
x	O
:	O
x	O
[	O
1	O
])`	O
to	O
pull	O
the	O
month	O
,	O
but	O
Fabio's	O
answer	O
is	O
better	O
from	O
a	O
data	O
organization	O
perspective	O
.	O

b.count	O
(	O
a	O
[	O
i	O
])	O
I	O
apply	O
this	O
but	O
received	O
this	O
error	O
.	O

AttributeError	O
:	O
'	O
Int64Index	O
'	O
object	O
has	O
no	O
attribute	O
'	O
levels	O
'	O

I'd	O
like	O
to	O
`	O
group_by	O
`	O
this	O
table	O
according	O
to	O
unique	O
combinations	O
of	O
`	O
id	O
`	O
and	O
`	O
timestamp	O
range	O
`	O
.	O

The	O
grouping	O
operation	O
should	O
ultimately	O
produce	O
a	O
single	O
`	O
grouped	O
`	O
object	O
that	O
I	O
can	O
then	O
apply	O
aggregations	O
on	O
.	O

For	O
example	O
:	O

you	O
might	O
also	O
want	O
to	O
apply	O
integer	O
division	O
to	O
generate	O
time	O
intervals	O
:	O
#CODE	O

Hi	O
Dima	O
,	O
thanks	O
for	O
your	O
answer	O
.	O

The	O
challenge	O
I'm	O
facing	O
is	O
creating	O
multiple	O
,	O
sometimes	O
overlapping	O
time	O
bins	O
that	O
only	O
apply	O
to	O
specific	O
`	O
id	O
`	O
s	O
.	O

If	O
you	O
try	O
to	O
produce	O
the	O
groups	O
from	O
my	O
example	O
you'll	O
see	O
what	O
I	O
mean	O
.	O

As	O
a	O
side-note	O
,	O
pandas	O
has	O
a	O
handy	O
convenience	O
function	O
for	O
grouping	O
on	O
binned	O
values	O
called	O
`	O
pd.cut	B-API
`	O
.	O

I'm	O
thinking	O
there	O
must	O
be	O
a	O
smarter	O
or	O
faster	O
way	O
to	O
do	O
this	O
,	O
a	O
mask	O
could	O
have	O
been	O
useful	O
except	O
you	O
can't	O
fill	O
down	O
with	O
this	O
data	O
as	O
`	O
price2	O
`	O
for	O
one	O
row	O
might	O
be	O
thousands	O
of	O
rows	O
after	O
the	O
`	O
price2	O
`	O
for	O
another	O
row	O
,	O
and	O
I	O
can't	O
find	O
a	O
way	O
to	O
turn	O
a	O
merge	O
into	O
a	O
cross	O
apply	O
like	O
one	O
might	O
in	O
TSQL	O
.	O

To	O
make	O
it	O
more	O
generic	O
,	O
compare	O
row	O
values	O
on	O
apply	O
method	O
.	O

You	O
should	O
actually	O
use	O
`	O
groupby	B-API
`	O
to	O
group	O
based	O
on	O
`	O
name	O
`	O
and	O
`	O
total_year	O
`	O
instead	O
of	O
`	O
apply	O
`	O
(	O
as	O
second	O
step	O
)	O
and	O
in	O
the	O
groupby	B-API
you	O
can	O
create	O
the	O
list	O
you	O
want	O
.	O

Example	O
-	O
#CODE	O

In	O
pandas	O
you	O
can	O
use	O
apply	O
to	O
apply	O
any	O
function	O
to	O
either	O
rows	O
or	O
columns	O
in	O
a	O
DataFrame	B-API
.	O

The	O
function	O
can	O
be	O
passed	O
with	O
a	O
lambda	O
,	O
or	O
defined	O
separately	O
.	O

(	O
side-remark	O
:	O
your	O
example	O
does	O
not	O
entirely	O
make	O
clear	O
if	O
you	O
actually	O
have	O
a	O
2-D	O
DataFrame	B-API
or	O
just	O
a	O
1-D	O
Series	O
.	O
Either	O
way	O
,	O
`	O
apply	O
`	O
can	O
be	O
used	O
)	O

The	O
`	O
.str	B-API
`	O
accessor	O
only	O
works	O
on	O
a	O
Series	O
or	O
a	O
single	O
column	O
of	O
a	O
DataFrame	B-API
(	O
not	O
an	O
entire	O
DataFrame	B-API
)	O
.	O

If	O
you	O
want	O
to	O
apply	O
this	O
method	O
to	O
multiple	O
columns	O
of	O
a	O
DataFrame	B-API
,	O
you'll	O
need	O
to	O
use	O
it	O
on	O
each	O
column	O
individually	O
in	O
turn	O
.	O

Sure	O
-	O
to	O
apply	O
the	O
method	O
to	O
the	O
'	O
words	O
'	O
column	O
,	O
you	O
could	O
write	O
`	O
df	O
[	O
'	O
words	O
']	O
.str	B-API
.cat	B-API
(	O
sep=	O
'	O
,	O
')`	O
(	O
where	O
`	O
df	O
`	O
is	O
the	O
name	O
of	O
your	O
DataFrame	B-API
)	O
.	O

try	O
to	O
use	O
"	O
apply	O
"	O
instead	O
of	O
"	O
map	O
"	O

Anzel	O
:	O
thanks	O
a	O
lot	O
for	O
the	O
answer	O
.	O

Unfortunately	O
,	O
I	O
get	O
the	O
same	O
output	O
with	O
"	O
apply	O
"	O
.	O

That	O
is	O
out	O
of	O
this	O
question	O
scope	O
,	O
but	O
if	O
you	O
have	O
mixed	O
types	O
both	O
non-evaluate	O
and	O
evaluated	O
,	O
then	O
do	O
a	O
map	O
or	O
apply	O
with	O
a	O
function	O
and	O
perform	O
a	O
try	O
/	O
except	O
then	O
you	O
should	O
be	O
good	O

Andy	O
,	O
thanks	O
a	O
lot	O
.	O

literal_eval	O
did	O
solve	O
the	O
problem	O
.	O

I	O
guess	O
that	O
,	O
as	O
a	O
non	O
expert	O
,	O
I	O
still	O
fight	O
a	O
bit	O
with	O
the	O
notion	O
of	O
apply	O
vs	O
map	O
.	O

After	O
filing	O
the	O
nans	O
with	O
strings	O
(	O
data	O
[	O
'	O
organization	O
']	O
=	O
data	O
[	O
'	O
organization	O
']	O
.fillna	B-API
(	O
'	O
[	O
]')	O
,	O
both	O
apply	O
and	O
map	O
on	O
literal_eval	O
did	O
the	O
job	O
.	O

But	O
when	O
is	O
one	O
is	O
one	O
preferable	O
to	O
the	O
other	O
?	O

btw	O
,	O
I	O
know	O
that	O
map	O
vs	O
.	O
apply	O
is	O
a	O
complete	O
different	O
question	O
,	O
do	O
not	O
feel	O
the	O
need	O
to	O
reply	O
it	O
.	O

I	O
will	O
some	O
do	O
some	O
research	O
on	O
it	O
.	O

Fantastic	O
!	O

Thanks	O
so	O
much	O
.	O

Ironically	O
,	O
I	O
had	O
just	O
been	O
using	O
indexed	O
keys	O
on	O
a	O
standard	O
json	O
import	O
a	O
little	O
earlier	O
,	O
but	O
hadn't	O
thought	O
to	O
apply	O
it	O
to	O
the	O
pandas	O
read	O
:)	O

I	O
would	O
like	O
to	O
filter	O
`	O
df1	O
`	O
keeping	O
only	O
the	O
values	O
that	O
ARE	O
NOT	O
in	O
`	O
df2	O
`	O
.	O

Values	O
to	O
filter	O
are	O
expected	O
to	O
be	O
as	O
`	O
(	O
A	O
,	O
b	O
)`	O
and	O
`	O
(	O
C	O
,	O
a	O
)`	O
tuples	O
.	O

So	O
far	O
I	O
tried	O
to	O
apply	O
the	O
`	O
isin	B-API
`	O
method	O
:	O
#CODE	O

You	O
can	O
also	O
create	O
a	O
function	O
to	O
check	O
your	O
conditions	O
,	O
and	O
apply	O
to	O
the	O
dataframe	B-API
:	O
#CODE	O

When	O
using	O
`	O
DataFrame.apply	B-API
`	O
if	O
you	O
use	O
`	O
axis=0	O
`	O
it	O
applies	O
the	O
condition	O
through	O
columns	O
,	O
to	O
use	O
`	O
apply	O
`	O
to	O
go	O
through	O
each	O
row	O
,	O
you	O
need	O
`	O
axis=1	O
`	O
.	O

You	O
can	O
just	O
set	O
all	O
the	O
values	O
that	O
meet	O
your	O
criteria	O
rather	O
than	O
looping	O
over	O
the	O
df	O
by	O
calling	O
`	O
apply	O
`	O
so	O
the	O
following	O
should	O
work	O
and	O
as	O
it's	O
vectorised	O
will	O
scale	O
better	O
for	O
larger	O
datasets	O
:	O
#CODE	O

this	O
will	O
set	O
all	O
rows	O
that	O
meet	O
the	O
criteria	O
,	O
the	O
problem	O
using	O
`	O
apply	O
`	O
is	O
that	O
it's	O
just	O
syntactic	O
sugar	O
for	O
a	O
`	O
for	O
`	O
loop	O
and	O
where	O
possible	O
this	O
should	O
be	O
avoided	O
where	O
a	O
vectorised	O
solution	O
exists	O
.	O

I	O
think	O
this	O
may	O
be	O
a	O
bug	O
in	O
apply	O
/	O
map_infer	O
,	O
definitely	O
worth	O
a	O
github	O
issue	O
.	O

It	O
seems	O
strange	O
to	O
use	O
a	O
lambda	O
that	O
returns	O
a	O
Series	O
in	O
a	O
transform	O
!	O

(	O
Rather	O
than	O
use	O
an	O
apply	O
.	O
)	O

I	O
guess	O
they	O
use	O
the	O
same	O
path	O
,	O
*	O
but	O
*	O
tranform	O
usually	O
means	O
that	O
one	O
value	O
is	O
spread	O
on	O
the	O
group	O
(	O
e.g.	O
transform	O
(	O
'	O
min	O
'))	O
whereas	O
apply	O
means	O
that	O
the	O
group	O
can	O
return	O
anything	O
.	O

But	O
y'know	O
I'm	O
not	O
sure	O
,	O
that	O
was	O
my	O
understanding	O
.	O

to	O
which	O
I	O
apply	O
pivot_table	B-API
#CODE	O

Bear	O
in	O
mind	O
that	O
groupby	B-API
didn't	O
really	O
apply	O
in	O
your	O
case	O
and	O
that	O
it	O
returns	O
a	O
`	O
DataFrame	B-API
`	O
-ish	O
object	O

I'm	O
looking	O
for	O
method	O
,	O
that	O
iterates	O
over	O
the	O
rows	O
,	O
but	O
apply	O
some	O
method	O
only	O
for	O
every	O
20th	O
or	O
30th	O
row	O
values	O

Actually	O
I	O
try	O
to	O
minimize	O
the	O
number	O
of	O
requests	O
,	O
cause	O
otherwise	O
I	O
have	O
the	O
timeout	O
issue	O
.	O

That's	O
why	O
I	O
tried	O
iterate	O
over	O
the	O
rows	O
,	O
and	O
apply	O
the	O
function	O
of	O
request	O
only	O
for	O
every	O
20th	O
or	O
60th	O
row	O
(	O
cause	O
I	O
have	O
7000	O
rows	O
)	O
and	O
not	O
to	O
speed	O
the	O
process	O
by	O
applying	O
the	O
time.sleep	O
method	O

then	O
you	O
can	O
apply	O
`	O
mean()	B-API
`	O
to	O
the	O
series	O
:	O
#CODE	O

Another	O
way	O
of	O
doing	O
this	O
is	O
to	O
put	O
your	O
conversion	O
logic	O
in	O
a	O
function	O
,	O
and	O
to	O
apply	O
this	O
function	O
over	O
the	O
column	O
.	O

#CODE	O

You're	O
looking	O
for	O
the	O
`	O
axis	O
`	O
parameter	O
.	O

Many	O
Pandas	O
functions	O
take	O
this	O
argument	O
to	O
apply	O
an	O
operation	O
across	O
the	O
columns	O
or	O
across	O
the	O
rows	O
.	O

Use	O
`	O
axis=0	O
`	O
to	O
apply	O
row-wise	O
and	O
`	O
axis=1	O
`	O
to	O
apply	O
column-wise	O
.	O

This	O
operation	O
is	O
actually	O
traversing	O
the	O
columns	O
,	O
so	O
you	O
want	O
`	O
axis=1	O
`	O
.	O

Problem	O
:	O
Given	O
the	O
dataframe	B-API
below	O
,	O
I'm	O
trying	O
to	O
come	O
up	O
with	O
the	O
code	O
that	O
will	O
apply	O
a	O
function	O
to	O
three	O
distinct	O
columns	O
without	O
having	O
to	O
write	O
three	O
separate	O
function	O
calls	O
.	O

Then	O
I	O
apply	O
the	O
function	O
to	O
the	O
particular	O
column	O
:	O
#CODE	O

This	O
works	O
exactly	O
as	O
I	O
want	O
it	O
to	O
for	O
that	O
one	O
column	O
.	O

However	O
,	O
I	O
don't	O
want	O
to	O
have	O
to	O
rewrite	O
this	O
for	O
each	O
of	O
the	O
three	O
different	O
"	O
spend	O
"	O
columns	O
(	O
30	O
,	O
90	O
,	O
365	O
)	O
.	O

I	O
want	O
to	O
be	O
able	O
to	O
write	O
code	O
that	O
will	O
generalize	O
and	O
apply	O
this	O
function	O
to	O
multiple	O
columns	O
in	O
one	O
pass	O
.	O

The	O
`	O
lambda	O
`	O
will	O
ensure	O
that	O
only	O
one	O
input	O
parameter	O
of	O
your	O
function	O
is	O
dangling	O
free	O
when	O
it	O
gets	O
`	O
apply	O
`	O
d	O
.	O

@USER	O
sure	O
:)	O
The	O
lambda	O
can	O
only	O
use	O
variables	O
that	O
are	O
explicitly	O
passed	O
to	O
it	O
,	O
so	O
you	O
pass	O
`	O
col	O
`	O
and	O
`	O
day	O
`	O
to	O
it	O
.	O

It's	O
a	O
lazy	O
thing	O
to	O
name	O
the	O
lambda's	O
parameters	O
this	O
way	O
,	O
probably	O
this	O
would	O
be	O
clearer	O
:	O
`	O
lambda	O
var1	O
,	O
var2=col	O
,	O
var3	O
=d	O
ay	O
:	O
annualize_spend	O
(	O
var2	O
,	O
var3	O
,	O
var1	O
)`	O
.	O

So	O
you	O
set	O
default	O
values	O
for	O
the	O
*	O
last	O
*	O
two	O
parameters	O
of	O
the	O
lambda	O
,	O
thereby	O
effectively	O
rendering	O
it	O
a	O
single-input	O
function	O
for	O
`	O
apply	O
`	O
.	O

Since	O
these	O
are	O
just	O
default	O
values	O
,	O
the	O
lambda	O
could	O
also	O
work	O
in	O
a	O
2	O
or	O
3-input	O
syntax	O
,	O
but	O
`	O
apply	O
`	O
only	O
uses	O
a	O
single	O
variable	O
,	O
so	O
it	O
must	O
have	O
at	O
most	O
1	O
non-default	O
parameter	O
.	O

:	O
Wow	O
,	O
thanks	O
so	O
much	O
for	O
the	O
explanation	O
.	O

One	O
more	O
(	O
general	O
)	O
question	O
:	O
why	O
pass	O
a	O
lambda	O
into	O
the	O
apply	O
function	O
instead	O
of	O
just	O
the	O
function	O
itself	O
?	O

That	O
is	O
why	O
df.apply	B-API
(	O
lambda	O
row	O
,	O
col=col	O
,	O
day	O
=d	O
ay	O
:	O
annualize_spend	O
(	O
col	O
,	O
day	O
,	O
row	O
)	O
instead	O
of	O
just	O
df.apply	B-API
(	O
annualize_spend	O
)	O
?	O

What	O
efficiency	O
/	O
value	O
is	O
gained	O
from	O
utilizing	O
lambda	O
functionality	O
when	O
the	O
function	O
has	O
already	O
been	O
created	O
?	O

(	O
I	O
have	O
seen	O
this	O
approach	O
taken	O
for	O
much	O
simpler	O
functions	O
,	O
and	O
was	O
curious	O
why	O
invoking	O
the	O
lambda	O
was	O
necessary	O
when	O
the	O
function	O
had	O
already	O
been	O
created	O
)	O
.	O

Thanks	O
again	O
,	O
most	O
helpful	O
!	O

@USER	O
try	O
it	O
without	O
the	O
lambda	O
:)	O
You	O
should	O
get	O
an	O
error	O
that	O
your	O
function	O
expects	O
3	O
arguments	O
,	O
and	O
only	O
1	O
is	O
specified	O
,	O
How	O
should	O
your	O
function	O
know	O
what	O
`	O
col	O
`	O
and	O
`	O
day	O
`	O
are	O
?	O

The	O
names	O
in	O
function	O
definitions	O
are	O
quite	O
arbitrary	O
,	O
as	O
exemplified	O
by	O
my	O
use	O
of	O
`	O
lambda	O
row	O
,	O
col=col	O
,	O
day	O
=d	O
ay	O
:	O
...	O

`	O
,	O
so	O
the	O
name	O
of	O
the	O
variables	O
in	O
the	O
function's	O
definition	O
can't	O
help	O
in	O
any	O
way	O
(	O
it	O
only	O
helps	O
the	O
programmer	O
)	O
.	O

So	O
it's	O
simply	O
because	O
`	O
apply	O
`	O
expects	O
a	O
single-input	O
function	O
,	O
which	O
it	O
then	O
applies	O
to	O
the	O
variable	O
.	O

Okay	O
,	O
I	O
think	O
I	O
understand	O
:	O
the	O
use	O
of	O
a	O
multi-argument	O
`	O
lambda	O
`	O
is	O
your	O
way	O
of	O
getting	O
around	O
the	O
single-argument	O
constraint	O
of	O
`	O
apply	O
`	O
.	O

And	O
this	O
approach	O
can	O
be	O
generalized	O
when	O
wanting	O
to	O
apply	O
**	O
any	O
**	O
multi-argument	O
function	O
with	O
`	O
apply	O
`	O
or	O
`	O
map	O
`	O
or	O
`	O
applymap	B-API
`	O
.	O

That	O
is	O
,	O
first	O
explicitly	O
create	O
the	O
multi-argument	O
function	O
.	O

Then	O
specify	O
each	O
argument	O
in	O
that	O
function	O
as	O
a	O
variable	O
in	O
the	O
lambda	O
.	O

Finally	O
,	O
complete	O
the	O
lambda	O
by	O
calling	O
the	O
function	O
(	O
along	O
with	O
each	O
argument	O
)	O
.	O

Again	O
,	O
many	O
thanks	O
!	O

I	O
thought	O
about	O
using	O
`	O
iloc	B-API
`	O
`	O
loc	O
`	O
but	O
I'm	O
not	O
very	O
strong	O
with	O
this	O
methods	O
,	O
so	O
if	O
you	O
know	O
how	O
better	O
apply	O
them	O
to	O
this	O
case	O
,	O
it	O
could	O
be	O
solution	O
for	O
my	O
problem	O

But	O
when	O
I	O
try	O
and	O
use	O
this	O
function	O
with	O
apply	O
:	O
#CODE	O

I'm	O
not	O
sure	O
why	O
you	O
have	O
this	O
problem	O
with	O
`	O
apply	O
`	O
,	O
but	O
you	O
should	O
not	O
write	O
the	O
function	O
like	O
you	O
did	O
in	O
the	O
first	O
place	O
.	O

Here	O
is	O
a	O
suggestion	O
that	O
avoids	O
dividing	O
two	O
huge	O
numbers	O
one	O
by	O
another	O
:	O
#CODE	O

Is	O
conversion	O
in	O
the	O
`	O
read_csv	B-API
`	O
is	O
mandatory	O
?	O

Otherwise	O
,	O
passing	O
a	O
function	O
which	O
returns	O
`	O
Series	O
`	O
to	O
`	O
apply	O
`	O
results	O
in	O
`	O
DataFrame	B-API
`	O
.	O

#CODE	O

You	O
can	O
construct	O
the	O
lists	O
for	O
each	O
continent	O
and	O
`	O
apply	O
`	O
a	O
func	O
:	O
#CODE	O

if	O
I	O
apply	O
`	O
.value_counts	B-API
`	O
directly	O
to	O
`	O
groupby	B-API
`	O
as	O
#CODE	O

I	O
have	O
tried	O
creating	O
a	O
new	O
function	O
and	O
using	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
,	O
but	O
this	O
works	O
only	O
if	O
rows	O
are	O
sorted	O
.	O

Also	O
it's	O
slow	O
and	O
ugly	O
.	O

#CODE	O

Not	O
sure	O
about	O
efficiently	O
but	O
a	O
cleaner	O
method	O
is	O
to	O
call	O
`	O
apply	O
`	O
and	O
pass	O
`'	O
,	O
'	O
,	O
join	O
`	O
as	O
the	O
func	O
to	O
call	O
:	O
#CODE	O

@USER	O
:	O
I	O
tried	O
it	O
with	O
column	O
name	O
also	O
,	O
but	O
it	O
did	O
not	O
help	O
.	O

My	O
dataframe	B-API
contains	O
one	O
column	O
which	O
consists	O
of	O
sentences	O
.	O

When	O
i	O
try	O
to	O
apply	O
drop_duplicates()	B-API
on	O
a	O
column	O
containing	O
1	O
or	O
2	O
words	O
,	O
if	O
works	O
fine	O
.	O

But	O
not	O
when	O
it	O
come	O
to	O
sentences	O
.	O

Anything	O
that	O
can	O
be	O
done	O
?	O

@USER	O
:	O
I	O
tried	O
it	O
with	O
column	O
name	O
also	O
,	O
but	O
it	O
did	O
not	O
help	O
.	O

My	O
dataframe	B-API
contains	O
one	O
column	O
which	O
consists	O
of	O
sentences	O
.	O

When	O
i	O
try	O
to	O
apply	O
drop_duplicates()	B-API
on	O
a	O
column	O
containing	O
1	O
or	O
2	O
words	O
,	O
or	O
on	O
a	O
smaller	O
sample	O
of	O
comments	O
,	O
if	O
works	O
fine	O
.	O

But	O
not	O
when	O
it	O
come	O
to	O
the	O
entire	O
dataset	O
(	O
about	O
300	O
rows	O
)	O
,	O
it	O
does	O
not	O
work	O
.	O

Anything	O
that	O
can	O
be	O
done	O
?	O

The	O
problem	O
I	O
am	O
running	O
in	O
to	O
is	O
`	O
df.loc	B-API
`	O
is	O
running	O
pretty	O
slow	O
on	O
large	O
DataFrames	O
(	O
2-7	O
million	O
rows	O
)	O
.	O

Is	O
there	O
a	O
way	O
to	O
speed	O
up	O
this	O
operation	O
?	O

I've	O
looked	O
into	O
`	O
eval()	B-API
`	O
,	O
but	O
it	O
doesn't	O
seem	O
to	O
apply	O
to	O
hard-coded	O
lists	O
of	O
index	O
values	O
like	O
this	O
.	O

I	O
have	O
also	O
thought	O
about	O
using	O
`	O
pd.DataFrame.isin	B-API
`	O
,	O
but	O
that	O
misses	O
the	O
repeat	O
values	O
(	O
only	O
returns	O
a	O
row	O
per	O
unique	O
element	O
in	O
`	O
selection	O
`)	O
.	O

I	O
want	O
to	O
use	O
a	O
function	O
from	O
an	O
add-in	O
in	O
excel	O
and	O
apply	O
it	O
to	O
some	O
data	O
i	O
have	O
simulated	O
in	O
python	O
.	O

Is	O
there	O
any	O
modules	O
that	O
can	O
achieve	O
this	O
?	O

Unfortunately	O
,	O
this	O
only	O
runs	O
a	O
macro	O
.	O

I	O
need	O
to	O
be	O
able	O
to	O
call	O
the	O
add-in	O
and	O
apply	O
my	O
data	O
indexes	O
there	O
...	O
something	O
along	O
these	O
lines	O
:	O
=	O
add-in_name	O
(	O
data_range1	O
,	O
data_range2	O
,	O
"	O
GGCV	O
")	O

To	O
take	O
this	O
further	O
,	O
you	O
could	O
use	O
an	O
[	O
apply	O
]	O
(	O
#URL	O
)	O
combined	O
with	O
a	O
function	O
to	O
carry	O
out	O
the	O
logic	O
to	O
remove	O
the	O
loop	O
entirely	O
.	O

This	O
would	O
make	O
the	O
code	O
a	O
lot	O
more	O
portable	O
(	O
and	O
hopefully	O
efficient	O
)	O
and	O
allow	O
the	O
output	O
to	O
also	O
be	O
a	O
pandas	O
object	O
without	O
any	O
conversion	O
.	O

You	O
can	O
then	O
apply	O
`	O
np.where	B-API
`	O
as	O
you	O
did	O
to	O
find	O
the	O
indices	O
where	O
your	O
condition	O
is	O
fulfilled	O
:	O
#CODE	O

When	O
you	O
use	O
`	O
apply	O
`	O
,	O
it	O
calls	O
your	O
function	O
once	O
for	O
each	O
column	O
,	O
with	O
that	O
column	O
as	O
an	O
argument	O
.	O

So	O
`	O
x	O
`	O
in	O
your	O
NewCols	O
will	O
be	O
set	O
to	O
a	O
single	O
column	O
.	O

When	O
you	O
do	O
`	O
x	O
[	O
string	O
]	O
=	O
list.count	O
(	O
string	O
)`	O
,	O
you	O
are	O
adding	O
values	O
to	O
that	O
column	O
.	O

Since	O
`	O
apply	O
`	O
is	O
called	O
for	O
each	O
column	O
,	O
you	O
wind	O
up	O
appending	O
the	O
values	O
to	O
both	O
columns	O
in	O
this	O
way	O
.	O

`	O
apply	O
`	O
is	O
not	O
the	O
right	O
choice	O
when	O
your	O
computation	O
depends	O
only	O
on	O
the	O
values	O
of	O
a	O
single	O
column	O
.	O

Instead	O
,	O
use	O
`	O
map	O
`	O
.	O

In	O
this	O
case	O
,	O
what	O
you	O
need	O
to	O
do	O
is	O
write	O
a	O
NewCol	O
function	O
that	O
accepts	O
a	O
single	O
`	O
Column2	O
`	O
value	O
and	O
returns	O
the	O
data	O
for	O
a	O
single	O
row	O
.	O

You	O
can	O
return	O
this	O
as	O
a	O
dict	O
,	O
or	O
,	O
handily	O
,	O
a	O
dict-like	O
object	O
such	O
as	O
a	O
`	O
collections.Counter	O
`	O
.	O

Then	O
you	O
need	O
to	O
wrap	O
this	O
new	O
row	O
data	O
into	O
a	O
DataFrame	B-API
and	O
attach	O
it	O
column-wise	O
to	O
your	O
existing	O
data	O
using	O
`	O
concat	O
`	O
.	O

Here	O
is	O
an	O
example	O
:	O
#CODE	O

Pandas	O
Dataframe	B-API
-	O
faster	O
apply	O
?	O

You	O
should	O
avoid	O
`	O
apply	O
`	O
and	O
use	O
`	O
to_datetime	B-API
`	O
:	O
`	O
df	O
[	O
'	O
local_time	O
']	O
=	O
pd.to_datetime	B-API
(	O
df	O
[	O
'	O
local_time	O
'])`	O

I	O
could	O
do	O
it	O
using	O
apply	O
and	O
a	O
for	O
loop	O
(	O
see	O
below	O
)	O
,	O
but	O
it	O
is	O
pretty	O
clunky	O
.	O

Is	O
there	O
a	O
better	O
way	O
?	O

#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
use	O
the	O
column's	O
`	O
name	O
`	O
attribute	O
to	O
get	O
the	O
key	O
for	O
the	O
outer	O
dictionary	O
:	O
#CODE	O

IIUC	O
correctly	O
then	O
you	O
use	O
`	O
apply	O
`	O
with	O
a	O
`	O
lambda	O
`	O
:	O
#CODE	O

Didn't	O
know	O
I	O
can	O
use	O
apply	O
and	O
axis=1	O
,	O
thanks	O
!	O

Should	O
the	O
DataFrame	B-API
be	O
used	O
in	O
this	O
way	O
?	O

I	O
know	O
that	O
dtype	B-API
object	O
can	O
be	O
ultra	O
slow	O
for	O
sorting	O
and	O
whatnot	O
,	O
but	O
I	O
am	O
really	O
just	O
using	O
the	O
dataframe	B-API
a	O
convenient	O
container	O
because	O
the	O
column	O
/	O
index	O
notation	O
is	O
quite	O
slick	O
.	O

If	O
DataFrames	O
should	O
not	O
be	O
used	O
in	O
this	O
way	O
is	O
there	O
similar	O
alternative	O
?	O

I	O
was	O
looking	O
at	O
the	O
Panel	O
class	O
but	O
I	O
am	O
not	O
sure	O
if	O
it	O
is	O
the	O
proper	O
solution	O
for	O
my	O
application	O
.	O

I	O
would	O
hate	O
forge	O
ahead	O
and	O
apply	O
the	O
hack	O
shown	O
above	O
to	O
some	O
code	O
and	O
then	O
have	O
it	O
not	O
supported	O
in	O
future	O
releases	O
of	O
pandas	O
.	O

You	O
can	O
create	O
a	O
list	O
of	O
column	O
names	O
and	O
then	O
iterate	O
through	O
them	O
and	O
apply	O
your	O
logic	O
for	O
them	O
.	O

Example	O
-	O
#CODE	O

Melt	B-API
the	O
data	O
frame	O
,	O
then	O
apply	O
the	O
repalce	O
and	O
to	O
lower	O
function	O
.	O

Pivot	B-API
the	O
data	O
frame	O
to	O
get	O
back	O

Firstly	O
column	O
`	O
week	O
`	O
is	O
set	O
to	O
index	O
.	O

Then	O
df	O
is	O
grouped	O
by	O
column	O
`	O
product	O
`	O
and	O
apply	O
reindex	O
by	O
max	O
values	O
of	O
index	O
of	O
each	O
group	O
.	O

Missing	O
values	O
are	O
filled	O
by	O
`	O
0	O
`	O
.	O

#CODE	O

Apply	O
function	O
with	O
args	O
in	O
pandas	O

You	O
can	O
then	O
apply	O
it	O
straightforwardly	O
:	O
#CODE	O

The	O
strange	O
thing	O
is	O
that	O
when	O
I	O
apply	O
this	O
logic	O
to	O
a	O
bigger	O
table	O
that	O
im	O
working	O
on	O
,	O
I	O
get	O
a	O
"	O
True	O
"	O
for	O
all	O
boolean	O
values	O
,	O
despite	O
me	O
having	O
different	O
"	O
time	O
"	O
-columns	O
and	O
the	O
same	O
ID-number	O
?	O

Do	O
you	O
know	O
if	O
there	O
are	O
any	O
cases	O
where	O
the	O
boolean	O
expression	O
isnt	O
evaluated	O
over	O
all	O
three	O
included	O
colums	O
,	O
so	O
it	O
only	O
looks	O
on	O
the	O
first	O
column	O
(	O
"	O
id	O
")	O

IIUC	O
then	O
you	O
`	O
groupby	B-API
`	O
on	O
`	O
level=0	O
`	O
of	O
your	O
index	O
and	O
`	O
apply	O
`	O
a	O
`	O
lambda	O
`	O
to	O
`	O
join	O
`	O
the	O
values	O
:	O
#CODE	O

One	O
way	O
would	O
be	O
to	O
use	O
`	O
apply	O
`	O
by	O
constructing	O
column	O
name	O
for	O
each	O
row	O
based	O
on	O
year	O
like	O
`'	O
w	O
'	O
+	O
str	O
(	O
x.year	O
)`	O
.	O

#CODE	O

I	O
am	O
facing	O
difficulty	O
with	O
the	O
correct	O
syntax	O
of	O
the	O
if	O
condition	O
.	O

I	O
want	O
to	O
apply	O
the	O
condition	O
to	O
check	O
the	O
equality	O
of	O
a	O
string	O
.	O

But	O
the	O
way	O
i	O
am	O
trying	O
to	O
do	O
it	O
,	O
is	O
giving	O
me	O
an	O
error	O
:	O
#CODE	O

simply	O
you	O
can	O
apply	O
the	O
regex	O
`	O
b	O
,?	O

`	O
,	O
which	O
means	O
replace	O
any	O
value	O
of	O
`	O
b	O
`	O
and	O
`	O
,	O
`	O
found	O
after	O
the	O
`	O
b	O
`	O
if	O
exists	O
#CODE	O

Now	O
let's	O
write	O
an	O
`	O
apply	O
`	O
function	O
that	O
adds	O
a	O
column	O
of	O
nearest	O
dates	O
to	O
`	O
df1	O
`	O
using	O
scikit-learn	O
:	O
#CODE	O

Next	O
I	O
apply	O
data	O
=	O
`	O
np.asarray()	B-API
`	O
on	O
the	O
DataFrame	B-API
:	O
#CODE	O

@USER	O
,	O
yes	O
I	O
know	O
I'll	O
have	O
to	O
specify	O
the	O
order	O
manually	O
,	O
I'm	O
just	O
wondering	O
how	O
to	O
apply	O
those	O
specified	O
orders	O
.	O

In	O
reality	O
my	O
dataset	O
is	O
much	O
larger	O
and	O
has	O
several	O
'	O
questions	O
'	O
with	O
the	O
same	O
set	O
of	O
responses	O
.	O

For	O
example	O
many	O
Questions	O
that	O
can	O
be	O
(	O
"	O
Yes	O
"	O
,	O
"	O
No	O
"	O
,	O
"	O
Unsure	O
")	O
,	O
many	O
questions	O
that	O
can	O
be	O
(	O
"	O
Not	O
at	O
all	O
"	O
,	O
"	O
A	O
Little	O
"	O
,	O
"	O
A	O
Lot	O
")	O
,	O
etc	O
.	O

I'd	O
like	O
to	O
specify	O
the	O
orders	O
of	O
these	O
responses	O
and	O
then	O
have	O
them	O
applied	O
to	O
the	O
appropriate	O
questions	O
(	O
level	O
0	O
in	O
the	O
index	O
)	O
.	O

Does	O
this	O
make	O
sense	O
?	O

If	O
you	O
have	O
multiple	O
conditions	O
besides	O
this	O
example	O
you	O
can	O
use	O
`	O
apply	O
`	O
:	O
#CODE	O

Does	O
color	O
mean	O
anything	O
special	O
or	O
can	O
we	O
treat	O
a	O
combination	O
of	O
item	O
id	O
and	O
color	O
id	O
as	O
a	O
new	O
unique	O
item	O
?	O

Does	O
the	O
store_min_buy	O
apply	O
to	O
just	O
the	O
one	O
thing	O
or	O
across	O
the	O
sum	O
of	O
all	O
the	O
things	O
you	O
buy	O
at	O
this	O
store	O
?	O

What	O
does	O
it	O
even	O
mean	O
that	O
there's	O
a	O
min_buy	O
of	O
9.14	O
,	O
can	O
I	O
buy	O
9	O
and	O
14%	O
of	O
an	O
item	O
somehow	O
?	O

Thanks	O
,	O
that's	O
a	O
good	O
hint	O
.	O

It	O
works	O
,	O
but	O
I	O
can't	O
pass	O
the	O
first()	B-API
-function	O
to	O
g.agg	O
(	O
...	O
)	O
,	O
can	O
I	O
?	O

I	O
would	O
like	O
that	O
better	O
,	O
because	O
I	O
would	O
like	O
to	O
apply	O
many	O
different	O
aggregation	O
functions	O
at	O
once	O
(	O
amin	B-API
,	O
amax	B-API
,	O
first	O
,	O
...	O
)	O
.	O

It	O
will	O
be	O
a	O
workaround	O
to	O
use	O
it	O
and	O
then	O
assemble	O
my	O
final	O
dataset	O
manually	O
,	O
I	O
guess	O
.	O

That's	O
not	O
an	O
error	O
,	O
just	O
a	O
representation	O
of	O
the	O
groupby	B-API
object	O
.	O

You	O
just	O
need	O
to	O
apply	O
an	O
aggregation	O
operation	O
to	O
the	O
object	O
to	O
return	O
a	O
DataFrame	B-API
or	O
Series	O
.	O

There's	O
more	O
information	O
about	O
this	O
in	O
the	O
docs	O
on	O
groupby	B-API
.	O

Group	O
series	O
using	O
mapper	O
(	O
dict	O
or	O
key	O
function	O
,	O
apply	O
given	O
function	O

Use	O
`	O
Series.value_counts	B-API
`	O
to	O
count	O
the	O
number	O
of	O
occurrences	O
for	O
each	O
city	O
in	O
`	O
US	O
[	O
'	O
city	O
']`	O
,	O
and	O
then	O
use	O
`	O
Series.map	B-API
`	O
to	O
apply	O
those	O
counts	O
to	O
corresponding	O
values	O
in	O
`	O
UK	O
[	O
'	O
city	O
']`	O
:	O
#CODE	O

I	O
have	O
tried	O
using	O
`	O
apply	O
`	O
but	O
it	O
is	O
pretty	O
slow	O
:	O
#CODE	O

`	O
get_dummies	B-API
`	O
and	O
other	O
Categorical	B-API
operations	O
don't	O
apply	O
because	O
they	O
operate	O
on	O
a	O
per	O
row	O
level	O
.	O

Not	O
within	O
the	O
row	O
.	O

Apply	O
a	O
function	O
to	O
each	O
of	O
the	O
subsequent	O
rows	O
of	O
the	O
dataframe	B-API
that	O
will	O
give	O
the	O
depreciation	O
relative	O
to	O
the	O
base-year	O
,	O
base-price	O
.	O

This	O
should	O
be	O
put	O
in	O
a	O
set	O
or	O
a	O
list	O
.	O

Used	O
group.apply()	O

I	O
constructed	O
a	O
separate	O
dataframe	B-API
with	O
one	O
column	O
as	O
"	O
make	O
"	O
,	O
another	O
as	O
"	O
model	O
"	O
,	O
and	O
a	O
third	O
one	O
"	O
average	O
yearly	O
depreciation	O
"	O
.	O

What	O
this	O
really	O
boiled	O
down	O
to	O
was	O
how	O
to	O
sequentially	O
apply	O
a	O
function	O
to	O
rows	O
of	O
a	O
dataframe	B-API
.	O

#CODE	O

Now	O
I	O
can	O
apply	O
a	O
function	O
:	O
#CODE	O

I'm	O
new	O
to	O
Pandas	O
.	O

I	O
created	O
this	O
pivot	B-API
table	O
,	O
but	O
I	O
need	O
to	O
figure	O
out	O
how	O
to	O
apply	O
a	O
function	O
within	O
each	O
day	O
on	O
the	O
'	O
is_match	O
'	O
values	O
only	O
.	O

See	O
img	O
below	O
for	O
head	O
of	O
data	O
.	O

Using	O
a	O
function	O
with	O
`	O
apply	O
`	O
is	O
slower	O
than	O
the	O
list	O
comprehension	O
:	O
#CODE	O

Thanks	O
!	O

Really	O
much	O
faster	O
.	O

But	O
maybe	O
it's	O
possible	O
to	O
make	O
it	O
trough	O
pandas	O
apply	O
/	O
map	O
function	O
?	O

You	O
can	O
use	O
`	O
apply	O
`	O
(	O
see	O
updated	O
answer	O
above	O
)	O
.	O

But	O
it	O
is	O
slower	O
due	O
to	O
the	O
function	O
calling	O
overhead	O
.	O

Yep	O
,	O
added	O
a	O
new	O
option	O
above	O
that	O
will	O
apply	O
the	O
same	O
logic	O
to	O
the	O
entire	O
df	O
.	O

This	O
also	O
looks	O
promising	O
.	O

Can	O
you	O
give	O
an	O
example	O
of	O
the	O
function	O
and	O
how	O
to	O
apply	O
to	O
the	O
groupby	B-API
?	O

Pandas	O
dataframe	B-API
apply	O
refer	O
to	O
previous	O
row	O
to	O
calculate	O
difference	O

The	O
problem	O
is	O
not	O
calculating	O
the	O
day-difference	O
between	O
two	O
`	O
datetime	O
`	O
objects	O
.	O

I	O
am	O
just	O
not	O
sure	O
on	O
how	O
to	O
add	O
the	O
new	O
column	O
.	O

I	O
know	O
,	O
that	O
I	O
have	O
to	O
make	O
a	O
`	O
groupby	B-API
`	O
first	O
(	O
`	O
df.groupby	B-API
(	O
'	O
player	O
')`)	O
and	O
then	O
use	O
`	O
apply	O
`	O
(	O
or	O
maybe	O
`	O
transform	O
`	O
?	O
)	O
.	O

However	O
,	O
I	O
am	O
stuck	O
,	O
because	O
for	O
calculating	O
the	O
difference	O
,	O
I	O
need	O
to	O
refer	O
to	O
the	O
previous	O
row	O
in	O
the	O
apply-function	O
,	O
and	O
I	O
don't	O
know	O
how	O
to	O
do	O
that	O
,	O
if	O
possible	O
at	O
all	O
.	O

I	O
suggest	O
that	O
you	O
apply	O
the	O
function	O
on	O
a	O
subset	O
of	O
data	O
for	O
example	O
the	O
first	O
`	O
100	O
`	O
row	O
if	O
it	O
worked	O
then	O
increase	O
the	O
subset	O
until	O
you	O
get	O
the	O
error	O
and	O
know	O
which	O
rows	O
specifically	O
in	O
your	O
data	O
set	O
causes	O
the	O
issue	O

use	O
of	O
apply	O
function	O
when	O
you	O
need	O
to	O
pass	O
'	O
self	O
'	O
as	O
argument	O

python	O
-	O
pass	O
dataframe	B-API
column	O
as	O
argument	O
in	O
apply	O
function	O

You	O
have	O
to	O
`	O
apply	O
`	O
over	O
the	O
other	O
axis	O
.	O

#CODE	O

does	O
not	O
work	O
.	O

Lets	O
assume	O
I	O
have	O
3	O
categories	O
in	O
column	O
a	O
,	O
for	O
each	O
specific	O
on	O
I	O
have	O
5	O
categories	O
of	O
b	O
.	O

What	O
I	O
need	O
to	O
do	O
is	O
to	O
find	O
total	O
number	O
of	O
on	O
class	O
of	O
b	O
for	O
each	O
class	O
of	O
a	O
.	O

I	O
tried	O
apply	O
command	O
,	O
but	O
I	O
think	O
I	O
do	O
not	O
know	O
how	O
to	O
use	O
it	O
properly	O
.	O

#CODE	O

Or	O
you	O
can	O
apply	O
a	O
`	O
lambda	O
`	O
function	O
onto	O
the	O
groups	O
:	O
#CODE	O

One	O
way	O
could	O
have	O
been	O
to	O
use	O
pd.exanding_apply()	O
,	O
but	O
it	O
doesn't	O
preserve	O
the	O
dataframe	B-API
to	O
apply	O
the	O
function	O
on	O
,	O
so	O
there	O
is	O
no	O
way	O
to	O
have	O
the	O
correct	O
groupyby	O
index	O
..	O

I	O
know	O
how	O
to	O
do	O
it	O
using	O
`	O
apply	O
`	O
with	O
python	O
function	O
but	O
it's	O
very	O
slow	O
:	O
~16s	O
for	O
1M	O
elements	O
on	O
a	O
MacBookPro	O
#CODE	O

I	O
have	O
a	O
data	O
frame	O
that	O
needs	O
a	O
column	O
,	O
`	O
c3	O
`	O
,	O
added	O
.	O

Each	O
entry	O
in	O
the	O
column	O
depends	O
on	O
entries	O
from	O
the	O
same	O
row	O
in	O
two	O
other	O
columns	O
,	O
`	O
c1	O
`	O
and	O
`	O
c2	O
`	O
.	O

`	O
c3	O
`	O
was	O
originally	O
created	O
by	O
mapping	O
a	O
function	O
over	O
pairs	O
of	O
entries	O
in	O
`	O
c1	O
`	O
and	O
`	O
c2	O
`	O
.	O

I'm	O
trying	O
to	O
speed	O
up	O
the	O
creation	O
of	O
`	O
c3	O
`	O
,	O
since	O
there	O
is	O
a	O
lot	O
of	O
data	O
,	O
by	O
using	O
`	O
apply	O
`	O
.	O

Here's	O
what	O
I	O
have	O
now	O
:	O
#CODE	O

However	O
,	O
when	O
I	O
do	O
this	O
,	O
'	O
c3	O
'	O
becomes	O
a	O
`	O
float64	O
`	O
,	O
while	O
I	O
need	O
it	O
to	O
be	O
of	O
type	O
`	O
object	O
`	O
to	O
preserve	O
`	O
None	O
`	O
values	O
that	O
I	O
have	O
for	O
further	O
processing	O
of	O
the	O
dataframe	B-API
(	O
rather	O
than	O
having	O
them	O
converted	O
to	O
`	O
NaN	O
`	O
,	O
which	O
is	O
what	O
happens	O
with	O
the	O
given	O
line	O
of	O
code	O
,	O
since	O
the	O
other	O
values	O
generated	O
by	O
the	O
function	O
are	O
of	O
type	O
`	O
int	O
`)	O
.	O

I	O
know	O
one	O
can	O
use	O
`	O
astype	B-API
`	O
to	O
change	O
the	O
type	O
of	O
a	O
column	O
,	O
but	O
using	O
it	O
on	O
the	O
already-created	O
column	O
does	O
not	O
work	O
-	O
the	O
`	O
NaN	O
`	O
values	O
remain	O
as	O
`	O
NaN	O
`	O
values	O
.	O

Is	O
there	O
any	O
way	O
to	O
tell	O
`	O
apply	O
`	O
that	O
I	O
want	O
to	O
preserve	O
the	O
`	O
None	O
`	O
values	O
?	O

Do	O
I	O
need	O
to	O
do	O
something	O
special	O
within	O
the	O
lambda	O
expression	O
or	O
within	O
`	O
my_func	O
`	O
?	O

Your	O
apply	O
function	O
is	O
weird	O
because	O
you	O
don't	O
use	O
`	O
x	O
`	O
,	O
instead	O
you	O
extract	O
the	O
two	O
whole	O
columns	O
of	O
your	O
dataframe	B-API
on	O
each	O
row	O
.	O

Apply	O
time	O
shift	O
on	O
Pandas	O
DataFrame	B-API
from	O
another	O
column	O

How	O
do	O
I	O
use	O
pandas	O
groupby	B-API
function	O
to	O
apply	O
a	O
formula	O
based	O
on	O
the	O
groupby	B-API
value	O

You	O
could	O
also	O
create	O
a	O
special	O
function	O
and	O
pass	O
it	O
to	O
the	O
groupby	B-API
`	O
apply	O
`	O
method	O
:	O
#CODE	O

Writing	O
a	O
named	O
funtion	O
and	O
using	O
`	O
apply	O
`	O
works	O
:	O
#CODE	O

and	O
after	O
that	O
apply	O
#CODE	O

Pandas	O
groupby	B-API
apply	O
performing	O
slow	O

The	O
bottleneck	O
seems	O
to	O
be	O
the	O
apply	O
function	O
,	O
even	O
when	O
I	O
remove	O
the	O
for	O
loop	O
in	O
the	O
function	O
it	O
remains	O
slow	O
(	O
~	O
4.25s	O
per	O
loop	O
)	O
.	O

I	O
am	O
wondering	O
if	O
there	O
is	O
another	O
way	O
to	O
apply	O
the	O
function	O
(	O
without	O
the	O
apply	O
command	O
)	O
.	O

I	O
perform	O
some	O
other	O
procedures	O
on	O
the	O
data	O
in	O
this	O
code	O
using	O
the	O
agg	O
command	O
.	O

This	O
works	O
much	O
faster	O
,	O
but	O
I	O
don't	O
know	O
if	O
its	O
possible	O
to	O
perform	O
this	O
check	O
(	O
full_coverage	O
)	O
using	O
the	O
agg	O
command	O
.	O

and	O
that	O
worked	O
on	O
the	O
masked	O
sample	O
.	O

But	O
since	O
I	O
have	O
to	O
apply	O
several	O
filters	O
keeping	O
the	O
original	O
`	O
H	O
`	O
column	O
for	O
non-filtered	O
values	O
I'm	O
getting	O
confused	O
.	O

If	O
you	O
have	O
a	O
`	O
groupby	B-API
`	O
object	O
,	O
you	O
should	O
use	O
the	O
`	O
apply	O
`	O
,	O
`	O
agg	O
`	O
,	O
`	O
filter	O
`	O
or	O
`	O
transform	O
`	O
methods	O
.	O

In	O
your	O
case	O
`	O
apply	O
`	O
is	O
appropriate	O
.	O

Now	O
,	O
let's	O
`	O
apply	O
`	O
that	O
to	O
each	O
group	O
of	O
your	O
real	O
dataframe	B-API
:	O
#CODE	O

You	O
apply	O
the	O
function	O
`	O
fill_seq	O
`	O
to	O
the	O
H	O
/	O
K	O
sequence	O
columns	O
using	O
the	O
values	O
from	O
H	O
/	O
K	O
sequence	O
as	O
input	O
.	O

You	O
can	O
call	O
`	O
apply	O
`	O
on	O
the	O
df	O
pass	O
`	O
axis=1	O
`	O
to	O
apply	O
row-wise	O
and	O
use	O
the	O
column	O
values	O
to	O
slice	O
the	O
str	O
:	O
#CODE	O

How	O
to	O
apply	O
a	O
function	O
on	O
every	O
row	O
on	O
a	O
dataframe	B-API
?	O

And	O
`	O
ch	O
`	O
and	O
`	O
ck	O
`	O
are	O
float	O
types	O
.	O

Now	O
I	O
want	O
to	O
apply	O
the	O
formula	O
to	O
every	O
row	O
on	O
the	O
dataframe	B-API
and	O
return	O
it	O
as	O
an	O
extra	O
row	O
'	O
Q	O
'	O
.	O

An	O
example	O
(	O
that	O
does	O
not	O
work	O
)	O
would	O
be	O
:	O
#CODE	O

Here	O
you	O
will	O
find	O
arrays	O
and	O
methods	O
that	O
are	O
much	O
faster	O
than	O
built-in	O
list	O
.	O

For	O
example	O
instead	O
of	O
looping	O
trough	O
every	O
element	O
in	O
a	O
numpy	O
array	O
to	O
do	O
some	O
processing	O
you	O
can	O
apply	O
a	O
numpy	O
function	O
directly	O
on	O
the	O
array	O
and	O
get	O
the	O
results	O
in	O
seconds	O
rather	O
than	O
hours	O
.	O
as	O
an	O
example	O
:	O
#CODE	O

the	O
`	O
f	O
`	O
function	O
is	O
more	O
complicated	O
that	O
this	O
one	O
,	O
of	O
course	O
,	O
and	O
I	O
want	O
to	O
apply	O
a	O
sequence	O
of	O
functions	O
to	O
transform	O
the	O
data	O
frame	O
.	O

There	O
are	O
basically	O
string	O
parsers	O
to	O
normalize	O
,	O
transform	O
to	O
unicode	O
,	O
remove	O
characters	O
,	O
split	O
into	O
components	O
,	O
etc	O
,	O
so	O
so	O
far	O
I	O
can	O
t	B-API
see	O
a	O
way	O
to	O
do	O
it	O
without	O
`	O
applymap	B-API
`	O
.	O

Can	O
you	O
give	O
more	O
insight	O
in	O
what	O
you	O
want	O
to	O
apply	O
?	O

(	O
the	O
simple	O
example	O
you	O
give	O
can	O
of	O
course	O
easily	O
be	O
done	O
without	O
`	O
applymap	B-API
`	O
,	O
but	O
maybe	O
your	O
real	O
function	O
as	O
well	O
?	O
)	O

Length	O
of	O
the	O
code	O
.	O

As	O
it	O
stands	O
,	O
one	O
would	O
need	O
to	O
keep	O
adding	O
`	O
&	O
`	O
in	O
order	O
to	O
add	O
more	O
columns	O
.	O

It	O
would	O
be	O
better	O
if	O
it	O
could	O
be	O
wrapped	O
into	O
,	O
say	O
,	O
a	O
list	O
comprehension	O
(	O
or	O
apply	O
function	O
)	O
since	O
each	O
column	O
is	O
independent	O

Python	O
pandas	O
groupby	B-API
object	O
apply	O
method	O
adds	O
index	O

I	O
have	O
this	O
question	O
is	O
an	O
extension	O
after	O
reading	O
the	O
"	O
Python	O
pandas	O
groupby	B-API
object	O
apply	O
method	O
duplicates	O
first	O
group	O
"	O
.	O

Actually	O
,	O
I	O
have	O
data	O
for	O
several	O
days	O
,	O
and	O
interpolate	O
one	O
by	O
one	O
is	O
a	O
dificult	O
option	O
.	O

Maybe	O
using	O
`	O
apply	O
`	O
but	O
I	O
dont	O
know	O
how	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
on	O
the	O
column	O
to	O
generate	O
a	O
boolean	O
mask	O
describing	O
the	O
desired	O
columns	O
,	O
and	O
then	O
filter	O
the	O
DataFrame	B-API
by	O
this	O
mask	O
:	O
#CODE	O

What	O
I've	O
got	O
so	O
far	O
is	O
printing	O
out	O
the	O
correct	O
expanded	O
dataframes	O
for	O
each	O
row	O
,	O
but	O
I	O
don't	O
know	O
how	O
to	O
consolidate	O
the	O
results	O
of	O
apply	O
:	O
#CODE	O

You	O
could	O
,	O
of	O
course	O
,	O
do	O
all	O
this	O
within	O
a	O
function	O
that	O
you	O
apply	O
on	O
a	O
`	O
groupby	B-API
`	O
,	O
but	O
it	O
would	O
be	O
superfluous	O
in	O
this	O
case	O
.	O

python	O
pandas	O
nested	O
loop	O
:	O
to	O
apply	O
a	O
function	O
to	O
each	O
element	O
of	O
e.g.	O
column	O
2	O
involving	O
compounding	O
same	O
elements	O
in	O
previous	O
column	O
1s	O

In	O
fact	O
,	O
it	O
seems	O
to	O
me	O
,	O
that	O
one	O
could	O
apply	O
a	O
similar	O
method	O
to	O
calculations	O
involving	O
n	O
nested	O
loops	O
.	O

As	O
long	O
as	O
one	O
has	O
pre-calculated	O
each	O
of	O
the	O
n	O
loops	O
,	O
and	O
ordered	O
them	O
using	O
sort	O
,	O
one	O
can	O
apply	O
a	O
function	O
to	O
the	O
result	O
by	O
using	O
groupby	B-API
on	O
the	O
nth	O
bin	O
directly	O
.	O

In	O
the	O
problem	O
above	O
,	O
the	O
loop	O
was	O
a	O
2-variable	O
nested	O
loop	O
,	O
with	O
bin	O
being	O
at	O
level	O
1	O
,	O
and	O
port	O
being	O
at	O
level	O
0	O
.	O

This	O
may	O
relate	O
to	O
indexing	O
?	O

I	O
feel	O
like	O
`	O
df.pct_change()	B-API
`	O
would	O
be	O
helpful	O
,	O
but	O
I	O
can't	O
figure	O
out	O
how	O
to	O
apply	O
it	O
in	O
the	O
way	O
I'm	O
trying	O
to	O
describe	O
.	O

or	O
apply	O
the	O
patch	O
in	O
the	O
pandas	O
code	O
(	O
see	O
the	O
link	O
above	O
,	O
it's	O
only	O
a	O
one	O
line	O
change	O
)	O

I	O
have	O
seen	O
here	O
a	O
similar	O
question	O
for	O
scatterplots	O
,	O
but	O
it	O
doesn't	O
seem	O
I	O
can	O
apply	O
the	O
same	O
solution	O
to	O
a	O
time	O
series	O
line	O
chart	O
.	O

Pandas	O
/	O
Scikit	O
-	O
Apply	O
sparse	O
PCA	B-API
while	O
creating	O
feature	O
vectors	O

I	O
am	O
planning	O
to	O
generate	O
a	O
huge	O
sparse	O
matrix	O
of	O
70000	O
rows	O
and	O
150000	O
columns	O
using	O
Pandas	O
get_dummies()	B-API
,	O
however	O
I	O
get	O
a	O
MemoryError	O
.	O

How	O
do	O
I	O
apply	O
PCA	B-API
on	O
this	O
sparse	O
matrix	O
to	O
reduce	O
dimensionality	O
?	O

How	O
can	O
I	O
do	O
this	O
without	O
using	O
groupby	B-API
and	O
apply	O
function	O
?	O

Because	O
I	O
need	O
a	O
good	O
performance	O
in	O
computation	O
.	O

The	O
normal	O
op	O
here	O
is	O
to	O
`	O
groupby	B-API
`	O
on	O
'	O
item	O
'	O
and	O
call	O
`	O
sum	O
`	O
on	O
the	O
'	O
grade	O
'	O
column	O
no	O
need	O
to	O
call	O
`	O
apply	O
`	O
here	O

Note	O
that	O
if	O
you	O
have	O
to	O
perform	O
`	O
urljoin	O
`	O
then	O
using	O
`	O
map	O
`	O
or	O
`	O
apply	O
`	O
would	O
be	O
fine	O
here	O

For	O
pure	O
string	O
concatenation	O
,	O
this	O
will	O
be	O
vectorised	O
,	O
using	O
`	O
map	O
`	O
and	O
`	O
apply	O
`	O
this	O
is	O
just	O
a	O
`	O
for	O
`	O
loop	O
so	O
this	O
approach	O
will	O
be	O
much	O
faster	O
for	O
large	O
datasets	O

In	O
`	O
R	O
`	O
,	O
can	O
use	O
`	O
na.aggregate	O
/	O
data.table	O
`	O
to	O
replace	O
the	O
`	O
NA	O
`	O
by	O
`	O
mean	O
`	O
value	O
of	O
the	O
group	O
.	O

We	O
convert	O
the	O
'	O
data.frame	O
'	O
to	O
'	O
data.table	O
'	O
(	O
`	O
setDT	O
(	O
df	O
)`)	O
,	O
grouped	O
by	O
'	O
A	O
'	O
,	O
apply	O
the	O
`	O
na.aggregate	O
`	O
on	O
'	O
B	O
'	O
.	O

#CODE	O

However	O
I	O
am	O
wondering	O
if	O
there	O
is	O
a	O
way	O
I	O
can	O
write	O
my	O
function	O
and	O
apply	O
it	O
to	O
my	O
grouped	O
object	O
such	O
that	O
I	O
can	O
specify	O
when	O
applying	O
it	O
,	O
which	O
column	O
I	O
want	O
to	O
calculate	O
for	O
(	O
or	O
both	O
)	O
.	O

Rather	O
than	O
have	O
'	O
var1	O
'	O
written	O
into	O
my	O
function	O
,	O
I'd	O
like	O
to	O
be	O
able	O
to	O
specify	O
when	O
applying	O
the	O
function	O
.	O

You	O
can	O
apply	O
and	O
return	O
both	O
averages	O
:	O
#CODE	O

Pandas	O
dataframe	B-API
:	O
how	O
to	O
apply	O
describe()	B-API
to	O
each	O
group	O
and	O
add	O
to	O
new	O
columns	O
?	O

Probably	O
a	O
convoluted	O
way	O
of	O
doing	O
it	O
,	O
but	O
You	O
could	O
`	O
groupby	B-API
`	O
ID1	O
and	O
ID2	O
;	O
then	O
*	O
iterate	O
over	O
the	O
groups	O
*	O
zipping	O
(	O
use	O
`	O
zip	O
`)	O
`	O
x	O
`	O
and	O
`	O
y	O
`	O
into	O
a	O
`	O
xy	O
`	O
column	O
where	O
values	O
are	O
points	O
(	O
x	O
,	O
y	O
)	O
.	O

Then	O
,	O
shifting	O
this	O
`	O
xy	O
`	O
column	O
by	O
1	O
(	O
use	O
`	O
shift	O
`)	O
,	O
get	O
a	O
new	O
column	O
`	O
xyshift	O
`	O
.	O

Then	O
apply	O
a	O
difference	O
function	O
in	O
the	O
row-axis	O
in	O
this	O
`	O
xyshift	O
`	O
column	O
;	O
and	O
finally	O
merge	O
it	O
iteratively	O
into	O
your	O
dataframe	B-API
or	O
compose	O
a	O
new	O
one	O

Here's	O
a	O
solution	O
with	O
apply	O
#CODE	O

Use	O
the	O
vectorised	O
`	O
str.split	B-API
`	O
this	O
will	O
be	O
much	O
faster	O
than	O
using	O
`	O
apply	O
`	O
on	O
a	O
large	O
dataset	O
:	O
#CODE	O

To	O
extract	O
just	O
the	O
month-year	O
piece	O
from	O
the	O
resulting	O
list	O
created	O
by	O
the	O
split	O
,	O
apply	O
`	O
map	O
`	O
and	O
a	O
lambda	O
to	O
the	O
result	O
:	O
#CODE	O

Or	O
as	O
@USER	O
suggests	O
apply	O
`	O
str	O
`	O
again	O
instead	O
of	O
the	O
map-lambda	O
:	O
#CODE	O

More	O
generally	O
,	O
it	O
is	O
a	O
case	O
of	O
`	O
rolling	O
`	O
apply	O
,	O
`	O
min_periods	O
`	O
control	O
the	O
minimal	O
window	O
that	O
will	O
be	O
considered	O
as	O
valid	O
.	O

Skipping	O
it	O
in	O
this	O
case	O
will	O
result	O
in	O
having	O
`	O
nan	O
`	O
for	O
the	O
1st	O
cell	O
:	O
#CODE	O

When	O
you	O
do	O
the	O
apply	O
,	O
it's	O
across	O
each	O
row	O
(	O
which	O
is	O
a	O
Series	O
)	O
.	O

I'm	O
guessing	O
the	O
slow	O
part	O
is	O
the	O
apply	O
(	O
rather	O
than	O
the	O
split	O
,	O
or	O
the	O
stack	O
)	O
?	O

@USER	O
how	O
would	O
you	O
apply	O
the	O
answer	O
in	O
your	O
link	O
to	O
my	O
question	O
?	O

This	O
is	O
my	O
first	O
question	O
,	O
I	O
wouldn't	O
mind	O
if	O
you	O
undid	O
your	O
down	O
vote	O
.	O

You	O
can	O
do	O
that	O
but	O
to	O
me	O
this	O
defeats	O
the	O
whole	O
point	O
of	O
using	O
pandas	O
which	O
provides	O
vectorised	O
methods	O
,	O
if	O
you're	O
going	O
to	O
do	O
that	O
then	O
use	O
`	O
apply	O
`	O
to	O
process	O
an	O
element	O

Tried	O
so	O
far	O
:	O
Re-indexing	O
to	O
Date_time	O
and	O
df2.update	O
(	O
df	O
)	O
with	O
variations	O
,	O
multiple	O
merging	O
/	O
join	O
/	O
concat	O
variations	O
,	O
an	O
adapted	O
definition	O
(	O
below	O
)	O
with	O
apply	O
...	O
and	O
now	O
wondering	O
if	O
I	O
need	O
to	O
use	O
iterrows	B-API
(	O
see	O
below	O
?	O
)	O
.	O

How	O
to	O
apply	O
a	O
function	O
to	O
rows	O
of	O
two	O
pandas	O
DataFrame	B-API

There	O
are	O
two	O
pandas	O
DataFrame	B-API
,	O
say	O
`	O
dfx	O
,	O
dfy	O
`	O
of	O
the	O
same	O
shape	O
and	O
exactly	O
the	O
same	O
column	O
and	O
row	O
indices	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
the	O
corresponding	O
rows	O
of	O
these	O
two	O
DataFrame	B-API
.	O

By	O
the	O
following	O
code	O
,	O
I	O
make	O
a	O
grouped	O
two-level	O
indexed	O
DataFrame	B-API
.	O

Then	O
I	O
do	O
not	O
know	O
how	O
to	O
apply	O
`	O
agg	O
`	O
in	O
the	O
proper	O
way	O
.	O

#CODE	O

However	O
,	O
it	O
occured	O
to	O
me	O
this	O
may	O
not	O
be	O
always	O
correct	O
,	O
since	O
there	O
is	O
no	O
guarantee	O
data	O
was	O
collected	O
everyday	O
.	O

Instead	O
,	O
I	O
tried	O
counting	O
unique	O
days	O
in	O
the	O
timestamp	O
series	O
using	O
`	O
map	O
`	O
and	O
`	O
apply	O
`	O
,	O
and	O
both	O
take	O
a	O
considerable	O
amount	O
of	O
time	O
for	O
3,000,000	O
rows	O
:	O
#CODE	O

@USER	O
do	O
you	O
mean	O
doing	O
the	O
apply	O
?	O

This	O
is	O
very	O
surprising	O
,	O
mainly	O
because	O
the	O
accepted	O
answer	O
is	O
O	O
(	O
n^2	O
)	O
.	O

I	O
can	O
see	O
the	O
apply	O
part	O
being	O
slow	O
,	O
but	O
as	O
I	O
say	O
I	O
don't	O
think	O
you	O
really	O
need	O
that	O
part	O
.	O

you've	O
got	O
a	O
couple	O
of	O
problems	O
here	O
.	O
the	O
first	O
involves	O
repopulating	O
your	O
dataframe	B-API
from	O
a	O
subset	O
.	O
the	O
other	O
,	O
more	O
computational	O
problem	O
involved	O
not	O
`	O
for	O
`	O
loops	O
,	O
but	O
`	O
groupby	B-API
`	O
and	O
`	O
transform	O
`	O
(	O
or	O
`	O
apply	O
`	O
?	O
)	O
operations	O
.	O

I	O
recommend	O
splitting	O
this	O
up	O
into	O
two	O
separate	O
questions	O
.	O

Consider	O
using	O
groupby	B-API
apply	O
functions	O
to	O
dataset	O
.	O

The	O
first	O
function	O
averages	O
the	O
values	O
only	O
for	O
'	O
Print	O
Buffer	O
'	O
using	O
`	O
mean()	B-API
`	O
,	O
leaving	O
the	O
others	O
in	O
Block	O
zero	O
.	O

And	O
then	O
the	O
second	O
function	O
maximizes	O
the	O
`	O
meanvalue	O
`	O
.	O

Finally	O
,	O
simply	O
create	O
`	O
newvalue	O
`	O
as	O
arithmetic	O
difference	O
:	O
#CODE	O

UPDATE	O
:	O
Here	O
is	O
a	O
photo	O
to	O
illustrate	O
what	O
I	O
keep	O
geting	O
!	O

Box	O
6	O
is	O
the	O
implementation	O
of	O
apply	O
,	O
and	O
box	O
7	O
is	O
what	O
my	O
data	O
looks	O
like	O
.	O

You	O
could	O
use	O
apply	O
method	O
for	O
pd.Series	B-API
of	O
dataframe	B-API

So	O
you	O
could	O
convert	O
your	O
`	O
df.columns	O
`	O
to	O
`	O
pd.Series	B-API
`	O
with	O
`	O
pd.Series	B-API
(	O
df.columns	O
)`	O
and	O
then	O
use	O
apply	O
method	O
.	O

Look	O
to	O
the	O
last	O
edit	O

Python	O
Pandas	O
Dataframe	B-API
Columns	O
of	O
Lists	O
,	O
Get	O
Intersection	O
And	O
Apply	O
Function	O
To	O
Another	O
Column	O

I'm	O
not	O
used	O
to	O
working	O
with	O
`	O
lists	O
`	O
in	O
columns	O
of	O
Pandas	O
and	O
don't	O
know	O
how	O
to	O
get	O
the	O
intersection	O
of	O
`	O
lists	O
`	O
from	O
two	O
columns	O
in	O
a	O
`	O
dataframe	B-API
`	O
,	O
then	O
get	O
the	O
index	O
of	O
where	O
the	O
words	O
appear	O
,	O
then	O
apply	O
plus	O
signs	O
to	O
the	O
front	O
of	O
each	O
found	O
index	O
.	O

Or	O
maybe	O
easier	O
would	O
be	O
a	O
string	O
replacement	O
on	O
`	O
df	O
[	O
'	O
Keyword	O
']`	O
using	O
the	O
words	O
from	O
`	O
StemmedAG	O
`	O
?	O

How	O
to	O
do	O
this	O
?	O

Do	O
we	O
have	O
any	O
function	O
?	O

I	O
tried	O
with	O
apply	O
and	O
groupby	B-API
function	O
,	O
did	O
not	O
work	O
.	O

Please	O
let	O
me	O
know	O
if	O
more	O
information	O
is	O
required	O
for	O
this	O
.	O

The	O
thing	O
is	O
,	O
I	O
know	O
that	O
I	O
can	O
set	O
it	O
to	O
the	O
Boolean	O
false	O
using	O
str.contains()	B-API
.	O

But	O
I	O
don't	O
know	O
what	O
the	O
proper	O
way	O
to	O
apply	O
str.contains()	B-API
to	O
pd.read_csv	B-API
'	O
s	O
na_values	O
.	O

#CODE	O

The	O
first	O
step	O
is	O
to	O
read	O
the	O
data	O
into	O
a	O
Pandas	O
DataFrame	B-API
.	O

If	O
the	O
format	O
of	O
the	O
dataframe	B-API
is	O
consistent	O
with	O
the	O
example	O
you	O
gave	O
above	O
,	O
then	O
you	O
can	O
apply	O
the	O
function	O
to	O
the	O
groupby	B-API
object	O
.	O

It	O
seems	O
some	O
error	O
(	O
s	O
)	O
come	O
out	O
of	O
the	O
reading	O
procedure	O
.	O

Another	O
method	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

I	O
am	O
able	O
to	O
add	O
a	O
new	O
column	O
in	O
Panda	O
by	O
defining	O
user	O
function	O
and	O
then	O
using	O
apply	O
.	O

However	O
,	O
I	O
want	O
to	O
do	O
this	O
using	O
lambda	O
;	O
is	O
there	O
a	O
way	O
around	O
?	O

Next	O
solution	O
is	O
with	O
function	O
apply	O
with	O
parameter	O
`	O
axis=1	O
`	O
:	O

axis	O
=	O
1	O
or	O
columns	O
:	O
apply	O
function	O
to	O
each	O
row	O

This	O
avoids	O
the	O
apply	O
so	O
will	O
be	O
more	O
efficient	O
.	O

Thanks	O
Andy	O
,	O
I	O
will	O
post	O
a	O
new	O
question	O
.	O

I	O
know	O
there	O
is	O
a	O
group	O
by	O
rank	O
function	O
but	O
the	O
challenge	O
so	O
far	O
is	O
to	O
combine	O
that	O
with	O
logical	O
operator	O
of	O
a	O
different	O
column	O
and	O
then	O
apply	O
to	O
all	O
rows	O
.	O

I	O
really	O
appreciate	O
your	O
help	O
.	O

call	O
`	O
apply	O
`	O
and	O
pass	O
func	O
`	O
len	O
`	O
:	O
#CODE	O

You	O
can	O
try	O
`	O
apply	O
(	O
pandas.Series.interpolate	B-API
)`	O
instead	O
of	O
`	O
fillna	B-API
`	O
.	O

@USER	O
first	O
transpose	O
your	O
dataframe	B-API
,	O
then	O
apply	O
my	O
solution	O
:	O
#URL	O

Python	O
pandas	O
groupby	B-API
transform	O
/	O
apply	O
function	O
operating	O
on	O
multiple	O
columns	O

Trying	O
to	O
use	O
apply-split-combine	O
pandas	O
transform	O
.	O

With	O
the	O
twist	O
that	O
the	O
apply	O
function	O
needs	O
to	O
operate	O
on	O
multiple	O
columns	O
.	O

It	O
seems	O
I	O
can't	O
get	O
it	O
to	O
work	O
using	O
`	O
pd.transform	O
`	O
and	O
have	O
to	O
go	O
indirect	O
via	O
`	O
pd.apply	O
`	O
.	O

There	O
a	O
way	O
to	O
do	O
#CODE	O

I	O
get	O
a	O
factor	O
of	O
~5	O
speed	O
improvement	O
on	O
a	O
simple	O
N=	O
10,000	O
test	O
case	O
by	O
using	O
a	O
pandas	O
groupby	B-API
/	O
apply	O
and	O
writing	O
the	O
csv	O
from	O
the	O
resulting	O
dataframe	B-API
:	O
#CODE	O

You	O
can	O
use	O
apply	O
with	O
`	O
to_json	B-API
`	O
:	O
#CODE	O

To	O
apply	O
functions	O
to	O
this	O
object	O
,	O
you	O
can	O
do	O
a	O
few	O
things	O
:	O

If	O
you	O
want	O
to	O
pass	O
a	O
custom	O
function	O
,	O
you	O
can	O
call	O
`	O
grouped.apply	O
(	O
func	O
)`	O
to	O
apply	O
that	O
function	O
to	O
each	O
group	O
.	O

The	O
last	O
question	O
about	O
the	O
average	O
over	O
a	O
range	O
of	O
columns	O
relies	O
on	O
pandas	O
understanding	O
of	O
how	O
it	O
should	O
apply	O
functions	O
.	O

If	O
you	O
take	O
a	O
dataframe	B-API
and	O
call	O
`	O
dataframe.mean()	B-API
`	O
,	O
pandas	O
returns	O
the	O
mean	O
of	O
each	O
column	O
.	O

There's	O
a	O
default	O
argument	O
in	O
`	O
mean()	B-API
`	O
that	O
is	O
`	O
axis=0	O
`	O
.	O

If	O
you	O
change	O
that	O
to	O
`	O
axis=1	O
`	O
,	O
pandas	O
will	O
instead	O
take	O
the	O
mean	O
of	O
each	O
row	O
.	O

However	O
,	O
when	O
I	O
apply	O
this	O
in	O
IPython	O
,	O
it	O
gives	O
me	O
this	O
error	O
:	O
#CODE	O

This	O
is	O
because	O
you	O
are	O
operating	O
a	O
element	O
`	O
x	O
`	O
against	O
series	O
`	O
va2	O
[	O
'	O
pct_vote	O
']`	O
.	O

What	O
you	O
need	O
is	O
operation	O
on	O
`	O
va2	O
[	O
'	O
winner	O
']`	O
and	O
`	O
va2	O
[	O
'	O
pct_vote	O
']`	O
element	O
wise	O
.	O

You	O
could	O
use	O
`	O
apply	O
`	O
to	O
achieve	O
that	O
.	O

You	O
could	O
use	O
Pandas	O
`	O
apply	O
`	O
function	O
,	O
which	O
allows	O
you	O
to	O
traverse	O
rows	O
or	O
columns	O
and	O
apply	O
your	O
own	O
function	O
to	O
them	O
.	O

and	O
apply	O
it	O
column-wise	O
:	O
#CODE	O

We	O
can	O
group	O
by	O
the	O
User	O
Id	O
,	O
and	O
then	O
for	O
each	O
group	O
apply	O
a	O
function	O
to	O
evaluate	O
the	O
difference	O
between	O
the	O
rows	O
.	O

Now	O
define	O
a	O
function	O
that	O
will	O
operate	O
on	O
each	O
group	O
,	O
and	O
apply	O
it	O
.	O

Apply	O
a	O
numeric	O
rank	O
column	O
basis	O
the	O
datetime	O

You	O
can	O
call	O
`	O
apply	O
`	O
and	O
convert	O
your	O
dict	O
values	O
into	O
a	O
set	O
can	O
convert	O
the	O
`	O
intersection	O
`	O
to	O
a	O
list	O
:	O
#CODE	O

Running	O
to_numeric	B-API
via	O
apply	O
on	O
the	O
dataframe	B-API
iloc	B-API
selection	O
,	O
ie	O
#CODE	O

So	O
your	O
approach	O
of	O
using	O
`	O
apply	O
`	O
is	O
the	O
correct	O
one	O
if	O
you	O
want	O
to	O
use	O
this	O
functions	O
on	O
several	O
columns	O
at	O
the	O
same	O
time	O
.	O

You	O
can	O
apply	O
difference	O
of	O
sets	O
converted	O
from	O
lists	O
of	O
columns	O
and	O
then	O
convert	O
to	O
list	O
.	O

You	O
have	O
to	O
use	O
`	O
axis=1	O
`	O
,	O
because	O
apply	O
function	O
to	O
each	O
row	O
.	O

#CODE	O

More	O
efficient	O
way	O
to	O
import	O
and	O
apply	O
a	O
function	O
to	O
text	O
data	O
in	O
a	O
Pandas	O
Dataframe	B-API

The	O
code	O
runs	O
fine	O
when	O
parsing	O
a	O
short	O
paragraph	O
,	O
but	O
when	O
working	O
on	O
larger	O
text	O
files	O
the	O
code	O
takes	O
a	O
lot	O
longer	O
.	O

I	O
know	O
the	O
key	O
to	O
speed	O
when	O
working	O
with	O
Dataframes	O
is	O
to	O
avoid	O
for-loops	O
and	O
to	O
apply	O
functions	O
to	O
the	O
whole	O
data	O
set	O
.	O

My	O
question	O
is	O
,	O
is	O
there	O
a	O
quicker	O
way	O
to	O
apply	O
a	O
function	O
to	O
a	O
string	O
when	O
reading	O
in	O
a	O
text	O
file	O
,	O
other	O
than	O
line	O
by	O
line	O
and	O
appending	O
it	O
to	O
a	O
dataframe	B-API
?	O

Right	O
.	O

The	O
problem	O
is	O
the	O
way	O
you	O
save	O
it	O
.	O

You	O
apply	O
jsonification	O
to	O
it	O
twice	O
.	O

You	O
should	O
do	O
something	O
like	O
`	O
with	O
open	O
(	O
myoutfilename	O
,	O
'	O
w	O
')	O
as	O
f	O
:\	O
n	O
f.write	O
(	O
dataframe.to_json()	B-API
)`	O

I	O
am	O
trying	O
to	O
apply	O
a	O
function	O
to	O
each	O
row	O
in	O
a	O
dataframe	B-API
.	O

The	O
problem	O
is	O
,	O
the	O
function	O
requires	O
output	O
from	O
the	O
previous	O
row	O
as	O
an	O
input	O
.	O

It	O
looks	O
like	O
you	O
want	O
to	O
apply	O
a	O
recursive	O
function	O
.	O

In	O
that	O
case	O
,	O
.rolling_apply	B-API
won't	O
work	O
.	O

One	O
way	O
would	O
be	O
to	O
use	O
the	O
series	O
values	O
as	O
a	O
list	O
or	O
numpy	O
array	O
.	O

Then	O
loop	O
through	O
the	O
list	O
to	O
use	O
the	O
recursive	O
function	O
.	O

Try	O
grouping	O
certain	O
columns	O
and	O
then	O
apply	O
sum()	B-API
like	O
this	O
:	O
#CODE	O

`	O
Series.str.replace	B-API
`	O
Cythonizes	O
the	O
calls	O
to	O
`	O
re.sub	O
`	O
(	O
which	O
makes	O
it	O
faster	O
than	O
what	O
you	O
could	O
achieve	O
using	O
`	O
apply	O
`	O
since	O
`	O
apply	O
`	O
uses	O
a	O
Python	O
loop	O
.	O
)	O

try	O
using	O
apply	O
function	O
.	O

#CODE	O

Pandas	O
apply	O
but	O
only	O
for	O
rows	O
where	O
a	O
condition	O
is	O
met	O

I	O
have	O
a	O
dataframe	B-API
that	O
I	O
created	O
from	O
a	O
text	O
file	O
.	O

Columns	O
B-F	O
should	O
apply	O
to	O
all	O
null	O
fields	O
below	O
them	O
,	O
then	O
once	O
all	O
nulls	O
are	O
filled	O
the	O
next	O
set	O
of	O
periods	O
should	O
be	O
filled	O
by	O
the	O
next	O
values	O
populated	O
in	O
B-F	O
.	O

How	O
would	O
I	O
go	O
about	O
accomplishing	O
this	O
?	O

But	O
what	O
is	O
the	O
common	O
approach	O
to	O
this	O
problem	O
.	O

Is	O
this	O
where	O
people	O
apply	O
normalization	O
?	O

It	O
would	O
be	O
great	O
if	O
someone	O
could	O
explain	O
how	O
to	O
apply	O
normalization	O
in	O
such	O
a	O
situation	O
.	O

Group	O
series	O
using	O
mapper	O
(	O
dict	O
or	O
key	O
function	O
,	O
apply	O
given	O
function	O
to	O
group	O
,	O
return	O
result	O
as	O
series	O
)	O
or	O
by	O
a	O
series	O
of	O
columns	O

As	O
a	O
workaround	O
for	O
now	O
,	O
you	O
can	O
easily	O
use	O
the	O
`	O
nunique	B-API
`	O
Series	O
method	O
through	O
`	O
apply	O
`	O
instead	O
of	O
calling	O
it	O
directly	O
on	O
the	O
groupby	B-API
object	O
:	O
#CODE	O

OK	O
I	O
missed	O
the	O
`	O
NaN	O
values	O
are	O
maintained	O
`	O
part	O
.	O

This	O
is	O
not	O
pretty	O
and	O
it	O
is	O
still	O
slow	O
(	O
but	O
faster	O
than	O
apply	O
):	O

But	O
that	O
is	O
different	O
from	O
what	O
you	O
will	O
get	O
using	O
the	O
apply	O
method	O
.	O

Here	O
your	O
mask	O
has	O
float	O
dtype	B-API
containing	O
NaN	O
,	O
0.0	O
and	O
1.0	O
.	O

In	O
the	O
apply	O
solution	O
you	O
get	O
`	O
object	O
`	O
dtype	B-API
with	O
NaN	O
,	O
False	O
,	O
and	O
True	O
.	O

Neither	O
are	O
OK	O
to	O
be	O
used	O
as	O
a	O
mask	O
because	O
you	O
might	O
not	O
get	O
what	O
you	O
want	O
.	O

IEEE	O
says	O
that	O
any	O
NaN	O
comparison	O
must	O
yield	O
False	O
and	O
the	O
apply	O
method	O
is	O
implicitly	O
violates	O
that	O
by	O
returning	O
NaN	O
!	O

but	O
after	O
that	O
one	O
can	O
apply	O
`	O
.reset_index	B-API
(	O
drop=True	O
)`	O
(	O
mind	O
drop=True	O
here	O
)	O
and	O
that	O
returns	O
#CODE	O

Just	O
the	O
usual	O
apply	O
warning	O
,	O
this	O
can	O
be	O
slow	O
(	O
that's	O
why	O
we	O
special	O
cased	O
groupby	B-API
head	O
to	O
use	O
cumcount	O
under	O
the	O
hood	O
,	O
at	O
least	O
originally	O
not	O
100%	O
sure	O
if	O
it	O
still	O
does	O
)	O
.	O

:)	O

as_type	O
has	O
casting	O
rules	O
,	O
none	O
of	O
which	O
seems	O
to	O
apply	O
(	O
you'd	O
think	O
it'd	O
be	O
casting=	O
'	O
safe	O
'	O
#URL	O
)	O

You	O
group	O
on	O
`	O
user.id	O
`	O
,	O
and	O
then	O
use	O
`	O
agg	O
`	O
to	O
apply	O
a	O
custom	O
aggregation	O
function	O
to	O
each	O
column	O
.	O

In	O
this	O
case	O
,	O
we	O
use	O
a	O
`	O
lambda	O
`	O
expression	O
and	O
then	O
use	O
`	O
iloc	B-API
`	O
to	O
take	O
the	O
last	O
member	O
of	O
each	O
group	O
.	O

We	O
then	O
use	O
`	O
count	O
`	O
on	O
the	O
text	O
column	O
.	O

#CODE	O

In	O
the	O
current	O
implementation	O
apply	O
calls	O
func	O
twice	O
on	O
the	O
first	O
group	O
to	O
decide	O
whether	O
it	O
can	O
take	O
a	O
fast	O
or	O
slow	O
code	O
path	O
.	O

This	O
can	O
lead	O
to	O
unexpected	O
behavior	O
if	O
func	O
has	O
side-effects	O
,	O
as	O
they	O
will	O
take	O
effect	O
twice	O
for	O
the	O
first	O
group	O
.	O

Pandas	O
Apply	O
Function	O
with	O
Multiple	O
**	O
Kwarg	O
Arguments	O

If	O
I	O
understand	O
your	O
question	O
,	O
it	O
seems	O
to	O
me	O
that	O
the	O
easiest	O
solution	O
would	O
be	O
to	O
pick	O
the	O
columns	O
from	O
your	O
dataframe	B-API
first	O
,	O
then	O
apply	O
a	O
function	O
that	O
concatenates	O
all	O
columns	O
.	O

This	O
is	O
just	O
as	O
dynamic	O
,	O
but	O
a	O
lot	O
cleaner	O
,	O
in	O
my	O
opinion	O
.	O

Probably	O
not	O
ideal	O
,	O
but	O
this	O
can	O
be	O
done	O
using	O
`	O
groupby	B-API
`	O
and	O
apply	O
a	O
function	O
which	O
returns	O
the	O
expanded	O
DataFrame	B-API
for	O
each	O
row	O
(	O
here	O
the	O
time	O
difference	O
is	O
assumed	O
to	O
be	O
fixed	O
at	O
2.0	O
):	O
#CODE	O

So	O
you	O
could	O
use	O
apply	O
and	O
pd.to_numeric	B-API
methods	O
:	O
#CODE	O

Your	O
solution	O
is	O
so	O
elegant	O
,	O
it	O
stimulates	O
me	O
to	O
learn	O
deeper	O
in	O
groupby	B-API
and	O
apply	O
methods	O
.	O

here	O
`	O
apply	O
`	O
will	O
call	O
`	O
nunique	B-API
`	O
on	O
each	O
column	O

Apply	O
a	O
value	O
to	O
max	O
values	O
in	O
a	O
groupby	B-API

The	O
idea	O
is	O
to	O
write	O
an	O
anonymous	O
function	O
that	O
operates	O
on	O
each	O
of	O
your	O
groups	O
and	O
feed	O
this	O
to	O
your	O
groupby	B-API
using	O
`	O
apply	O
`	O
:	O
#CODE	O

Assuming	O
that	O
your	O
'	O
Time	O
'	O
column	O
is	O
already	O
a	O
`	O
datetime64	O
`	O
then	O
you	O
want	O
to	O
`	O
groupby	B-API
`	O
on	O
'	O
ID	O
'	O
column	O
and	O
then	O
call	O
`	O
transform	O
`	O
to	O
apply	O
a	O
lambda	O
to	O
create	O
a	O
series	O
with	O
an	O
index	O
aligned	O
with	O
your	O
original	O
df	O
:	O
#CODE	O

apply	O
a	O
function	O
to	O
a	O
dataframe	B-API
column	O
(	O
datetime.date	O
)	O

I'm	O
trying	O
to	O
apply	O
this	O
formula	O
on	O
a	O
dataframe	B-API
column	O
'	O
Days	O
'	O
(	O
datetime.date	O
type	O
):	O
#CODE	O

function	O
won't	O
apply	O
to	O
pandas	O
data	O
frame	O
,	O
getting	O
syntax	O
error	O

I'm	O
trying	O
to	O
apply	O
this	O
function	O
to	O
a	O
pandas	O
data	O
frame	O
in	O
order	O
to	O
see	O
if	O
a	O
taxi	O
pickup	O
or	O
dropoff	O
time	O
falls	O
within	O
the	O
range	O
that	O
I	O
created	O
using	O
the	O
arrivemin	O
,	O
arrive	O
max	O
variable	O
below	O
.	O

Let's	O
say	O
forecast	O
is	O
the	O
function	O
I	O
have	O
created	O
that	O
I	O
want	O
to	O
apply	O
:	O
#CODE	O

But	O
here	O
we	O
are	O
where	O
my	O
problem	O
is	O
...	O

How	O
can	O
I	O
apply	O
this	O
function	O
to	O
the	O
dataframes	O
?	O

I	O
have	O
tried	O
the	O
apply	O
function	O
as	O
follows	O
:	O
#CODE	O

The	O
`	O
apply	O
`	O
function	O
takes	O
in	O
a	O
function	O
and	O
its	O
args	O
.	O

The	O
documentation	O
is	O
here	O
.	O

How	O
do	O
I	O
apply	O
datetime.date()	O
and	O
datetime.time()	O
to	O
the	O
whole	O
series	O

Whether	O
the	O
speed	O
of	O
this	O
operation	O
is	O
important	O
is	O
unknown	O
--	O
it	O
probably	O
isn't	O
at	O
all	O
.	O

It's	O
certainly	O
the	O
nice	O
,	O
normal	O
,	O
readable	O
thing	O
to	O
use	O
serieswise	O
operations	O
rather	O
than	O
apply	O
in	O
these	O
sorts	O
of	O
cases	O
,	O
though	O
.	O

So	O
is	O
the	O
issue	O
that	O
I'm	O
creating	O
lists	O
in	O
my	O
dataframe	B-API
or	O
that	O
I'm	O
applying	O
a	O
function	O
to	O
adjacent	O
rows	O
?	O

I	O
just	O
used	O
the	O
list	O
function	O
arbitrarily	O
in	O
this	O
example	O
and	O
am	O
more	O
interested	O
generally	O
in	O
how	O
to	O
apply	O
a	O
function	O
to	O
adjacent	O
rows	O
.	O

You	O
can	O
write	O
your	O
own	O
function	O
that	O
accepts	O
a	O
subdataframe	O
in	O
the	O
groupby	B-API
...	O
what	O
function	O
do	O
you	O
want	O
to	O
apply	O
?	O

Or	O
is	O
the	O
question	O
how	O
to	O
groupby	B-API
adjacency	O
?	O

I've	O
done	O
some	O
debugging	O
and	O
everytime	O
I	O
get	O
this	O
error	O
is	O
when	O
apply	O
duplicates	O
the	O
first	O
group	O
.	O

So	O
are	O
there	O
any	O
better	O
ways	O
to	O
do	O
it	O
without	O
using	O
apply	O
?	O

Consider	O
simply	O
creating	O
an	O
absolute	O
value	O
column	O
through	O
a	O
defined	O
function	O
,	O
apply	O
the	O
function	O
on	O
a	O
groupby	B-API
,	O
and	O
then	O
sorting	O
item	O
ascending	O
and	O
absolute	O
value	O
descending	O
.	O

Finally	O
,	O
filter	O
out	O
the	O
newly	O
created	O
,	O
unneeded	O
column	O
:	O
#CODE	O

Actually	O
,	O
when	O
i	O
apply	O
it	O
to	O
some	O
dataFrame	B-API
where	O
some	O
entries	O
are	O
nan	O
,	O
and	O
some	O
with	O
unequal	O
length	O
,	O
I	O
have	O
this	O
error	O
:	O
Unalignable	O
boolean	O
Series	O
key	O
provided	O

It's	O
not	O
really	O
a	O
bug	O
,	O
and	O
it's	O
just	O
when	O
you	O
use	O
`	O
apply	O
`	O
.	O

Did	O
you	O
read	O
the	O
documentation	O
referenced	O
in	O
the	O
github	O
function	O
?	O

Can	O
you	O
make	O
a	O
more	O
demonstrative	O
example	O
?	O

You're	O
not	O
really	O
even	O
using	O
the	O
data	O
frame	O
on	O
which	O
you're	O
calling	O
`	O
apply	O
`	O
other	O
than	O
the	O
needless	O
print	O
statement	O
.	O

Seems	O
like	O
omitted	O
that	O
would	O
provide	O
the	O
desired	O
results	O
.	O

I	O
can	O
imagine	O
a	O
use	O
case	O
would	O
be	O
:	O
generating	O
a	O
column	O
representing	O
a	O
state	O
,	O
whose	O
value	O
changes	O
according	O
to	O
both	O
the	O
previous	O
state	O
and	O
the	O
other	O
current	O
row	O
values	O
.	O

This	O
is	O
typically	O
a	O
case	O
the	O
Pandas	O
doc	O
warns	O
about	O
when	O
using	O
the	O
apply	O
method	O
(	O
"	O
side-effect	O
")	O
...	O

`	O
apply	O
`	O
works	O
fine	O
for	O
that	O
.	O

I	O
think	O
you're	O
missing	O
the	O
fundamentals	O
of	O
apply	O
,	O
when	O
passed	O
the	O
Series	O
`	O
clasif	O
`	O
,	O
your	O
function	O
should	O
do	O
something	O
with	O
`	O
clasif	O
`	O
(	O
at	O
the	O
moment	O
,	O
the	O
function	O
body	O
makes	O
no	O
mention	O
of	O
it	O
)	O
.	O

You	O
have	O
to	O
pass	O
the	O
function	O
to	O
`	O
apply	O
`	O
.	O

#CODE	O

for	O
example	O
,	O
i'm	O
looping	O
through	O
a	O
dataset	O
.	O
after	O
the	O
first	O
loop	O
,	O
i	O
get	O
a	O
subset	O
of	O
my	O
dataframe	B-API
(	O
rows	O
1-10	O
for	O
example	O
)	O
.	O
for	O
the	O
next	O
loop	O
,	O
i	O
want	O
it	O
to	O
start	O
iterating	O
on	O
`	O
index	O
=	O
11	O
`	O
,	O
and	O
then	O
apply	O
whatever	O
alg	O
i	O
have	O
.	O
the	O
thing	O
is	O
,	O
i	O
do	O
it	O
by	O
truncating	O
the	O
dataframe	B-API
.	O

so	O
if	O
the	O
last	O
item	O
in	O
the	O
previous	O
run	O
was	O
at	O
`	O
index=10	O
`	O
i	O
truncate	O
the	O
dataframe	B-API
to	O
`	O
df	O
=	O
df	O
[	O
11	O
:]	O
`	O

I	O
am	O
trying	O
to	O
iterate	O
over	O
groups	O
(	O
produced	O
by	O
group.by	O
in	O
Pandas	O
)	O
in	O
order	O
to	O
apply	O
a	O
function	O
(	O
create	O
a	O
chart	O
in	O
MatPlotLib	O
)	O
and	O
get	O
a	O
result	O
for	O
each	O
group	O
in	O
the	O
DataFrame	B-API
.	O

I	O
thought	O
to	O
do	O
something	O
like	O
this	O
,	O
but	O
I	O
know	O
there's	O
a	O
better	O
/	O
functional	O
way	O
:	O
#CODE	O

The	O
result	O
of	O
the	O
groupby	B-API
function	O
is	O
a	O
pandas	O
data	O
frame	O
or	O
series	O
.	O

You	O
can	O
use	O
the	O
apply	O
function	O
.	O

See	O
below	O
example	O
:	O
#CODE	O

You	O
can	O
filter	O
the	O
columns	O
first	O
to	O
get	O
the	O
cols	O
of	O
interest	O
and	O
then	O
call	O
`	O
apply	O
`	O
and	O
use	O
the	O
boolean	O
mask	O
to	O
mask	O
the	O
cols	O
:	O
#CODE	O

You	O
can	O
apply	O
function	O
`	O
f	O
`	O
for	O
each	O
group	O
.	O

the	O
answer	O
was	O
to	O
resample	O
so	O
I	O
won't	O
have	O
any	O
hole	O
,	O
and	O
then	O
apply	O
the	O
answer	O
for	O
this	O
question	O
:	O
How	O
do	O
you	O
shift	O
Pandas	O
DataFrame	B-API
with	O
a	O
multiindex	O
?	O

Apply	O
Number	O
formatting	O
to	O
Pandas	O
HTML	O
CSS	O
Styling	O

Given	O
the	O
following	O
,	O
how	O
can	O
I	O
set	O
the	O
NaN	O
/	O
None	O
value	O
of	O
the	O
B	O
row	O
based	O
on	O
the	O
other	O
rows	O
?	O

Should	O
I	O
use	O
apply	O
?	O

#CODE	O

Apply	O
is	O
the	O
way	O
forward	O
,	O
it	O
seems	O
.	O

`	O
fillna	B-API
`	O
doesn't	O
appear	O
to	O
accept	O
custom	O
functions	O
.	O

[	O
Reference	O
SO	O
question	O
]	O
(	O
#URL	O
)	O

Then	O
I	O
use	O
apply	O
:	O
#CODE	O

dropped	O
vectorization	O
and	O
list-comprehension	O
tags	O
-	O
they	O
don't	O
really	O
apply	O
here	O

I	O
said	O
,	O
let	O
me	O
use	O
a	O
lambda	O
to	O
apply	O
the	O
.hour	B-API
to	O
every	O
"	O
row	O
"	O
.	O

Thus	O
:	O
#CODE	O

not	O
sure	O
how	O
to	O
apply	O
this	O
suggestion	O
to	O
the	O
problem	O
above	O
.	O

First	O
of	O
all	O
-	O
does	O
your	O
suggestion	O
select	O
the	O
columns	O
in	O
the	O
hypothetical	O
array	O
you	O
suggest	O
?	O

Or	O
would	O
I	O
do	O
array	O
[:	O
,	O
mask	O
]	O
which	O
doesn't	O
seem	O
to	O
work	O
?	O

Can	O
I	O
use	O
the	O
apply	O
method	O
to	O
this	O
task	O
?,	O
can	O
someone	O
help	O
me	O
to	O
do	O
in	O
the	O
right	O
way	O
using	O
pandas	O
.	O

Apply	O
group	O
specific	O
function	O
to	O
groups	O
in	O
Pandas	O

I'm	O
trying	O
to	O
figure	O
out	O
the	O
best	O
way	O
to	O
apply	O
a	O
function	O
to	O
groups	O
within	O
a	O
Pandas	O
dataframe	B-API
where	O
the	O
function	O
depends	O
on	O
the	O
group	O
.	O

This	O
question	O
manages	O
the	O
result	O
for	O
a	O
single	O
column	O
,	O
but	O
I	O
have	O
an	O
arbitrary	O
number	O
of	O
columns	O
,	O
and	O
I	O
want	O
to	O
lag	O
all	O
of	O
them	O
.	O

I	O
can	O
use	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
,	O
but	O
`	O
apply	O
`	O
runs	O
the	O
`	O
shift	O
`	O
function	O
over	O
each	O
column	O
independently	O
,	O
and	O
it	O
doesn't	O
seem	O
to	O
like	O
receiving	O
an	O
`	O
[	O
nrow	O
,	O
2	O
]`	O
shaped	O
dataframe	B-API
in	O
return	O
.	O

Is	O
there	O
perhaps	O
a	O
function	O
like	O
`	O
apply	O
`	O
that	O
acts	O
on	O
the	O
whole	O
group	O
sub-frame	O
?	O

Or	O
is	O
there	O
a	O
better	O
way	O
to	O
do	O
this	O
?	O

Great	O
,	O
thanks	O
,	O
I	O
can't	O
remember	O
why	O
I	O
thought	O
I	O
needed	O
to	O
do	O
it	O
with	O
`	O
apply	O
`	O
-	O
maybe	O
it'll	O
come	O
to	O
me	O
later	O
.	O

Part	O
of	O
the	O
solution	O
,	O
because	O
you'll	O
have	O
duplicated	O
rows	O
with	O
slightly	O
different	O
names	O
so	O
you	O
couldn't	O
apply	O
drop_duplicates	B-API
method	O
of	O
dataframes	O
:	O
#CODE	O

Within	O
each	O
iteration	O
,	O
apply	O
the	O
function	O
.	O

As	O
a	O
general	O
idea	O
,	O
you	O
can	O
use	O
`	O
apply	O
`	O
on	O
your	O
grouped	O
data	O
to	O
take	O
compute	O
the	O
ratio	O
for	O
each	O
state	O
:	O
`	O
sum	O
(	O
bads	O
)	O
/	O
sum	O
(	O
goods	O
)`	O

The	O
easiest	O
way	O
would	O
probably	O
be	O
to	O
set	O
'	O
Date	O
and	O
Time	O
'	O
as	O
the	O
index	O
and	O
then	O
use	O
`	O
groupby	B-API
`	O
with	O
`	O
TimeGrouper	O
`	O
to	O
group	O
the	O
dates	O
.	O

Then	O
you	O
can	O
apply	O
`	O
cumsum()	B-API
`	O
:	O
#CODE	O

In	O
reality	O
I	O
need	O
to	O
apply	O
this	O
function	O
on	O
40K	O
over	O
rows	O
.	O

And	O
currently	O
it	O
runs	O

very	O
slow	O
using	O
Pandas	O
'	O
apply	O
'	O
:	O
#CODE	O

Without	O
trying	O
this	O
I	O
can't	O
be	O
entirely	O
sure	O
that	O
the	O
returned	O
value	O
of	O
`	O
func	O
`	O
will	O
be	O
acceptable	O
for	O
use	O
with	O
`	O
apply	O
`	O
,	O
so	O
you	O
might	O
need	O
to	O
play	O
around	O
with	O
that	O
a	O
little	O
.	O

But	O
this	O
should	O
give	O
you	O
a	O
series	O
with	O
the	O
index	O
being	O
the	O
description	O
and	O
the	O
value	O
being	O
a	O
list	O
or	O
dict	O
of	O
the	O
last	O
five	O
counts	O
.	O

After	O
creating	O
new	O
dataframe	B-API
by	O
`	O
concat	O
`	O
dataframes	O
I	O
can	O
group	O
it	O
by	O
row	O
and	O
apply	O
`	O
resample	O
`	O
on	O
each	O
of	O
these	O
groups	O
(	O
with	O
method	O
`	O
ffill	B-API
`	O
to	O
forward	O
fill	O
)	O
.	O

#CODE	O

numpy	O
and	O
pandas	O
are	O
not	O
needed	O
here	O
although	O
you	O
need	O
to	O
apply	O
the	O
strip	O
function	O
to	O
every	O
element	O
in	O
each	O
row	O
to	O
remove	O
excess	O
spaces	O
(	O
`	O
map	O
(	O
str.strip	B-API
,	O
row	O
)`)	O
and	O
also	O
pass	O
`	O
delimiter=	O
'	O
|	O
'`	O
into	O
`	O
csv.reader	O
`	O
because	O
the	O
default	O
delimiter	O
is	O
a	O
comma	O
.	O

Lastly	O
you	O
need	O
to	O
`	O
return	O
sum	O
`	O
at	O
the	O
end	O
of	O
you	O
function	O
.	O

Thanks	O
for	O
the	O
great	O
solution	O
.	O

Is	O
your	O
use	O
of	O
`	O
apply	O
`	O
a	O
recommended	O
method	O
to	O
access	O
pandas	O
functionality	O
that	O
isn't	O
present	O
in	O
dask	O
(	O
assuming	O
the	O
block	O
can	O
fit	O
into	O
memory	O
)	O
?	O

This	O
would	O
be	O
a	O
huge	O
help	O
to	O
by-pass	O
the	O
current	O
limitations	O
of	O
dask	O
dataframes	O
!	O

For	O
the	O
record	O
`	O
applymap	B-API
`	O
is	O
used	O
to	O
apply	O
a	O
lambda	O
function	O
elementwise	O
(	O
documentation	O
)	O

You	O
could	O
use	O
standard	O
method	O
of	O
strings	O
`	O
isnumeric	B-API
`	O
and	O
apply	O
it	O
to	O
each	O
value	O
in	O
your	O
`	O
id	O
`	O
column	O
:	O
#CODE	O

I	O
then	O
would	O
like	O
to	O
apply	O
a	O
function	O
to	O
each	O
of	O
these	O
groups	O
.	O

This	O
function	O
computes	O
two	O
values	O
for	O
each	O
group	O
#CODE	O

I	O
am	O
having	O
some	O
issues	O
understanding	O
the	O
type	O
of	O
your	O
`	O
group	O
`	O
argument	O
to	O
`	O
compute_thing()	O
`	O
.	O

Shouldn't	O
apply	O
iterate	O
over	O
the	O
results	O
of	O
the	O
grouping	O
,	O
and	O
the	O
`	O
group	O
`	O
argument	O
refers	O
to	O
the	O
current	O
group	O
in	O
consideration	O
?	O

I	O
am	O
familiar	O
with	O
the	O
page	O
.	O
but	O
I	O
dont	O
know	O
how	O
i	O
can	O
apply	O
this	O
to	O
my	O
data	O
and	O
plot	O
,	O
as	O
they	O
are	O
using	O
only	O
one	O
variable	O
with	O
an	O
arithmetic	O
operation	O
,	O
while	O
I	O
have	O
a	O
dataset	O
with	O
different	O
categories	O
.	O

so	O
you	O
can	O
later	O
apply	O
:	O
#CODE	O

Although	O
technically	O
correct	O
we	O
should	O
avoid	O
posting	O
answers	O
that	O
use	O
`	O
apply	O
`	O
where	O
a	O
vectorised	O
solution	O
exists	O
as	O
this	O
confuses	O
users	O

Figured	O
it	O
out	O
!	O

Apparently	O
I	O
had	O
some	O
missing	O
values	O
denoted	O
as	O
'	O
..	O

'	O
,	O
so	O
I	O
had	O
to	O
wrangle	O
it	O
out	O
first	O
by	O
dropping	O
those	O
rows	O
-	O
then	O
I	O
can	O
apply	O
.astype	B-API

Is	O
there	O
some	O
way	O
i	O
can	O
apply	O
a	O
lambda	O
function	O
to	O
all	O
members	O
of	O
the	O
list	O
columns	O
in	O
order	O
to	O
speed	O
the	O
following	O
up	O
?	O

Thanks	O
!	O

#CODE	O

All	O
you're	O
doing	O
is	O
skipping	O
rows	O
that	O
have	O
`	O
?	O

`	O
so	O
you	O
can	O
just	O
filter	O
these	O
out	O
using	O
`	O
apply	O
`	O
:	O
#CODE	O

Is	O
there	O
a	O
way	O
to	O
apply	O
a	O
`	O
math	O
`	O
function	O
to	O
a	O
whole	O
column	O
?	O

You	O
could	O
use	O
apply	O
:	O
#CODE	O

Index	O
levels	O
doubled	O
when	O
using	O
groupby	B-API
/	O
apply	O
on	O
a	O
multiindexed	O
dataframe	B-API

I	O
have	O
a	O
problem	O
when	O
using	O
a	O
groupby	B-API
/	O
apply	O
chain	O
on	O
multiindexed	O
pandas	O
data	O
frames	O
:	O
The	O
resulting	O
data	O
frame	O
contains	O
the	O
grouped	O
level	O
(	O
s	O
)	O
twice	O
!	O

Is	O
this	O
intended	O
behavior	O
?	O

How	O
can	O
I	O
avoid	O
that	O
another	O
index	O
level	O
is	O
created	O
?	O

Do	O
I	O
have	O
to	O
remove	O
it	O
by	O
hand	O
every	O
time	O
I	O
do	O
a	O
groupby	B-API
/	O
apply	O
operation	O
?	O

My	O
actual	O
function	O
that	O
I	O
apply	O
looks	O
different	O
.	O

I	O
just	O
used	O
the	O
sum	O
here	O
to	O
show	O
the	O
effect	O
of	O
a	O
function	O
that	O
takes	O
a	O
dataframe	B-API
and	O
returns	O
a	O
dataframe	B-API
(	O
"	O
case	O
2	O
"	O
in	O
the	O
documentation	O
of	O
apply	O
)	O
.	O

It	O
seems	O
that	O
you	O
would	O
have	O
quite	O
a	O
few	O
columns	O
to	O
aggregate	O
-	O
assume	O
'	O
date	O
'	O
is	O
your	O
timestamp	O
,	O
there	O
seem	O
to	O
be	O
seven	O
,	O
ie	O
,	O
data1	O
-	O
data7	O
.	O

If	O
you	O
apply	O
three	O
aggregation	O
functions	O
to	O
these	O
seven	O
columns	O
(	O
mean	O
,	O
min	O
,	O
max	O
)	O
you'll	O
get	O
7	O
x	O
3	O
columns	O
with	O
a	O
hierarchical	O
`	O
MultiIndex	O
`	O
(	O
where	O
`	O
.agg	B-API
(	O
dict	O
)`	O
works	O
differently	O
as	O
for	O
'	O
ordinary	O
'	O
columns	O
)	O
.	O

Example	O
follows	O
,	O
including	O
saving	O
to	O
csv	O
at	O
the	O
end	O
.	O

`	O
GroupBy	B-API
`	O
docs	O
and	O
`	O
to_csv	B-API
`	O
docs	O
.	O

Thank	O
you	O
so	O
much	O
:)	O
it	O
prints	O
the	O
output	O
in	O
the	O
way	O
you've	O
shown	O
.	O

AttributeError	O
:	O
Cannot	O
access	O
callable	O
attribute	O
'	O
to_csv	B-API
'	O
of	O
'	O
DataFrameGroupBy	B-API
'	O
objects	O
,	O
try	O
using	O
the	O
'	O
apply	O
'	O
method	O
But	O
I	O
still	O
get	O
this	O
error	O
while	O
printing	O
to	O
csv	O
file	O

Then	O
you	O
can	O
use	O
`	O
apply	O
`	O
(	O
or	O
there	O
probably	O
is	O
something	O
better	O
)	O
,	O
to	O
get	O
the	O
output	O
you	O
have	O
above	O
:	O
#CODE	O

The	O
simplest	O
way	O
would	O
be	O
to	O
use	O
DeepSpace	O
answer	O
.	O

However	O
,	O
if	O
you	O
really	O
want	O
to	O
use	O
an	O
anonymous	O
function	O
you	O
can	O
use	O
apply	O
:	O
#CODE	O

In	O
xlswriter	O
,	O
once	O
a	O
format	O
is	O
defined	O
,	O
how	O
can	O
you	O
apply	O
it	O
to	O
a	O
range	O
and	O
not	O
to	O
the	O
whole	O
column	O
or	O
the	O
whole	O
row	O
?	O

In	O
xlswriter	O
,	O
once	O
a	O
format	O
is	O
defined	O
,	O
how	O
can	O
you	O
apply	O
it	O
to	O
a	O
range	O
and	O
not	O
to	O
the	O
whole	O
column	O
or	O
the	O
whole	O
row	O
?	O

There	O
isn't	O
a	O
helper	O
function	O
to	O
do	O
this	O
.	O

You	O
will	O
need	O
to	O
loop	O
over	O
the	O
range	O
and	O
apply	O
the	O
data	O
and	O
formatting	O
to	O
each	O
cell	O
.	O

I've	O
written	O
some	O
code	O
to	O
clean	O
up	O
the	O
tweet	O
for	O
some	O
machine	O
learning	O
applications	O
and	O
I	O
would	O
like	O
to	O
apply	O
the	O
cleaning	O
function	O
to	O
the	O
entire	O
Tweet	O
column	O
.	O

If	O
this	O
is	O
the	O
reason	O
,	O
you	O
would	O
need	O
to	O
apply	O
`	O
.fillna	B-API
(	O
value	O
)`	O
prior	O
to	O
`	O
.groupby()	B-API
`	O
with	O
a	O
value	O
of	O
your	O
choice	O
-	O
for	O
instance	O
0	O
.	O

it	O
just	O
returns	O
a	O
df	O
with	O
all	O
NaN	O
values	O
.	O

With	O
rolling	O
apply	O
is	O
the	O
window	O
size	O
time	O
based	O
?	O

Is	O
there	O
no	O
other	O
ways	O
to	O
reference	O
the	O
value	O
in	O
a	O
previous	O
row	O
.	O

I	O
get	O
this	O
error	O
:	O
TypeError	O
:	O
unsupported	O
operand	O
type	O
(	O
s	O
)	O
for	O
+	O
:	O
'	O
numpy.int64	O
'	O
and	O
'	O
str	O
'	O
.	O

This	O
is	O
how	O
I	O
apply	O
your	O
code	O
:	O
featuresA	O
=	O
[	O
col	O
+	O
'	O
_x	O
'	O
for	O
col	O
in	O
group.to_frame()	O
.columns	O
]	O

Scikit	O
learn's	O
MultiLabelBinarizer	O
creates	O
a	O
binary	O
matrix	O
from	O
labels	O
.	O

You	O
can	O
extract	O
`	O
feature	O
`	O
column	O
from	O
pandas	O
dataframe	B-API
and	O
apply	O
it	O
:	O
#CODE	O

Another	O
approach	O
which	O
might	O
be	O
cleaner	O
if	O
you	O
have	O
a	O
lot	O
of	O
conditions	O
to	O
apply	O
would	O
to	O
be	O
to	O
chain	O
your	O
filters	O
together	O
with	O
reduce	O
or	O
a	O
loop	O
:	O
#CODE	O

I	O
completely	O
change	O
your	O
solution	O
to	O
`	O
groupby	B-API
`	O
with	O
`	O
apply	O
`	O
custom	O
function	O
`	O
f	O
`	O
.	O

For	O
check	O
string	O
values	O
is	O
better	O
use	O
`	O
isin	B-API
`	O
.	O

I	O
would	O
like	O
to	O
apply	O
a	O
boolean	O
`	O
mask	O
`	O
in	O
function	O
of	O
the	O
name	O
of	O
the	O
column	O
.	O

I	O
know	O
that	O
it	O
is	O
easy	O
for	O
values	O
:	O
#CODE	O

I	O
am	O
sure	O
that	O
could	O
be	O
do	O
with	O
aggregates	O
(	O
lambdas	O
func	O
)	O
or	O
apply	O
.	O

How	O
to	O
apply	O
drop_duplicates	B-API
to	O
grouped	O
dataframe	B-API
?	O

You	O
could	O
once	O
iterate	O
over	O
the	O
array	O
and	O
get	O
the	O
colours	O
corresponding	O
to	O
each	O
value	O
and	O
store	O
them	O
in	O
an	O
NxMx3	O
(	O
image	O
)	O
array	O
.	O

Then	O
sort	O
the	O
array	O
and	O
the	O
image	O
in	O
the	O
same	O
manner	O
e.g.	O
get	O
the	O
sort	O
indices	O
from	O
the	O
original	O
array	O
and	O
apply	O
them	O
to	O
the	O
image	O
array	O
.	O

Then	O
you	O
can	O
display	O
the	O
image	O
with	O
`	O
plt.imshow	B-API
`	O

I	O
found	O
an	O
issue	O
about	O
a	O
similar	O
error	O
when	O
using	O
the	O
apply	O
method	O
and	O
that	O
bug	O
was	O
fixed	O
.	O

Since	O
they	O
fixed	O
for	O
apply	O
I	O
used	O
the	O
apply	O
function	O
to	O
do	O
what	O
I	O
want	O
.	O

#CODE	O

I	O
used	O
the	O
apply	O
method	O
on	O
the	O
grouped	O
data	O
,	O
and	O
the	O
easiest	O
way	O
to	O
get	O
the	O
'	O
identifier	O
'	O
was	O
to	O
get	O
the	O
groups	O
keys	O
.	O

If	O
you	O
have	O
a	O
suggestion	O
on	O
how	O
to	O
do	O
this	O
more	O
efficiently	O
let	O
me	O
know	O
!	O

tz-aware	O
datetime	O
series	O
producing	O
UTC-based	O
.date()	B-API
output	O
in	O
pandas	O
series	O
apply	O
(	O
lambda	O
)	O
operation	O

Pandas	O
apply	O
function	O
-	O
comparing	O
each	O
row	O
to	O
entire	O
column	O

The	O
`	O
groupby	B-API
`	O
function	O
makes	O
sense	O
,	O
but	O
I'm	O
having	O
trouble	O
defining	O
the	O
appropriate	O
apply	O
function	O
.	O

I've	O
seen	O
examples	O
using	O
multiple	O
columns	O
as	O
inputs	O
to	O
a	O
function	O
,	O
and	O
others	O
using	O
`	O
axis=1	O
`	O
to	O
look	O
at	O
individual	O
rows	O
,	O
but	O
haven't	O
seen	O
a	O
description	O
of	O
using	O
both	O
the	O
entire	O
column	O
(	O
to	O
look	O
for	O
matches	O
)	O
and	O
the	O
entry	O
for	O
the	O
row	O
in	O
question	O
(	O
to	O
determine	O
the	O
time	O
range	O
)	O
.	O

Not	O
sure	O
if	O
I	O
understand	O
what	O
you	O
looking	O
for	O
.	O

But	O
you	O
can	O
access	O
a	O
column	O
inside	O
an	O
`	O
apply	O
`	O
function	O
.	O

For	O
example	O
,	O
this	O
calculates	O
how	O
many	O
rows	O
inside	O
a	O
group	O
have	O
times	O
less	O
than	O
12	O
:	O
#CODE	O

This	O
functionality	O
makes	O
sense	O
-	O
you	O
can	O
use	O
an	O
apply	O
to	O
compare	O
each	O
element	O
to	O
a	O
fixed	O
value	O
(	O
in	O
your	O
example	O
,	O
`	O
x	O
<	O
12	O
`	O
and	O
`	O
6	O
<	O
x	O
<	O
12	O
`)	O
.	O

What	O
I	O
am	O
looking	O
for	O
would	O
need	O
to	O
,	O
for	O
each	O
element	O
,	O
compare	O
to	O
all	O
the	O
other	O
elements	O
and	O
return	O
the	O
number	O
matching	O
the	O
closeness	O
criterion	O
.	O

To	O
continue	O
-	O
I	O
think	O
it	O
is	O
O	O
(	O
n^2	O
)	O
,	O
as	O
it	O
needs	O
to	O
compare	O
each	O
value	O
to	O
all	O
other	O
values	O
.	O

I	O
had	O
hoped	O
using	O
a	O
grouping	O
criterion	O
that	O
produces	O
a	O
greater	O
number	O
of	O
smaller	O
segments	O
to	O
apply	O
the	O
function	O
to	O
would	O
speed	O
up	O
the	O
calculation	O
,	O
but	O
this	O
doesn't	O
seem	O
to	O
be	O
the	O
case	O
in	O
practice	O
.	O

Any	O
idea	O
whether	O
this	O
is	O
a	O
fundamental	O
misunderstanding	O
,	O
or	O
just	O
issues	O
with	O
the	O
implementation	O
?	O

To	O
get	O
around	O
this	O
,	O
I	O
found	O
that	O
you	O
can	O
apply	O
a	O
date	O
function	O
to	O
the	O
column	O
in	O
sqlalchemy	O
,	O
similar	O
to	O
this	O
issue	O
.	O

Use	O
`	O
apply	O
`	O
and	O
pass	O
`	O
axis=1	O
`	O
to	O
call	O
`	O
describe	O
`	O
row-wise	O
:	O
#CODE	O

But	O
when	O
I	O
apply	O
the	O
code	O
,	O
I	O
get	O
the	O
following	O
Error	O
:	O
#CODE	O

However	O
,	O
when	O
I	O
try	O
to	O
apply	O
that	O
function	O
in	O
order	O
to	O
write	O
the	O
output	O
to	O
a	O
new	O
column	O
in	O
a	O
pandas	O
data	O
frame	O
,	O
it's	O
returning	O
None	O
.	O

See	O
below	O
:	O
#CODE	O

formatter	O
function	O
to	O
apply	O
to	O
columns	O
elements	O
if	O
they	O
are	O
floats	O
,	O
default	O
None	O
.	O

The	O
result	O
of	O
this	O
function	O
must	O
be	O
a	O
unicode	O
string	O
.	O

One	O
option	O
is	O
to	O
use	O
an	O
apply	O
:	O
#CODE	O

My	O
understanding	O
is	O
that	O
this	O
just	O
uses	O
the	O
keys	O
to	O
perform	O
the	O
lookup	O
,	O
same	O
as	O
if	O
you	O
pass	O
a	O
`	O
Series	O
`	O
and	O
similarly	O
it	O
will	O
bork	O
and	O
generate	O
a	O
`	O
KeyError	O
`	O
if	O
the	O
label	O
/	O
key	O
doesn't	O
exist	O
,	O
in	O
that	O
case	O
doing	O
`	O
apply	O
(	O
lambda	O
x	O
:	O
other_dict.get	O
(	O
x	O
,	O
other_val	O
))`	O
would	O
at	O
least	O
not	O
go	O
mental	O
if	O
the	O
key	O
doesn't	O
exist	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
groups	O
of	O
`	O
x1	O
`	O
based	O
on	O
the	O
columns	O
in	O
`	O
x2	O
`	O
.	O

e.g.	O
:	O
#CODE	O

I	O
have	O
a	O
big	O
dataframe	B-API
,	O
and	O
I'm	O
grouping	O
by	O
one	O
to	O
n	O
columns	O
,	O
and	O
want	O
to	O
apply	O
a	O
function	O
on	O
these	O
groups	O
across	O
two	O
columns	O
(	O
e.g.	O
foo	O
and	O
bar	O
)	O
.	O

But	O
`	O
transform	O
`	O
apparently	O
isn't	O
able	O
to	O
combine	O
multiple	O
columns	O
together	O
because	O
it	O
looks	O
at	O
each	O
column	O
separately	O
(	O
unlike	O
apply	O
)	O
.	O

What	O
is	O
the	O
next	O
best	O
alternative	O
in	O
terms	O
of	O
speed	O
/	O
elegance	O
?	O

e.g.	O
I	O
could	O
use	O
`	O
apply	O
`	O
and	O
then	O
create	O
`	O
df	O
[	O
'	O
new_col	O
']`	O
by	O
using	O
`	O
pd.match	O
`	O
,	O
but	O
that	O
would	O
necessitate	O
matching	O
over	O
sometimes	O
multiple	O
groupby	B-API
columns	O
(	O
col1	O
and	O
col2	O
)	O
which	O
seems	O
really	O
hacky	O
/	O
would	O
take	O
a	O
fair	O
amount	O
of	O
code	O
.	O

P.S.	O

:	O
Guess	O
need	O
to	O
use	O
the	O
groupby	B-API
function	O
,	O
but	O
because	O
of	O
lack	O
of	O
experience	O
,	O
do	O
not	O
understand	O
how	O
to	O
apply	O
it	O
to	O
my	O
problem	O
.	O

I've	O
also	O
done	O
my	O
Google	O
searches	O
but	O
I	O
do	O
not	O
feel	O
found	O
results	O
apply	O
to	O
my	O
issue	O
.	O

using	O
the	O
`	O
apply	O
`	O
method	O
of	O
the	O
DataFrame	B-API
,	O
with	O
something	O
like	O
:	O

Actually	O
apply	O
produces	O
the	O
`	O
<	O
built-in	O
method	O
values	O
of	O
dict	O
object	O
at	O
0x00	O
...	O

`	O
output	O
.	O

So	O
apply()	B-API
may	O
not	O
be	O
good	O
for	O
this	O
particular	O
transformation	O
.	O

I	O
also	O
tend	O
to	O
not	O
use	O
apply	O
but	O
it	O
can	O
be	O
convenient	O
(	O
for	O
readability	O
or	O
when	O
using	O
certain	O
functions	O
for	O
example	O
)	O
.	O

Anyway	O
in	O
my	O
test	O
(	O
on	O
python	O
3.4	O
/	O
pandas	O
0.17	O
)	O
the	O
following	O
statment	O
```	O
df	O
[	O
'	O
word	O
count	O
']	O
=	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
dict	O
(	O
Counter	O
(	O
x	O
[	O
'	O
test	O
']	O
.split	B-API
(	O
"	O
"))	O
.items()	O
)	O
,	O
axis=1	O
)```	O
make	O
a	O
new	O
column	O
with	O
the	O
word	O
count	O
(	O
not	O
sure	O
why	O
you	O
use	O
join	O
*	O
and	O
*	O
split	O
on	O
your	O
text	O
)	O
.	O

You	O
can	O
also	O
use	O
list	O
comprehension	O
to	O
avoid	O
apply	O
,	O
like	O
```	O
df	O
[	O
'	O
word	O
count	O
']	O
=	O
[	O
dict	O
(	O
Counter	O
(	O
i	O
[	O
1	O
]	O
[	O
'	O
text	O
']	O
.split	B-API
(	O
"	O
"))	O
.items()	O
)	O
for	O
i	O
in	O
df.iterrows()	B-API
]```	O

You	O
are	O
right	O
,	O
join	O
isn't	O
needed	O
.	O

i	O
see	O
now	O
Counter	O
works	O
fine	O
on	O
split	O
words	O
without	O
needing	O
commas	O
to	O
separate	O
them	O
.	O

List	O
comprehension	O
works	O
perfectly	O
.	O

Apply	O
still	O
outputs	O
`	O
<	O
built-in	O
method	O
values	O
of	O
dict	O
object	O
at	O
0x00	O
...	O

`	O
Quick	O
timer	O
test	O
shows	O
apply	O
is	O
bit	O
faster	O
than	O
direct	O
method	O
:	O
**	O
apply	O
method	O
**	O
`	O
1	O
loops	O
,	O
best	O
of	O
3	O
:	O
14.6	O
s	O
per	O
loop	O
`	O
**	O
direct	O
method	O
**	O
`	O
1	O
loops	O
,	O
best	O
of	O
3	O
:	O
18.2	O
s	O
per	O
loop	O
`	O
.	O

My	O
data	O
has	O
~60k	O
rows	O
and	O
mean	O
of	O
314	O
words	O
per	O
row	O
.	O

Type	O
of	O
`	O
df	O
`	O
isn't	O
`	O
dataframe	B-API
`	O
,	O
but	O
`	O
TextFileReader	O
`	O
.	O

I	O
think	O
you	O
need	O
concat	O
all	O
chunks	O
to	O
dataframe	B-API
by	O
function	O
`	O
concat	O
`	O
and	O
then	O
apply	O
function	O
:	O
#CODE	O

You	O
can	O
use	O
the	O
`	O
apply	O
`	O
and	O
`	O
applymap	B-API
`	O
from	O
pandas	O
.	O

But	O
I	O
don't	O
how	O
to	O
apply	O
that	O
to	O
my	O
code	O
either	O
.	O

Please	O
help	O
.	O

(	O
Note	O
:	O
this	O
assumes	O
the	O
rows	O
we	O
need	O
to	O
fill	O
look	O
like	O
the	O
ones	O
in	O
your	O
example	O
.	O
If	O
they're	O
messier	O
we'd	O
have	O
to	O
do	O
a	O
little	O
more	O
work	O
,	O
but	O
the	O
same	O
techniques	O
will	O
apply	O
.	O
)	O

Haven't	O
benched	O
this	O
,	O
@USER	O
,	O
but	O
I	O
think	O
the	O
numpy	O
approach	O
should	O
be	O
pretty	O
quick	O
too	O
.	O

Especially	O
because	O
Pandas	O
`	O
.apply()	B-API
`	O
now	O
runs	O
through	O
the	O
first	O
apply	O
twice	O
,	O
to	O
find	O
out	O
if	O
it	O
can	O
take	O
a	O
shortcut	O
approach	O
.	O

I	O
don't	O
know	O
the	O
details	O
of	O
under-the-hood	O
working	O
,	O
but	O
it	O
looks	O
similar	O
to	O
Numba's	O
approach	O
at	O
speeding	O
things	O
up	O
:	O
run	O
once	O
to	O
figure	O
out	O
what's	O
happening	O
,	O
speed	O
up	O
,	O
if	O
possible	O
.	O

This	O
is	O
a	O
new	O
thing	O
I	O
found	O
in	O
their	O
[	O
docs	O
here	O
]	O
(	O
#URL	O
)	O
.	O

Read	O
the	O
warning	O
towards	O
the	O
end	O
of	O
the	O
subsection	O
.	O

It's	O
been	O
doing	O
that	O
for	O
as	O
long	O
a	O
I	O
can	O
remember	O
(	O
a	O
few	O
years	O
(	O
!	O
)	O
at	O
least	O
)	O
:)	O
The	O
apply	O
still	O
happens	O
in	O
python	O
so	O
if	O
you	O
have	O
a	O
lot	O
of	O
small	O
groups	O
the	O
dummy_column	O
+	O
groupby	B-API
sum	O
will	O
blow	O
apply	O
out	O
of	O
the	O
water	O
.	O

Numba	O
is	O
a	O
game	O
changer	O
however	O
,	O
if	O
it	O
were	O
using	O
numba	O
it	O
might	O
be	O
different	O
...	O

(	O
Edit	O
:	O
[	O
the	O
warning	O
is	O
new	O
though	O
]	O
(	O
#URL	O
)	O
.	O
)	O

@USER	O
-	O
I	O
am	O
new	O
to	O
pandas.I	O
am	O
guessing	O
from	O
you	O
explanation	O
and	O
needing	O
to	O
apply	O
some	O
some	O
map	O
reduce	O
type	O
of	O
thing	O
is	O
going	O
on	O
?	O

Is	O
my	O
assumption	O
correct	O
?	O

If	O
I	O
use	O
groupby	B-API
apply	O
,	O
everything	O
works	O
fine	O
:	O
#CODE	O

Thanks	O
for	O
the	O
links	O
,	O
@USER	O
,	O
unfortunately	O
this	O
is	O
what	O
I	O
was	O
saying	O
in	O
my	O
intro	O
,	O
those	O
approaches	O
work	O
like	O
a	O
charm	O
when	O
you	O
have	O
non	O
complex	O
data	O
such	O
as	O
int	O
or	O
float	O
,	O
but	O
in	O
the	O
case	O
of	O
vectors	O
inside	O
the	O
dataframe	B-API
,	O
things	O
get	O
pretty	O
messy	O
.	O

I	O
tried	O
those	O
ideas	O
and	O
failed	O
,	O
so	O
maybe	O
I	O
am	O
just	O
missing	O
how	O
to	O
apply	O
them	O
in	O
my	O
situation	O
:(	O

Then	O
you	O
can	O
apply	O
the	O
numpy	O
/	O
scipy	O
vectorised	O
methods	O
for	O
computing	O
cosine	O
similarity	O
as	O
in	O
Whats	O
the	O
fastest	O
way	O
in	O
Python	O
to	O
calculate	O
cosine	O
similarity	O
given	O
sparse	O
matrix	O
data	O
?	O

It's	O
because	O
`	O
apply	O
`	O
method	O
works	O
for	O
column	O
by	O
default	O
,	O
change	O
`	O
axis	O
`	O
to	O
1	O
if	O
you'd	O
like	O
through	O
rows	O
:	O

0	O
or	O
index	O
:	O
apply	O
function	O
to	O
each	O
column	O

1	O
or	O
columns	O
:	O
apply	O
function	O
to	O
each	O
row	O

Like	O
indicated	O
by	O
Anton	O
you	O
should	O
execute	O
the	O
apply	O
function	O
with	O
`	O
axis=1	O
`	O
parameter	O
.	O

However	O
it	O
is	O
not	O
necessary	O
to	O
then	O
loop	O
through	O
the	O
rows	O
as	O
you	O
did	O
in	O
the	O
function	O
test	O
,	O
since	O

the	O
`	O
apply	O
`	O
documentation	O
mentions	O
:	O

How	O
to	O
apply	O
a	O
function	O
to	O
two	O
columns	O
of	O
Pandas	O
dataframe	B-API

If	O
you're	O
using	O
`	O
apply	O
`	O
,	O
the	O
speed	O
difference	O
is	O
minimal	O
;	O
you	O
should	O
feel	O
free	O
to	O
use	O
`	O
iteritems	B-API
`	O
.	O

Thanks	O
a	O
lot	O
!	O

If	O
I	O
am	O
focusing	O
on	O
a	O
single	O
dataframe	B-API
,	O
and	O
want	O
to	O
use	O
function	O
to	O
do	O
calculations	O
to	O
each	O
column	O
,	O
is	O
iteritems()	B-API
also	O
better	O
than	O
apply	O
(	O
lambda	O
x	O
)	O
?	O

@USER	O
-	O
they	O
are	O
very	O
similar	O
from	O
a	O
pandas	O
POV	O
I	O
think	O
-	O
it's	O
just	O
whatever	O
you	O
think	O
is	O
cleaner	O
.	O

For	O
me	O
,	O
`	O
apply	O
`	O
is	O
cleaner	O
,	O
but	O
you	O
don't	O
get	O
the	O
name	O
.	O

to	O
apply	O
various	O
aggregation	O
functions	O
as	O
described	O
in	O
the	O
docs	O
.	O

If	O
you	O
provide	O
some	O
detail	O
on	O
what	O
you'd	O
like	O
to	O
aggregate	O
and	O
how	O
,	O
happy	O
to	O
add	O
an	O
example	O
.	O

Generally	O
speaking	O
,	O
you'd	O
apply	O
an	O
"	O
easing	O
function	O
"	O
over	O
some	O
range	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
to	O
every	O
group	O
in	O
a	O
`	O
groupby	B-API
`	O
object	O
,	O
so	O
that	O
the	O
function	O
operates	O
on	O
multiple	O
columns	O
of	O
each	O
group	O
,	O
and	O
returns	O
a	O
1	O
x	O
n	O
"	O
row	O
vector	O
"	O
as	O
result	O
.	O

I	O
want	O
the	O
n	O
entries	O
of	O
these	O
row	O
vectors	O
to	O
form	O
the	O
contents	O
of	O
n	O
new	O
columns	O
in	O
the	O
resulting	O
dataframe	B-API
.	O

What	O
did	O
you	O
try	O
?	O

Attach	O
part	O
of	O
your	O
dataframe	B-API
.	O

You	O
could	O
use	O
`	O
apply	O
`	O
with	O
`	O
rsplit	B-API
`	O
.	O

You	O
are	O
probably	O
right	O
.	O

But	O
I	O
thought	O
`	O
map	O
`	O
method	O
access	O
directrly	O
to	O
each	O
value	O
instead	O
of	O
`	O
apply	O
`	O
which	O
for	O
whole	O
Series	O
.	O

If	O
so	O
it	O
should	O
access	O
as	O
Pandas	O
`	O
Timedelta	O
`	O
.	O

Is	O
it	O
correct	O
?	O

`	O
apply	O
`	O
would	O
fail	O
here	O
also	O
,	O
`	O
apply	O
`	O
is	O
also	O
a	O
`	O
for	O
`	O
loop	O
it	O
just	O
allows	O
you	O
operate	O
either	O
column-wise	O
or	O
row-wise	O
when	O
called	O
on	O
a	O
df	O
,	O
the	O
type	O
conversion	O
is	O
being	O
doing	O
by	O
pandas	O
here	O

but	O
this	O
will	O
filter	O
the	O
data	O
frame	O
several	O
times	O
,	O
one	O
value	O
at	O
a	O
time	O
,	O
and	O
not	O
apply	O
all	O
filters	O
at	O
the	O
same	O
time	O
.	O

Is	O
there	O
a	O
way	O
to	O
do	O
it	O
programmatically	O
?	O

if	O
used	O
apply	O
i	O
will	O
be	O
how	O
to	O
implement	O
them	O
thx	O
;	O
^^	O

Consider	O
a	O
series	O
sum	O
function	O
and	O
apply	O
it	O
to	O
a	O
`	O
groupby()	B-API
`	O
:	O
#CODE	O

Previously	O
`	O
train_y	O
`	O
was	O
a	O
Series	O
,	O
now	O
it's	O
numpy	O
array	O
(	O
it	O
is	O
a	O
column-vector	O
)	O
.	O

If	O
I	O
apply	O
`	O
train_y.ravel()	O
`	O
,	O
then	O
it	O
becomes	O
a	O
row	O
vector	O
and	O
no	O
error	O
message	O
appears	O
,	O
through	O
the	O
prediction	O
step	O
takes	O
very	O
long	O
time	O
(	O
actually	O
it	O
never	O
finishes	O
...	O
)	O
.	O

A	O
custom	O
function	O
should	O
apply	O
to	O
a	O
series	O
of	O
the	O
dataframe	B-API
,	O
a	O
boolean	O
operator	O
for	O
example	O
:	O
#CODE	O

I	O
currently	O
want	O
to	O
apply	O
several	O
machine	O
learning	O
models	O
on	O
this	O
data	O
.	O

With	O
some	O
models	O
,	O
it	O
is	O
necessary	O
to	O
do	O
normalization	O
to	O
get	O
better	O
result	O
.	O

For	O
example	O
,	O
converting	O
categorical	B-API
variable	O
into	O
dummy	O
/	O
indicator	O
variables	O
.	O

Indeed	O
,	O
pandas	O
has	O
a	O
function	O
called	O
get_dummies	B-API
for	O
that	O
purpose	O
.	O

However	O
,	O
this	O
function	O
returns	O
the	O
result	O
depending	O
on	O
the	O
data	O
.	O

So	O
if	O
I	O
call	O
get_dummies	B-API
on	O
training	O
data	O
,	O
then	O
call	O
it	O
again	O
on	O
test	O
data	O
,	O
columns	O
achieved	O
in	O
two	O
cases	O
can	O
be	O
different	O
because	O
a	O
categorical	B-API
column	O
in	O
test	O
data	O
can	O
contains	O
just	O
a	O
sub-set	O
/	O
different	O
set	O
of	O
possible	O
values	O
compared	O
to	O
possible	O
values	O
in	O
training	O
data	O
.	O

@USER	O
-so	O
one	O
more	O
thing	O
,	O
can	O
i	O
apply	O
chunksize	O
filtering	O
(	O
taking	O
a	O
chunk	O
of	O
dataframe	B-API
like	O
in	O
the	O
case	O
of	O
pandas	O
dataframe	B-API
,	O
then	O
doing	O
some	O
Op	O
.	O
then	O
merging	O
them	O
--	O
sending	O
back	O
)	O
on	O
dask	O
dataframe	B-API
???	O

would	O
give	O
you	O
the	O
mean	O
for	O
the	O
second	O
row	O
anyway	O
,	O
to	O
operate	O
row-wise	O
you	O
can	O
use	O
`	O
apply	O
`	O
and	O
pass	O
a	O
`	O
lambda	O
`	O
:	O
#CODE	O

First	O
I	O
started	O
by	O
using	O
`	O
pd.rank()	O
`	O
on	O
the	O
data	O
and	O
then	O
I	O
planned	O
on	O
then	O
using	O
`	O
pd.cut()	B-API
`	O
to	O
cut	O
the	O
data	O
into	O
bins	O
,	O
but	O
it	O
does	O
not	O
seem	O
like	O
this	O
accepts	O
top	O
N%	O
,	O
rather	O
it	O
accepts	O
explicit	O
bin	O
edges	O
.	O

Is	O
there	O
an	O
easy	O
way	O
to	O
do	O
this	O
in	O
pandas	O
,	O
or	O
do	O
I	O
need	O
to	O
create	O
a	O
lambda	O
/	O
apply	O
function	O
which	O
calculates	O
which	O
bin	O
each	O
of	O
the	O
ranked	O
items	O
should	O
be	O
placed	O
in	O
.	O

Not	O
quite	O
.	O

When	O
I	O
apply	O
this	O
to	O
my	O
data	O
set	O
it	O
says	O
there	O
are	O
419	O
posts	O
in	O
the	O
top	O
0-5	O
%	O
percentile	O
,	O
when	O
in	O
actuality	O
in	O
my	O
data	O
set	O
of	O
1674	O
samples	O
,	O
there	O
should	O
only	O
be	O
84	O
samples	O
within	O
the	O
top	O
5%	O

You	O
can	O
use	O
`	O
apply	O
`	O
and	O
apply	O
a	O
lambda	O
row-wise	O
:	O
#CODE	O

You	O
can	O
use	O
`	O
apply	O
`	O
with	O
a	O
`	O
lambda	O
`	O
to	O
return	O
the	O
name	O
of	O
the	O
column	O
,	O
here	O
we	O
compare	O
the	O
value	O
row-wise	O
against	O
the	O
max	O
,	O
this	O
produces	O
a	O
boolean	O
mask	O
we	O
can	O
use	O
to	O
mask	O
the	O
columns	O
:	O
#CODE	O

which	O
difference	O
?	O

sorry	O
but	O
your	O
are	O
asking	O
a	O
lot	O
of	O
questions	O
in	O
a	O
single	O
question	O
!	O

which	O
is	O
not	O
SO	O
working	O
...	O

I	O
already	O
provided	O
two	O
different	O
answer	O
solving	O
the	O
original	O
problem	O
(	O
with	O
`	O
apply	O
`	O
and	O
a	O
`	O
vectorized	O
`	O
one	O
)	O

You	O
can	O
use	O
double	O
square	O
brackets	O
to	O
force	O
`	O
apply	O
`	O
to	O
be	O
called	O
on	O
a	O
`	O
df	O
`	O
,	O
this	O
allows	O
you	O
operate	O
row-wise	O
,	O
then	O
use	O
a	O
user	O
defined	O
func	O
to	O
compare	O
the	O
current	O
row	O
value	O
against	O
all	O
row	O
values	O
prior	O
to	O
current	O
row	O
,	O
this	O
generates	O
a	O
boolean	O
mask	O
to	O
select	O
the	O
invalid	O
rows	O
and	O
assign	O
`	O
NaN	O
`	O
to	O
these	O
and	O
then	O
`	O
ffill	B-API
`	O
:	O
#CODE	O

which	O
I	O
read	O
as	O
for	O
each	O
`	O
x	O
`	O
in	O
the	O
series	O
`	O
df1.var1	O
`	O
,	O
apply	O
the	O
function	O
`	O
np.percentile	B-API
(	O
df2.var1	O
,	O
x	O
)`	O
,	O
which	O
finds	O
the	O
percentile	O
of	O
`	O
x	O
`	O
in	O
the	O
series	O
`	O
df2.var1	O
`	O
.	O

For	O
some	O
reason	O
,	O
I'm	O
getting	O
the	O
error	O
#CODE	O

This	O
allows	O
me	O
to	O
control	O
the	O
layout	O
,	O
but	O
I	O
can't	O
apply	O
it	O
to	O
bar	O
charts	O
.	O

I'm	O
assuming	O
you	O
want	O
to	O
use	O
all	O
`	O
[	O
'	O
W	O
'	O
,	O
'	O
X	O
'	O
,	O
'	O
Y	O
'	O
,	O
'	O
Z	O
']`	O
`	O
columns	O
`	O
,	O
and	O
only	O
one	O
of	O
the	O
`	O
date	O
`	O
columns	O
.	O

If	O
so	O
,	O
the	O
below	O
should	O
get	O
you	O
there	O
-	O
if	O
you	O
first	O
apply	O
`	O
set_index	B-API
`	O
and	O
then	O
`	O
unstack	O
`	O
,	O
`	O
pandas	O
`	O
creates	O
the	O
`	O
MultiIndex	O
`	O
automatically	O
,	O
which	O
you	O
can	O
then	O
`	O
swap	O
`	O
by	O
`	O
level	O
`	O
and	O
`	O
sort	O
`	O
as	O
you	O
wish	O
:	O
#CODE	O

How	O
to	O
apply	O
a	O
expanding	O
window	O
formula	O
that	O
restarts	O
with	O
change	O
in	O
date	O
in	O
Pandas	O
dataframe	B-API
?	O

So	O
in	O
your	O
example	O
,	O
do	O
`	O
df.set_index	B-API
(	O
'	O
Date	O
Time	O
')`	O
and	O
then	O
`	O
groupby	B-API
`	O
and	O
`	O
apply	O
`	O
.	O

You	O
can	O
of	O
course	O
assign	O
the	O
result	O
back	O
to	O
the	O
original	O
`	O
DataFrame	B-API
`	O
.	O

You	O
can	O
use	O
`	O
apply	O
`	O
together	O
with	O
a	O
lambda	O
expression	O
to	O
check	O
for	O
the	O
target	O
word	O
in	O
each	O
column	O
.	O

Then	O
use	O
`	O
any	O
(	O
axis=1	O
)`	O
to	O
locate	O
any	O
row	O
containing	O
that	O
word	O
.	O

Finally	O
,	O
use	O
boolean	O
indexing	O
with	O
a	O
tilda	O
(	O
`	O
~	O
`)	O
to	O
locate	O
all	O
rows	O
where	O
income	O
is	O
NOT	O
in	O
the	O
row	O
.	O

#CODE	O

Without	O
seeing	O
the	O
data	O
and	O
assuming	O
you	O
want	O
the	O
resultant	O
prediction	O
as	O
a	O
column	O
in	O
the	O
second	O
data	O
(	O
df2	O
)	O
frame	O
you	O
can	O
apply	O
the	O
kn.predict()	O
using	O
the	O
.apply()	B-API
function	O
and	O
specifying	O
the	O
vertical	O
axis	O
.	O

This	O
will	O
give	O
you	O
an	O
additional	O
column	O
with	O
the	O
predicted	O
output	O
.	O

Heres	O
the	O
info	O
on	O
apply	O
.	O

`	O
shifted	O
=	O
data.sign()	O
!	O

=	O
data.sign()	O
.shift()	B-API
`	O
should	O
work	O
rather	O
than	O
use	O
`	O
apply	O
`	O

HINT	O
:	O
Use	O
the	O
Theano	O
flag	O
'	O
exception_verbosity=high	O
'	O
for	O
a	O
debugprint	O
and	O
storage	O
map	O
footprint	O
of	O
this	O
apply	O
node	O
.	O

You	O
have	O
to	O
use	O
apply	O
.	O

Here's	O
a	O
toy	O
example	O
:	O
#CODE	O

why	O
I	O
need	O
to	O
apply	O
nth	O
to	O
the	O
whole	O
grouped	O
dataframe	B-API

Because	O
you	O
need	O
first	O
apply	O
function	O
`	O
nth	O
`	O
for	O
all	O
group	O
and	O
then	O
get	O
first	O
rows	O
of	O
group	O
.	O

I	O
try	O
it	O
in	O
second	O
approach	O
.	O

It	O
is	O
together	O
`	O
df.groupby	B-API
([	O
'	O
a	O
'	O
,	O
'	O
b	O
'])	O
[	O
'	O
c	O
']`	O
and	O
then	O
apply	O
function	O
`	O
nth	O
`	O
.	O

Not	O
for	O
all	O
group	O
`	O
df.groupby	B-API
([	O
'	O
a	O
'	O
,	O
'	O
b	O
'])`	O
.	O

@USER	O
:	O
Your	O
first	O
block	O
isn't	O
applicable	O
to	O
my	O
question	O
as	O
the	O
group	O
index	O
is	O
not	O
present	O
(	O
I	O
want	O
to	O
maintain	O
this	O
)	O
.	O

In	O
your	O
2nd	O
example	O
,	O
I	O
don't	O
understand	O
why	O
I	O
can't	O
just	O
do	O
`	O
g	O
[	O
'	O
c	O
']	O
.nth	B-API
(	O
0	O
)`	O
and	O
why	O
I	O
need	O
to	O
apply	O
`	O
nth	O
`	O
to	O
the	O
whole	O
grouped	O
dataframe	B-API
and	O
_then_	O
select	O
`	O
c	O
`	O
.	O

If	O
you	O
want	O
to	O
apply	O
it	O
to	O
all	O
columns	O
,	O
do	O
`	O
df	O
[	O
df	O
0	O
]`	O
with	O
`	O
dropna()	B-API
`	O
:	O
#CODE	O

If	O
you	O
know	O
what	O
columns	O
to	O
apply	O
it	O
to	O
,	O
then	O
do	O
for	O
only	O
those	O
cols	O
with	O
`	O
df	O
[	O
df	O
[	O
cols	O
]	O
0	O
]`	O
:	O
#CODE	O

access	O
previous	O
rows	O
in	O
python	O
dataframe	B-API
apply	O
method	O

For	O
this	O
dataset	O
if	O
I	O
delete	O
the	O
first	O
3	O
rows	O
the	O
fit	O
is	O
greater	O
than	O
0.995	O
,	O
I	O
have	O
tested	O
this	O
but	O
I	O
want	O
this	O
to	O
be	O
a	O
general	O
expression	O
so	O
I	O
can	O
apply	O
it	O
to	O
other	O
datasets	O
.	O

`	O
apply	O
`	O
a	O
lambda	O
to	O
access	O
the	O
last	O
element	O
:	O
#CODE	O

I	O
have	O
two	O
pandas	O
tables	O
,	O
`	O
d	O
`	O
and	O
`	O
num_original_introns	O
`	O
.	O

They	O
are	O
both	O
indexed	O
with	O
the	O
same	O
non-numeric	O
index	O
.	O

I	O
want	O
to	O
apply	O
a	O
step	O
function	O
to	O
transform	O
`	O
d	O
`	O
based	O
on	O
values	O
in	O
`	O
d	O
`	O
and	O
`	O
num_original_introns	O
`	O
,	O
like	O
so	O
:	O
#CODE	O

I	O
know	O
that	O
this	O
is	O
invalid	O
,	O
and	O
it	O
is	O
not	O
possible	O
to	O
apply	O
a	O
pair	O
of	O
conditionals	O
like	O
this	O
,	O
but	O
I	O
can't	O
seem	O
to	O
find	O
an	O
alternative	O
from	O
googling	O
.	O

How	O
can	O
I	O
do	O
this	O
?	O

Why	O
you	O
couldn't	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
then	O
?	O

IIUC	O
you	O
could	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
and	O
`	O
fillna	B-API
`	O
with	O
your	O
custom	O
function	O
:	O
#CODE	O

If	O
you	O
want	O
to	O
get	O
column	O
names	O
for	O
missing	O
values	O
you	O
could	O
apply	O
or	O
use	O
that	O
function	O
for	O
processing	O
:	O
#CODE	O

When	O
looking	O
online	O
,	O
I	O
tend	O
to	O
see	O
examples	O
of	O
'	O
hardcoded	O
'	O
variables	O
,	O
but	O
I	O
don't	O
get	O
how	O
to	O
apply	O
this	O
to	O
a	O
dataframe	B-API
column	O
-	O
I	O
found	O
that	O
I	O
should	O
use	O
strptime	O
to	O
identify	O
what	O
format	O
my	O
date	O
column	O
is	O
,	O
but	O
I	O
don't	O
know	O
if	O
this	O
has	O
any	O
effect	O
(	O
I	O
get	O
the	O
same	O
error	O
if	O
I	O
comment	O
out	O
the	O
convert_dates	O
apply	O
method	O
)	O
.	O

python	O
pandas-	O
apply	O
function	O
with	O
two	O
arguments	O
to	O
columns	O

Continuing	O
off	O
of	O
part	O
1	O
,	O
you	O
can	O
merge	O
the	O
values	O
back	O
on	O
to	O
the	O
original	O
dataframe	B-API
.	O

At	O
that	O
point	O
,	O
you	O
can	O
write	O
a	O
custom	O
function	O
to	O
subtract	O
your	O
date	O
strings	O
and	O
then	O
apply	O
it	O
to	O
each	O
row	O
.	O

You	O
can	O
`	O
groupby	B-API
`	O
dataframe	B-API
by	O
column	O
`	O
Name	O
`	O
,	O
`	O
apply	O
`	O
custom	O
function	O
`	O
f	O
`	O
and	O
then	O
select	O
dataframes	O
`	O
df_A	O
`	O
and	O
`	O
df_B	O
`	O
:	O
#CODE	O

I	O
have	O
a	O
dataframe	B-API
and	O
I'd	O
like	O
to	O
apply	O
a	O
function	O
to	O
each	O
2	O
columns	O
(	O
or	O
3	O
,	O
it's	O
variable	O
)	O
.	O

For	O
example	O
with	O
the	O
following	O
`	O
DataFrame	B-API
`	O
,	O
I'd	O
like	O
to	O
apply	O
the	O
mean	O
function	O
to	O
columns	O
0-1	O
,	O
2-3	O
,	O
4-5	O
,	O
....	O

28-29	O
#CODE	O

Then	O
I	O
push	O
all	O
but	O
1	O
column	O
into	O
the	O
index	O
with	O
set_index	B-API
.	O

This	O
leaves	O
one	O
column	O
which	O
comes	O
back	O
as	O
a	O
Series	O
.	O

Then	O
use	O
apply	O
and	O
return	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
set	O
of	O
dates	O
for	O
each	O
row	O
(	O
Series	O
of	O
Series	O
=	O
DataFrame	B-API
)	O
.	O

So	O
for	O
each	O
of	O
the	O
7	O
rows	O
in	O
the	O
DataFrame	B-API
,	O
I	O
get	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
date	O
range	O
.	O

Then	O
its	O
just	O
clever	O
stacking	O
,	O
naming	O
,	O
and	O
reset_index	B-API
.	O

#CODE	O

You	O
can	O
`	O
apply	O
`	O
function	O
to	O
`	O
groupby	B-API
`	O
where	O
use	O
another	O
`	O
apply	O
`	O
with	O
`	O
replace	O
`	O
`	O
0	O
`	O
to	O
`	O
NaN	O
`	O
:	O
#CODE	O

You	O
can	O
use	O
this	O
apply	O
function	O
:	O
#CODE	O

Although	O
this	O
does	O
not	O
use	O
explicit	O
`	O
for-loop	O
`	O
s	O
or	O
a	O
list	O
comprehension	O
,	O
there	O
is	O
an	O
implicit	O
for-loop	O
hidden	O
in	O
the	O
call	O
to	O
`	O
apply	O
`	O
.	O

In	O
fact	O
,	O
it	O
is	O
much	O
slower	O
than	O
using	O
a	O
list	O
comprehension	O
:	O
#CODE	O

Yes	O
and	O
no	O
--	O
there	O
is	O
a	O
way	O
to	O
do	O
it	O
using	O
`	O
apply	O
/	O
stack	O
`	O
which	O
avoids	O
the	O
*	O
explicit	O
*	O
double	O
for-loops	O
,	O
but	O
it	O
is	O
actually	O
much	O
slower	O
than	O
the	O
list	O
comprehension-based	O
solution	O
shown	O
above	O
.	O

So	O
if	O
you	O
are	O
trying	O
to	O
avoid	O
`	O
for-loop	O
`	O
s	O
for	O
performance	O
,	O
then	O
I	O
don't	O
think	O
there	O
is	O
a	O
good	O
way	O
.	O

You	O
see	O
,	O
when	O
you	O
put	O
non-native	O
NumPy	O
data	O
types	O
,	O
such	O
as	O
lists	O
,	O
in	O
a	O
DataFrame	B-API
,	O
ultimately	O
computations	O
on	O
those	O
values	O
require	O
plain	O
Python	O
methods	O
which	O
are	O
relatively	O
slow	O
(	O
compared	O
to	O
native	O
NumPy	O
methods	O
)	O
.	O

To	O
break	O
apart	O
the	O
items	O
in	O
the	O
lists	O
require	O
plain	O
Python	O
loops	O
no	O
matter	O
how	O
you	O
phrase	O
it	O
.	O

Do	O
I	O
then	O
save	O
that	O
as	O
a	O
function	O
and	O
apply	O
it	O
to	O
the	O
dataframe	B-API
or	O
could	O
I	O
just	O
run	O
that	O
on	O
it's	O
own	O
and	O
have	O
it	O
append	O
the	O
column	O
to	O
the	O
original	O
df	O
?	O

`	O
apply	O
(	O
F	O
)`	O
calles	O
`	O
_python_apply_general	O
`	O
.	O

As	O
the	O
name	O
implies	O
,	O
it	O
is	O
ageneral	O
propose	O
method	O
.	O

Under	O
the	O
hood	O
,	O
it	O
does	O
not	O
attempt	O
checking	O
if	O
a	O
faster	O
`	O
cython	O
`	O
version	O
of	O
aggerate	O
function	O
exists	O
.	O

It	O
applies	O
`	O
F	O
`	O
to	O
each	O
group	O
and	O
assembles	O
the	O
results	O
together	O
,	O
which	O
means	O
it	O
would	O
run	O
slower	O
than	O
the	O
optimized	O
`	O
cython	O
`	O
version	O
equivalent	O
(	O
such	O
as	O
`	O
.sum	B-API
`)	O
.	O

Finally	O
,	O
`	O
apply	O
(	O
lambda	O
x	O
:	O
F	O
(	O
x	O
))`	O
will	O
be	O
slightly	O
slower	O
than	O
`	O
apply	O
(	O
F	O
)`	O
due	O
to	O
the	O
additional	O
`	O
lambda	O
`	O
function	O
.	O

In	O
Pandas	O
,	O
how	O
to	O
apply	O
a	O
customized	O
function	O
using	O
Group	O
mean	O
on	O
Groupby	B-API
Object	O

I	O
want	O
to	O
create	O
groups	O
based	O
on	O
value	O
of	O
column	O
A	O
.	O

So	O
I	O
slice	O
A	O
first	O
.	O

And	O
define	O
a	O
function	O
.	O

Then	O
I	O
use	O
apply	O
method	O
on	O
the	O
Groupby	B-API
Obj	O
.	O

I	O
am	O
expecting	O
the	O
new	O
column	O
to	O
be	O
the	O
difference	O
between	O
B	O
and	O
C	O
over	O
the	O
group	O
mean	O
of	O
A	O
.	O

#CODE	O

I	O
want	O
to	O
apply	O
a	O
group	O
by	O
on	O
a	O
pandas	O
dataframe	B-API
.	O

I	O
want	O
to	O
group	O
by	O
three	O
columns	O
and	O
calculate	O
their	O
count	O
.	O

I	O
used	O
the	O
following	O
code	O
#CODE	O

I	O
think	O
native	O
apply	O
is	O
the	O
best	O
,	O
but	O
not	O
.	O

I	O
found	O
faster	O
approach	O
:	O
#CODE	O

You	O
can	O
use	O
apply	O
with	O
lambda	O
with	O
is	O
faster	O
than	O
your	O
solution	O
:	O
#CODE	O

You	O
could	O
use	O
`	O
functools.reduce	O
`	O
to	O
iteratively	O
apply	O
`	O
pd.merge	B-API
`	O
to	O
each	O
of	O
the	O
DataFrames	O
:	O
#CODE	O

you	O
don't	O
even	O
need	O
to	O
use	O
`	O
apply	O
`	O
:	O
`	O
df	O
[[	O
'	O
AccX	O
'	O
,	O
'	O
AccY	O
']]	O
.values	B-API
`	O

But	O
if	O
I	O
want	O
to	O
do	O
some	O
operation	O
on	O
each	O
row	O
,	O
I	O
still	O
need	O
`	O
apply	O
`	O
correct	O
?	O

Also	O
I	O
kind	O
of	O
just	O
want	O
to	O
know	O
why	O
the	O
first	O
three	O
don't	O
work	O
.	O

My	O
whole	O
data	O
frame	O
has	O
11	O
columns	O

This	O
code	O
gives	O
me	O
an	O
attribute	O
error	O
when	O
I	O
apply	O
the	O
seasonal_decompose	O
method	O
:	O

Creating	O
Period	O
objects	O
is	O
expensive	O
,	O
so	O
let's	O
identify	O
the	O
unique	O
quarters	O
and	O
then	O
apply	O
the	O
period	O
mapping	O
.	O

#CODE	O

Consider	O
a	O
groupby	B-API
apply	O
function	O
with	O
sort	O
:	O
#CODE	O

This	O
works	O
fine	O
for	O
some	O
files	O
but	O
for	O
some	O
other	O
files	O
it	O
raises	O
the	O
error	O
:	O
`	O
ValueError	O
:	O
could	O
not	O
convert	O
string	O
to	O
float	O
`	O
.	O

Which	O
naturally	O
makes	O
me	O
think	O
there	O
is	O
something	O
wrong	O
with	O
the	O
file	O
.	O

But	O
,	O
when	O
I	O
try	O
to	O
loop	O
sequentially	O
over	O
the	O
data	O
and	O
apply	O
the	O
same	O
conversion	O
it	O
doesn't	O
give	O
any	O
error	O
.	O

So	O
I	O
cannot	O
figure	O
out	O
where	O
the	O
problem	O
in	O
the	O
file	O
is	O
or	O
what's	O
the	O
problem	O
with	O
the	O
converter	O
.	O

I	O
can't	O
seem	O
to	O
apply	O
`	O
to_datetime	B-API
`	O
to	O
a	O
pandas	O
dataframe	B-API
column	O
,	O
although	O
I've	O
done	O
it	O
dozens	O
of	O
times	O
in	O
the	O
past	O
.	O

The	O
following	O
code	O
tells	O
me	O
that	O
any	O
random	O
value	O
in	O
the	O
"	O
Date	O
Time	O
"	O
column	O
is	O
a	O
string	O
,	O
after	O
I	O
try	O
to	O
convert	O
it	O
to	O
a	O
timestamp	O
.	O

The	O
`'	O
errors=coerce	O
'`	O
should	O
convert	O
any	O
parsing	O
errors	O
to	O
`'	O
NaT	O
'`	O
,	O
but	O
instead	O
I	O
still	O
have	O
`'	O
2015-10-10	O
12:31	O
:	O
04	O
'`	O
as	O
a	O
string	O
.	O

#CODE	O

I	O
have	O
an	O
`	O
apply	O
`	O
function	O
that	O
operates	O
on	O
each	O
row	O
in	O
my	O
dataframe	B-API
.	O

The	O
result	O
of	O
that	O
`	O
apply	O
`	O
function	O
is	O
a	O
new	O
value	O
.	O

This	O
new	O
value	O
is	O
intended	O
to	O
go	O
in	O
a	O
new	O
column	O
for	O
that	O
row	O
.	O

If	O
you	O
need	O
to	O
use	O
other	O
arguments	O
,	O
you	O
can	O
pass	O
them	O
to	O
the	O
`	O
apply	O
`	O
function	O
,	O
but	O
sometimes	O
it's	O
easier	O
(	O
for	O
me	O
)	O
to	O
just	O
use	O
a	O
lambda	O
:	O
#CODE	O

I	O
should've	O
mentioned	O
this	O
before	O
:	O
my	O
function	O
has	O
two	O
arguments	O
,	O
a	O
row	O
from	O
the	O
`	O
dataframe	B-API
`	O
,	O
and	O
a	O
global	O
dictionary	O
.	O

I	O
tried	O
incorporating	O
these	O
like	O
so	O
:	O
`	O
df	O
[	O
'	O
new_column	O
']	O
=	O
df.apply	B-API
(	O
my_fxn	O
(	O
row	O
)	O
,	O
args	O
=(	O
)	O
,	O
axis=1	O
)`	O
but	O
it	O
seems	O
to	O
be	O
breaking	O
the	O
global_dictionary	O
up	O
into	O
individual	O
individual	O
K	O
/	O
V	O
pairs	O
.	O

As	O
a	O
result	O
it	O
tells	O
me	O
that	O
there	O
are	O
too	O
many	O
arguments	O
.	O

How	O
do	O
I	O
pass	O
arguments	O
to	O
the	O
`	O
apply	O
`	O
function	O
?	O

I'm	O
hoping	O
the	O
solution	O
will	O
detect	O
that	O
there	O
is	O
no	O
existing	O
COL3=	O
'	O
Y	O
'	O
for	O
COL1=	O
'	O
B	O
'	O
and	O
therefore	O
add	O
the	O
row	O
while	O
setting	O
COL2	O
to	O
0	O
for	O
the	O
new	O
row	O
.	O

The	O
code	O
should	O
get	O
the	O
set	O
of	O
unique	O
values	O
of	O
COL3	O
,	O
check	O
to	O
see	O
if	O
all	O
exist	O
for	O
all	O
unique	O
values	O
of	O
COL1	O
,	O
and	O
if	O
not	O
,	O
add	O
the	O
row	O
.	O

It	O
doesn't	O
get	O
more	O
complex	O
than	O
this	O
,	O
I	O
was	O
only	O
trying	O
to	O
get	O
an	O
answer	O
that	O
I	O
can	O
apply	O
to	O
many	O
rows	O
instead	O
of	O
just	O
manually	O
inserting	O
that	O
specific	O
row	O
.	O

There	O
must	O
be	O
a	O
way	O
to	O
use	O
pandas	O
/	O
numpy	O
array	O
functions	O
but	O
tell	O
it	O
to	O
skip	O
the	O
first	O
row	O
in	O
the	O
calculation	O
.	O

How	O
to	O
do	O
that	O
?	O

I've	O
tried	O
Boolean	O
indexing	O
but	O
can't	O
get	O
it	O
to	O
work	O
,	O
and	O
maybe	O
there	O
is	O
a	O
way	O
to	O
tell	O
Pandas	O
to	O
skip	O
the	O
NaN	O
results	O
...	O
but	O
the	O
best	O
approach	O
seems	O
to	O
be	O
a	O
qualifier	O
that	O
says	O
"	O
apply	O
this	O
code	O
,	O
starting	O
at	O
the	O
second	O
row	O
.	O

"	O

It	O
occurred	O
to	O
me	O
that	O
it	O
might	O
be	O
much	O
faster	O
to	O
identify	O
those	O
groups	O
that	O
have	O
duplicates	O
using	O
count	O
.	O

Then	O
I	O
can	O
apply	O
the	O
max	O
transformation	O
to	O
that	O
grouping	O
,	O
and	O
then	O
recombine	O
the	O
two	O
into	O
one	O
.	O

I	O
think	O
the	O
problem	O
is	O
that	O
g	O
[	O
"	O
liq	O
"]	O
.transform	B-API
(	O
"	O
max	O
")	O
resets	O
the	O
index	O
,	O
losing	O
the	O
original	O
index	O
in	O
the	O
process	O
?	O

certainly	O
df	O
[	O
df	O
[	O
"	O
liq	O
"]	O
==	O
g	O
[	O
"	O
liq	O
"]	O
.transform	B-API
(	O
"	O
max	O
")	O
results	O
in	O
a	O
memory	O
error	O
...	O

I'm	O
still	O
struggling	O
with	O
this	O
.	O
doing	O
g.size()	O
produces	O
an	O
effective	O
count	O
of	O
the	O
number	O
of	O
duplicates	O
,	O
and	O
is	O
very	O
,	O
very	O
,	O
fast	O
,	O
so	O
I	O
am	O
trying	O
to	O
use	O
this	O
to	O
get	O
the	O
unique_id	O
and	O
period_id	O
pairs	O
where	O
size	O
>	O
2	O
,	O
then	O
apply	O
the	O
max	O
idea	O
above	O
to	O
those	O
which	O
should	O
be	O
much	O
faster	O
,	O
and	O
then	O
I'll	O
need	O
to	O
recombine	O
with	O
the	O
original	O
data	O
frame	O
.	O

Pandas	O
DataFrame	B-API
apply	O
Specific	O
Function	O
to	O
Each	O
column	O

In	O
case	O
you	O
have	O
a	O
core	O
set	O
of	O
columns	O
,	O
as	O
here	O
represented	O
by	O
`	O
df1	O
`	O
,	O
you	O
could	O
apply	O
`	O
.fillna()	B-API
`	O
to	O
the	O
`	O
.difference()	B-API
`	O
between	O
the	O
core	O
set	O
and	O
any	O
new	O
columns	O
in	O
more	O
recent	O
`	O
DataFrames	O
`	O
.	O

#CODE	O

what	O
is	O
your	O
pandas	O
version	O
.	O

I	O
can	O
run	O
this	O
example	O
fine	O
in	O
0.16.1	O
.	O

As	O
an	O
aside	O
,	O
rather	O
than	O
doing	O
apply	O
(	O
pd.to_datetime	B-API
)	O
,	O
just	O
do	O
pd.to_datetime	B-API
(	O
df	O
)	O
.	O

This	O
line	O
:	O
df	O
[	O
0	O
]=	O
df	O
[	O
0	O
]	O
.apply	B-API
(	O
pd.to_datetime	B-API
)	O
also	O
seems	O
to	O
be	O
wrong	O
it	O
seems	O
you	O
want	O
df	O
[	O
'	O
timestamp	O
']	O
=	O
df	O
[	O
'	O
timestamp	O
']	O
.	O

.	O

Apply	O
functon	O
with	O
a	O
condition	O
on	O
the	O
first	O
row	O

For	O
instance	O
,	O
I	O
would	O
like	O
to	O
apply	O
(	O
lambda	O
x	O
:	O
x+	O
273.15	O
)	O
on	O
each	O
columns	O
which	O
contain	O
C	O
data	O
.	O

Ah	O
,	O
now	O
I	O
understand	O
.	O

Unfortunately	O
,	O
I	O
can't	O
think	O
of	O
a	O
good	O
solution	O
.	O

Which	O
dataframe	B-API
operation	O
do	O
you	O
want	O
to	O
apply	O
if	O
you	O
had	O
the	O
rows	O
combined	O
into	O
a	O
dataframe	B-API
?	O

Edit	O
:	O
I	O
have	O
found	O
a	O
way	O
to	O
do	O
that	O
:	O
I	O
apply	O
`	O
ast.literal_eval	O
`	O
to	O
each	O
line	O
.	O

Apply	O
function	O
to	O
each	O
column	O
that	O
returns	O
the	O
value	O
associated	O
with	O
the	O
`	O
index	O
`	O
of	O
the	O
`	O
min	O
`	O
`	O
abs	O
`	O
value	O
like	O
so	O
:	O
#CODE	O

You	O
could	O
pass	O
an	O
argument	O
to	O
`	O
apply	O
`	O
:	O
#CODE	O

Using	O
apply	O
to	O
go	O
through	O
row	O
by	O
row	O
and	O
test	O
whether	O
the	O
value	O
is	O
numeric	O
of	O
string	O
is	O
the	O
quickest	O
way	O
separate	O
them	O
.	O

#CODE	O

I	O
have	O
tried	O
expressing	O
it	O
in	O
terms	O
of	O
join	O
or	O
merge	O
but	O
have	O
failed	O
so	O
far	O
.	O

Is	O
there	O
any	O
simple	O
way	O
to	O
express	O
that	O
or	O
will	O
I	O
have	O
to	O
use	O
apply	O
and	O
create	O
a	O
new	O
DataFrame	B-API
?	O

You	O
could	O
use	O
`	O
apply	O
`	O
with	O
`	O
axis=1	O
`	O
to	O
apply	O
for	O
rows	O
with	O
`	O
any	O
`	O
method	O
,	O
if	O
you	O
have	O
only	O
one	O
valid	O
value	O
and	O
all	O
other	O
are	O
`	O
NaN	O
`	O
(	O
using	O
@USER	O
example	O
):	O
#CODE	O

If	O
you	O
want	O
to	O
subset	O
your	O
dataframe	B-API
you	O
could	O
use	O
mask	O
with	O
your	O
columns	O
and	O
apply	O
it	O
to	O
the	O
whole	O
dataframe	B-API
:	O
#CODE	O

and	O
then	O
use	O
groupBy	B-API
and	O
apply	O
to	O
calculate	O
the	O
median	O
somehow	O
?	O

and	O
apply	O
a	O
function	O
to	O
the	O
groups	O
.	O

Ex	O
.	O

1	O
Find	O
the	O
number	O
of	O
trips	O
each	O
team	O
went	O
on	O
.	O

`	O
team	O
`	O
is	O
the	O
grouper	B-API
,	O
and	O
we	O
apply	O
the	O
function	O
`	O
count()	B-API
`	O
on	O
column	O
`	O
[	O
'	O
trips	O
']`	O
.	O

#CODE	O

Ex	O
.	O

2	O
(	O
multiple	O
columns	O
)	O
:	O
Find	O
the	O
total	O
time	O
each	O
player	O
on	O
a	O
team	O
spent	O
traveling	O
.	O

We	O
use	O
2	O
columns	O
`	O
[	O
'	O
team	O
'	O
,	O
'	O
player	O
']`	O
as	O
the	O
grouper	B-API
,	O
and	O
apply	O
the	O
function	O
`	O
sum()	B-API
`	O
on	O
column	O
`	O
[	O
'	O
time	O
']`	O
.	O

#CODE	O

IIUC	O
you	O
need	O
groupby	B-API
by	O
`	O
Feed	O
`	O
from	O
multiindex	O
and	O
apply	O
`	O
pct_change	B-API
`	O
.	O

Then	O
you	O
can	O
use	O
subset	O
of	O
`	O
df3	O
`	O
,	O
where	O
column	O
`	O
Rate_Return	O
`	O
is	O
`	O
notnull	O
`	O
#CODE	O

We	O
get	O
3	O
rows	O
but	O
only	O
2	O
columns	O
.	O

In	O
the	O
docs	O
I	O
find	O
that	O
different	O
from	O
standard	O
python	O
,	O
label	O
based	O
slicing	O
in	O
pandas	O
is	O
inclusive	O
.	O

Does	O
this	O
apply	O
here	O
and	O
is	O
it	O
inclusive	O
for	O
rows	O
but	O
not	O
for	O
columns	O
then	O
?	O

Here	O
,	O
I	O
am	O
grouping	O
by	O
`	O
id	O
`	O
and	O
for	O
each	O
`	O
id	O
`	O
,	O
the	O
df	O
is	O
sorted	O
by	O
`	O
time	O
`	O
.	O

Now	O
,	O
I	O
want	O
to	O
replace	O
the	O
values	O
in	O
`	O
a	O
`	O
and	O
`	O
b	O
`	O
by	O
the	O
maximum	O
value	O
seen	O
thus	O
far	O
.	O

I	O
guess	O
I	O
can	O
apply	O
a	O
rolling	O
max	O
on	O
each	O
group	O
but	O
is	O
there	O
a	O
better	O
way	O
to	O
do	O
this	O
?	O

You	O
can	O
`	O
apply	O
`	O
custom	O
function	O
,	O
where	O
find	O
index	O
of	O
first	O
1	O
by	O
`	O
idxmax	B-API
`	O
and	O
set	O
rows	O
to	O
the	O
end	O
of	O
group	O
to	O
`	O
1	O
`	O
:	O
#CODE	O

My	O
knowledge	O
isn't	O
that	O
great	O
of	O
Pandas	O
(	O
yet	O
)	O
,	O
but	O
I'm	O
guessing	O
it's	O
an	O
"	O
apply	O
"	O
or	O
an	O
agg()	B-API
function	O
but	O
so	O
far	O
,	O
syntactically	O
,	O
I'm	O
banging	O
my	O
head	O
from	O
the	O
syntax	O
errors	O
,	O
but	O
I	O
appreciate	O
any	O
pointers	O
in	O
the	O
right	O
direction	O
.	O
..	O

JW	O

But	O
this	O
takes	O
quite	O
a	O
while	O
given	O
the	O
time	O
complexity	O
,	O
running	O
at	O
around	O
20s	O
for	O
500	O
points	O
and	O
I	O
have	O
a	O
much	O
longer	O
list	O
.	O

This	O
has	O
me	O
looking	O
at	O
vectorization	O
,	O
and	O
I've	O
come	O
across	O
`	O
numpy.vectorize	B-API
`	O
(	O
(	O
docs	O
)	O
,	O
but	O
can't	O
figure	O
out	O
how	O
to	O
apply	O
it	O
in	O
this	O
context	O
.	O

Thanks	O
.	O

It	O
doesn	O
t	B-API
work	O
.	O

The	O
format	O
of	O
the	O
date	O
is	O
"	O
2015-12-01	O
00:00	O
:	O
00-06	O
:	O
00	O
"	O
.	O

I	O
used	O
"	O
to_datetime	B-API
"	O
to	O
convert	O
the	O
original	O
date	O
format	O
to	O
a	O
datetime	O
object	O
,	O
in	O
order	O
to	O
apply	O
"	O
tz_localize	B-API
"	O
to	O
convert	O
to	O
another	O
time	O
zone	O
.	O

It	O
seems	O
tz_localize	B-API
adds	O
that	O
offset	O
and	O
I	O
have	O
not	O
found	O
how	O
to	O
get	O
rid	O
of	O
it	O
.	O

I	O
am	O
not	O
exactly	O
sure	O
how	O
to	O
go	O
about	O
this	O
.	O

One	O
of	O
the	O
ideas	O
is	O
use	O
itterrows()	O
and	O
apply	O
harvesine()	O
function	O
,	O
if	O
rows	O
'	O
sequence	O
'	O
parameter	O
is	O
not	O
0	O
and	O
row's	O
'	O
track_id	O
'	O
is	O
equal	O
to	O
previous	O
row's	O
'	O
track_id	O
'	O

[	O
EDIT	O
]	O
I	O
figured	O
there	O
is	O
no	O
need	O
to	O
check	O
if	O
'	O
track_id	O
'	O
of	O
row	O
and	O
previous	O
row	O
is	O
the	O
same	O
,	O
since	O
the	O
haversine()	O
function	O
is	O
applied	O
to	O
two	O
rows	O
only	O
,	O
and	O
when	O
sequence	O
=	O
0	O
,	O
that	O
row's	O
distance	O
==	O
0	O
,	O
which	O
means	O
that	O
the	O
track_id	O
has	O
changed	O
.	O

So	O
,	O
basically	O
,	O
apply	O
haversine()	O
function	O
to	O
all	O
rows	O
whose	O
'	O
sequence	O
'	O
!	O

=	O
0	O
,	O
ie	O
haversine	O
(	O
previous_row.lng	O
,	O
previous_row.lat	O
,	O
current_row.lng	O
,	O
current_row.lat	O
)	O
.	O

Still	O
need	O
help	O
with	O
that	O
though	O

I	O
normally	O
populate	O
new	O
columns	O
using	O
"	O
apply	O
,	O
axis	O
=	O
1	O
"	O
so	O
I	O
would	O
really	O
appreciate	O
any	O
solution	O
based	O
on	O
that	O
.	O

I	O
found	O
that	O
"	O
apply	O
"	O
works	O
fine	O
when	O
for	O
each	O
row	O
,	O
computation	O
is	O
done	O
across	O
columns	O
using	O
values	O
at	O
the	O
same	O
row	O
level	O
.	O

However	O
,	O
I	O
don't	O
know	O
how	O
an	O
"	O
apply	O
"	O
function	O
can	O
involve	O
different	O
rows	O
,	O
which	O
is	O
what	O
this	O
problem	O
requires	O
.	O
the	O
only	O
exception	O
I	O
have	O
seen	O
so	O
far	O
is	O
"	O
diff	O
"	O
,	O
which	O
is	O
not	O
useful	O
here	O
.	O

@USER	O
:	O
using	O
min_period	O
to	O
fill	O
in	O
NaN	O
is	O
good	O
if	O
e.g.	O
one	O
wants	O
to	O
remove	O
seasonality	O
in	O
data	O
.	O

I	O
,	O
however	O
,	O
want	O
to	O
use	O
the	O
rolling	O
mean	O
to	O
create	O
a	O
feature	O
to	O
feed	O
into	O
a	O
ML	O
model	O
.	O

I	O
can't	O
use	O
rolling_mean	B-API
for	O
store-dates	O
not	O
in	O
the	O
initial	O
dataset	O
,	O
which	O
min_period	O
does	O
.	O

Therefore	O
,	O
I	O
loop	O
over	O
the	O
1115	O
stores	O
and	O
apply	O
your	O
solution	O
(	O
without	O
min_periods	O
)	O
,	O
which	O
is	O
still	O
much	O
faster	O
than	O
my	O
initial	O
attempt	O
.	O

Thanks	O
for	O
your	O
help	O

I	O
have	O
a	O
data	O
frame	O
in	O
pandas	O
which	O
includes	O
number	O
of	O
days	O
since	O
an	O
event	O
occurred	O
.	O

I	O
want	O
to	O
create	O
a	O
new	O
column	O
that	O
calculates	O
the	O
date	O
of	O
the	O
event	O
by	O
subtracting	O
the	O
number	O
of	O
days	O
from	O
the	O
current	O
date	O
.	O

Every	O
time	O
I	O
attempt	O
to	O
apply	O
`	O
pd.offsets.Day	O
`	O
or	O
`	O
pd.Timedelta	O
`	O
I	O
get	O
an	O
error	O
stating	O
that	O
Series	O
are	O
an	O
unsupported	O
type	O
.	O

This	O
also	O
occurs	O
when	O
I	O
use	O
`	O
apply	O
`	O
.	O

When	O
I	O
use	O
`	O
map	O
`	O
I	O
receive	O
a	O
runtime	O
error	O
saying	O
"	O
maximum	O
recursion	O
depth	O
exceeded	O
while	O
calling	O
a	O
Python	O
object	O
"	O
.	O

What	O
is	O
a	O
proper	O
idiom	O
in	O
pandas	O
for	O
creating	O
a	O
dataframes	O
from	O
the	O
output	O
of	O
a	O
apply	O
function	O
on	O
a	O
df	O
?	O

One	O
of	O
the	O
operations	O
I	O
need	O
to	O
conduct	O
is	O
grabbing	O
the	O
latest	O
feed	O
entries	O
---	O
the	O
feed	O
urls	O
exist	O
in	O
a	O
column	O
in	O
a	O
data	O
frame	O
.	O

Once	O
I've	O
done	O
the	O
apply	O
I	O
get	O
feed	O
objects	O
back	O
:	O
#CODE	O

So	O
,	O
now	O
I'm	O
stuck	O
with	O
the	O
feed	O
entries	O
in	O
the	O
"	O
entries	O
"	O
column	O
,	O
I'd	O
like	O
to	O
create	O
a	O
two	O
new	O
data	O
frames	O
in	O
one	O
apply	O
method	O
,	O
and	O
concatenate	O
the	O
two	O
frames	O
immediately	O
.	O

But	O
I'm	O
not	O
sure	O
how	O
this	O
will	O
help	O
me	O
.	O

I	O
took	O
a	O
look	O
at	O
the	O
pandas	O
Dataframe.to_dict()	B-API
but	O
I	O
don't	O
think	O
the	O
above	O
code	O
reads	O
into	O
a	O
dataframe	B-API
(	O
or	O
,	O
if	O
it	O
does	O
,	O
I	O
don't	O
understand	O
the	O
documentation	O
well	O
enough	O
)	O
.	O

It	O
looks	O
like	O
it'll	O
only	O
store	O
one	O
value	O
per	O
key	O
at	O
a	O
time	O
.	O

Another	O
thread	O
I	O
was	O
reading	O
says	O
it's	O
possible	O
to	O
store	O
more	O
than	O
one	O
value	O
per	O
key	O
,	O
though	O
(	O
using	O
.append()	B-API
)	O
but	O
I	O
don't	O
know	O
how	O
to	O
apply	O
it	O
to	O
this	O
situation	O
.	O

Pandas	O
:	O
apply	O
returns	O
list	O

I	O
have	O
the	O
following	O
function	O
that	O
I	O
want	O
to	O
apply	O
to	O
each	O
group	O
:	O
#CODE	O

How	O
do	O
I	O
make	O
the	O
results	O
of	O
the	O
apply	O
operation	O
the	O
values	O
of	O
the	O
"	O
mean_to_date	O
"	O
column	O
?	O

That	O
is	O
,	O
the	O
mean_to_date	O
for	O
player	O
200	O
,	O
season	O
21999	O
would	O
be	O
0	O
and	O
10	O
,	O
then	O
for	O
player	O
200	O
,	O
season	O
21200	O
it	O
would	O
be	O
0	O
,	O
10	O
,	O
and	O
15	O
,	O
and	O
so	O
forth	O
.	O

Note	O
that	O
the	O
mean_to_date	O
value	O
represents	O
the	O
mean	O
prior	O
to	O
the	O
game	O
,	O
so	O
before	O
the	O
1st	O
game	O
it	O
is	O
zero	O
,	O
and	O
before	O
the	O
second	O
game	O
it	O
is	O
the	O
total	O
from	O
the	O
first	O
game	O
.	O

you're	O
getting	O
lists	O
back	O
because	O
your	O
function	O
`	O
previous_mean	O
`	O
,	O
when	O
fed	O
a	O
dataframe	B-API
,	O
returns	O
a	O
list	O
--	O
it	O
has	O
nothing	O
to	O
do	O
with	O
`	O
apply	O
`	O
.	O

You	O
said	O
in	O
another	O
comment	O
that	O
you	O
want	O
one	O
mean	O
per	O
row	O
,	O
therefore	O
the	O
function	O
you	O
apply	O
should	O
return	O
a	O
single	O
value	O
.	O

Apply	O
the	O
function	O
to	O
the	O
groups	O
:	O
#CODE	O

How	O
to	O
apply	O
a	O
function	O
(	O
BigramCollocationFinder	O
)	O
to	O
Pandas	O
DataFrame	B-API

I	O
want	O
to	O
adapt	O
this	O
function	O
to	O
my	O
Pandas	O
Dataframe	B-API
.	O

I	O
am	O
aware	O
of	O
the	O
apply	O
function	O
for	O
Pandas	O
Dataframes	O
,	O
but	O
can't	O
manage	O
to	O
get	O
it	O
work	O
.	O

If	O
you	O
want	O
to	O
apply	O
`	O
BigramCollocationFinder.from_words()	O
`	O
to	O
each	O
`	O
value	O
`	O
in	O
the	O
`	O
Body	O
`	O
`	O
column	O
,	O
you'd	O
have	O
to	O
do	O
:	O
#CODE	O

In	O
essence	O
,	O
`	O
apply	O
`	O
allows	O
you	O
to	O
loop	O
through	O
the	O
`	O
rows	O
`	O
and	O
provide	O
the	O
corresponding	O
`	O
value	O
`	O
of	O
the	O
`	O
Body	O
`	O
`	O
column	O
`	O
to	O
the	O
applied	O
function	O
.	O

`	O
Apply	O
`	O
function	O
over	O
rows	O
and	O
put	O
the	O
result	O
in	O
a	O
new	O
column	O
.	O

#CODE	O

You	O
could	O
also	O
do	O
apply	O
:	O
#CODE	O

For	O
my	O
data	O
set	O
(	O
with	O
tens	O
of	O
thousands	O
of	O
rows	O
)	O
,	O
this	O
is	O
somewhat	O
slow	O
,	O
and	O
I	O
understand	O
that	O
loops	O
should	O
be	O
avoided	O
when	O
possible	O
when	O
using	O
pandas	O
dataframes	O
.	O

I	O
feel	O
like	O
the	O
pandas	O
`	O
apply	O
`	O
function	O
may	O
be	O
able	O
to	O
do	O
what	O
I	O
need	O
,	O
but	O
I'm	O
at	O
a	O
loss	O
as	O
to	O
how	O
to	O
implement	O
it	O
.	O

`	O
apply	O
`	O
calls	O
`	O
tuple_to_timestamp	O
`	O
for	O
each	O
row	O
of	O
`	O
df	O
[	O
'	O
orig	O
']`	O
.	O

The	O
first	O
operation	O
can	O
be	O
done	O
with	O
an	O
`	O
apply	O
`	O
function	O
returning	O
a	O
series	O
(	O
see	O
the	O
accepted	O
answer	O
to	O
this	O
question	O
)	O
,	O
followed	O
by	O
a	O
horizontal	O
`	O
concat	O
`	O
operation	O
(	O
i.e.	O
,	O
with	O
`	O
axis=1	O
`)	O
.	O

I	O
have	O
a	O
groupby	B-API
object	O
I	O
apply	O
expanding	O
mean	O
to	O
.	O

However	O
I	O
want	O
that	O
calculation	O
over	O
another	O
series	O
/	O
group	O
at	O
the	O
same	O
time	O
.	O

Here	O
is	O
my	O
code	O
:	O
#CODE	O

Then	O
,	O
define	O
what's	O
a	O
'	O
win	O
'	O
,	O
calculate	O
overall	O
record	O
and	O
apply	O
`	O
expanding_mean	B-API
`	O
:	O
#CODE	O

I	O
have	O
already	O
asked	O
a	O
similar	O
question	O
here	O
but	O
couldn't	O
manage	O
to	O
apply	O
the	O
solution	O
for	O
my	O
problem	O
with	O
two	O
columns	O
.	O
