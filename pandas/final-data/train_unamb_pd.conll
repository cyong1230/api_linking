Can	O
pandas.concat	B-API
handle	O
non	O
float64	O
dtypes	B-API
?	O

You're	O
looking	O
for	O
an	O
[	O
`	O
expanding_mean	B-API
`]	O
(	O
#URL	O
)	O

You	O
can	O
always	O
`	O
pd.infer_freq	B-API
(	O
an_index	O
)`	O
if	O
you	O
need	O
to	O
re-infer	O
the	O
freqency	O
(	O
if	O
possible	O
)	O
.	O

actually	O
even	O
just	O
calling	O
`	O
df.isnull()	B-API
.sum()	B-API
`	O
takes	O
6.61ms	O

The	O
`	O
applymap	B-API
`	O
approach	O
consistently	O
seems	O
a	O
factor	O
of	O
2	O
or	O
so	O
faster	O
in	O
my	O
tests	O
,	O
but	O
YMMV	O
,	O
and	O
I'd	O
be	O
pretty	O
surprised	O
if	O
this	O
were	O
a	O
bottleneck	O
anyhow	O
.	O

Here	O
`	O
all_treatments.shape	O
=	O
(	O
53	O
,	O
12	O
)`	O
,	O
`	O
originalN	O
=	O
53	O
`	O
,	O
`	O
newN	O
=	O
64	O
`	O
,	O
`	O
all_treatments.loc	O
[	O
#URL	O
=	O
(	O
0	O
,	O
12	O
)`	O
,	O
`	O
all_treatments.loc	O
[	O
0	O
:	O
newrowcount	O
,	O
:]	O
.shape	B-API
=	O
(	O
12	O
,	O
12	O
)`	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_index	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
"	O

I	O
tried	O
`	O
df.hist()	B-API
`	O
.	O

Print	O
different	O
precision	O
by	O
column	O
with	O
pandas.DataFrame.to_csv()	B-API
?	O

If	O
so	O
,	O
I	O
read	O
in	O
those	O
same	O
fields	O
by	O
passing	O
`	O
dtype=float64	O
`	O
to	O
`	O
pd.read_csv	B-API
`	O
.	O

aha	O
drop_duplicates	B-API
,	O
didn't	O
know	O
about	O
that	O
one	O
,	O
thanks	O
!	O

More	O
generally	O
there	O
are	O
a	O
number	O
of	O
rolling-style	O
functions	O
to	O
handle	O
common	O
cases	O
and	O
a	O
`	O
rolling_apply	B-API
`	O
for	O
user	O
functions	O
.	O

of	O
`	O
df.loc	B-API
[	O
'	O
A	O
'	O
,	O
:]	O
`	O
.	O

`	O
.any()	B-API
`	O
returns	O
rows	O
of	O
boolean	O

`	O
DFdate.groupby	O
(	O
'	O
ID	O
')	O
.agg	B-API
(	O
lambda	O
col	O
:	O
col	O
[	O
col.notnull()	O
]	O
.head	B-API
(	O
1	O
))`	O

`	O
df	O
[	O
'	O
created_at	O
']	O
=	O
df	O
[	O
'	O
created_at	O
']	O
.apply	B-API
(	O
timeremap	O
)`	O

This	O
line	O
:	O
df	O
[	O
0	O
]=	O
df	O
[	O
0	O
]	O
.apply	B-API
(	O
pd.to_datetime	B-API
)	O
also	O
seems	O
to	O
be	O
wrong	O
it	O
seems	O
you	O
want	O
df	O
[	O
'	O
timestamp	O
']	O
=	O
df	O
[	O
'	O
timestamp	O
']	O
.	O

Out	O
[	O
26	O
]:	O
dtype	B-API
(	O
'	O
int64	O
')`	O
.	O

You're	O
looking	O
for	O
an	O
[	O
`	O
expanding_mean	B-API
`]	O
(	O
#URL	O
)	O

Clearly	O
I'm	O
missing	O
something	O
as	O
to	O
why	O
df.loc	B-API
[:	O
,	O
tuple	O
]	O
is	O
different	O
than	O
df	O
[	O
tuple	O
]	O
.	O

Try	O
`	O
.iloc	B-API
[	O
i-1	O
,	O
]`	O
and	O
`	O
.iloc	B-API
[	O
i	O
,	O
]`	O
instead	O
of	O
`	O
.iloc	B-API
[	O
i-1	O
,	O
:]	O
`	O
and	O
`	O
.iloc	B-API
[	O
i	O
,	O
:]	O
`	O
...	O

Is	O
there	O
a	O
way	O
to	O
write	O
percentages	O
in	O
Pandas	O
'	O
to_excel	B-API
?	O

For	O
example	O
,	O
`	O
X	O
[[	O
'	O
var2	O
'	O
,	O
'	O
var3	O
']]	O
.iloc	B-API
[[	O
0	O
,	O
1	O
]]	O
=	O
...	O

As	O
recommended	O
in	O
this	O
other	O
question	O
,	O
normally	O
I	O
would	O
skip	O
the	O
get_figure()	B-API
and	O
the	O
fig.savefig()	B-API
,	O
opting	O
instead	O
for	O
plt.savefig	B-API
,	O
but	O
I	O
am	O
making	O
multiple	O
figures	O
.	O

I'm	O
stuck	O
with	O
this	O
:	O
`	O
pd.concat	B-API
(	O
ndf	O
,	O
axis=1	O
)`	O

Note	O
#2	O
:	O
by	O
doing	O
an	O
implicit	O
"	O
right	O
=	O
1	O
-	O
left	O
"	O
,	O
I'm	O
assuming	O
that	O
no	O
ages	O
are	O
NaN	O
and	O
so	O
one	O
of	O
>	O
=	O
or	O
must	O
be	O
true	O
;	O
if	O
that's	O
not	O
certain	O
,	O
you	O
could	O
do	O
`	O
right	O
=	O
(	O
df	O
[	O
"	O
age	O
"]	O
.values	B-API
bins	O
[:	O
,	O
None	O
]	O
.T	B-API
.astype	B-API
(	O
int	O
)`	O
instead	O
.	O
)	O

I've	O
tried	O
reading	O
about	O
.loc	B-API
and	O
indexing	O
in	O
the	O
Pandas	O
documentation	O
and	O
failed	O
to	O
make	O
sense	O
of	O
it	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
`	O

Try	O
with	O
`	O
closed=	O
'	O
right	O
'`	O
on	O
the	O
call	O
to	O
`	O
date_range	B-API
`	O
.	O

However	O
,	O
on	O
a	O
10000	O
row	O
df	O
of	O
randn	B-API
,	O
this	O
is	O
almost	O
2000	O
times	O
faster	O
than	O
the	O
`	O
.apply	B-API
`	O
solution	O
above	O
:	O
3ms	O
vs	O
5850ms	O
.	O

Specify	O
float64	O
dtype	B-API
:	O
#CODE	O

Ah	O
,	O
yeah	O
,	O
I	O
just	O
re-wrote	O
the	O
answer	O
using	O
merge()	B-API
.	O

You	O
should	O
consider	O
using	O
`	O
pandas.melt	B-API
`	O
and	O
avoid	O
having	O
duplicate	O
columns	O
.	O

Note	O
that	O
`	O
df.filter	B-API
(	O
regex=	O
"	O
a	O
")`	O
is	O
equivalent	O
to	O
`	O
df	O
[[	O
'	O
a1	O
'	O
,	O
'	O
a2	O
'	O
,	O
'	O
a3	O
'	O
,	O
'	O
a4	O
']]`	O
#CODE	O

The	O
reason	O
is	O
because	O
internally	O
,	O
pandas	O
converts	O
a	O
regular	O
frequency	O
DatetimeIndex	B-API
to	O
PeriodIndex	O
to	O
hook	O
into	O
formatters	O
/	O
locators	O
in	O
pandas	O
,	O
and	O
currently	O
PeriodIndex	O
does	O
NOT	O
retain	O
timezone	O
information	O
.	O

Unfortunately	O
the	O
rolling_mean()	B-API
window	O
argument	O
only	O
accepts	O
integers	O
.	O

df_authors	O
=	O
pd.concat	B-API
([	O
df_addresses	O
,	O
df_authors	O
]	O
,	O
keys=	O
'	O
ISI_LOC	O
')	O

df.columns	O
=	O
df.iloc	B-API
[	O
idx_loc	O
]	O

Pandas	O
DataFrames	O
to_latex	B-API
:	O
how	O
to	O
fit	O
tables	O
on	O
a	O
page	O
?	O

@USER	O
--	O
`	O
np.diff	B-API
`	O
doesn't	O
seem	O
to	O
work	O
with	O
`	O
df.index	O
`	O
;	O
`	O
df.index.values	O
`	O
fixes	O
the	O
problem	O
though	O
...	O

Note	O
that	O
I	O
also	O
replaced	O
`	O
median()	B-API
`	O
by	O
`	O
last()	B-API
`	O
to	O
make	O
the	O
sorting	O
clearer	O
,	O
but	O
I	O
also	O
lose	O
entries	O
with	O
`	O
median()	B-API
`	O
.	O

How	O
to	O
modify	O
Pandas's	O
Read_html	B-API
user-agent	O
?	O

What	O
is	O
the	O
dtype	B-API
of	O
'	O
SMA_22	O
'	O
?	O

In	O
your	O
program	O
change	O
to	O
read_csv	B-API
.	O

I've	O
appended	O
your	O
comment	O
and	O
also	O
updated	O
with	O
the	O
newer	O
categorical	B-API
method	O
-	O
which	O
I	O
think	O
is	O
a	O
little	O
neater	O
:)	O
.	O

It	O
sounds	O
like	O
maybe	O
you	O
want	O
`	O
pandas.concat	B-API
`	O
?	O

well	O
,	O
pd.to_datetime	B-API
is	O
in	O
local	O
timezone	O
.	O

You	O
can	O
indeed	O
just	O
rely	O
on	O
`	O
.cummax()	B-API
`	O
with	O
`	O
.groupby()	B-API
`	O
and	O
`	O
.apply()	B-API
`	O
,	O
using	O
`	O
lambda	O
`	O
-	O
see	O
some	O
examples	O
:	O
#CODE	O

df.dtypes	B-API

So	O
now	O
,	O
the	O
dtypes	B-API
look	O
like	O
:	O
#CODE	O

iloc	B-API
should	O
be	O
in	O
0.11	O
btw	O
:	O
#URL	O

pd.read_csv	B-API
(	O
parse_dates	O
...	O
[	O
date_formatter	O
=])	O
returns	O
dtype	B-API
'	O
object	O
'	O
not	O
'	O
datetime64	O
'	O

This	O
is	O
a	O
string	O
I'm	O
getting	O
out	O
of	O
`	O
pandas.DataFrame.to_json()	B-API
`	O
,	O
putting	O
it	O
into	O
redis	O
,	O
getting	O
it	O
out	O
of	O
redis	O
elsewhere	O
,	O
and	O
trying	O
to	O
read	O
it	O
via	O
`	O
pandas.read_json()	B-API
`	O
:	O
#CODE	O

And	O
now	O
it's	O
getting	O
almost	O
2	O
times	O
faster	O
then	O
`	O
convert_objects	B-API
`	O
.	O

Is	O
this	O
page	O
also	O
documenting	O
Series.to_json()	B-API
in	O
addition	O
to	O
DataFrame.to_json()	B-API
?	O

The	O
DataFrame's	O
`	O
__getitem__	B-API
`	O
method	O
returns	O
a	O
different	O

You	O
can	O
check	O
`	O
.pivot	B-API
`	O
as	O
well	O
.	O

`	O
df.loc	B-API
[:	O
,	O
[	O
'	O
a	O
'	O
,	O
'	O
c	O
'	O
,	O
'	O
d	O
'	O
,	O
'	O
e	O
']]`	O

`	O
data.ix	O
[[	O
0	O
]	O
,	O
:]	O
.iloc	B-API
[:	O
,	O
0	O
]	O
.dtype	B-API
`	O
returns	O
the	O
right	O
dtype	B-API
,	O
but	O
`	O
data.ix	O
[[	O
]	O
,	O
:]	O
.iloc	B-API
[:	O
,	O
0	O
]	O
.dtype	B-API
`	O
does	O
not	O
.	O

I	O
am	O
appending	O
rows	O
to	O
a	O
`	O
HDFStore	B-API
`	O
with	O
`	O
append_as_multiple()	O
`	O
.	O

For	O
example	O
using	O
integers	O
in	O
a	O
DatetimeIndex	B-API
.	O

Also	O
,	O
reviewing	O
your	O
code	O
,	O
it	O
appears	O
that	O
you	O
are	O
specifying	O
your	O
`	O
iloc	B-API
`	O
columns	O
incorrectly	O
.	O

df.country	O
=	O
np.where	B-API
(	O
df.country	O
==	O
"	O
Australia	O
"	O
,	O
1	O
,	O
(	O
np.where	B-API
(	O
df.country	O
==	O
"	O
China	O
"	O
,	O
2	O
,	O
(	O
np.where	B-API
(	O
df.country	O
==	O
"	O
Japan	O
"	O
,	O
3	O
and	O
so	O
on	O
..	O
but	O
this	O
was	O
getting	O
way	O
long	O
.	O

That	O
was	O
supposed	O
to	O
be	O
`	O
dtype	B-API
`	O
not	O
`	O
dtypes	B-API
`	O
,	O
my	O
bad	O
,	O
sorry	O
.	O

Thanks	O
,	O
I	O
mistakenly	O
tried	O
using	O
.ix	B-API
[	O
'	O
False	O
']	O

pd.cut	B-API
worked	O
in	O
this	O
case	O
but	O
it's	O
good	O
to	O
learn	O
other	O
approaches	O
.	O

It	O
doesn't	O
seem	O
to	O
be	O
applying	O
ewma	B-API
on	O
[	O
2	O
,	O
4	O
]	O
or	O
[	O
2	O
,	O
2	O
,	O
4	O
]	O
.	O

To	O
avoid	O
this	O
`	O
.loc	B-API
`	O
syntax	O
is	O
used	O
.	O

`	O
_NDFrameIndexer	O
`'	O
s	O
`	O
__setitem__	B-API
`	O
is	O
a	O
different	O
story	O
.	O

I've	O
been	O
using	O
json_normalize	B-API
with	O
success	O
until	O
I	O
came	O
across	O
a	O
certain	O
json	O
.	O

Actually	O
I	O
was	O
imaging	O
there	O
may	O
be	O
something	O
like	O
`	O
pd.concat	B-API
([	O
#URL	O
...	O
)	O
.sum	B-API
(	O
axis=1	O
)	O
.....	O

Now	O
,	O
adding	O
the	O
cumsum	B-API
of	O
this	O
gets	O
you	O
the	O
result	O
you're	O
after	O
:	O
#CODE	O

And	O
`	O
df.groupby	B-API
(	O
'	O
age	O
')	O
.mean()	B-API
`	O
would	O
achieve	O
the	O
same	O
result	O
.	O

I	O
think	O
this	O
must	O
be	O
a	O
bug	O
with	O
MultiIndex.from_product()	B-API
because	O
the	O
long	O
version	O
,	O
using	O
MultiIndex.from_tuples()	B-API
works	O
:	O
#CODE	O

In	O
pandas	O
is	O
there	O
something	O
like	O
a	O
GroupBy.get_group	B-API
,	O
but	O
with	O
an	O
optional	O
default	O
value	O
?	O

Should	O
I	O
change	O
read_CSV	B-API
options	O
?	O

If	O
there	O
are	O
also	O
2-digit	O
variants	O
like	O
"	O
13	O
"	O
or	O
"	O
30	O
"	O
,	O
then	O
you	O
would	O
need	O
to	O
pass	O
a	O
more	O
complicated	O
regex	O
pattern	O
to	O
`	O
str.contains	B-API
`	O
.	O

dt_a1	O
=	O
dt_a.tolist()	O
#	O
yields	O
a	O
datetime	O
object	O
in	O
UTC	O
,	O
but	O
without	O
tzinfo	B-API

`	O
dtypes	B-API
:	O
float64	O
(	O
6	O
)	O
,	O
object	O
(	O
1	O
)`	O

I	O
was	O
trying	O
to	O
do	O
something	O
similar	O
with	O
`	O
ndimage.filters.generic_filter()	O
`	O
with	O
a	O
footprint	O
of	O
`	O
np.ones	B-API
(	O
consecutive	O
)`	O
and	O
playing	O
with	O
`	O
np.trim_zeros()	B-API
`	O
but	O
it	O
was	O
a	O
bit	O
far-fetched	O
.	O

`	O
.ix	B-API
`	O
and	O
`	O
.loc	B-API
`	O
are	O
equivalent	O
in	O
this	O
example	O
(	O
just	O
more	O
explicit	O
)	O
#CODE	O

This	O
looks	O
like	O
an	O
issue	O
with	O
spyder	O
being	O
unable	O
to	O
understand	O
the	O
dtype	B-API
,	O
not	O
sure	O
what	O
to	O
suggest	O
here	O
other	O
than	O
calling	O
`	O
print	O
`	O

resample()	B-API
is	O
expecting	O
:	O
if	O
isinstance	O
(	O
ax	O
,	O
DatetimeIndex	B-API
):	O
.....	O

poor	O
alignment	O
of	O
pandas.series	B-API
:	O
#URL	O

good	O
to	O
know	O
that	O
,	O
I'm	O
just	O
starting	O
with	O
pandas	O
,	O
i	O
will	O
read	O
the	O
doc	O
about	O
.loc	B-API
and	O
.iloc	B-API

Check	O
out	O
diff()	B-API
.	O

`	O
re.sub	O
`	O
is	O
a	O
resource	O
hog	O
compared	O
to	O
`	O
str.replace	B-API
`	O
.	O

Is	O
this	O
page	O
also	O
documenting	O
Series.to_json()	B-API
in	O
addition	O
to	O
DataFrame.to_json()	B-API
?	O

What	O
also	O
bothers	O
me	O
is	O
the	O
different	O
indexing	O
in	O
numpy.array	B-API
and	O
pandas.Panel	B-API
:	O
#CODE	O

Pandas	O
read_csv	B-API
not	O
recognizing	O
ISO8601	O
as	O
datetime	O
dtype	B-API

`	O
data=	O
pd.io.parsers.read_fwf	O
(	O
file	O
,	O
colspecs	O
=	O
([	O
79	O
,	O
81	O
]	O
,	O
[	O
87	O
,	O
90	O
])	O
,	O
header	O
=	O
None	O
,	O
dtype	B-API
=	O
{	O
0	O
:	O
np.str	O
,	O
1	O
:	O
np.str	O
}	O
)`	O

If	O
you're	O
on	O
0.15	O
,	O
then	O
it	O
has	O
new	O
and	O
improved	O
categorical	B-API
dtypes	B-API
that	O
were	O
only	O
introduced	O
fairly	O
recently	O
,	O
and	O
other	O
libraries	O
like	O
statsmodels	O
that	O
depend	O
on	O
pandas	O
probably	O
haven't	O
caught	O
up	O
yet	O
.	O

`	O
df.describe()	B-API
`	O
is	O
giving	O
different	O
results	O
compared	O
to	O
`	O
df.describe	B-API
`	O
.	O

What	O
is	O
the	O
``	O
dtype	B-API
``	O
of	O
your	O
'	O
datetime	O
'	O
column	O
?	O

We	O
can	O
do	O
this	O
using	O
`	O
np.r_	B-API
`	O
,	O
which	O
concatenates	O
arrays	O
:	O
#CODE	O

Have	O
you	O
tried	O
`	O
df.replace	B-API
(	O
'	O
SUPP	O
'	O
,	O
3.0	O
,	O
inplace=True	O
)`	O
?	O

It	O
sounds	O
like	O
what	O
you	O
are	O
looking	O
for	O
is	O
pd.rolling_mean	B-API
:	O
#CODE	O

How	O
can	O
I	O
access	O
multiple	O
columns	O
in	O
Pandas	O
0.15	O
DataFrame.resample	B-API
method	O
?	O

Note	O
,	O
I	O
added	O
1	O
to	O
the	O
`	O
pct_change()	B-API
`	O
method	O
because	O
it	O
computes	O
the	O
net	O
percent	O
change	O
.	O

df.dropna	B-API
(	O
subset	O
=[	O
'	O
tenant	O
']	O
,	O
inplace=True	O
)	O
works	O
.	O

`	O
pd.melt	B-API
`	O
it	O
is	O
!	O

I've	O
tried	O
appending	O
`	O
.any()	B-API
`	O
to	O
the	O
ends	O
of	O
the	O
`	O
contains()	B-API
`	O
statements	O
but	O
it	O
applies	O
the	O
`	O
Brand	O
`	O
label	O
to	O
every	O
row	O
.	O

I	O
think	O
you	O
can	O
just	O
write	O
`	O
df	O
[	O
"	O
y	O
"]	O
,	O
df	O
[	O
"	O
z	O
"]	O
=	O
zip	O
(	O
*df	O
[	O
"	O
x	O
"]	O
.apply	B-API
(	O
fn	O
))`	O
,	O
as	O
done	O
in	O
the	O
answer	O
to	O
[	O
this	O
question	O
]	O
(	O
#URL	O
)	O
.	O

``	O
pd.cut	B-API
``	O
is	O
often	O
used	O
for	O
this	O
as	O
well	O
(	O
and	O
you	O
can	O
specify	O
your	O
bins	O
)	O
,	O
see	O
here	O
:	O
#URL	O

@USER	O
is	O
this	O
solved	O
by	O
using	O
pd.concat	B-API
with	O
axis=1	O
i.e.	O
`	O
pd.concat	B-API
([	O
g	O
[	O
"	O
component	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)	O
,	O
g	O
[	O
"	O
gender	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)]	O
,	O
axis=1	O
)`	O
.	O

It	O
works	O
for	O
put()	B-API
but	O
not	O
for	O
append()	B-API
.	O

`	O
X	O
[	O
X.columns	O
-	O
Y.columns	O
]	O
.join	B-API
(	O
Y	O
)`	O

Try	O
`	O
pd.merge	B-API
(	O
A	O
,	O
A	O
,	O
...	O
)`	O
and	O
you'll	O
see	O
why	O
your	O
results	O
don't	O
work	O
.	O

Another	O
option	O
is	O
to	O
only	O
include	O
the	O
rows	O
that	O
have	O
a	O
value	O
:	O
"	O
df	O
[	O
df	O
[	O
'	O
FK_COL	O
']	O
.notnull()	B-API
]"	O
.	O

`	O
np.array	B-API
([	O
df	O
[	O
'	O
point	O
']])`	O
just	O
wraps	O
it	O
in	O
another	O
dimension	O
,	O
without	O
addressing	O
the	O
fundamental	O
object	O
dtype	B-API
issue	O
.	O

this	O
is	O
just	O
lnanenok's	O
answer	O
and	O
using	O
`	O
unstack()	B-API
`	O
to	O
make	O
it	O
more	O
readable	O
.	O
credit	O
should	O
go	O
to	O
lanenok	O
.	O

Atm	O
groupby.diff()	O
is	O
actually	O
doing	O
groupby.apply	B-API
(	O
pd.Series.diff	B-API
)	O
,	O
and	O
that's	O
usually	O
appears	O
to	O
be	O
slower	O
.	O

Because	O
to	O
me	O
it	O
seems	O
join()	B-API
handles	O
both	O
alignment	O
and	O
concatenation	O
in	O
one	O
go	O
.	O

That	O
wouldn't	O
help	O
here	O
because	O
I	O
am	O
using	O
merged_df.stack	O
(	O
0	O
)	O
.reset_index	B-API
(	O
1	O
)	O
in	O
a	O
pandas.merge	B-API
operation	O
....	O

yep	O
you	O
need	O
0.14.1	O
(	O
else	O
you	O
can	O
do	O
:	O
``	O
df.loc	B-API
[:	O
,	O
df.dtypes	B-API
!	O
=	O
'	O
object	O
']``)	O

And	O
then	O
calling	O
`	O
pd.merge	B-API
`	O
multiple	O
times	O
:	O
#CODE	O

The	O
final	O
result	O
is	O
equivalent	O
to	O
`	O
pd.Series	B-API
(	O
Counter	O
(	O
at_mentions.sum()	O
))`	O
.	O

`	O
sort_df	O
(	O
df	O
,	O
'	O
B	O
'	O
,	O
cmp	O
)	O
.drop_duplicates	B-API
(	O
'	O
A	O
'	O
,	O
take_last=True	O
)`	O
#CODE	O

@USER	O
OK	O
I	O
think	O
I	O
can	O
see	O
the	O
issue	O
with	O
my	O
code	O
,	O
`	O
df.ix	B-API
[((	O
df.mi.value_counts()	O
>	O
2	O
)	O
.index	B-API
)]	O
.dropna()	B-API
`	O
seems	O
to	O
give	O
you	O
what	O
you	O
want	O
.	O

Reindexing	O
produces	O
NaNs	O
because	O
they're	O
different	O
dtypes	B-API
.	O

I	O
don't	O
think	O
you	O
need	O
to	O
do	O
this	O
in	O
one	O
line	O
(	O
as	O
you	O
say	O
yourself	O
):	O
`	O
s	O
=	O
df	O
[	O
'	O
salary	O
']	O
;	O
df	O
[	O
'	O
salary	O
']	O
=	O
s.diff()	O
;	O
df	O
[	O
'	O
salary	O
']	O
.iloc	B-API
[	O
0	O
]	O
=	O
s.iloc	O
[	O
0	O
]`	O
.	O

Better	O
to	O
do	O
this	O
once	O
then	O
write	O
them	O
as	O
HDF5	O
files	O
;	O
they	O
come	O
already	O
blocked	O
by	O
dtypes	B-API
(	O
on	O
reading	O
)	O
.	O

I	O
guess	O
it	O
may	O
come	O
from	O
the	O
fact	O
that	O
`	O
pd.cut	B-API
`	O
is	O
optimized	O
to	O
work	O
on	O
columns	O
,	O
not	O
on	O
single	O
rows	O
...	O

Thanks	O
,	O
I	O
tried	O
something	O
similar	O
series1.divide	O
(	O
series2.reindex_like	O
(	O
series1+series2	O
)	O
.fillna	B-API
(	O
0	O
))	O
but	O
that	O
gave	O
a	O
slightly	O
different	O
result	O
.	O

I	O
noticed	O
that	O
`	O
DataFrame.to_html()	B-API
`	O
has	O
a	O
`	O
formatters	O
`	O
parameter	O
that	O
allows	O
one	O
to	O
do	O
just	O
that	O
,	O
mapping	O
different	O
formats	O
to	O
different	O
columns	O
.	O

But	O
`	O
df.iloc	B-API
[	O
5	O
]	O
[	O
'	O
B	O
']	O
=	O
'	O
three	O
'`	O
does	O
not	O
do	O
that	O
.	O

Hi	O
Matt	O
,	O
1	O
,	O
`	O
S4	O
`	O
is	O
the	O
`	O
numpy	O
`	O
`	O
dtype	B-API
`	O
for	O
`	O
string	O
`	O
.	O

pd.rolling_apply	B-API
(	O
df.exma	O
,	O
2	O
,	O
(	O
df.alpha	O
*	O
df.exma.shift	O
(	O
1	O
))	O
+	O
((	O
1	O
-	O
df.alpha	O
)	O
*	O
df.outperf	O
))	O

You	O
can	O
see	O
that	O
the	O
dtype	B-API
is	O
now	O
`	O
float32	O
`	O

When	O
putting	O
it	O
in	O
the	O
.ix	B-API
form	O
it	O
makes	O
much	O
more	O
sense	O
.	O

So	O
you	O
can	O
do	O
df2.shift	O
(	O
freq=	O
'	O
D	O
')	O
.stack	B-API
(	O
'	O
Trader	O
')	O
.	O

When	O
passing	O
`	O
aggfunc=	O
'	O
np.mean	B-API
'`	O
,	O
it	O
works	O
.	O

pandas	O
`	O
df.loc	B-API
[:	O
,	O
(	O
'	O
col_a	O
'	O
,	O
'	O
col_b	O
')]`	O

It	O
worked	O
both	O
your	O
way	O
and	O
this	O
one	O
:	O
`	O
df.to_csv	B-API
(	O
'	O
corr2.csv	O
'	O
,	O
sep=	O
'	O
\t	O
'	O
,	O
cols	O
=(	O
'	O
CO2abs	O
'	O
,	O
'	O
CO2corr	O
'))`	O

This	O
is	O
what	O
`	O
pct_change	B-API
`	O
is	O
doing	O
under	O
the	O
bonnet	O
.	O

s=	O
"	O
"	O
.join	B-API
(	O
x	O
)	O

As	O
I	O
mentioned	O
,	O
I	O
believe	O
that	O
the	O
bottleneck	O
is	O
not	O
Disk	O
I	O
/	O
O	O
but	O
rather	O
the	O
slowness	O
of	O
the	O
read_excel	B-API
package	O
.	O

Thanks	O
I	O
had	O
never	O
seen	O
this	O
before	O
:)	O
rolling_sum	B-API
could	O
also	O
be	O
useful	O
for	O
other	O
similar	O
problems	O
I	O
had	O
in	O
the	O
past	O
.	O

aha	O
drop_duplicates	B-API
,	O
didn't	O
know	O
about	O
that	O
one	O
,	O
thanks	O
!	O

I	O
tried	O
`	O
df.hist()	B-API
`	O
.	O

can	O
you	O
just	O
suggest	O
something	O
to	O
read	O
about	O
the	O
problem	O
`	O
to_datetime	B-API
`	O
,	O
or	O
when	O
do	O
I	O
need	O
it	O
??	O

Ok	O
,	O
I	O
tried	O
it	O
without	O
other	O
paratmeters	O
,	O
just	O
like	O
this	O
,	O
pd.merge	B-API
(	O
Up	O
[[	O
'	O
Gene_id	O
']]	O
,	O
annon	O
,	O
left_on=	O
'	O
Gene_id	O
'	O
,	O
right_on=	O
'	O
Gene_id	O
')	O
and	O
its	O
printing	O
out	O
the	O
header	O
from	O
df2	O
and	O
nothing	O
else	O
,	O
means	O
No	O
other	O
rows	O
..	O

import	O
pandas	O
as	O
pd	O
;	O
pd.concat	B-API
([	O
df1	O
,	O
s1	O
]);	O
Is	O
that	O
what	O
you're	O
looking	O
for	O
?	O

So	O
I	O
should	O
have	O
used	O
`	O
df.loc	B-API
`	O
**	O
not	O
**	O
`	O
df.iloc	B-API
`	O
.	O

Am	O
I	O
messing	O
up	O
`	O
pd.MultiIndex.from_product()	B-API
`	O
or	O
can	O
it	O
not	O
handle	O
being	O
passed	O
large	O
lists	O
?	O

I	O
print	O
out	O
the	O
objects	O
returned	O
by	O
`	O
read_csv	B-API
`	O
,	O
and	O
am	O
curious	O
about	O
the	O
differences	O
in	O
the	O
output	O
:	O

(	O
Note	O
:	O
this	O
is	O
wrong	O
-	O
bools	O
[	O
pd.isnull	B-API
(	O
df1	O
)	O
==	O
pd.isnull	B-API
(	O
df2	O
)]	O
=	O
False	O
)	O

IIUC	O
,	O
`	O
pivot_table	B-API
`	O
should	O
give	O
you	O
what	O
you	O
want	O
:	O
#CODE	O

i	O
guess	O
i'm	O
confused	O
.	O
are	O
these	O
so	O
big	O
that	O
using	O
`	O
iloc	B-API
`	O
won't	O
work	O
with	O
@USER	O
'	O
s	O
suggestions	O
?	O

I	O
am	O
particularly	O
talking	O
about	O
Pandas	O
version	O
0.11	O
as	O
I	O
am	O
busy	O
replacing	O
my	O
uses	O
of	O
.ix	B-API
with	O
either	O
.loc	B-API
or	O
.iloc	B-API
.	O

What	O
about	O
`	O
numpy.count_nonzero	B-API
`	O
:	O
#CODE	O

This	O
concats	O
correctly	O
:	O
`	O
df	O
=	O
pd.concat	B-API
([	O
room1	O
,	O
weather	O
]	O
,	O
axis=1	O
)`	O
.	O

to	O
ensure	O
the	O
conversion	O
uses	O
the	O
correct	O
dtype	B-API
.	O

dtypes	B-API
:	O
float64	O
(	O
1	O
)	O
,	O
object	O
(	O
3	O
)	O

However	O
,	O
adding	O
a	O
row	O
changes	O
dtype	B-API
to	O
float64	O
:	O
#CODE	O

Oh	O
,	O
I	O
didn't	O
know	O
about	O
`	O
diff()	B-API
`	O
.	O

Here	O
is	O
another	O
way	O
,	O
using	O
np.argmax	B-API
:	O
#CODE	O

I	O
thought	O
`	O
DF.apply	B-API
(	O
operator.itemgetter	O
(	O
-1	O
)	O
,	O
axis=1	O
)`	O
should	O
work	O
but	O
actually	O
it	O
won't	O
?	O

iloc()	B-API
works	O
.	O

freq_in_hertz	O
=	O
freqs	O
[	O
ind	O
[	O
ind1	O
]]	O
.mean()	B-API
`	O
.	O

```	O
In	O
[	O
15	O
]:	O
pd.to_timedelta	B-API
(	O
s.str.replace	O
(	O
'	O
hrs	O
'	O
,	O
'	O
h	O
'))	O

don't	O
have	O
a	O
usecase	O
handy	O
,	O
but	O
I'd	O
suspect	O
it's	O
:	O
`	O
df.loc	B-API
[(	O
df.index	O
[	O
'	O
a	O
']	O
<	O
something	O
&	O
df.index	O
[	O
'	O
b	O
']	O
<	O
another_thing	O
)]`	O

dtypes	B-API
are	O
different	O
:	O
#CODE	O

It	O
means	O
that	O
`	O
STORE	O
`	O
column	O
dtype	B-API
is	O
probably	O
float	O
,	O
try	O
`	O
df	O
[	O
'	O
STORE	O
']	O
=	O
df	O
[	O
'	O
STORE	O
']	O
.astype	B-API
(	O
int	O
)`	O
and	O
the	O
write	O
out	O
to	O
csv	O

I	O
think	O
`	O
get_value()	B-API
`	O
and	O
`	O
lookup()	B-API
`	O
is	O
faster	O
:	O
#CODE	O

IOW	O
:	O
`	O
first_two	O
=	O
df.iloc	B-API
[:	O
2	O
]`	O

If	O
I	O
understand	O
you	O
correctly	O
,	O
`	O
pivot_table	B-API
`	O
might	O
be	O
closer	O
to	O
what	O
you	O
need	O
:	O
#CODE	O

Can	O
you	O
do	O
a	O
df.dtypes	B-API
?	O

Now	O
the	O
`	O
date_range	B-API
`	O
behaviour	O
is	O
consistent	O
,	O
always	O
including	O
the	O
`	O
start	O
`	O
and	O
the	O
end	O
of	O
the	O
`	O
DatetimeIndex	B-API
`	O
always	O
=	O
`	O
end	O
`	O
.	O

`	O
.replace	B-API
(	O
'	O
[	O
\$	O
]'	O
,	O
`	O

I	O
am	O
contemplating	O
using	O
fromtxt	O
or	O
genfromtxt	B-API
to	O
read	O
the	O
file	O
in	O
,	O
then	O
pass	O
to	O
pandas	O

Also	O
I	O
know	O
this	O
must	O
be	O
possible	O
using	O
groupby.transform	B-API
.	O

The	O
only	O
potential	O
concern	O
is	O
the	O
change	O
of	O
`	O
dtype	B-API
`	O
,	O
`	O
x.dtype	O
`	O
is	O
`	O
dtype	B-API
(	O
'	O
float64	O
')`	O
,	O
while	O
`	O
y.dtype	O
`	O
is	O
`	O
dtype	B-API
(	O
'	O
object	O
')`	O
.	O

If	O
starting	O
from	O
`	O
idx	O
=	O
df	O
[[	O
"	O
col	O
A	O
"	O
,	O
"	O
col	O
B	O
"]]	O
.abs()	B-API
.idxmax	B-API
(	O
axis=1	O
)`	O

dtype	B-API
.	O

An	O
alternative	O
solution	O
,	O
it	O
uses	O
str.join	B-API
:	O
#CODE	O

of	O
the	O
dtype	B-API
:	O
#CODE	O

Here	O
it	O
is	O
:	O
{	O
dtype	B-API
(	O
'	O
int64	O
')	O
:	O
5074800	O
,	O
dtype	B-API
(	O
'	O
float64	O
')	O
:	O
1162129200	O
,	O
dtype	B-API
(	O
'	O
O	O
')	O
:	O
2369931600	O
}	O

I'm	O
not	O
completely	O
sure	O
I	O
understood	O
correctly	O
what	O
you	O
want	O
your	O
output	O
to	O
be	O
and	O
also	O
I	O
don't	O
think	O
using	O
`	O
dict	O
`	O
in	O
`	O
pandas.DataFrame	B-API
`	O
is	O
a	O
very	O
good	O
idea	O
in	O
general	O
.	O

I	O
did	O
it	O
using	O
df.groupby	B-API
(	O
df.index	O
)	O
.aggregate	B-API
(	O
np.sum	B-API
)	O
.	O

You	O
can	O
generate	O
the	O
counts	O
by	O
flattening	O
the	O
df	O
using	O
`	O
ravel	B-API
`	O
and	O
`	O
value_counts	B-API
`	O
,	O
from	O
this	O
you	O
can	O
construct	O
the	O
final	O
df	O
:	O
#CODE	O

Either	O
change	O
the	O
user	O
interface	O
so	O
that	O
`	O
filter_nan	O
`	O
is	O
an	O
additional	O
parameter	O
and	O
NaN	O
is	O
not	O
included	O
in	O
`	O
filter_list	O
`	O
,	O
or	O
else	O
check	O
`	O
pd.isnull	B-API
(	O
filter_list	O
)	O
.any()	B-API
`	O
and	O
handle	O
the	O
cases	O
accordingly	O
.	O

=	O
"	O
and	O
"	O
not_equal	B-API
"	O
in	O
pandas	O

Ouput	O
using	O
df.groupby	B-API
(	O
'	O
integer_id	O
')	O
.sum()	B-API
:	O
#CODE	O

(	O
There	O
is	O
both	O
`	O
Series.shift	B-API
`	O
and	O
`	O
DataFrame.shift	B-API
`	O
.	O
)	O
#CODE	O

df1.groupby	O
(	O
level=0	O
)	O
[	O
'	O
value	O
']	O
.apply	B-API
(	O
func	O
)`	O
let	O
me	O
know	O
if	O
this	O
works	O
for	O
you	O

@USER	O
is	O
this	O
solved	O
by	O
using	O
pd.concat	B-API
with	O
axis=1	O
i.e.	O
`	O
pd.concat	B-API
([	O
g	O
[	O
"	O
component	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)	O
,	O
g	O
[	O
"	O
gender	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)]	O
,	O
axis=1	O
)`	O
.	O

However	O
,	O
I	O
would	O
like	O
the	O
layout	O
to	O
be	O
generated	O
from	O
the	O
number	O
of	O
levels	O
in	O
the	O
categorical	B-API
conditioning	O
(	O
or	O
"	O
by	O
")	O
variable	O
(	O
s	O
)	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

@USER	O
i.e.	O
`	O
pd.concat	B-API
([	O
s1	O
,	O
s2	O
]	O
,	O
axis=1	O
)	O
.reset_index()	B-API
`	O

This	O
is	O
still	O
faster	O
then	O
using	O
np.loadtxt	B-API
(	O
iter	O
)	O

Does	O
your	O
dtype	B-API
happen	O
to	O
be	O
`	O
int32	O
`	O
?	O

I	O
don't	O
think	O
.shift()	B-API
works	O
in	O
this	O
case	O
as	O
'	O
rule3	O
'	O
is	O
a	O
calculated	O
column	O
with	O
each	O
row	O
value	O
dependant	O
on	O
the	O
previous	O
row	O
value	O
.	O

`	O
and	O
/	O
or	O
`	O
pd.rolling_std	B-API
=	O
...	O

dtypes	B-API
:	O
float64	O
(	O
4	O
)	O

`	O
df	O
[	O
'	O
Ck_SCR	O
']	O
=	O
df	O
[	O
'	O
Ck	O
']	O
.apply	B-API
(	O
getScoringFunction	O
(	O
Ck_dct	O
))`	O

Ideally	O
,	O
I	O
would	O
like	O
to	O
be	O
able	O
to	O
do	O
`	O
race1.index.hist()	O
`	O
or	O
`	O
race1.index.to_series()	O
.hist()	B-API
`	O
,	O
but	O
I	O
know	O
that	O
doesn't	O
work	O
.	O

Conversely	O
`	O
EArray	O
`	O
can	O
be	O
extended	O
with	O
the	O
`	O
.append()	B-API
`	O
method	O
.	O

Then	O
your	O
.ix	B-API
indexing	O
should	O
work	O
as	O
you'd	O
expect	O
.	O

This	O
is	O
a	O
typical	O
example	O
of	O
a	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

I	O
tried	O
using	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
isinstance	O
(	O
df	O
[	O
A	O
]	O
,	O
(	O
int	O
,	O
float	O
))	O
,	O
axis=1	O
)`	O
but	O
it	O
return	O
always	O
False	O
.	O

This	O
sounds	O
like	O
a	O
job	O
for	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

Fixing	O
them	O
with	O
fillna	B-API
(	O
0	O
)	O
and	O
.loc	B-API
solved	O
it	O
.	O

`	O
X	O
=	O
np.vstack	B-API
(	O
X.sum	O
(	O
axis=1	O
))`	O

You	O
need	O
special	O
methods	O
for	O
that	O
,	O
and	O
this	O
is	O
what	O
.isnull()	B-API
is	O
about	O
.	O

When	O
I	O
run	O
the	O
line	O
returnsDf.iloc	O
[	O
1	O
:]	O
=	O
returnsDf.iloc	O
[	O
1	O
:]	O
.shift()	B-API
*	O
np.exp	B-API
(	O
rollReturnRandomDf.iloc	O
[	O
1	O
:])	O
the	O
code	O
runs	O
but	O
not	O
additional	O
output	O
is	O
produced	O
?	O

`	O
print	O
(	O
dt.date	B-API
(	O
2014	O
,	O
1	O
,	O
4	O
)	O
,	O
8	O
)	O
in	O
tmp.index	O
`	O
should	O
NOT	O
be	O
`	O
True	O
`	O

Just	O
out	O
of	O
curiosity	O
does	O
the	O
following	O
work	O
:	O
`	O
result	O
=	O
pandas.merge	B-API
(	O
left	O
,	O
right	O
,	O
how=	O
'	O
left	O
'	O
,	O
left_on=	O
left.columns	O
[	O
0	O
]	O
,	O
right_on=	O
right.columns	O
[	O
0	O
])`	O
?	O

`	O
inds	O
=	O
pd.isnull	B-API
(	O
df	O
)	O
.any	B-API
(	O
1	O
)	O
.nonzero()	B-API
[	O
0	O
]`	O
#CODE	O

Or	O
`	O
pd.concat	B-API
([	O
dat1	O
,	O
dat2	O
]	O
,	O
axis=1	O
)`	O
in	O
this	O
case	O
.	O

One	O
option	O
using	O
`	O
df.reindex	B-API
`	O
:	O
#CODE	O

Jahresgang	O
=	O
pd.DataFrame	B-API
(	O
Exceldata	O
,	O
dtype=	O
'	O
float	O
')	O

Do	O
this	O
:	O
df.applymap	B-API
(	O
lambda	O
x	O
:	O
x.astype	O
(	O
int	O
))	O
.to_csv	B-API
(	O
'	O
mycsv.csv	O
')	O

Pandas	O
module	O
read_csv	B-API
reads	O
file	O
within	O
Eclipse+pydev	O
while	O
fail	O
if	O
I	O
run	O
standalone	O

This	O
was	O
added	O
in	O
[	O
`	O
0.17.0	O
`]	O
(	O
#URL	O
)	O
scroll	O
a	O
bit	O
further	O
down	O
for	O
the	O
bit	O
on	O
`	O
drop_duplicates	B-API
`	O

df.Date	O
=	O
df.Date.apply	O
(	O
lambda	O
x	O
:	O
dt.datetime.strptime	O
(	O
x	O
,	O
'	O
%Y	O
/	O
%m	O
/	O
%d	O
')	O
.date()	B-API
)	O

I'm	O
not	O
sure	O
why	O
the	O
x_axis	O
is	O
formatted	O
like	O
that	O
in	O
pandas	O
,	O
it's	O
possible	O
your	O
2	O
line	O
issue	O
is	O
because	O
matplotlib	O
doesn't	O
understand	O
datetime64	O
dtype	B-API
correctly	O
,	O
see	O
this	O
:	O
#URL	O

Here	O
is	O
another	O
way	O
to	O
do	O
it	O
using	O
`	O
pd.get_dummies()	B-API
`	O
.	O

The	O
output	O
from	O
the	O
pandas.merge	B-API
is	O
:	O

Trying	O
to	O
think	O
of	O
a	O
way	O
leverage	O
applymap	B-API
for	O
this	O
issue	O
but	O
not	O
sure	O
how	O
to	O
implement	O
.	O

If	O
I	O
coerce	O
the	O
datetime64	O
to	O
dtype	B-API
object	O
then	O
it	O
aggregates	O
as	O
intended	O
.	O

I	O
did	O
`	O
df.astype	B-API
(	O
float32	O
)	O
.diff()	B-API
`	O
and	O
it	O
worked	O
.	O

I	O
think	O
they'll	O
be	O
imported	O
as	O
NaNs	O
,	O
then	O
,	O
so	O
dropna()	B-API
might	O
do	O
the	O
trick	O
.	O

When	O
running	O
timeit's	O
on	O
numpy	O
ndarrays	O
or	O
matrices	O
of	O
dtype	B-API
int64	O
,	O
you	O
see	O
the	O
same	O
performance	O
lag	O
.	O

However	O
,	O
I	O
have	O
tried	O
doing	O
`	O
df1	O
[	O
'	O
binned_a	O
']	O
=	O
pd.Series	B-API
(	O
pd.qcut	B-API
(	O
df1	O
[	O
'	O
a	O
']	O
,	O
4	O
))`	O
and	O
still	O
no	O
result	O
...	O

To	O
make	O
a	O
bit	O
more	O
explicit	O
what	O
Quazi	O
posted	O
:	O
`	O
drop_duplicates()	B-API
`	O
is	O
what	O
you	O
need	O
.	O

Same	O
dtypes	B-API
for	O
every	O
column	O
.	O

Hopefully	O
some	O
help	O
:	O
`	O
grouped.size()	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
>	O
1	O
)`	O
,	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
do	O
this	O

The	O
way	O
I	O
got	O
it	O
to	O
work	O
anyway	O
was	O
by	O
doing	O
something	O
like	O
:	O
`	O
atom_col	O
=	O
'	O
*	O
'	O
.join	B-API
(	O
pd.Series	B-API
(	O
df	O
[	O
'	O
label	O
']))	O
.split	B-API
(	O
'	O
*	O
')	O
.unique()	B-API
`	O

The	O
`	O
.loc	B-API
`	O
syntax	O
for	O
extending	O
on	O
purpose	O
will	O
not	O
preserve	O
the	O
dtypes	B-API
in	O
a	O
multi-dtype	O
case	O
.	O

Specify	O
float64	O
dtype	B-API
:	O
#CODE	O

>>>	O
Why	O
is	O
python	O
in	O
the	O
"	O
for	O
i	O
in	O
df.iterrows()	B-API
:	O
"	O
still	O
executing	O
the	O
if-statement	O
on	O
the	O
whole	O
dataframe-level	O
instead	O
on	O
row-by-row	O
basis	O
.	O

or	O
`	O
.groupby	B-API
`	O
followed	O
by	O
`	O
.unstack	B-API
`	O
and	O
`	O
.fillna	B-API
`	O
:	O
#CODE	O

`'	O
,	O
'	O
.join	B-API
(	O
df	O
[	O
"	O
city	O
"]	O
.values	B-API
)`	O
--	O
this	O
will	O
return	O
a	O
comma-separated	O
string	O
.	O

You're	O
looking	O
for	O
`	O
df.replace	B-API
`	O

Can	O
I	O
do	O
this	O
with	O
a	O
rolling_apply	B-API
or	O
rolling_sum	B-API
?	O

@USER	O
oh	O
,	O
you're	O
looking	O
for	O
idxmax	B-API
so	O
:	O
`	O
df1.groupby	O
(	O
'	O
voting	O
')	O
.get_group	B-API
(	O
1	O
)	O
.mean()	B-API
.idxmax()	B-API
`	O
.	O

EDIT	O
:	O
Using	O
`	O
pd.merge	B-API
(	O
df1	O
,	O
df2	O
,	O
copy=False	O
)`	O
(	O
or	O
`	O
df1.merge	O
(	O
df2	O
,	O
copy=False	O
)`)	O
when	O
`	O
df1.dtype	O
!	O

`	O
df	O
[	O
'	O
max_bidhigh	O
']	O
=	O
pd.rolling_max	B-API
(	O
df	O
[	O
'	O
bidhigh	O
']	O
,	O
15	O
)	O
.shift	B-API
(	O
-14	O
)`	O
and	O

Then	O
you	O
can	O
reorder	O
the	O
columns	O
using	O
`	O
reindex_axis	B-API
`	O
:	O
#CODE	O

Pandas	O
-	O
Retrieve	O
Value	O
from	O
df.loc	B-API

or	O
simply	O
`	O
df.ix	B-API
[	O
0	O
,	O
'	O
A	O
']`	O

`	O
df.groupby	B-API
([	O
'	O
formation	O
'])	O
.aggregate	B-API
([	O
np.mean	B-API
,	O
np.size	O
])`	O
did	O
the	O
trick	O

SettingWitchCopyWarning	O
Pandas	O
using	O
.ix	B-API

Splitting	O
a	O
large	O
ndarray	B-API

As	O
of	O
version	O
`	O
0.17.0	O
`	O
you	O
can	O
do	O
this	O
using	O
`	O
dt.strftime	B-API
`	O
#CODE	O

Thanks	O
--	O
I	O
am	O
starting	O
to	O
think	O
that	O
I	O
can	O
do	O
this	O
with	O
`	O
pd.merge()	B-API
`	O
..	O

df	O
[	O
'	O
rolling_avg	O
']	O
=	O
pd.rolling_mean	B-API
(	O
df.price	O
,	O
n	O
,	O
1	O
)	O

in	O
viewlim_to_dt	B-API
(	O
self	O
)	O

Other	O
formulation	O
of	O
the	O
question	O
:	O
Why	O
is	O
python	O
in	O
the	O
"	O
for	O
i	O
in	O
df.iterrows()	B-API
:	O
"	O
still	O
executing	O
the	O
if-statement	O
on	O
the	O
whole	O
dataframe-level	O
instead	O
on	O
row-by-row	O
basis	O
.	O

`	O
df	O
[	O
'	O
exr_ln	O
']	O
=	O
df	O
[	O
'	O
exr	O
']	O
.map	B-API
(	O
math.log	O
)`	O

`	O
nx.set_edge_attributes	O
(	O
G	O
,	O
'	O
myattr	O
'	O
,	O
df	O
[	O
'	O
attribute	O
']	O
.astype	B-API
(	O
int	O
)	O
.to_dict()	B-API
)`	O
works	O
fine	O
but	O
then	O
`	O
nx.write_gexf()	O
`	O
complains	O
.	O

if	O
S	O
>	O
0	O
,	O
cost	O
=	O
(	O
M-A	O
)	O
.shift	B-API
(	O
1	O
)	O
*S	O

provides	O
integer	O
based	O
lookups	O
analogously	O
to	O
iloc	B-API

dtypes	B-API
:	O
object	O
(	O
3	O
)	O

I've	O
managed	O
to	O
read	O
them	O
into	O
numpy	O
using	O
numpy's	O
genfromtxt	B-API
,	O
but	O
I'm	O
not	O
sure	O
what	O
to	O
do	O
from	O
here	O
.	O

I've	O
explored	O
`	O
set_index()	B-API
`	O
,	O
`	O
replace()	B-API
`	O
,	O
`	O
to_datetime()	B-API
`	O
and	O
`	O
reindex()	B-API
`	O
and	O
possibly	O
some	O
others	O
but	O
non	O
seem	O
to	O
be	O
able	O
to	O
achieve	O
this	O
overwrite	O
.	O

`	O
df	O
[	O
'	O
timestamps	O
']	O
.tz_convert	B-API
(	O
'	O
US	O
/	O
Eastern	O
')`	O

Pandas	O
DataFrames	O
to_latex	B-API
:	O
how	O
to	O
fit	O
tables	O
on	O
a	O
page	O
?	O

df.groupBy	B-API
(	O
"	O
Type	O
")	O
.apply	B-API
(	O
lambda	O
x	O
:	O
(	O
x.Date	O
,	O
x.Number	O
))	O

have	O
you	O
tryed	O
`	O
print	O
type	O
(	O
float	O
(	O
'	O
-	O
1650.00	O
'	O
.replace	B-API
(	O
'	O
,	O
'	O
,	O
'')))`	O
?	O

You	O
can	O
do	O
this	O
using	O
`	O
date_range	B-API
`	O
easier	O
!	O

You	O
can	O
even	O
do	O
this	O
in	O
one	O
line	O
`	O
df	O
[	O
df	O
]	O
.stack()	B-API
.index	B-API
.tolist()	B-API
`	O
.	O

I	O
had	O
thought	O
of	O
shift()	B-API
and	O
diff()	B-API
,	O
but	O
realized	O
this	O
would	O
have	O
to	O
be	O
recursive	O
if	O
there	O
were	O
multiple	O
and	O
I	O
didn't	O
know	O
how	O
many	O
there	O
were	O
.	O

I'm	O
trying	O
to	O
generate	O
a	O
`	O
pandas.DateTimeIndex	B-API
`	O
with	O
a	O
samplefrequency	O
of	O
5120	O
Hz	O
.	O

I	O
recently	O
started	O
using	O
pandas	O
and	O
I	O
have	O
some	O
issue	O
regarding	O
date_range	B-API
.	O

for	O
passenger_index	O
,	O
passenger	O
in	O
df.iterrows()	B-API
:	O

To	O
expand	O
on	O
Tim's	O
idea	O
,	O
Example	O
:	O
`	O
df.drop	B-API
(	O
label	O
,	O
inplace=True	O
)`	O

`	O
object	O
`	O
is	O
the	O
correct	O
`	O
dtype	B-API
`	O
here	O
though	O
:	O
#URL	O
they	O
are	O
really	O
booleans	O
so	O
you	O
needn't	O
worry	O

It	O
is	O
also	O
used	O
like	O
this	O
in	O
methods	O
like	O
`	O
.mean	B-API
`	O
,	O
`	O
.prod	B-API
`	O
,	O
`	O
.any	B-API
`	O
,	O
`	O
.max	B-API
`	O
.	O

Then	O
its	O
simply	O
a	O
call	O
to	O
`	O
.stack()	B-API
`	O
and	O
some	O
basic	O
filtering	O
to	O
complete	O
.	O

`	O
df	O
[[	O
'	O
dservice	O
'	O
,	O
'	O
sservice	O
']]	O
=	O
df	O
[[	O
'	O
dport	O
'	O
,	O
'	O
sport	O
']]	O
.applymap	B-API
(	O
port_dict.get	O
)`	O

I	O
tried	O
using	O
the	O
pd.cut	B-API
:	O
#CODE	O

Note	O
instead	O
`	O
stacked.stack	O
(	O
level=1	O
)	O
.fillna	B-API
(	O
method=	O
'	O
ffill	B-API
')`	O

s=	O
"	O
"	O
.join	B-API
(	O
x	O
)	O

pandas.merge	B-API
is	O
adding	O
extra	O
rows	O

outage_by_hour_num.Time	O
=	O
pd.to_datetime	B-API
(	O
outage_by_hour_num.Time	O
)	O

`	O
MvT102	O
=	O
df.loc	B-API
[	O
df	O
[	O
'	O
MvT	O
']	O
==	O
102	O
]`	O

Change	O
in	O
PANDAS	O
.to_csv	B-API
default	O
formats	O
?	O

After	O
using	O
pd.get_dummies	B-API
,	O
it	O
has	O
300+	O
columns	O
,	O
for	O
example	O
#CODE	O

Have	O
a	O
general	O
question	O
on	O
assignments	O
with	O
indexing	O
/	O
slicing	O
using	O
.loc	B-API
.	O

The	O
`	O
df	O
[	O
'	O
A	O
']	O
[	O
10	O
]`	O
does	O
return	O
`'	O
a	O
'`	O
,	O
but	O
`	O
df	O
[	O
'	O
A	O
']	O
.ix	B-API
[	O
0	O
]`	O
throws	O
a	O
`	O
KeyError	O
:	O
0	O
`	O
.	O

I	O
ask	O
because	O
you	O
can	O
do	O
`	O
pd.read_clipboard()	B-API
`	O
in	O
`	O
pandas	O
`	O
and	O
there	O
is	O
this	O
question	O
:	O
#URL	O

You	O
need	O
to	O
do	O
an	O
assigment	O
like	O
`	O
df2	O
=	O
df.applymap	B-API
(	O
lambda	O
s	O
:	O
mymap.get	O
(	O
s	O
)	O
if	O
s	O
in	O
mymap	O
else	O
s	O
)`	O
.	O

Maybe	O
using	O
.ix	B-API
module	O
?	O

It	O
is	O
recommended	O
that	O
`	O
.loc	B-API
`	O
attribute	O
is	O
used	O
as	O
the	O
primary	O
label	O
based	O
access	O
method	O
to	O
avoid	O
problems	O
with	O
chained	O
assignment	O
.	O

(	O
And	O
in	O
case	O
you	O
are	O
wondering	O
,	O
the	O
`	O
ax.plot	O
`	O
stuff	O
is	O
equivalent	O
to	O
`	O
plt.plot	B-API
`	O
but	O
using	O
the	O
recommended	O
object-oriented	O
interface	O
.	O
)	O

Unfortunately	O
,	O
using	O
`	O
.ix	B-API
[	O
...	O
]`	O
still	O
seems	O
to	O
cause	O
nonsensical	O
axes-swapping	O
behavior	O
.	O

You	O
can	O
pass	O
a	O
delimiter	O
to	O
the	O
read_csv	B-API
method	O
but	O
in	O
your	O
case	O
,	O
since	O
the	O
delimiter	O
changes	O
by	O
file	O
,	O
you	O
want	O
to	O
pass	O
None	O
-	O
this	O
will	O
make	O
Pandas	O
auto-detect	O
the	O
correct	O
delimiter	O
.	O

Interestingly	O
,	O
the	O
`	O
object	O
`	O
dtype	B-API
in	O
pandas	O
is	O
a	O
NumPy	O
ndarray	B-API
which	O
holds	O
pointers	O
to	O
variable-length	O
string	O
items	O
.	O

@USER	O
btw	O
,	O
not	O
sure	O
why	O
,	O
but	O
`	O
read_fwf	B-API
`	O
doesn't	O
seem	O
to	O
support	O
`	O
dtype	B-API
`	O
even	O
though	O
it's	O
in	O
the	O
document	O
#URL	O

TypeError	O
:	O
map()	B-API
got	O
an	O
unexpected	O
keyword	O
argument	O
'	O
intializer	O
'`	O

So	O
are	O
you	O
looking	O
for	O
`	O
np.logical_or	B-API
((	O
df	O
>	O
0.4	O
)	O
,	O
(	O
df.shift()	B-API
>	O
=	O
0.3	O
))	O
.astype	B-API
(	O
int	O
)`	O
?	O

numpy.histogram	B-API

this	O
suggests	O
a	O
feature	O
:	O
``	O
.resample	B-API
(	O
'	O
D	O
'	O
,	O
how=	O
'	O
range	O
'	O
,	O
start=0	O
,	O
stop=3	O
)	O
.median()	B-API
``	O

Perform	O
read_clipboard	B-API
in	O
iPython	O
Qt	O
console	O
as	O
described	O
in	O
above	O
code	O
block	O

Ipython	O
:	O
`	O
pd.get_option	B-API
(	O
'	O
display.encoding	O
')	O
Out	O
[	O
141	O
]:	O
'	O
UTF-8	O
'`	O
.	O

force	O
datetime	O
conversion	O
,	O
coerce	O
datetime	O
dtype	B-API
,	O
with	O
read_table	B-API
in	O
pandas	O

do	O
this	O
:	O
``	O
df.ix	B-API
[	O
0	O
,	O
'	O
a	O
']	O
+=	O
1	O
``	O
.	O

I	O
tried	O
it	O
with	O
`	O
pd.read_clipboard()	B-API
`	O
from	O
the	O
OP	O
.	O
