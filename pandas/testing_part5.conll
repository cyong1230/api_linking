Replacing	O
item	O
values	O
in	O
a	O
data	O
frame	O
on	O
certain	O
condition	O
in	O
other	O
columns	O

I	O
have	O
a	O
pandas	O
data	O
frame	O
like	O
this	O
one	O
:	O
#CODE	O

There	O
are	O
two	O
sets	O
of	O
columns	O
:	O
dx	O
and	O
dxpoa	O
.	O

Depending	O
on	O
certain	O
values	O
in	O
dxpoa	O
,	O
I	O
have	O
to	O
keep	O
values	O
in	O
dx	O
or	O
discard	O
it	O
.	O

Foe	O
each	O
value	O
in	O
dx	O
there	O
is	O
a	O
value	O
in	O
corresponding	O
dxpoa	O
in	O
that	O
row	O
.	O

For	O
ex	O
:	O
If	O
dxpoa	O
=	O
[	O
'	O
Y'or	O
'	O
W	O
'	O
or	O
'	O
1	O
'	O
or	O
'	O
E	O
']	O
then	O
keep	O
dx	O
value	O
in	O
corresponding	O
row	O
otherwise	O
discard	O
it	O
or	O
fill	O
it	O
with	O
0	O
.	O

Like	O
dxpoa1	O
,	O
in	O
first	O
row	O
,	O
is	O
'	O
Y	O
'	O
therefore	O
dx1	O
will	O
remain	O
as	O
it	O
is	O
.	O

But	O
dxpoa1	O
,	O
in	O
second	O
row	O
,	O
is	O
'	O
N	O
'	O
therefore	O
corresponding	O
value	O
of	O
dx1	O
,	O
of	O
second	O
row	O
,	O
will	O
become	O
0	O
.	O

Did	O
you	O
already	O
try	O
anything	O
?	O

Are	O
you	O
facing	O
any	O
issues	O
there	O
?	O

@USER	O
:	O
I	O
can	O
change	O
value	O
of	O
a	O
column	O
in	O
a	O
row	O
but	O
don't	O
know	O
how	O
to	O
iterate	O
over	O
row	O
or	O
column	O
.	O

I	O
am	O
trying	O
to	O
use	O
iterrow()	O
function	O
.	O

But	O
handicapped	O
with	O
little	O
knowledge	O
of	O
python	O
.	O

Given	O
a	O
dataframe	B-API
built	O
like	O
so	O
:	O
#CODE	O

Which	O
gives	O
:	O
#CODE	O

Define	O
a	O
function	O
that	O
implements	O
your	O
substitution	O
rules	O
.	O

This	O
is	O
replaces	O
the	O
target	O
column	O
with	O
zero	O
when	O
the	O
value	O
in	O
the	O
reference	O
column	O
is	O
not	O
'	O
Y	O
'	O
,	O
'	O
W	O
'	O
,	O
'	O
1	O
'	O
or	O
'	O
E	O
'	O
,	O
as	O
I	O
understood	O
from	O
your	O
description	O
:	O
#CODE	O

Then	O
iterate	O
over	O
the	O
column	O
names	O
applying	O
subfunc	O
over	O
each	O
row	O
:	O
#CODE	O

Results	O
in	O
the	O
dataframe	B-API
#CODE	O

Here's	O
a	O
vectorized	O
way	O
of	O
looking	O
at	O
it	O
(	O
using	O
@USER	O
'	O
s	O
handy	O
starting	O
frame	O
):	O
#CODE	O

What	O
this	O
does	O
is	O
make	O
an	O
array	O
of	O
True	O
and	O
False	O
for	O
the	O
last	O
N	O
//	O
2	O
columns	O
,	O
with	O
True	O
where	O
the	O
value	O
is	O
in	O
the	O
list	O
and	O
False	O
where	O
it's	O
not	O
(	O
note	O
also	O
that	O
I'm	O
assuming	O
1	O
is	O
the	O
string	O
`"	O
1	O
"`	O
and	O
not	O
the	O
integer	O
`	O
1	O
`)	O
:	O
#CODE	O

Then	O
we	O
can	O
use	O
`	O
where	B-API
`	O
to	O
set	O
the	O
value	O
of	O
the	O
first	O
N	O
//	O
2	O
columns	O
,	O
keeping	O
the	O
values	O
where	O
`	O
keep	O
`	O
is	O
True	O
and	O
otherwise	O
replacing	O
them	O
with	O
0	O
.	O

split	O
dataframe	B-API
into	O
multiple	O
dataframes	O
based	O
on	O
number	O
of	O
rows	O

I	O
have	O
a	O
dataframe	B-API
`	O
df	O
`	O
:	O
#CODE	O

that	O
I	O
need	O
to	O
split	O
into	O
multiple	O
dataframes	O
that	O
will	O
contain	O
every	O
10	O
rows	O
of	O
`	O
df	O
`	O
,	O
and	O
every	O
small	O
dataframe	B-API
I	O
will	O
write	O
to	O
separate	O
file	O
.	O

so	O
I	O
decided	O
create	O
multilevel	O
dataframe	B-API
,	O
and	O
for	O
this	O
first	O
assign	B-API
the	O
index	O
to	O
every	O
10	O
rows	O
in	O
my	O
`	O
df	O
`	O
with	O
this	O
method	O
:	O
#CODE	O

that	O
throws	O
out	O
#CODE	O

so	O
have	O
you	O
idea	O
how	O
to	O
fix	O
it	O
?	O

where	O
my	O
method	O
is	O
wrong	O
?	O

but	O
if	O
you	O
have	O
another	O
approache	O
to	O
split	O
my	O
dataframe	B-API
into	O
multiple	O
dataframes	O
every	O
of	O
which	O
contains	O
10	O
rows	O
of	O
`	O
df	O
`	O
,	O
you	O
are	O
also	O
welcome	O
,	O
cause	O
this	O
approach	O
was	O
just	O
the	O
first	O
I	O
thought	O
about	O
,	O
but	O
I'm	O
not	O
sure	O
that	O
it's	O
the	O
best	O
one	O

You	O
can	O
use	O
a	O
dictionary	O
comprehension	O
to	O
save	O
slices	O
of	O
the	O
dataframe	B-API
in	O
groups	O
of	O
ten	O
rows	O
:	O
#CODE	O

There	O
are	O
many	O
ways	O
to	O
do	O
what	O
you	O
want	O
,	O
your	O
method	O
looks	O
over-complicated	O
.	O

A	O
groupby	B-API
using	O
a	O
scaled	O
index	O
as	O
the	O
grouping	O
key	O
would	O
work	O
:	O
#CODE	O

thanks	O
@USER	O
,	O
it's	O
exactly	O
what	O
I	O
was	O
looking	O
for	O
!!	O

groupby	B-API
common	O
values	O
in	O
two	O
columns	O

I	O
need	O
to	O
extract	O
a	O
common	O
max	O
value	O
from	O
pairs	O
of	O
rows	O
that	O
have	O
common	O
values	O
in	O
two	O
columns	O
.	O

The	O
commonality	O
is	O
between	O
values	O
in	O
columns	O
A	O
and	O
B	O
.	O

Rows	O
0	O
and	O
1	O
are	O
common	O
,	O
2	O
and	O
3	O
,	O
and	O
4	O
is	O
on	O
its	O
own	O
.	O

#CODE	O

The	O
goal	O
is	O
to	O
extract	O
max	O
values	O
,	O
so	O
the	O
end	O
result	O
is	O
:	O
#CODE	O

I	O
could	O
do	O
this	O
if	O
there	O
is	O
a	O
way	O
to	O
assign	B-API
a	O
common	O
,	O
non-repeating	O
key	O
:	O
#CODE	O

Following	O
up	O
with	O
the	O
groupby	B-API
and	O
transform	O
:	O
#CODE	O

Question	O
1	O
:	O

How	O
would	O
one	O
assign	B-API
this	O
common	O
key	O
?	O

Question	O
2	O
:	O

Is	O
there	O
a	O
better	O
way	O
of	O
doing	O
this	O
,	O
skipping	O
the	O
common	O
key	O
step	O

Cheers	O
...	O

You	O
could	O
sort	O
the	O
values	O
in	O
columns	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O
so	O
that	O
for	O
each	O
row	O
the	O
value	O
in	O
`	O
A	O
`	O
is	O
less	O
than	O
or	O
equal	O
to	O
the	O
value	O
in	O
`	O
B	O
`	O
.	O

Once	O
the	O
values	O
are	O
ordered	O
,	O
then	O
you	O
could	O
apply	B-API
`	O
groupby-transform-max	O
`	O
as	O
usual	O
:	O
#CODE	O

yields	O
#CODE	O

The	O
above	O
method	O
will	O
still	O
work	O
even	O
if	O
the	O
values	O
in	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O
are	O
strings	O
.	O

For	O
example	O
,	O
#CODE	O

yields	O
#CODE	O

Thanks	O
@USER	O
.	O

Is	O
there	O
a	O
similar	O
approach	O
with	O
the	O
strings	O
?	O

df	O
=	O
DataFrame	B-API
([[	O
'	O
ab	O
'	O
,	O
'	O
ac	O
'	O
,	O
30	O
]	O
,	O
[	O
'	O
ac	O
'	O
,	O
'	O
ab	O
'	O
,	O
20	O
]	O
,	O

[	O
'	O
cb	O
'	O
,	O
'	O
ca	O
'	O
,	O
15	O
]	O
,	O
[	O
'	O
ca	O
'	O
,	O
'	O
cb	O
'	O
,	O
70	O
]	O
,	O

[	O
'	O
ff	O
'	O
,	O
'	O
zz	O
'	O
,	O
35	O
]]	O
,	O
columns	O
=[	O
'	O
A	O
'	O
,	O
'	O
B	O
'	O
,	O
'	O
Value	O
'])	O

Ah	O
,	O
in	O
that	O
case	O
,	O
geometry	O
is	O
not	O
going	O
to	O
help	O
--	O
unless	O
you	O
convert	O
the	O
values	O
to	O
factors	O
first	O
.	O

But	O
that	O
would	O
probably	O
negate	O
the	O
speed	O
advantage	O
.	O

Used	O
Categorical	B-API
and	O
get_indexer	B-API
.	O

Seem	O
to	O
work	O
.	O

Thanks	O
for	O
help	O
.	O

c	O
=	O
pd.Categorical.from_array	O
(	O
df.A	O
)	O

idx	O
=	O
c.levels	O

df	O
[	O
'	O
A1	O
']	O
=	O
idx.get_indexer	O
(	O
df.A	O
)	O

df	O
[	O
'	O
B1	O
']	O
=	O
idx.get_indexer	O
(	O
df.B	O
)	O

That	O
may	O
not	O
work	O
since	O
`	O
idx.get_indexer	O
(	O
df.B	O
)`	O
will	O
return	O
-1	O
wherever	O
the	O
value	O
in	O
`	O
B	O
`	O
is	O
not	O
in	O
`	O
A	O
`	O
.	O

Thus	O
,	O
`	O
(	O
ff	O
,	O
zz	O
)`	O
and	O
`	O
(	O
ff	O
,	O
qq	O
)`	O
would	O
both	O
be	O
mapped	O
to	O
something	O
like	O
`	O
(	O
4	O
,	O
-1	O
)`	O
.	O

@USER	O
:	O
The	O
first	O
method	O
still	O
works	O
even	O
if	O
the	O
values	O
are	O
strings	O
.	O

It's	O
not	O
the	O
most	O
performant	O
,	O
but	O
there's	O
also	O
`	O
df	O
[	O
"	O
Value	O
"]	O
.groupby	B-API
(	O
map	B-API
(	O
frozenset	O
,	O
df	O
[[	O
"	O
A	O
"	O
,	O
"	O
B	O
"]]	O
.values	B-API
)	O
,	O
sort=False	O
)	O
.transform	O
(	O
max	O
)`	O
.	O

Looking	O
up	O
values	O
from	O
one	O
csv-file	O
in	O
another	O
csv-file	O
,	O
using	O
a	O
third	O
csv-file	O
as	O
map	B-API

I	O
didn't	O
quite	O
figure	O
how	O
to	O
formulate	O
this	O
question	O
,	O
suggestions	O
to	O
improve	O
the	O
title	O
is	O
welcome	O
.	O

I	O
have	O
three	O
files	O
:	O
e_data.csv	O
,	O
t_data.csv	O
and	O
e2d.csv	O
.	O

I	O
want	O
to	O
merge	B-API
`	O
e_id	O
`	O
,	O
`	O
t_id	O
`	O
,	O
`	O
gene_name	O
`	O
and	O
`	O
value	O
`	O
into	O
one	O
file	O
,	O
as	O
represented	O
by	O
desired_result.csv	O
.	O

The	O
naive	O
approach	O
is	O
as	O
follows	O
:	O

For	O
each	O
row	O
in	O
e_data.csv	O
,	O
extract	O
`	O
e_id	O
`	O
and	O
`	O
value	O
`	O
.	O

Check	O
e2t.csv	O
for	O
which	O
`	O
t_id	O
`	O
that	O
corresponds	O
to	O
the	O
given	O
`	O
e_id	O
`	O
.	O

Check	O
t_data.csv	O
for	O
which	O
`	O
gene_name	O
`	O
that	O
corresponds	O
to	O
the	O
given	O
`	O
t_id	O
`	O
.	O

Merge	B-API
them	O
all	O
to	O
one	O
file	O
.	O

Please	O
see	O
the	O
following	O
example	O
for	O
what	O
I'm	O
trying	O
to	O
achieve	O
:	O

e_data.csv	O
:	O
#CODE	O

e2t.csv	O
:	O
#CODE	O

t_data.csv	O
:	O
#CODE	O

desired_result.csv	O
:	O
#CODE	O

There's	O
no	O
limitation	O
to	O
which	O
tools	O
or	O
language	O
to	O
use	O
,	O
but	O
I	O
would	O
prefer	O
to	O
use	O
Python	O
,	O
as	O
that's	O
what	O
I'm	O
most	O
familiar	O
with	O
.	O

R	O
could	O
also	O
be	O
an	O
option	O
.	O

I've	O
already	O
implemented	O
a	O
solution	O
in	O
pure	O
Python	O
,	O
but	O
the	O
datasets	O
are	O
rather	O
large	O
,	O
and	O
I'm	O
hoping	O
something	O
like	O
Pandas	O
or	O
Numpy	O
can	O
speed	O
things	O
up	O
a	O
bit	O
.	O

Thanks	O
!	O

After	O
you	O
load	O
all	O
the	O
csvs	O
using	O
`	O
read_csv	B-API
`	O
you	O
can	O
just	O
iteratively	O
`	O
merge	B-API
`	O
them	O
so	O
long	O
as	O
the	O
column	O
names	O
are	O
consistent	O
:	O
#CODE	O

The	O
above	O
works	O
as	O
by	O
default	O
it	O
will	O
try	O
to	O
merge	B-API
on	O
matching	O
column	O
names	O
and	O
perform	O
an	O
inner	O
merge	B-API
so	O
the	O
column	O
values	O
must	O
match	O
on	O
lhs	O
and	O
rhs	O
.	O

Thanks	O
for	O
the	O
quick	O
reply	O
!	O

I	B-API
get	O
an	O
empty	O
DataFrame	B-API
when	O
trying	O
to	O
do	O
t_data.merge	O
(	O
e2t.merge	O
(	O
e_data	O
))	O
.	O

But	O
the	O
column	O
names	O
are	O
the	O
same	O
as	O
in	O
your	O
answer	O
.	O

Merging	O
e2t	O
and	O
e_data	O
works	O
,	O
however	O
.	O

I'll	O
look	O
into	O
the	O
documentation	O
on	O
merge	B-API
,	O
perhaps	O
I'm	O
doing	O
something	O
wrong	O
.	O

I'd	O
look	O
at	O
the	O
output	O
of	O
each	O
merge	B-API
,	O
also	O
you	O
don't	O
necessarily	O
need	O
to	O
merge	B-API
the	O
entire	O
df	O
to	O
debug	O
this	O
,	O
ie	O
.	O

`	O
e2t.iloc	O
[:	O
5	O
]	O
.merge	O
(	O
e_data.iloc	O
[:	O
5	O
])`	O
will	O
merge	B-API
just	O
the	O
first	O
5	O
lines	O

For	O
some	O
reason	O
,	O
e2t	O
and	O
t_data	O
won't	O
merge	B-API
in	O
my	O
example	O
,	O
which	O
is	O
identical	O
to	O
the	O
data	O
in	O
the	O
question	O
.	O

I	O
shouldn't	O
matter	O
that	O
the	O
the	O
position	O
of	O
the	O
t_id	O
column	O
is	O
different	O
in	O
the	O
two	O
files	O
,	O
right	O
?	O

On	O
my	O
real	O
data	O
it	O
works	O
,	O
however	O
,	O
and	O
I	O
have	O
to	O
say	O
,	O
it	O
is	O
lightning	O
fast	O
compared	O
to	O
my	O
pure	O
python	O
solution	O
.	O

position	O
doesn't	O
care	O
,	O
I'd	O
check	O
the	O
column	O
names	O
to	O
see	O
if	O
the	O
spelling	O
is	O
identical	O
`	O
e2t.columns.tolist()	O
`	O
and	O
`	O
t_date.columns.tolist()	O
`	O

Do	O
all	O
the	O
entries	O
in	O
the	O
DataFrames	O
have	O
to	O
be	O
the	O
same	O
data	O
type	O
?	O

If	O
I'm	O
changing	O
"	O
Gene1	O
"	O
etc	O
to	O
integers	O
(	O
or	O
,	O
conversely	O
,	O
the	O
IDs	O
to	O
strings	O
)	O
,	O
the	O
merge	B-API
goes	O
fine	O
.	O

Not	O
sure	O
,	O
I'd	O
imagine	O
it	O
will	O
either	O
barf	O
or	O
produce	O
a	O
mixed	O
dtype	B-API
column	O

OK	O
,	O
I	O
just	O
tried	O
this	O
,	O
the	O
dtypes	B-API
have	O
to	O
match	O
otherwise	O
you	O
get	O
an	O
empty	O
df	O
,	O
so	O
that's	O
your	O
problem	O

Yes	O
,	O
good	O
to	O
know	O
.	O

Thanks	O
for	O
helping	O
me	O
out	O
!	O

Python	O
-	O
Using	O
a	O
List	O
,	O
Dict	O
Comprehension	O
,	O
and	O
Mapping	O
to	O
Change	O
Plot	O
Order	O

I	O
am	O
relatively	O
new	O
to	O
Python	O
,	O
Pandas	O
,	O
and	O
plotting	O
.	O

I	O
am	O
looking	O
to	O
make	O
a	O
custom	O
sort	O
order	O
in	O
a	O
pandas	O
plot	O
using	O
a	O
list	O
,	O
mapping	O
,	O
and	O
sending	O
them	O
through	O
to	O
the	O
plot	O
function	O
.	O

I	O
am	O
not	O
"	O
solid	O
"	O
on	O
mapping	O
or	O
dict	O
comprehensions	O
.	O

I've	O
looked	O
around	O
a	O
bit	O
on	O
Google	O
and	O
haven't	O
found	O
anything	O
really	O
clear	O
-	O
so	O
any	O
direction	O
to	O
helpful	O
references	O
would	O
be	O
much	O
appreciated	O
.	O

I	O
have	O
a	O
dataframe	B-API
that	O
is	O
the	O
result	O
of	O
a	O
groupby	B-API
:	O
#CODE	O

The	O
numerical	O
column	O
is	O
'	O
Symbol	O
'	O
and	O
the	O
exchange	O
listing	O
is	O
the	O
index	O

When	O
I	O
do	O
a	O
straightforward	O
pandas	O
plot	O
#CODE	O

I	O
get	O
this	O
:	O

The	O
columns	O
are	O
in	O
the	O
order	O
of	O
the	O
rows	O
in	O
the	O
dataframe	B-API
(	O
Amex	O
,	O
NYSE	O
,	O
Nasdaq	O
)	O
but	O
I	O
would	O
like	O
to	O
present	O
,	O
left	O
to	O
right	O
,	O
NYSE	O
,	O
Nasdaq	O
,	O
and	O
Amex	O
.	O

So	O
a	O
"	O
sort	O
"	O
won't	O
work	O
.	O

There	O
is	O
another	O
post	O
:	O

Sorting	O
the	O
Order	O
of	O
Bars	O

that	O
gets	O
at	O
this	O
-	O
but	O
I	O
just	O
couldn't	O
figure	O
it	O
out	O
.	O

I	O
feel	O
like	O
the	O
solution	O
is	O
one	O
step	O
out	O
of	O
my	O
reach	O
.	O

I	O
think	O
this	O
is	O
a	O
very	O
important	O
concept	O
to	O
get	O
down	O
as	O
it	O
would	O
help	O
me	O
considerably	O
in	O
visualizing	O
data	O
where	O
the	O
not-infrequent	O
case	O
of	O
a	O
custom	O
row	O
presentation	O
in	O
a	O
chart	O
is	O
needed	O
.	O

I'm	O
also	O
hoping	O
discussion	O
here	O
could	O
help	O
me	O
better	O
understand	O
mapping	O
as	O
that	O
seems	O
to	O
be	O
very	O
useful	O
in	O
many	O
instances	O
but	O
I	O
just	O
can't	O
seem	O
to	O
find	O
the	O
right	O
on-line	O
resource	O
to	O
explain	O
it	O
clearly	O
.	O

Thank	O
you	O
in	O
advance	O
.	O

The	O
solution	O
to	O
your	O
problem	O
is	O
putting	O
your	O
output	O
dataframe	B-API
into	O
desired	O
order	O
:	O
#CODE	O

As	O
soon	O
as	O
you	O
have	O
the	O
rightly	O
ordered	O
data	O
you	O
can	O
plot	O
it	O
:	O
#CODE	O

Thanks	O
for	O
this	O
-	O
so	O
easy	O
and	O
yet	O
it	O
escaped	O
me	O
.	O

The	O
real	O
lesson	O
here	O
for	O
me	O
was	O
the	O
use	O
of	O
iloc	B-API
.	O

I'm	O
familiar	O
with	O
using	O
it	O
to	O
iterate	O
in	O
two	O
dimensions	O
(	O
e.g.	O
,	O
df.iloc	B-API
[	O
row	O
,	O
column	O
])	O
.	O

I	O
didn't	O
know	O
I	O
could	O
iterate	O
this	O
way	O
where	O
a	O
column	O
is	O
specified	O
.	O

Makes	O
it	O
super	O
simple	O
.	O

Thanks	O
again	O
!	O

Finding	O
index	O
of	O
a	O
pandas	O
DataFrame	B-API
value	O

I	O
am	O
trying	O
to	O
process	O
some	O
.csv	O
data	O
using	O
pandas	O
,	O
and	O
I	O
am	O
struggling	O
with	O
something	O
that	O
I	O
am	O
sure	O
is	O
a	O
rookie	O
move	O
,	O
but	O
after	O
spending	O
a	O
lot	O
of	O
time	O
trying	O
to	O
make	O
this	O
work	O
,	O
I	O
need	O
your	O
help	O
.	O

Essentially	O
,	O
I	O
am	O
trying	O
to	O
find	O
the	O
index	O
of	O
a	O
value	O
within	O
a	O
dataframe	B-API
I	O
have	O
created	O
.	O

#CODE	O

The	O
maxindex	O
variable	O
gets	O
me	O
the	O
answer	O
using	O
idxmax()	B-API
,	O
but	O
what	O
if	O
I	O
am	O
not	O
looking	O
for	O
the	O
index	O
of	O
a	O
max	O
value	O
?	O

What	O
if	O
it	O
is	O
some	O
random	O
value's	O
index	O
that	O
I	O
am	O
looking	O
at	O
,	O
how	O
would	O
I	O
go	O
about	O
it	O
?	O

Clearly	O
.index	B-API
does	O
not	O
work	O
for	O
me	O
here	O
.	O

Thanks	O
in	O
advance	O
for	O
any	O
help	O
!	O

Does	O
this	O
dataframe	B-API
have	O
only	O
1	O
column	O
or	O
do	O
you	O
know	O
which	O
column	O
has	O
the	O
max	O
value	O
?	O

if	O
you	O
know	O
the	O
column	O
then	O
`	O
df.loc	B-API
[	O
df.col	O
==	O
max	O
]	O
.index	B-API
`	O
would	O
return	O
you	O
the	O
index	O

Hi	O
EdChum	O
,	O
thanks	O
for	O
your	O
answer	O
.	O

Doing	O
this	O
gives	O
me	O
the	O
following	O
error	O

`	O
Traceback	O
(	O
most	O
recent	O
call	O
last	O
):	O

File	O
"	O
psims2.py	O
"	O
,	O
line	O
81	O
,	O
in	O

print	O
cd_gross_revenue.loc	O
[	O
cd_gross_revenue.col	O
==	O
max	O
]	O
.index	B-API

File	O
"	O
C	O
:\	O
Python27\lib\	O
site-packages	O
\	O
pandas-0.14.1-py2.7-win32.egg	O
\pandas\core\	O
generic.py	O
"	O
,	O
line	O
18	O

43	O
,	O
in	O
__getattr__	O

(	O
type	O
(	O
self	O
)	O
.__name__	O
,	O
name	O
))	O

AttributeError	O
:	O
'	O
Series	B-API
'	O
object	O
has	O
no	O
attribute	O
'	O
col	O
'`	O

I	O
think	O
you	O
misunderstand	O
,	O
`	O
col	O
`	O
was	O
a	O
generic	O
name	O
for	O
your	O
column	O
of	O
interest	O
so	O
substitute	O
the	O
column	O
name	O
with	O
the	O
one	O
from	O
your	O
df	O
,	O
my	O
question	O
is	O
how	O
many	O
columns	O
does	O
this	O
df	O
have	O
and	O
is	O
there	O
only	O
1	O
or	O
do	O
you	O
know	O
which	O
column	O
has	O
the	O
max	O
value	O
,	O
if	O
so	O
the	O
subsitute	O
`	O
col	O
`	O
with	O
that	O
name	O

Use	O
a	O
boolean	O
mask	O
to	O
get	O
the	O
rows	O
where	O
the	O
value	O
is	O
equal	O
to	O
the	O
random	O
variable	O
.	O

Then	O
use	O
that	O
mask	O
to	O
index	O
the	O
dataframe	B-API
or	O
series	B-API
.	O

Then	O
you	O
would	O
use	O
the	O
`	O
.index	B-API
`	O
field	O
of	O
the	O
pandas	O
dataframe	B-API
or	O
series	B-API
.	O

An	O
example	O
is	O
:	O
#CODE	O

Hi	O
Daniel	O
,	O
thanks	O
for	O
your	O
response	O
,	O
this	O
worked	O
!	O

When	O
you	O
called	O
idxmax	B-API
it	O
returned	O
the	O
key	O
in	O
the	O
index	O
which	O
corresponded	O
to	O
the	O
max	O
value	O
.	O

You	O
need	O
to	O
pass	O
that	O
key	O
to	O
the	O
dataframe	B-API
to	O
get	O
that	O
value	O
.	O

#CODE	O

`	O
s	O
[	O
s	O
==	O
13	O
]`	O

Is	O
all	O
you	O
need	O
.	O

from	O
pandas	O
import	O
Series	B-API
#CODE	O

Yields	O
#CODE	O

filling	O
data	O
gaps	O
with	O
monthly	O
averages	O
(	O
Python	O
)	O

I	O
have	O
a	O
very	O
long	O
time	O
series	B-API
over	O
10	O
years	O
with	O
half-hourly	O
measurements	O
as	O
Csv	O
file	O
.	O

Every	O
now	O
and	O
then	O
the	O
measurement	O
device	O
break	O
down	O
.	O

I	O
want	O
to	O
interpolate	B-API
this	O
gaps	O
either	O
with	O
the	O
monthly	O
average	O
or	O
a	O
moving	O
average	O
(	O
which	O
neglect	O
missing	O
values	O
)	O
.	O

I	O
guess	O
I	O
need	O
a	O
for-loop	O
to	O
do	O
this	O
but	O
I	O
have	O
no	O
Idea	O
how	O
to	O
do	O
this	O
exactly	O
.	O

Could	O
anybody	O
help	O
me	O
?	O

My	O
data	O
look	O
like	O
this	O
:	O
#CODE	O

my	O
current	O
code	O
is	O
:	O
#CODE	O

So	O
i	O
get	O
the	O
daily	O
sum	O
of	O
my	O
evaporation	O
data	O
.	O

I	O
can	O
resample	B-API
the	O
monthly	O
daily	O
average	O
as	O
well	O
but	O
I	O
don't	O
know	O
how	O
to	O
tell	O
Python	O
it	O
need	O
to	O
use	O
for	O
each	O
gap	O
the	O
meanvalue	O
for	O
this	O
specific	O
month	O
.	O

I'd	O
propose	O
to	O
interpolate	B-API
the	O
missing	O
values	O
from	O
the	O
two	O
surrounding	O
values	O
;	O
that	O
should	O
be	O
closer	O
to	O
the	O
real	O
missing	O
value	O
than	O
a	O
monthly	O
average	O
.	O

In	O
case	O
you've	O
got	O
your	O
values	O
in	O
a	O
list	O
(	O
alas	O
,	O
you	O
didn't	O
state	O
your	O
data	O
structures	O
)	O
of	O
tuples	O
`	O
(	O
timestamp	O
,	O
value	O
)`	O
:	O
#CODE	O

This	O
will	O
print	O
#CODE	O

well	O
,	O
I	O
have	O
a	O
csv	O
file	O
with	O
160,000	O
entries	O
.	O

The	O
missing	O
values	O
are	O
somtimes	O
several	O
days	O
(	O
which	O
means	O
one	O
day	O
=	O
48	O
measurements	O
which	O
are	O
missing	O
)	O
,	O
sometimes	O
several	O
weeks	O
.	O

I	O
think	O
this	O
solution	O
is	O
only	O
for	O
a	O
short	O
series	B-API
,	O
isn't	O
it	O
?	O

I	O
don't	O
see	O
a	O
reason	O
why	O
even	O
a	O
million	O
entries	O
should	O
pose	O
a	O
problem	O
.	O

But	O
of	O
course	O
,	O
interpolation	O
won't	O
simulate	O
typical	O
daily	O
curves	O
.	O

You	O
will	O
get	O
a	O
straight	O
line	O
from	O
one	O
existing	O
point	O
to	O
the	O
next	O
only	O
.	O

Okay	O
thanks	O
for	O
your	O
effort	O
!	O

As	O
far	O
as	O
i	O
understand	O
it	O
,	O
it	O
build	O
averages	O
from	O
the	O
last	O
known	O
value	O
and	O
the	O
next	O
value	O
after	O
the	O
gap	O
,	O
correct	O
?	O

I	O
have	O
two	O
Questions	O
:	O
1	O
)	O
is	O
it	O
possible	O
to	O
fill	O
the	O
gap	O
with	O
the	O
monthly	O
average	O
(	O
or	O
30	O
day	O
moving	O
average	O
)	O
,	O
because	O
this	O
would	O
be	O
more	O
accurate	O
?	O

2	O
)	O
My	O
data	O
are	O
originally	O
in	O
a	O
csv	O
file	O
which	O
i	O
need	O
to	O
import	O
to	O
python	O
.	O

If	O
i	O
use	O
"	O
data	O
=	O
pd.read_csv	B-API
(	O
'	O
ET_T_2000.csv	O
'	O
,	O
sep=	O
'	O
;	O
'	O
,	O
parse_dates	O
=[[	O
'	O
date	O
'	O
,	O
'	O
time	O
']])	O
I	O
get	O
an	O
error	O
"	O
KeyError	O
:	O
u'no	O
item	O
named	O
187055	O
'"	O
.	O
the	O
csv	O
file	O
has	O
187057	O
rows	O
.	O

do	O
you	O
have	O
any	O
idea	O
how	O
to	O
fix	O
it	O
?	O

Of	O
course	O
you	O
can	O
compute	O
a	O
monthly	O
average	O
and	O
use	O
this	O
to	O
fill	O
any	O
gap	O
,	O
but	O
that's	O
more	O
complicated	O
(	O
and	O
this	O
is	O
not	O
a	O
site	O
for	O
developing	O
solutions	O
but	O
just	O
for	O
answers	O
to	O
questions	O
)	O
.	O

Concerning	O
the	O
KeyError	O
:	O
sounds	O
like	O
another	O
question	O
you	O
should	O
ask	O
here	O
(	O
do	O
not	O
mix	O
all	O
problems	O
into	O
one	O
question	O
;-)	O

Note	O
:	O
This	O
should	O
be	O
a	O
comment	O
but	O
I	O
don't	O
have	O
the	O
rep	O
for	O
it	O
:)	O

Pandas	O
has	O
a	O
nice	O
'	O
interpolate	B-API
'	O
function	O
on	O
both	O
series	B-API
and	O
dataframes	O
:	O
(	O
#URL	O
)	O
.	O

I'm	O
going	O
to	O
suggest	O
,	O
especially	O
if	O
you	O
have	O
'	O
several	O
days	O
'	O
of	O
missing	O
data	O
,	O
that	O
you	O
just	O
leave	O
the	O
values	O
as	O
NaNs	O
(	O
#URL	O
)	O
.	O

Pandas	O
has	O
really	O
nice	O
support	O
for	O
plots	O
with	O
NA	O
values	O
and	O
seeing	O
a	O
plot	O
that	O
has	O
the	O
correct	O
measurement	O
values	O
and	O
then	O
a	O
'	O
gap	O
'	O
is	O
easily	O
to	O
interpret	O
.	O

Also	O
that	O
approach	O
gives	O
additional	O
information	O
,	O
lets	O
say	O
that	O
you're	O
looking	O
at	O
the	O
plots	O
and	O
you	O
see	O
that	O
the	O
weekends	O
have	O
more	O
gaps	O
than	O
other	O
days	O
,	O
that	O
might	O
indicate	O
the	O
measure	O
device	O
is	O
less	O
stable	O
on	O
the	O
weekend	O
(	O
or	O
whatever	O
)	O
.	O

Yes	O
,	O
thank	O
you	O
.	O

I	O
know	O
this	O
interpolation	O
function	O
of	O
pandas	O
,	O
but	O
it	O
uses	O
only	O
some	O
values	O
before	O
and	O
after	O
the	O
gap	O
.	O
this	O
is	O
too	O
inaccurate	O
.	O
the	O
data	O
represant	O
evaporation	O
in	O
a	O
forest	O
.	O

If	O
for	O
some	O
days	O
the	O
device	O
broke	O
down	O
and	O
it	O
interpolate	B-API
just	O
the	O
values	O
before	O
and	O
after	O
the	O
gap	O
then	O
I	O
don't	O
get	O
the	O
course	O
over	O
the	O
day	O
and	O
it's	O
in	O
general	O
to	O
inaccurate	O
.	O

I	O
agree	O
that	O
for	O
your	O
use	O
case	O
interpolation	O
might	O
not	O
be	O
what	O
you	O
want	O
that's	O
why	O
I	O
suggested	O
just	O
leaving	O
the	O
data	O
as	O
NA	O
values	O
.	O

Pandas	O
has	O
great	O
support	O
for	O
it	O
and	O
functions	O
like	O
'	O
mean	O
,	O
min	O
,	O
max	O
,	O
std	O
'	O
will	O
all	O
work	O
well	O
(	O
do	O
the	O
right	O
thing	O
)	O
with	O
NA	O
values	O
.	O

If	O
you	O
replace	O
the	O
missing	O
values	O
with	O
'	O
monthly	O
average	O
'	O
than	O
all	O
of	O
those	O
stats	O
will	O
be	O
incorrect	O
.	O

With	O
such	O
big	O
gaps	O
of	O
missing	O
values	O
,	O
I	O
guess	O
you're	O
really	O
better	O
off	O
,	O
to	O
keep	O
them	O
as	O
NANs	O
,	O
and	O
adjust	O
your	O
calculations	O
,	O
that	O
they	O
can	O
deal	O
with	O
missing	O
data	O
.	O

Looks	O
like	O
you're	O
doing	O
financial	O
simulations	O
with	O
it	O
,	O
and	O
in	O
the	O
long	O
run	O
,	O
it	O
will	O
always	O
backfire	O
,	O
if	O
you	O
modify	O
the	O
actual	O
raw	O
data	O
.	O

In	O
case	O
you're	O
using	O
Numpy	O
for	O
the	O
calculations	O
,	O
Bottleneck	O
adds	O
a	O
bunch	O
of	O
modified	O
functions	O
,	O
that	O
skip	O
NAN	O
values	O
in	O
arrays	O
,	O
e.g.	O
when	O
calculating	O
means	O
and	O
so	O
on	O
.	O

Better	O
go	O
on	O
with	O
that	O
!	O

Don't	O
whatever	O
you	O
do	O
,	O
change	O
your	O
source	O
data	O
:	O
always	O
keep	O
original	O
data	O
as	O
it	O
is	O
.	O

Any	O
consumers	O
of	O
the	O
data	O
can	O
then	O
decide	O
on	O
a	O
particular	O
interpolation	O
scheme	O
relevant	O
to	O
what	O
the	O
data	O
are	O
showing	O
and	O
what	O
they	O
intend	O
to	O
do	O
with	O
it	O
.	O

In	O
particular	O
,	O
if	O
you	O
are	O
doing	O
some	O
volatility	O
analysis	O
of	O
the	O
data	O
then	O
your	O
putting	O
in	O
interpolated	O
values	O
will	O
have	O
the	O
effect	O
of	O
artificially	O
reducing	O
that	O
volatility	O
.	O

(	O
PS	O
you	O
say	O
you	O
have	O
a	O
Character	O
Separated	O
Value	O
file	O
,	O
but	O
what	O
is	O
the	O
delimiter	O
?	O
)	O

the	O
delimiter	O
is	O
"	O
;	O
"	O
.	O

I	O
need	O
to	O
interpolate	B-API
it	O
cause	O
I	O
want	O
to	O
sum	O
up	O
all	O
values	O
per	O
year	O
to	O
create	O
a	O
water	O
balance	O
.	O

This	O
values	O
are	O
evaporation	O
data	O
.	O

If	O
i	O
build	O
a	O
cumulative	O
sum	O
for	O
a	O
year	O
with	O
so	O
many	O
missing	O
values	O
,	O
the	O
sum	O
will	O
be	O
much	O
to	O
less	O
below	O
the	O
real	O
evaporation	O
.	O

So	O
I	O
need	O
to	O
interpolate	B-API
.	O

(	O
I	O
don't	O
see	O
any	O
delimiters	O
in	O
the	O
file	O
)	O
.	O

In	O
this	O
case	O
then	O
,	O
consider	O
computing	O
your	O
sum	O
(	O
`	O
s	O
`)	O
and	O
the	O
number	O
of	O
recorded	O
times	O
(	O
`	O
t	O
`)	O
and	O
scaling	O
that	O
to	O
the	O
whole	O
year	O
using	O
`	O
s	O
*	O
p	O
/	O
t	O
`	O
where	B-API
`	O
p	O
`	O
is	O
the	O
potential	O
number	O
of	O
records	O
.	O

Maybe	O
you	O
should	O
sum	O
the	O
existing	O
values	O
,	O
count	O
them	O
and	O
then	O
use	O
their	O
mean	O
value	O
to	O
estimate	O
what	O
the	O
sum	O
for	O
a	O
complete	O
year	O
would	O
have	O
been	O
.	O

Interpolating	O
here	O
could	O
grossly	O
falsify	O
the	O
value	O
if	O
data	O
dropout	O
is	O
correlated	O
to	O
extreme	O
values	O
(	O
e	O
.	O
g	O
.	O
if	O
the	O
sensor	O
always	O
breaks	O
when	O
the	O
water	O
is	O
extremely	O
high	O
)	O
because	O
then	O
the	O
interpolation	O
would	O
extend	O
the	O
extreme	O
value	O
to	O
a	O
longer	O
time	O
period	O
than	O
it	O
actually	O
was	O
.	O

how	O
to	O
Join	O
2	O
columns	O
in	O
numpy	O
when	O
they	O
are	O
list	O
of	O
lists	O
?	O

Dataframe	B-API
is	O
:	O
#CODE	O

The	O
convenient	O
way	O
,	O
but	O
slow	O
way	O
,	O
is	O
to	O
use	O
:	O
#CODE	O

I	O
want	O
to	O
achieve	O
this	O
method	O
by	O
`	O
numpy	O
`	O
,	O
for	O
now	O
it	O
is	O
very	O
slow	O
`	O
4	O
seconds	O
`	O
.	O

As	O
`	O
Pandas	O
`	O
use	O
numpy	O
I	O
think	O
I	O
should	O
use	O
numpy	O
without	O
using	O
`	O
Pandas	O
`	O
in	O
order	O
to	O
reduce	O
the	O
overhead	O
.	O

I	O
use	O
`	O
column_stack	O
`	O
but	O
the	O
output	O
is	O
:	O
#CODE	O

[	O
concatenate	O
]	O
(	O
#URL	O
)	O
?	O

This	O
may	O
no	O
be	O
fast	O
,	O
however	O
,	O
`	O
[	O
np.append	O
(	O
x	O
,	O
y	O
)	O
for	O
x	O
,	O
y	O
in	O
zip	O
(	O
a	O
,	O
b	O
)]`	O
works	O
?	O

@USER	O
I'm	O
looking	O
for	O
a	O
fast	O
way	O
as	O
`	O
df	O
[	O
'	O
something	O
']	O
+	O
df	O
[	O
'	O
another_thing	O
']`	O
would	O
solve	O
my	O
problem	O
without	O
code	O
complexity	O
.	O

@USER	O
`	O
concatenate	O
`	O
is	O
not	O
the	O
solution	O
as	O
it	O
merge	B-API
the	O
way	O
I	O
don't	O
want	O
to	O
.	O

I	O
want	O
something	O
similar	O
to	O
`	O
column_stack	O
`	O

The	O
problem	O
with	O
`	O
np.column_stack	O
`	O
is	O
that	O
in	O
`	O
b	O
`	O
you	O
don't	O
have	O
equal-length	O
columns	O
(	O
and	O
thus	O
a	O
`	O
dtype	B-API
`	O
of	O
`	O
object	O
`)	O
.	O

You	O
can	O
do	O
this	O
with	O
`	O
np.concatenate	O
`	O
(	O
or	O
as	O
@USER	O
Galt	O
said	O
in	O
comments	O
`	O
np.append	O
`)	O
;	O
e.g.	O
:	O
#CODE	O

pandas	O
merging	O
of	O
two	O
data-frames	O
using	O
conditions	O

Is	O
there	O
a	O
way	O
in	O
pandas	O
to	O
merge	B-API
two	O
data	O
frames	O
with	O
varying	O
lengths	O
by	O
using	O
a	O
conditional	O
statement	O
?	O

eg	O
:	O
#CODE	O

For	O
example	O
assume	O
there	O
are	O
two	O
data	O
frames	O
,	O
df1	O
and	O
df2	O
with	O
10,000	O
and	O
15,000	O
objects	O
respectively	O
.	O

I	O
want	O
to	O
match	O
common	O
objects	O
between	O
the	O
two	O
catalogues	O
using	O
their	O
x	O
and	O
y	O
position	O
.	O

Objects	O
should	O
be	O
matched	O
between	O
df1	O
and	O
df2	O
such	O
that	O
the	O
matched	O
objects	O
fall	O
within	O
1m	O
radius	O
of	O
each	O
other	O
.	O

Other	O
than	O
x	O
and	O
y	O
,	O
there	O
is	O
nothing	O
common	O
between	O
between	O
the	O
two	O
data	O
frames	O
.	O

The	O
best	O
I	O
can	O
think	O
so	O
far	O
involves	O
a	O
for	O
loop	O
.	O

I'm	O
sure	O
there	O
is	O
a	O
faster	O
and	O
better	O
way	O
to	O
do	O
this	O
?	O

#CODE	O

Do	O
you	O
need	O
to	O
compare	O
each	O
value	O
in	O
df2	O
with	O
each	O
in	O
df1	O
?	O

And	O
what	O
if	O
more	O
than	O
one	O
row	O
fulfil	O
the	O
condition	O
?	O

Would	O
that	O
be	O
possible	O
?	O

You	O
**	O
cannot	O
**	O
join	O
on	O
a	O
conditional	O
statement	O
with	O
any	O
pandas	O
functions	O
.	O

You	O
have	O
to	O
create	O
keys	O
in	O
each	O
dataframe	B-API
that	O
can	O
be	O
joined	O
on	O
.	O

@USER	O
-sc	O
yes	O
for	O
all	O
the	O
questions	O
.	O

so	O
this	O
should	O
be	O
able	O
to	O
identify	O
multiple	O
matches	O
and	O
return	O
them	O
as	O
well	O
.	O

@USER	O
can	O
you	O
please	O
explain	O
how	O
would	O
you	O
do	O
this	O
in	O
pandas	O
then	O
?	O

Apparently	O
there	O
is	O
a	O
non-pandas	O
function	O
that	O
does	O
similarly	O
using	O
a	O
kd-tree	O
:	O
#URL	O

When	O
you	O
need	O
to	O
check	O
each	O
value	O
permutation	O
,	O
this	O
is	O
of	O
O	O
(	O
m*n	O
)	O
complexity	O
(	O
with	O
m	O
and	O
n	O
the	O
number	O
of	O
values	O
per	O
df	O
)	O
.	O

The	O
problem	O
you	O
need	O
to	O
solve	O
is	O
how	O
to	O
get	O
your	O
loops	O
more	O
efficient	O
,	O
but	O
I	O
don't	O
think	O
there	O
is	O
a	O
straight	O
forward	O
way	O
(	O
aka	O
existing	O
function	O
)	O
to	O
do	O
that	O
in	O
pandas	O
.	O

Pandas	O
groupby	B-API
category	O
,	O
rating	O
,	O
get	O
top	O
value	O
from	O
each	O
category	O
?	O

First	O
question	O
on	O
SO	O
,	O
very	O
new	O
to	O
pandas	O
and	O
still	O
a	O
little	O
shaky	O
on	O
the	O
terminology	O
:	O
I'm	O
trying	O
to	O
figure	O
out	O
the	O
proper	O
syntax	O
/	O
sequence	O
of	O
operations	O
on	O
a	O
dataframe	B-API
to	O
be	O
able	O
to	O
group	O
by	O
column	O
B	O
,	O
find	O
the	O
max	O
(	O
or	O
min	O
)	O
corresponding	O
value	O
for	O
each	O
group	O
in	O
column	O
C	O
,	O
and	O
retrieve	O
the	O
corresponding	O
value	O
for	O
that	O
in	O
column	O
A	O
.	O

Suppose	O
this	O
is	O
my	O
dataframe	B-API
:	O
#CODE	O

Using	O
`	O
df.groupby	B-API
(	O
'	O
type	O
')	O
.votes	O
.agg	O
(	O
'	O
max	O
')`	O
returns	O
:	O
#CODE	O

So	O
far	O
,	O
so	O
good	O
.	O

However	O
,	O
I'd	O
like	O
to	O
figure	O
out	O
how	O
to	O
return	O
this	O
:	O
#CODE	O

I've	O
gotten	O
as	O
far	O
as	O
`	O
df.groupby	B-API
([	O
'	O
type	O
'	O
,	O
'	O
votes	O
'])	O
.name	B-API
.agg	O
(	O
'	O
max	O
')`	O
,	O
though	O
that	O
returns	O
#CODE	O

...	O
which	O
is	O
fine	O
for	O
this	O
pretend	O
dataframe	B-API
,	O
but	O
doesn't	O
quite	O
help	O
when	O
working	O
with	O
a	O
much	O
larger	O
one	O
.	O

Thanks	O
very	O
much	O
!	O

If	O
`	O
df	O
`	O
has	O
an	O
index	O
with	O
no	O
duplicate	O
values	O
,	O
then	O
you	O
can	O
use	O
`	O
idxmax	B-API
`	O
to	O
return	O
the	O
index	O
of	O
the	O
maximum	O
row	O
for	O
each	O
group	O
.	O

Then	O
use	O
`	O
df.loc	B-API
`	O
to	O
select	O
the	O
entire	O
row	O
:	O
#CODE	O

If	O
`	O
df.index	O
`	O
has	O
duplicate	O
values	O
,	O
i.e.	O
is	O
not	O
a	O
unique	O
index	O
,	O
then	O
make	O
the	O
index	O
unique	O
first	O
:	O
#CODE	O

then	O
use	O
`	O
idxmax	B-API
`	O
:	O
#CODE	O

If	O
you	O
really	O
need	O
to	O
,	O
you	O
can	O
return	O
`	O
df	O
`	O
to	O
its	O
original	O
state	O
:	O
#CODE	O

but	O
in	O
general	O
life	O
is	O
much	O
better	O
with	O
a	O
unique	O
index	O
.	O

Here	O
is	O
an	O
example	O
showing	O
what	O
goes	O
wrong	O
when	O
`	O
df	O
`	O
does	O
not	O
have	O
a	O
unique	O

index	O
.	O

Suppose	O
the	O
`	O
index	B-API
`	O
is	O
`	O
AABB	O
`	O
:	O
#CODE	O

`	O
idxmax	B-API
`	O
returns	O
the	O
index	O
values	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O
:	O
#CODE	O

But	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O
do	O
not	O
uniquely	O
specify	O
the	O
desired	O
rows	O
.	O

`	O
df.loc	B-API
[	O
...	O
]`	O

returns	O
all	O
rows	O
whose	O
index	O
value	O
is	O
`	O
A	O
`	O
or	O
`	O
B	O
`	O
:	O
#CODE	O

In	O
contrast	O
,	O
if	O
we	O
reset	O
the	O
index	O
:	O
#CODE	O

then	O
`	O
df.loc	B-API
`	O
can	O
be	O
used	O
to	O
select	O
the	O
desired	O
rows	O
:	O
#CODE	O

Thank	O
you	O
very	O
much	O
!	O

Still	O
trying	O
to	O
get	O
the	O
hang	O
of	O
indexes	O
,	O
will	O
read	O
through	O
documentation	O
much	O
more	O
thoroughly	O
.	O

Thanks	O
again	O
!	O
