I	O
think	O
that	O
I	O
understand	O
what's	O
going	O
on	O
:	O
create	O
a	O
frequency	O
table	O
of	O
ALL	O
words	O
.	O

After	O
each	O
operation	O
,	O
drop	N
all	O
relevant	O
columns	O
,	O
then	O
finally	O
count	O
all	O
remaining	O
columns	O
.	O

Also	O
,	O
I	O
quickly	O
tried	O
this	O
in	O
Python	O
3.4.3	O
and	O
I	O
got	O
the	O
error	O
that	O
freqDf	O
isn't	O
defined	O
.	O

Should	O
I	O
first	O
create	O
a	O
new	O
table	O
named	O
freqDf	O
?	O

`	O
df.precedingWord.isin	O
(	O
neuter	O
)`	O
is	O
just	O
a	O
Series	O
of	O
True	O
or	O
False	O
(	O
results	O
of	O
the	O
previous	O
test	O
`	O
isin	Y
`)	O
,	O
and	O
pandas	O
will	O
just	O
access	O
True	O
indexes	O
with	O
`	O
loc	Y
`	O

I	O
have	O
tried	O
a	O
some	O
join	Y
/	O
merge	Y
ideas	O
but	O
can't	O
seem	O
to	O
get	O
it	O
to	O
work	O
.	O

Just	O
`	O
concat	Y
`	O
them	O
and	O
pass	O
param	O
`	O
axis=1	O
`	O
:	O
#CODE	O

Or	O
`	O
merge	Y
`	O
on	O
'	O
Symbol	O
'	O
column	O
:	O
#CODE	O

Pandas	O
:	O
join	N
with	O
outer	O
product	O

How	O
to	O
join	N
/	O
multiply	O
the	O
DataFrames	O
`	O
areas	O
`	O
and	O
`	O
demand	O
`	O
together	O
in	O
a	O
decent	O
way	O
?	O

Now	O
`	O
apply	Y
`	O
needs	O
to	O
return	O
a	O
`	O
Series	Y
`	O
,	O
not	O
a	O
`	O
DataFrame	Y
`	O
.	O

One	O
way	O
to	O
turn	O
a	O
`	O
DataFrame	Y
`	O
into	O
a	O
`	O
Series	Y
`	O
is	O
to	O
use	O
`	O
stack	Y
`	O
.	O

`	O
stack	Y
`	O
this	O
DataFrame	Y
.	O

This	O
can	O
be	O
done	O
with	O
`	O
unstack	Y
`	O
:	O
#CODE	O

`	O
del	O
`	O
+	O
`	O
pivot	Y
`	O
turns	O
out	O
to	O
be	O
faster	O
than	O
`	O
pivot_table	Y
`	O
in	O
this	O
case	O
.	O

Maybe	O
the	O
reason	O
`	O
pivot	Y
`	O
exists	O
is	O
because	O
it	O
is	O
faster	O
than	O
`	O
pivot_table	Y
`	O
for	O
those	O
cases	O
where	O
it	O
is	O
applicable	O
(	O
such	O
as	O
when	O
you	O
don't	O
need	O
aggregation	O
)	O
.	O

`	O
apply	Y
`	O
is	O
now	O
among	O
my	O
top	O
5	O
functions	O
to	O
always	O
remember	O
.	O

Concerning	O
the	O
`	O
pivot_table	Y
`	O
solution	O
:	O
At	O
which	O
point	O
am	O
I	O
supposed	O
to	O
enter	O
the	O
line	O
?	O

No	O
matter	O
when	O
in	O
my	O
attempt	O
above	O
,	O
I	O
always	O
get	O
`	O
no	O
item	O
named	O
Edge	O
`	O
.	O

Or	O
pass	O
`	O
axis=0	O
`	O
to	O
`	O
loc	Y
`	O
:	O
#CODE	O

I've	O
got	O
2	O
pandas	O
dataframes	O
,	O
each	O
of	O
them	O
has	O
an	O
index	O
with	O
dtype	Y
`	O
object	O
`	O
,	O
and	O
in	O
both	O
of	O
them	O
I	O
can	O
see	O
the	O
value	O
`	O
533	O
`	O
.	O

However	O
,	O
when	O
I	O
join	Y
them	O
the	O
result	O
is	O
empty	O
,	O
as	O
one	O
of	O
them	O
is	O
the	O
number	O
`	O
533	O
`	O
and	O
the	O
other	O
is	O
a	O
string	O
`"	O
533	O
"`	O
.	O

Ideally	O
I	O
would	O
like	O
something	O
like	O
`	O
apply_chunk()	O
`	O
which	O
is	O
the	O
same	O
as	O
apply	Y
but	O
only	O
works	O
on	O
a	O
piece	O
of	O
the	O
dataframe	Y
.	O

This	O
has	O
to	O
be	O
a	O
common	O
problem	O
though	O
,	O
is	O
there	O
a	O
design	O
pattern	O
I	O
should	O
be	O
using	O
for	O
adding	O
columns	O
to	O
large	O
pandas	O
dataframes	O
?	O

whats	O
about	O
using	O
the	O
apply	Y
method	O
?	O

Anytime	O
you	O
find	O
yourself	O
using	O
`	O
apply	Y
`	O
or	O
`	O
iloc	Y
`	O
in	O
a	O
loop	O
it's	O
likely	O
that	O
Pandas	O
is	O
operating	O
much	O
slower	O
than	O
is	O
optimal	O
.	O

Convert	O
freq	N
string	O
to	O
DateOffset	Y
in	O
pandas	O

In	O
pandas	O
documentation	O
one	O
can	O
read	O
"	O
Under	O
the	O
hood	O
,	O
these	O
frequency	O
strings	O
are	O
being	O
translated	O
into	O
an	O
instance	O
of	O
pandas	O
DateOffset	Y
"	O
when	O
speaking	O
of	O
freq	N
string	O
such	O
as	O
"	O
W	O
"	O
or	O
"	O
W-SUN	O
"	O
.	O

stack	N
/	O
unstack	N
/	O
pivot	N
dataframe	Y
on	O
python	O
/	O
pandas	O

yes	O
,	O
`	O
isnull	Y
`	O
will	O
create	O
a	O
boolean	O
series	O
,	O
`	O
all	Y
`	O
returns	O
`	O
True	O
`	O
if	O
all	O
are	O
`	O
True	O
`	O

Then	O
merge	N
the	O
sub-tables	O
back	O
together	O
in	O
a	O
way	O
that	O
replaces	O
NaN	O
values	O
when	O
there	O
is	O
data	O
in	O
one	O
of	O
the	O
tables	O
.	O

I	O
regularly	O
work	O
with	O
very	O
large	O
data	O
sets	O
that	O
are	O
too	O
big	O
to	O
manipulate	O
in	O
memory	O
.	O

I	O
would	O
like	O
to	O
read	O
in	O
a	O
csv	O
file	O
iteratively	O
,	O
append	N
each	O
chunk	O
into	O
HDFStore	Y
object	O
,	O
and	O
then	O
work	O
with	O
subsets	O
of	O
the	O
data	O
.	O

If	O
you	O
replace	N
that	O
line	O
with	O
:	O

I	O
wanted	O
to	O
merge	N
these	O
files	O
so	O
that	O
i	O
have	O
something	O
like	O
this	O
#CODE	O

If	O
it's	O
six	O
,	O
then	O
you	O
can	O
use	O
join	Y
method	O
by	O
@USER	O
Hayden	O
.	O

Then	O
you	O
can	O
simply	O
`	O
join	Y
`	O
them	O
:	O
#CODE	O

@USER	O
when	O
you	O
do	O
a	O
join	Y
with	O
2x2	O
duplicates	O
you	O
get	O
4	O
in	O
the	O
joined	O
DataFrame	Y
.	O

It's	O
unclear	O
how	O
pandas	O
should	O
join	N
in	O
this	O
case	O
,	O
so	O
you	O
need	O
to	O
be	O
more	O
explicit	O
to	O
it	O
(	O
and	O
tell	O
it	O
what	O
do	O
you	O
want	O
)	O
.	O

On	O
the	O
similar	O
note	O
,	O
is	O
there	O
a	O
way	O
to	O
merge	N
values	O
based	O
on	O
index	O
.	O

For	O
example	O
,	O
instead	O
of	O
listing	O
Bact5	O
in	O
two	O
rows	O
,	O
can	O
we	O
merge	N
its	O
value	O
corresponding	O
to	O
file2	O
in	O
one	O
row	O
separated	O
by	O
a	O
delimeter	O
?	O

Pandas	O
dataframe	Y
insert	N
rows	O

I	O
want	O
to	O
insert	N
rows	O
in	O
DF	O
and	O
modify	O
its	O
related	O
values	O
:	O

The	O
code	O
can	O
only	O
append	N
rows	O
but	O
how	O
to	O
modify	O
its	O
values	O
in	O
a	O
faster	O
way	O
?	O

I	O
want	O
to	O
use	O
a	O
function	O
from	O
an	O
add-in	O
in	O
excel	O
and	O
apply	N
it	O
to	O
some	O
data	O
i	O
have	O
simulated	O
in	O
python	O
.	O

I	O
need	O
to	O
be	O
able	O
to	O
call	O
the	O
add-in	O
and	O
apply	N
my	O
data	O
indexes	O
there	O
...	O
something	O
along	O
these	O
lines	O
:	O
=	O
add-in_name	O
(	O
data_range1	O
,	O
data_range2	O
,	O
"	O
GGCV	O
")	O

After	O
reading	O
one	O
line	O
I	O
append	N
the	O
dictionary	O
to	O
a	O
list	O
(	O
so	O
,	O
the	O
number	O
of	O
dictionaries	O
in	O
the	O
list	O
is	O
equal	O
to	O
the	O
number	O
of	O
lines	O
in	O
the	O
file	O
)	O
.	O

I	O
can	O
easily	O
do	O
this	O
iteratively	O
with	O
loops	O
,	O
but	O
I've	O
read	O
that	O
you're	O
supposed	O
to	O
slice	Y
/	O
merge	Y
/	O
join	Y
data	O
frames	O
holistically	O
,	O
so	O
I'm	O
trying	O
to	O
see	O
if	O
I	O
can	O
find	O
a	O
better	O
way	O
of	O
doing	O
this	O
.	O

A	O
join	Y
will	O
give	O
me	O
all	O
the	O
stuff	O
that	O
matches	O
,	O
but	O
that's	O
not	O
exactly	O
what	O
I'm	O
looking	O
for	O
,	O
since	O
I	O
need	O
a	O
resulting	O
dataframe	Y
for	O
each	O
key	O
(	O
i.e.	O
for	O
every	O
row	O
)	O
in	O
A	O
.	O

You	O
then	O
want	O
to	O
apply	N
some	O
function	O
to	O
each	O
group	O
of	O
rows	O
in	O
`	O
b	O
`	O
where	O
the	O
`	O
b	O
[	O
"	O
key	O
"]`	O
is	O
one	O
of	O
the	O
values	O
in	O
`	O
keys	N
`	O
.	O

Under	O
the	O
covers	O
,	O
these	O
are	O
really	O
similar	O
uses	O
of	O
`	O
apply	Y
`	O
.	O

`	O
loop_iter	O
=	O
len	Y
(	O
A	O
)	O
/	O
max	Y
(	O
A	O
[	O
'	O
SEQ_NUM	O
'])	O

Easy	O
way	O
to	O
apply	N
transformation	O
from	O
`	O
pandas.get_dummies	Y
`	O
to	O
new	O
data	O
?	O

As	O
an	O
aside	O
that	O
may	O
help	O
you	O
in	O
the	O
meantime	O
,	O
with	O
datetime-indexed	O
data	O
,	O
[	O
resample	Y
]	O
(	O
#URL	O
)	O
is	O
usually	O
a	O
better	O
choice	O
than	O
reindex	Y
.	O

Call	O
`	O
transform	Y
`	O
on	O
the	O
'	O
measurement	O
'	O
column	O
and	O
pass	O
the	O
method	O
`	O
diff	Y
`	O
,	O
transform	Y
returns	O
a	O
series	O
with	O
an	O
index	O
aligned	O
to	O
the	O
original	O
df	O
:	O
#CODE	O

If	O
you	O
are	O
intending	O
to	O
apply	N
some	O
sorting	O
on	O
the	O
result	O
of	O
`	O
transform	Y
`	O
then	O
sort	O
the	O
df	O
first	O
:	O
#CODE	O

Or	O
you	O
can	O
slice	O
the	O
columns	O
and	O
pass	O
this	O
to	O
`	O
drop	Y
`	O
:	O
#CODE	O

These	O
values	O
are	O
median	N
values	O
I	O
calculated	O
from	O
elsewhere	O
,	O
and	O
I	O
have	O
also	O
their	O
variance	O
and	O
standard	O
deviation	O
(	O
and	O
standard	O
error	O
,	O
too	O
)	O
.	O

=	O
Hash	O
[	O
0	O
]	O
was	O
my	O
point	O
,	O
but	O
even	O
without	O
arithmetic	O
,	O
there	O
will	O
be	O
a	O
huge	O
range	O
values	O
for	O
the	O
keys	O
that	O
will	O
give	O
potentially	O
unfortunate	O
results	O
.	O

if	O
precision	O
is	O
to	O
decimal	O
place	O
,	O
I'd	O
multiply	O
it	O
by	O
10	O
and	O
truncate	N
maybe	O
.	O

the	O
documentation	O
to	O
concat	Y
is	O
impenetrable	O
and	O
its	O
hard	O
to	O
find	O
examples	O
of	O
this	O
relatively	O
simple	O
task	O
in	O
the	O
docs	O

If	O
you	O
had	O
not	O
called	O
`	O
apply	Y
`	O
on	O
the	O
`	O
groupby	Y
`	O
object	O
then	O
you	O
could	O
access	O
the	O
`	O
groups	Y
`	O
:	O
#CODE	O

pandas	O
groupby	Y
X	O
,	O
Y	O
and	O
select	O
last	O
week	O
of	O
X1	O
and	O
X2	O
(	O
which	O
have	O
diff	N
frequency	O
)	O

Then	O
you	O
can	O
select	O
the	O
rows	O
you	O
want	O
in	O
an	O
apply	Y
call	O
on	O
the	O
grouped	O
object	O
:	O
#CODE	O

If	O
you	O
can't	O
upgrade	O
or	O
don't	O
solve	O
the	O
issue	O
you	O
have	O
with	O
0.14	O
,	O
you	O
can	O
try	O
to	O
use	O
`	O
ix	Y
`	O
instead	O
of	O
`	O
iloc	Y
`	O

How	O
do	O
I	O
export	O
multiple	O
pivot	N
tables	O
from	O
python	O
using	O
pandas	O
to	O
a	O
single	O
csv	O
document	O
?	O

Say	O
I	O
have	O
a	O
function	O
pivots()	O
which	O
aggregates	O
pivot	N
tables	O
#CODE	O

I	O
know	O
how	O
to	O
export	O
a	O
single	O
pivot	N
table	O
#CODE	O

You	O
can	O
use	O
`	O
to_csv	Y
(	O
path	O
,	O
mode=	O
'	O
a	O
')`	O
to	O
append	N
files	O
.	O

Use	O
`	O
shift	Y
`	O
and	O
`	O
np.log	Y
`	O
:	O
#CODE	O

I'd	O
look	O
at	O
seeing	O
if	O
you	O
can	O
export	O
it	O
in	O
it's	O
raw	O
form	O
,	O
otherwise	O
this	O
must	O
be	O
a	O
common	O
problem	O
and	O
someone	O
somewhere	O
has	O
probably	O
coded	O
a	O
method	O
to	O
strip	N
the	O
emojis	O
out	O
of	O
the	O
text	O

Python	O
pandas	O
map	N
dict	O
keys	O
to	O
values	O

I	O
have	O
a	O
csv	O
for	O
input	O
,	O
whose	O
row	O
values	O
I'd	O
like	O
to	O
join	N
into	O
a	O
new	O
field	O
.	O

This	O
new	O
field	O
is	O
a	O
constructed	O
url	O
,	O
which	O
will	O
then	O
be	O
processed	O
by	O
the	O
requests.post()	Y
method	O
.	O

I	O
tried	O
to	O
map	N
values	O
to	O
keys	O
with	O
a	O
dict	O
comprehension	O
,	O
but	O
the	O
assignment	O
of	O
a	O
key	O
like	O
'	O
FIRST_NAME	O
'	O
could	O
end	O
up	O
mapping	O
to	O
values	O
from	O
an	O
arbitrary	O
field	O
like	O
test_df	O
[	O
'	O
CITY	O
']	O
.	O

which	O
will	O
give	O
you	O
output	O
as	O
follows	O
:	O
`	O
[	O
{	O
'	O
FIRST_NAME	O
'	O
:	O
...,	O
'	O
LAST_NAME	O
'	O
:	O
...	O
}	O
,	O
{	O
'	O
FIRST_NAME	O
'	O
:	O
...,	O
'	O
LAST_NAME	O
'	O
:	O
...	O
}	O
]`	O
(	O
which	O
will	O
give	O
you	O
a	O
list	O
that	O
has	O
equal	O
length	O
as	O
`	O
test_df	O
`)	O
.	O

This	O
might	O
be	O
one	O
possibility	O
to	O
easily	O
map	N
it	O
to	O
a	O
correct	O
row	O
.	O

Do	O
you	O
know	O
if	O
append	Y
returns	O
a	O
copy	O
/	O
view	O
/	O
reference	O
of	O
the	O
original	O
dataframe	Y
?	O

Right	O
now	O
,	O
I	O
am	O
trying	O
to	O
replace	N
a	O
stored	O
procedure	O
with	O
a	O
Python	O
service	O
,	O
and	O
the	O
temp	O
tables	O
with	O
Pandas	O
dataframes	O
.	O

You	O
could	O
pass	O
an	O
argument	O
to	O
`	O
apply	Y
`	O
:	O
#CODE	O

Originally	O
,	O
I	O
used	O
append	Y
api	O
to	O
create	O
a	O
single	O
table	O
'	O
impression	O
'	O
,	O
however	O
that	O
was	O
taking	O
80sec	O
per	O
dataframe	Y
and	O
given	O
that	O
I	O
have	O
almost	O
200	O
of	O
files	O
to	O
be	O
processed	O
,	O
the	O
'	O
append	Y
'	O
appeared	O
to	O
be	O
too	O
slow	O
.	O

Also	O
,	O
why	O
is	O
append	Y
so	O
much	O
slower	O
than	O
put	O
?	O

pandas	O
merge	Y
with	O
MultiIndex	Y
,	O
when	O
only	O
one	O
level	O
of	O
index	O
is	O
to	O
be	O
used	O
as	O
key	O

I	O
want	O
to	O
recover	O
the	O
values	O
in	O
the	O
column	O
'	O
_Cat	O
'	O
from	O
df2	O
and	O
merge	N
them	O
into	O
df1	O
for	O
the	O
appropriate	O
values	O
of	O
'	O
_ItemId	O
'	O
.	O

This	O
is	O
almost	O
(	O
I	O
think	O
?	O
)	O
a	O
standard	O
many-to-one	O
merge	N
,	O
except	O
that	O
the	O
appropriate	O
key	O
for	O
the	O
left	O
df	O
is	O
one	O
of	O
MultiIndex	Y
levels	O
.	O

Or	O
is	O
there	O
a	O
better	O
approach	O
to	O
this	O
merge	Y
?	O

loc	Y
will	O
not	O
attempt	O
to	O
use	O
a	O
number	O
(	O
eg	O
1	O
)	O
as	O
a	O
positional	O
argument	O
at	O
all	O
(	O
and	O
will	O
raise	O
instead	O
);	O
see	O
main	O
pandas	O
docs	O
/	O
selecting	O
data	O

I	O
have	O
the	O
following	O
boxplot	Y
:	O
#CODE	O

My	O
question	O
is	O
:	O
how	O
can	O
I	O
change	O
the	O
whiskers	O
/	O
quantiles	O
being	O
plotted	O
in	O
the	O
boxplot	Y
?	O

it'll	O
be	O
difficult	O
to	O
translate	N
those	O
`	O
ddply	O
`	O
calls	O
to	O
pandas	O
.	O

I	O
guess	O
`	O
groupby	Y
`	O
should	O
be	O
used	O
but	O
I	O
find	O
this	O
format	O
very	O
cryptic	O
so	O
it's	O
hard	O
to	O
translate	N
to	O
python	O

If	O
you	O
drop	N
the	O
"	O
%	O
"	O
sign	O
,	O
you	O
can	O
make	O
the	O
plot	O
without	O
ticks	O
.	O

Append	N
Two	O
Dataframes	O
Together	O
(	O
Pandas	O
,	O
Python3	O
)	O

I	O
am	O
trying	O
to	O
append	N
/	O
join	N
(	O
?	O
)	O
two	O
different	O
dataframes	O
together	O
that	O
don't	O
share	O
any	O
overlapping	O
data	O
.	O

I	O
am	O
trying	O
to	O
append	N
these	O
together	O
using	O
#CODE	O

EDIT	O
:	O
in	O
regards	O
to	O
Edchum's	O
answers	O
,	O
I	O
have	O
tried	O
merge	Y
and	O
join	Y
but	O
each	O
create	O
somewhat	O
strange	O
tables	O
.	O

OK	O
,	O
what	O
you	O
have	O
to	O
do	O
is	O
reindex	Y
or	O
reset	Y
the	O
index	O
so	O
they	O
align	N

Use	O
`	O
concat	Y
`	O
and	O
pass	O
param	O
`	O
axis=1	O
`	O
:	O
#CODE	O

`	O
join	Y
`	O
also	O
works	O
:	O
#CODE	O

As	O
does	O
`	O
merge	Y
`	O
:	O
#CODE	O

In	O
the	O
case	O
where	O
the	O
indices	O
do	O
not	O
align	N
where	O
for	O
example	O
your	O
first	O
df	O
has	O
index	O
`	O
[	O
0	O
,	O
1	O
,	O
2	O
,	O
3	O
]`	O
and	O
your	O
second	O
df	O
has	O
index	O
`	O
[	O
0	O
,	O
2	O
]`	O
this	O
will	O
mean	O
that	O
the	O
above	O
operations	O
will	O
naturally	O
align	N
against	O
the	O
first	O
df's	O
index	O
resulting	O
in	O
a	O
`	O
NaN	O
`	O
row	O
for	O
index	O
row	O
`	O
1	O
`	O
.	O

To	O
fix	O
this	O
you	O
can	O
reindex	N
the	O
second	O
df	O
either	O
by	O
calling	O
`	O
reset_index()	Y
`	O
or	O
assign	O
directly	O
like	O
so	O
:	O
`	O
df2.index	O
=[	O
0	O
,	O
1	O
]`	O
.	O

And	O
you	O
could	O
always	O
drop	N
back	O
to	O
numpy	O
operations	O
on	O
the	O
numpy	O
array	O
`	O
pan.values	O
`	O
if	O
need	O
be	O
,	O
though	O
,	O
hopefully	O
,	O
that	O
would	O
be	O
unnecessary	O
.	O

This	O
argument	O
is	O
new	O
in	O
1.9	O
...	O
but	O
there	O
is	O
a	O
workaround	O
,	O
try	O
`	O
np.linspace	Y
(	O
0	O
,	O
len	Y
(	O
pep_list	O
)	O
,	O
n+1	O
,	O
endpoint=True	O
)	O
.astype	Y
(	O
int	O
)`	O

Take	O
the	O
time	O
difference	O
(	O
using	O
`	O
shift	Y
`	O
)	O
til	O
the	O
next	O
value	O
,	O
and	O
multiply	O
(	O
value	O
*	O
seconds	O
):	O
#CODE	O

Then	O
do	O
the	O
resample	N
to	O
seconds	O
(	O
sum	O
the	O
value*seconds	O
):	O
#CODE	O

you	O
can	O
isnull	Y
(	O
df	O
[	O
'	O
difference	O
'])	O
will	O
give	O
True	O
on	O
NaT	O
,	O
so	O
you	O
could	O
subtract	O
then	O
use	O
mask	Y
I	O
think	O

After	O
they	O
are	O
done	O
,	O
merge	N
the	O
two	O
frames	O
together	O
:	O
#CODE	O

Another	O
solution	O
(	O
slightly	O
harder	O
):	O
Merge	N
the	O
columns	O
`	O
transcript_id	O
`	O
,	O
`	O
gene_id	O
`	O
and	O
`	O
gene_name	O
`	O
in	O
another	O
column	O
,	O
say	O
`	O
merged_id	O
`	O
and	O
`	O
groupby	Y
`	O
on	O
`	O
merged_id	O
`	O
.	O

Geo	O
Pandas	O
Data	O
Frame	O
/	O
Matrix	O
-	O
filter	O
/	O
drop	N
NaN	O
/	O
False	O
values	O

Then	O
I	O
stack	N
the	O
dataframe	Y
,	O
give	O
the	O
index	O
levels	O
the	O
desired	O
names	O
,	O
and	O
select	O
only	O
the	O
rows	O
where	O
we	O
have	O
'	O
True	O
'	O
values	O
:	O
#CODE	O

Can	O
you	O
enable	O
the	O
debugger	O
to	O
get	O
a	O
stack	N
trace	O
?	O

reshape	O
data	O
frame	O
in	O
pandas	O
with	O
pivot	N
table	O

With	O
pivot	N
table	O
you	O
can	O
get	O
a	O
matrix	O
showing	O
which	O
`	O
baz	O
`	O
corresponds	O
to	O
which	O
`	O
qux	O
`	O
:	O
#CODE	O

Rolling	O
apply	N
question	O

For	O
each	O
group	O
in	O
the	O
groupby	Y
object	O
,	O
we	O
will	O
want	O
to	O
apply	N
a	O
function	O
:	O
#CODE	O

We	O
want	O
to	O
take	O
the	O
Times	O
column	O
,	O
and	O
for	O
each	O
time	O
,	O
apply	N
a	O
function	O
.	O

That's	O
done	O
with	O
`	O
applymap	Y
`	O
:	O
#CODE	O

Given	O
a	O
time	O
`	O
t	O
`	O
,	O
we	O
can	O
select	O
the	O
`	O
Value	O
`	O
s	O
from	O
`	O
subf	O
`	O
whose	O
times	O
are	O
in	O
the	O
half-open	O
interval	O
`	O
(	O
t-60	O
,	O
t	O
]`	O
using	O
the	O
`	O
ix	Y
`	O
method	O
:	O
#CODE	O

pandas	O
join	N
data	O
frames	O
on	O
similar	O
but	O
not	O
identical	O
string	O
using	O
lower	O
case	O
only	O

I	O
need	O
to	O
join	N
data	O
frames	O
on	O
columns	O
that	O
are	O
similar	O
but	O
not	O
identical	O
.	O

So	O
I	O
am	O
trying	O
to	O
isolate	O
the	O
lowercase	O
letters	O
from	O
each	O
column	O
,	O
create	O
new	O
columns	O
to	O
join	N
on	O
.	O

Note	O
that	O
this	O
assumes	O
collecting	O
all	O
ASCII	O
characters	O
from	O
`	O
a	O
`	O
to	O
`	O
z	O
`	O
suffices	O
to	O
produce	O
values	O
on	O
which	O
to	O
join	N
.	O

You	O
can	O
of	O
course	O
extend	O
this	O
with	O
several	O
joins	O
,	O
the	O
join	N
solution	O
detects	O
common	O
indices	O
automatically	O
.	O

My	O
data	O
is	O
in	O
a	O
DataFrame	Y
of	O
about	O
10378	O
rows	O
and	O
`	O
len	Y
(	O
df	O
[	O
'	O
Full	O
name	O
'])`	O
is	O
10378	O
,	O
as	O
expected	O
.	O

But	O
`	O
len	Y
(	O
choices	O
)`	O
is	O
only	O
1695	O
.	O

I'm	O
fairly	O
certain	O
that	O
the	O
issue	O
is	O
in	O
the	O
first	O
line	O
,	O
with	O
the	O
`	O
to_dict()	Y
`	O
function	O
,	O
as	O
`	O
len	Y
(	O
df	O
[	O
'	O
Full	O
name	O
']	O
.astype	Y
(	O
str	O
)`	O
results	O
in	O
10378	O
and	O
`	O
len	Y
(	O
df	O
[	O
'	O
Full	O
name	O
']	O
.to_dict()	Y
)`	O
results	O
in	O
1695	O
.	O

what	O
is	O
`	O
len	Y
(	O
df.index.unique()	O
)`	O
?	O

@USER	O
using	O
`	O
choices	O
=	O
dict	O
(	O
zip	O
(	O
df	O
[	O
'	O
n	O
']	O
,	O
df	O
[	O
'	O
Full	O
name	O
']	O
.astype	Y
(	O
str	O
)))`	O
,	O
where	O
df	O
[	O
'	O
n	O
']	O
is	O
np.arange	Y
(	O
len	Y
(	O
df	O
))	O
,	O
worked	O
fine	O
and	O
got	O
what	O
I	O
needed	O
.	O

Had	O
some	O
indexing	O
issues	O
because	O
I	O
was	O
importing	O
the	O
data	O
from	O
different	O
Excel	O
spreadsheets	O
.	O

This	O
is	O
what	O
is	O
happening	O
in	O
your	O
case	O
,	O
and	O
noted	O
from	O
the	O
comments	O
,	O
since	O
the	O
amount	O
of	O
`	O
unique	N
`	O
values	O
for	O
the	O
index	O
are	O
only	O
`	O
1695	O
`	O
,	O
we	O
can	O
confirm	O
this	O
by	O
testing	O
the	O
value	O
of	O
`	O
len	Y
(	O
df.index.unique()	O
)`	O
.	O

what	O
do	O
you	O
mean	O
by	O
normalize	N
?	O

The	O
other	O
way	O
is	O
much	O
easier	O
and	O
involves	O
using	O
`	O
resample	Y
`	O
to	O
convert	O
to	O
daily	O
observations	O
and	O
backfill	O
daily	O
consumption	O
.	O

(	O
Note	O
that	O
the	O
first	O
and	O
last	O
months	O
are	O
based	O
on	O
partial	O
data	O
,	O
you	O
may	O
want	O
to	O
either	O
drop	N
them	O
or	O
pro-rate	O
the	O
daily	O
consumption	O
.	O
)	O
#CODE	O

Basically	O
,	O
after	O
calculating	O
the	O
daily	O
consumption	O
,	O
do	O
a	O
partial	O
resample	Y
by	O
adding	O
the	O
first	O
and	O
last	O
day	O
of	O
each	O
month	O
.	O

I	O
will	O
implement	O
it	O
and	O
see	O
how	O
it	O
goes	O
,	O
but	O
can	O
you	O
also	O
explain	O
what	O
'	O
1d	O
'	O
means	O
in	O
the	O
resample	Y
method	O
?	O

@USER	O
'	O
1d	O
'	O
just	O
means	O
1	O
day	O
for	O
the	O
frequency	O
of	O
the	O
resample	Y
.	O

So	O
I	O
want	O
something	O
that	O
will	O
drop	N
the	O
`	O
lob	O
`	O
group	O
,	O
but	O
keep	O
every	O
record	O
of	O
both	O
the	O
`	O
mol	O
`	O
and	O
`	O
thg	O
`	O
group	O
.	O

Pandas	O
Merge	N
2	O
data	O
frames	O
by	O
2	O
columns	O
each	O

In	O
each	O
data	O
frame	O
i	O
have	O
column	O
with	O
the	O
same	O
name	O
and	O
values	O
(	O
Key_Merge1	O
)	O
and	O
in	O
each	O
data	O
frame	O
i	O
have	O
2	O
different	O
column	O
names	O
with	O
same	O
values	O
(	O
Key_Merge2	O
)	O
.	O

How	O
can	O
i	O
merge	N
2	O
data	O
frames	O
by	O
2	O
columns	O
:	O

Can	O
you	O
post	O
an	O
example	O
data	O
and	O
df	O
,	O
your	O
text	O
description	O
is	O
not	O
clear	O
enough	O
but	O
generally	O
you	O
want	O
to	O
merge	N
and	O
pass	O
the	O
list	O
of	O
cols	O
to	O
merge	N
the	O
;	O
hs	O
and	O
rhs	O
on	O
:	O
`	O
pd.merge	Y
(	O
df1	O
,	O
df2	O
,	O
left_on	O
=[	O
'	O
Key_Merge1	O
'	O
,	O
'	O
Key_Merge21	O
']	O
,	O
right_on	O
=[	O
'	O
Key_Merge1	O
'	O
,	O
'	O
Key_merge22	O
'])`	O

OK	O
,	O
you	O
have	O
to	O
rename	O
'	O
PRODUCT_GROUP	O
'	O
in	O
DF2	O
in	O
order	O
for	O
the	O
`	O
merge	Y
`	O
to	O
work	O
:	O
#CODE	O

the	O
merge	Y
will	O
naturally	O
find	O
the	O
2	O
columns	O
that	O
match	O
and	O
perform	O
an	O
inner	O
merge	Y
as	O
desired	O

I	O
can	O
strip	N
out	O
the	O
rightmost	O
'	O
.csv	O
'	O
part	O
like	O
this	O
:	O
#CODE	O

How	O
to	O
merge	N
two	O
DataFrame	Y
columns	O
and	O
apply	N
pandas.to_datetime	Y
to	O
it	O
?	O

What	O
would	O
be	O
a	O
more	O
pythonic	O
way	O
to	O
merge	N
two	O
columns	O
,	O
and	O
apply	N
a	O
function	O
into	O
the	O
result	O
?	O

once	O
sorted	O
I	O
replace	N
the	O
df.index	O
with	O
a	O
numerical	O
index	O
#CODE	O

This	O
can	O
be	O
accomplished	O
with	O
a	O
one	O
line	O
solution	O
using	O
Pandas	O
'	O
boolean	O
indexing	O
.	O

The	O
one-liner	O
also	O
employs	O
some	O
other	O
tricks	O
:	O
Pandas	O
'	O
`	O
map	Y
`	O
and	O
`	O
diff	Y
`	O
methods	O
and	O
a	O
`	O
lambda	O
`	O
function	O
.	O

`	O
map	Y
`	O
is	O
used	O
to	O
apply	Y
the	O
`	O
lambda	O
`	O
function	O
to	O
all	O
rows	O
.	O

The	O
`	O
lambda	O
`	O
function	O
is	O
needed	O
to	O
create	O
a	O
custom	O
less-then	O
comparison	O
that	O
will	O
evaluate	O
NaN	O
values	O
to	O
True	O
.	O

There	O
is	O
a	O
built	O
in	O
method	O
for	O
this	O
`	O
diff	Y
`	O
:	O
#CODE	O

as	O
pointed	O
out	O
calling	O
`	O
diff	Y
`	O
here	O
will	O
lose	O
the	O
first	O
row	O
so	O
I'm	O
using	O
a	O
ugly	O
hack	O
where	O
I	O
concatenate	O
the	O
first	O
row	O
with	O
the	O
result	O
of	O
the	O
`	O
diff	Y
`	O
so	O
I	O
don't	O
lose	O
the	O
first	O
row	O

Using	O
`	O
diff	Y
`	O
like	O
this	O
drops	O
the	O
first	O
row	O
.	O

(	O
I	O
can	O
also	O
use	O
the	O
chunksize	O
option	O
and	O
concat	N
myself	O
,	O
but	O
that	O
seems	O
to	O
be	O
a	O
bit	O
of	O
a	O
hack	O
.	O
)	O

Jeff	O
,	O
I	O
updated	O
sec_id	O
and	O
dt	Y
in	O
the	O
dataframe	Y
.	O

Sorry	O
,	O
I	O
had	O
to	O
update	O
"	O
sec_id	O
"	O
and	O
"	O
dt	N
"	O
to	O
"	O
id	O
"	O
and	O
"	O
date	O
"	O
.	O

0.12	O
is	O
fine	O
;	O
FYI	O
the	O
format	O
keyword	O
doesn't	O
do	O
anything	O
with	O
append	Y
(	O
and	O
it's	O
for	O
0.13	O
anyhow	O
);	O
append	Y
always	O
is	O
a	O
table	O

I	O
would	O
like	O
to	O
get	O
every	O
,	O
let's	O
say	O
,	O
6	O
hours	O
of	O
data	O
and	O
independently	O
fit	O
a	O
curve	O
to	O
that	O
data	O
.	O

Since	O
pandas	O
'	O
`	O
resample	Y
`	O
function	O
has	O
a	O
`	O
how	O
`	O
keyword	O
that	O
is	O
supposed	O
to	O
be	O
any	O
numpy	O
array	O
function	O
,	O
I	O
thought	O
that	O
I	O
could	O
maybe	O
try	O
to	O
use	O
resample	Y
to	O
do	O
that	O
with	O
`	O
polyfit	Y
`	O
,	O
but	O
apparently	O
there	O
is	O
no	O
way	O
(	O
right	O
?	O
)	O
.	O

Why	O
does	O
the	O
second	O
block	O
of	O
code	O
not	O
work	O
?	O

Doesn't	O
DataFrame.apply()	Y
default	O
to	O
inplace	O
?	O

There	O
is	O
no	O
inplace	O
parameter	O
to	O
the	O
apply	Y
function	O
.	O

Even	O
if	O
it	O
doesn't	O
default	O
to	O
inplace	O
,	O
shouldn't	O
it	O
provide	O
an	O
inplace	O
parameter	O
the	O
way	O
replace()	Y
does	O
?	O

No	O
,	O
apply	Y
does	O
not	O
work	O
inplace*	O
.	O

In	O
general	O
apply	Y
is	O
slow	O
(	O
since	O
you	O
are	O
basically	O
iterating	O
through	O
each	O
row	O
in	O
python	O
)	O
,	O
and	O
the	O
"	O
game	O
"	O
is	O
to	O
rewrite	O
that	O
function	O
in	O
terms	O
of	O
pandas	O
/	O
numpy	O
native	O
functions	O
and	O
indexing	O
.	O

If	O
you	O
want	O
to	O
delve	O
into	O
more	O
details	O
about	O
the	O
internals	O
,	O
check	O
out	O
the	O
BlockManager	O
in	O
core	O
/	O
internals.py	O
,	O
this	O
is	O
the	O
object	O
which	O
holds	O
the	O
underlying	O
numpy	O
arrays	O
.	O

*	O
apply	Y
is	O
not	O
usually	O
going	O
to	O
make	O
sense	O
inplace	O
(	O
and	O
IMO	O
this	O
behaviour	O
would	O
rarely	O
be	O
desired	O
)	O
.	O

I	O
use	O
this	O
function	O
with	O
pandas	O
to	O
apply	N
it	O
to	O
each	O
month	O
of	O
a	O
historical	O
record	O
:	O
#CODE	O

I	O
am	O
trying	O
to	O
merge	N
tsv	O
files	O
using	O
pandas	O
but	O
cannot	O
get	O
pandas	O
to	O
return	O
the	O
file	O
contents	O
correctly	O
.	O

You	O
can	O
use	O
the	O
vectorised	O
`	O
str	Y
`	O
methods	O
to	O
replace	N
the	O
unwanted	O
characters	O
and	O
then	O
cast	O
the	O
type	O
to	O
int	O
:	O
#CODE	O

perhaps	O
`	O
reindex	Y
`	O
creates	O
a	O
new	O
dataframe	Y
,	O
`	O
ix	Y
`	O
returns	O
a	O
view	O

@USER	O
you	O
are	O
,	O
of	O
course	O
,	O
absolutely	O
right	O
.	O
what	O
do	O
`	O
loc	Y
`	O
and	O
`	O
iloc	Y
`	O
do	O
?	O

The	O
reason	O
for	O
the	O
seeming	O
redundancy	O
is	O
that	O
,	O
while	O
using	O
`	O
ix	Y
`	O
is	O
syntacticly	O
limiting	O
(	O
you	O
can	O
only	O
pass	O
a	O
single	O
argument	O
to	O
`	O
__getitem__	O
`)	O
,	O
`	O
reindex	Y
`	O
is	O
a	O
method	O
,	O
which	O
supports	O
taking	O
various	O
optional	O
parameters	O
.	O

I	O
am	O
getting	O
different	O
results	O
when	O
using	O
`	O
reindex	Y
`	O
with	O
`	O
inplace=True	O
`	O
vs	O
using	O
`	O
ix	Y
`	O
(	O
I	O
updated	O
the	O
OP	O
)	O

What	O
if	O
you	O
have	O
many	O
conditions	O
,	O
e.g.	O
you	O
want	O
to	O
split	O
up	O
the	O
scatters	O
into	O
4	O
types	O
of	O
points	O
or	O
even	O
more	O
,	O
plotting	O
each	O
in	O
different	O
shape	O
/	O
color	O
.	O

How	O
can	O
you	O
elegantly	O
apply	N
condition	O
a	O
,	O
b	O
,	O
c	O
,	O
etc	O
.	O
and	O
make	O
sure	O
you	O
then	O
plot	O
"	O
the	O
rest	O
"	O
(	O
things	O
not	O
in	O
any	O
of	O
these	O
conditions	O
)	O
as	O
the	O
last	O
step	O
?	O

To	O
find	O
points	O
skipped	O
due	O
to	O
NA	O
,	O
try	O
the	O
`	O
isnull	Y
`	O
method	O
:	O
`	O
df	O
[	O
df.col3.isnull()	O
]`	O

How	O
do	O
I	O
create	O
a	O
pivot	N
table	O
in	O
Pandas	O
where	O
one	O
column	O
is	O
the	O
mean	O
of	O
some	O
values	O
,	O
and	O
the	O
other	O
column	O
is	O
the	O
sum	O
of	O
others	O
?	O

Basically	O
,	O
how	O
would	O
I	O
create	O
a	O
pivot	N
table	O
that	O
consolidates	O
data	O
,	O
where	O
one	O
of	O
the	O
columns	O
of	O
data	O
it	O
represents	O
is	O
calculated	O
,	O
say	O
,	O
by	O
`	O
likelihood	O
percentage	O
`	O
(	O
0.0	O
-	O
1.0	O
)	O
by	O
taking	O
the	O
mean	O
,	O
and	O
another	O
is	O
calculated	O
by	O
`	O
number	O
ordered	O
`	O
which	O
sums	O
all	O
of	O
them	O
?	O
