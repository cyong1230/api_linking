Pandas: change data type of columns
I want to convert a table, represented as a list of lists, into a Pandas DataFrame. As an extremely simplified example: @CODE
What is the best way to convert the columns to the appropriate types, in this case columns 2 and 3 into floats? Is there a way to specify the types while converting to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the type for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns and I don't want to specify exactly which columns are of which type. All I can guarantee is that each columns contains values of the same type.
what is the original source of data ``csv``, ``sql``, generated? some other source?
in 0.11 (coming in next few days), you can do ``df.convert_objects(convert_dates='coerce', convert_numeric=True)`` to essentially force number like things to numbers and dates to dates (can be column by column or on everything), but for example best to do this with ``read_csv`` if reading from csv or ``pd.io.sql.read_from`` if reading from ``sql`` as these do it as you are reading
For this particular data `df = pd.DataFrame(a, dtype='float')` did the trick. I cannot pass a sequence however as a `dtype`.
The raw data is read from csv and it is very unstructured, i.e. rows do not have the same number of columns. That's why I had to read from it using the basic IO functions instead of pd.read_csv.
Rows not having the same number of columns may also not be an issue in 0.11...
How about this? 
`a = [['a', '1.2', '4.2'], ['b', '70', '0.03'], ['x', '5', '0']]
df = pd.DataFrame(a, columns=['one', 'two', 'three'])
df
Out[16]: 
one two three
0 a 1.2 4.2
1 b 70 0.03
2 x 5 0
df.dtypes
Out[17]: 
one object
two object
three object
df[['two', 'three']] = df[['two', 'three']].astype(float)
df.dtypes
Out[19]: 
one object
two float64
three float64
`
Can this be done when the dataframe is created?
Yes! `pd.DataFrame` has a `dtype` argument that might let you do w/ you're looking for. &#xA;&#xA;df = pd.DataFrame(a, columns=['one', 'two', 'three'], dtype=float)&#xA;In [2]: df.dtypes&#xA;Out[2]:&#xA;one       object&#xA;two      float64&#xA;three    float64&#xA;dtype: object
When I try as suggested, I get a warning `SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.&#xA;Try using .loc[row_index,col_indexer] = value instead`. This may have been introduced in a newer version of pandas and I don't see anything wrong as a result, but I just wonder what this warning is all about. Any idea?
@orange the warning is to alert users to potentially confusing behavior with chained operations, and with pandas returning copies of rather than editing dataframes. see http://stackoverflow.com/questions/20625582/how-to-deal-with-this-pandas-warning and related.
That's a good method, but it doesn't work when there are NaN in a column. Have no idea why NaN just cannot stay NaN when casting float to int: `ValueError: Cannot convert NA to integer`
@VitalyIsaev: because numpy ints don't have a representation for NaN: http://pandas.pydata.org/pandas-docs/stable/gotchas.html#support-for-integer-na
As of 0.17, you can use `pd.to_numeric` , which converts a column or a Series to an appropriate numeric type. The function also takes an `errors` kwarg that lets you force not-numeric values to be `NaN`: @CODE
(As before there is `pd.to_datetime` and `pd.to_timedelta` for conversion to dates and timestamnps.) 
In previous versions of pandas, `convert_objects` (described below) performed a similar function across the whole DataFrame but has now been deprecated. As of November 2015, discussion about a replacement for `convert_objects` (which converts the whole DataFrame) is ongoing: GH11221 
(prior to 0.17) 
As mentioned in the comments above, `convert_objects` can be used to coerce the `object` columns in a DataFrame to a more suitable datatype. 
For example, to convert columns with object type to suitable numeric datatypes, use: @CODE
The advantage of this method is that it can be applied to whole DataFrame in one go: there's no need to select columns individually and use `astype`. If a column can't be converted to a non-object datatype, it is just left alone. 
For example, the method will to coerce the columns of a DataFrame which hold numerical strings to appropriate numeric datatypes: @CODE
Here it chooses the most suitable numeric type for the values. Column `a` could not be converted to a numeric (or date) type and so is left untouched. Column `b` contains only integers and so is converted to `int64` type. Because it contains floating point number strings, the values in column `c` are cast to the `float64` datatype. 
This method returns a copy of the DataFrame.
Also, unlike .astype(float), this will convert strings to NaNs instead of raising an error
`.convert_objects` is depracated since `0.17` - use `df.to_numeric` instead
Thanks - I should update this answer. It's maybe worth noting that `pd.to_numeric` and its companion methods will only work on one column at a time, unlike `convert_objects`. Discussion about a replacement function in the API appears to be [ongoing](https://github.com/pydata/pandas/issues/11221); I hope a method that works across the whole DataFrame will remain because it's very useful.
