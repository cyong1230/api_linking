What	O
is	O
the	O
most	O
efficient	O
way	O
to	O
loop	O
through	O
dataframes	B-API
with	O
pandas	O
?	O

I	O
want	O
to	O
perform	O
my	O
own	O
complex	O
operations	O
on	O
financial	O
data	O
in	O
dataframes	B-API
in	O
a	O
sequential	O
manner	O
.	O

For	O
example	O
I	O
am	O
using	O
the	O
following	O
MSFT	O
CSV	O
file	O
taken	O
from	O
Yahoo	O
Finance	O
:	O

@CODE	O

I	O
then	O
do	O
the	O
following	O
:	O

@CODE	O

Is	O
that	O
the	O
most	O
efficient	O
way	O
?	O

Given	O
the	O
focus	O
on	O
speed	O
in	O
pandas	O
,	O
I	O
would	O
assume	O
there	O
must	O
be	O
some	O
special	O
function	O
to	O
iterate	O
through	O
the	O
values	O
in	O
a	O
manner	O
that	O
one	O
also	O
retrieves	O
the	O
index	O
(	O
possibly	O
through	O
a	O
generator	O
to	O
be	O
memory	O
efficient	O
)	O
?	O

`	O
df.iteritems	O
`	O
unfortunately	O
only	O
iterates	O
column	O
by	O
column	O
.	O

Pandas	O
is	O
based	O
on	O
NumPy	O
arrays	O
.	O

The	O
key	O
to	O
speed	O
with	O
NumPy	O
arrays	O
is	O
to	O
perform	O
your	O
operations	O
on	O
the	O
whole	O
array	O
at	O
once	O
,	O
never	O
row-by-row	O
or	O
item-by-item	O
.	O

For	O
example	O
,	O
if	O
`	O
close	O
`	O
is	O
a	O
1-d	O
array	O
,	O
and	O
you	O
want	O
the	O
day-over-day	O
percent	O
change	O
,	O

@CODE	O

This	O
computes	O
the	O
entire	O
array	O
of	O
percent	O
changes	O
as	O
one	O
statement	O
,	O
instead	O
of	O

@CODE	O

So	O
try	O
to	O
avoid	O
the	O
Python	O
loop	O
`	O
for	O
i	O
,	O
row	O
in	O
enumerate	O
(	O
...	O
)`	O
entirely	O
,	O
and	O

think	O
about	O
how	O
to	O
perform	O
your	O
calculations	O
with	O
operations	O
on	O
the	O
entire	O
array	O
(	O
or	O
dataframe	B-API
)	O
as	O
a	O
whole	O
,	O
rather	O
than	O
row-by-row	O
.	O

You	O
can	O
loop	O
through	O
the	O
rows	O
by	O
transposing	O
and	O
then	O
calling	O
iteritems	B-API
:	O

@CODE	O

I	O
am	O
not	O
certain	O
about	O
efficiency	O
in	O
that	O
case	O
.	O

To	O
get	O
the	O
best	O
possible	O
performance	O
in	O
an	O
iterative	O
algorithm	O
,	O
you	O
might	O
want	O
to	O
explore	O
writing	O
it	O
in	O
Cython	O
,	O
so	O
you	O
could	O
do	O
something	O
like	O
:	O

@CODE	O

I	O
would	O
recommend	O
writing	O
the	O
algorithm	O
in	O
pure	O
Python	O
first	O
,	O
make	O
sure	O
it	O
works	O
and	O
see	O
how	O
fast	O
it	O
is	O
--	O
if	O
it's	O
not	O
fast	O
enough	O
,	O
convert	O
things	O
to	O
Cython	O
like	O
this	O
with	O
minimal	O
work	O
to	O
get	O
something	O
that's	O
about	O
as	O
fast	O
as	O
hand-coded	O
C	O
/	O
C++	O
.	O

The	O
newest	O
versions	O
of	O
pandas	O
now	O
include	O
a	O
built-in	O
function	O
for	O
iterating	O
over	O
rows	O
.	O

@CODE	O

Or	O
,	O
if	O
you	O
want	O
it	O
faster	O
use	O
`	O
itertuples()	B-API
`	O

But	O
,	O
unutbu's	O
suggestion	O
to	O
use	O
numpy	O
functions	O
to	O
avoid	O
iterating	O
over	O
rows	O
will	O
produce	O
the	O
fastest	O
code	O
.	O

I	O
checked	O
out	O
`	O
iterrows	B-API
`	O
after	O
noticing	O
Nick	O
Crawford's	O
answer	O
,	O
but	O
found	O
that	O
it	O
yields	O
(	O
index	O
,	O
Series	B-API
)	O
tuples	O
.	O

Not	O
sure	O
which	O
would	O
work	O
best	O
for	O
you	O
,	O
but	O
I	O
ended	O
up	O
using	O
the	O
`	O
itertuples	B-API
`	O
method	O
for	O
my	O
problem	O
,	O
which	O
yields	O
(	O
index	O
,	O
row_value1	O
...	O
)	O
tuples	O
.	O

There's	O
also	O
`	O
iterkv	B-API
`	O
,	O
which	O
iterates	O
through	O
(	O
column	O
,	O
series	O
)	O
tuples	O
.	O

Just	O
as	O
a	O
small	O
addition	O
,	O
you	O
can	O
also	O
do	O
an	O
apply	O
if	O
you	O
have	O
a	O
complex	O
function	O
that	O
you	O
apply	O
to	O
a	O
single	O
column	O
:	O

http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.apply.html	O

@CODE	O

Another	O
suggestion	O
would	O
be	O
to	O
combine	O
groupby	B-API
with	O
vectorized	O
calculations	O
if	O
subsets	O
of	O
the	O
rows	O
shared	O
characteristics	O
which	O
allowed	O
you	O
to	O
do	O
so	O
.	O
