Python	O
Pandas	O
:	O
dataframe	B-API
groupby	B-API
and	O
aggregation	O
UnicodeEncodeError	O

i	O
have	O
a	O
dataframe	B-API
y	O
that	O
i	O
read	O
it	O
from	O
a	O
csv	O
file	O
with	O
has	O
two	O
columns	O
one	O
for	O
text	O
and	O
other	O
for	O
votes	O
#CODE	O

what	O
i	O
need	O
to	O
is	O
group	O
by	O
unique	O
text	O
and	O
omit	O
remove	O
controversy	O
text	O
which	O
has	O
mixed	O
votes	O
,	O
(	O
only	O
keep	O
text	O
groups	O
which	O
all	O
of	O
them	O
has	O
same	O
vote	O
either	O
1	O
or	O
-1	O
)	O

there's	O
no	O
nans	O
in	O
the	O
data	O
so	O
far	O
.	O

the	O
"	O
text	O
"	O
column	O
values	O
are	O
in	O
arabic	O
utf-8	O
read	O
characters	O

what	O
i	O
have	O
tried	O
is	O
:	O
#CODE	O

unfortunately	O
i	O
have	O
this	O
error	O
:	O
#CODE	O

#CODE	O

the	O
first	O
line	O
give	O
me	O
the	O
same	O
UnicodeEncodeError	O
,	O
probably	O
also	O
it	O
wasn't	O
clear	O
(	O
edited	O
now	O
)	O
that	O
i	O
read	O
the	O
data	O
using	O
pandas.read_csv	B-API
function	O
which	O
AFAIK	O
fills	O
the	O
datatypes	O
automatically	O
in	O
the	O
dataframe	B-API

pandas.Series.interpolate()	B-API
does	O
nothing	O
.	O

Why	O
?	O

I	O
have	O
a	O
dataframe	B-API
with	O
DatetimeIndex	B-API
.	O

This	O
is	O
one	O
of	O
columns	O
:	O
#CODE	O

When	O
I'm	O
trying	O
to	O
use	O
`	O
interpolate()	B-API
`	O
on	O
function	O
I	O
get	O
absolutly	O
nothing	O
changes	O
:	O
#CODE	O

How	O
to	O
make	O
it	O
work	O
?	O

Update	O
:	O

the	O
code	O
for	O
generating	O
such	O
a	O
dataframe	B-API
.	O

#CODE	O

After	O
that	O
I	O
fill	O
cells	O
with	O
some	O
data	O
.	O

I	O
have	O
dataframe	B-API
`	O
field_data	O
`	O
with	O
survey	O
data	O
about	O
boarding	O
and	O
alighting	O
on	O
railroad	O
,	O
and	O
`	O
station	O
`	O
variable	O
.	O

I	O
also	O
have	O
`	O
interval_end	O
`	O
function	O
defined	O
like	O
this	O
:	O
#CODE	O

The	O
code	O
:	O
#CODE	O

Absolutly	O
the	O
same	O
results	O
I	O
achieve	O
with	O
`	O
linear	O
`	O
,	O
`	O
cubic	O
`	O
and	O
all	O
other	O
methods	O
.	O

Can	O
you	O
provide	O
a	O
[	O
SSCCE	O
]	O
(	O
#URL	O
)	O
?	O

Esp	O
.	O
some	O
code	O
to	O
construct	O
your	O
dataframe	B-API
,	O
that	O
would	O
be	O
nice	O

I	O
think	O
interpolate	B-API
needs	O
regular	O
spaced	O
time	O
series	B-API
.	O

Looks	O
like	O
you	O
need	O
to	O
resample	B-API
before	O
.	O

Try	O
converting	O
your	O
series	B-API
to	O
a	O
float	O
dtype	B-API
.	O

You	O
need	O
to	O
convert	O
your	O
`	O
Series	B-API
`	O
to	O
have	O
a	O
dtype	B-API
of	O
`	O
float64	O
`	O
instead	O
of	O
your	O
current	O
`	O
object	O
`	O
.	O

Here's	O
an	O
example	O
to	O
illustrate	O
the	O
difference	O
.	O

Note	O
that	O
in	O
general	O
`	O
object	O
`	O
dtype	B-API
`	O
Series	B-API
`	O
are	O
of	O
limited	O
use	O
,	O
the	O
most	O
common	O
case	O
being	O
a	O
`	O
Series	B-API
`	O
containing	O
strings	O
.	O

Other	O
than	O
that	O
they	O
are	O
very	O
slow	O
since	O
they	O
cannot	O
take	O
advantage	O
of	O
any	O
data	O
type	O
information	O
.	O

#CODE	O

Pandas	O
to_sql	B-API
returning	O
error	O
due	O
to	O
column	O
names	O
with	O
sqlite	O
?	O

I'm	O
trying	O
to	O
store	O
stock	O
screens	O
in	O
an	O
sqlite	O
database	O
but	O
when	O
I	O
use	O
screen.to_sql()	O
from	O
pandas	O
it	O
returns	O
:	O
#CODE	O

If	O
I	O
replace	O
all	O
the	O
slashes	O
with	O
'	O
over	O
'	O
then	O
I	O
get	O
the	O
following	O
:	O
#CODE	O

I'm	O
confused	O
because	O
this	O
code	O
is	O
nearly	O
identical	O
to	O
the	O
one	O
I	O
used	O
for	O
a	O
mysql	O
database	O
,	O
can	O
anyone	O
see	O
why	O
sqlite	O
does	O
not	O
like	O
this	O
?	O

Here	O
is	O
the	O
full	O
query	O
as	O
created	O
by	O
pandas	O
.	O

#CODE	O

is	O
this	O
the	O
cause	O
:	O
[	O
This_Yr	O
`	O
s_Est.d_Growth_	O
(	O
F	O
(	O
1	O
)	O
/	O
F	O
(	O
0	O
))]	O
TEXT	O
it	O
looks	O
like	O
this	O
maybe	O
escaping	O
the	O
string	O

Taking	O
care	O
of	O
both	O
the	O
/	O
and	O
the	O
`	O
we	O
end	O
up	O
with	O

[	O
This_Yr's_Est	O
.d_Growth_	O
(	O
F	O
(	O
1	O
)	O
_over_F	O
(	O
0	O
))]	O
TEXT	O
,	O

but	O
it	O
still	O
returns	O
the	O
error	O
concerning	O
the	O
]	O
.	O

Thanks	O
though	O
!	O

I'd	O
do	O
a	O
divide	O
and	O
conquer	O
to	O
find	O
the	O
offending	O
column	O
line	O
,	O
so	O
remove	O
half	O
the	O
columns	O
,	O
parse	O
again	O
,	O
if	O
it	O
succeeds	O
,	O
try	O
the	O
other	O
half	O
,	O
on	O
failure	O
keep	O
halving	O
until	O
you	O
find	O
the	O
line	O
.	O

Fix	O
it	O
and	O
restart	O
again	O

I'll	O
probably	O
just	O
make	O
a	O
quick	O
python	O
screen	O
to	O
try	O
to	O
make	O
a	O
table	O
with	O
each	O
line	O
individually	O
.	O

Thanks	O
!	O

even	O
`"`	O
may	O
break	O
now	O
depending	O
on	O
the	O
database	O
backend	O
,	O
I	O
have	O
created	O
an	O
issue	O
[	O
here	O
]	O
(	O
#URL	O
)	O
and	O
the	O
fix	O
is	O
to	O
properly	O
quote	O
and	O
escape	O
things	O
.	O

Actually	O
the	O
issue	O
is	O
about	O
table	O
names	O
,	O
but	O
similar	O
.	O

`	O
[	O
]`	O
quotes	O
cannot	O
be	O
nested	O
.	O

You	O
should	O
use	O
a	O
quote	O
character	O
that	O
can	O
be	O
escaped	O
,	O
such	O
as	O
`"`	O
(	O
which	O
would	O
have	O
to	O
be	O
doubled	O
):	O
#CODE	O

(	O
In	O
this	O
case	O
,	O
you	O
don't	O
even	O
have	O
`"`	O
in	O
the	O
names	O
.	O
)	O

Matplotlib	O
DateFormatter	O
for	O
axis	O
label	O
not	O
working	O

I'm	O
trying	O
to	O
adjust	O
the	O
formatting	O
of	O
the	O
date	O
tick	O
labels	O
of	O
the	O
x-axis	O
so	O
that	O
it	O
only	O
shows	O
the	O
Year	O
and	O
Month	O
values	O
.	O

From	O
what	O
I've	O
found	O
online	O
,	O
I	O
have	O
to	O
use	O
mdates.DateFormatter	O
,	O
but	O
it's	O
not	O
taking	O
effect	O
at	O
all	O
with	O
my	O
current	O
code	O
as	O
is	O
.	O

Anyone	O
see	O
where	O
the	O
issue	O
is	O
?	O

(	O
the	O
dates	O
are	O
the	O
index	O
of	O
the	O
pandas	O
DF	O
)	O
#CODE	O

thanks	O
guys	O
!	O

Reproducible	O
scenario	O
code	O
:	O
#CODE	O

Still	O
can't	O
get	O
just	O
the	O
year	O
and	O
month	O
to	O
show	O
up	O
...	O

what	O
happens	O
if	O
you	O
set	O
the	O
format	O
after	O
you	O
draw	O
the	O
bars	O
?	O

@USER	O
-	O
if	O
I	O
set	O
the	O
format	O
after	O
.plot	B-API
,	O
get	O
an	O
error	O
like	O
this	O
:	O
ValueError	O
:	O
DateFormatter	O
found	O
a	O
value	O
of	O
x=0	O
,	O
which	O
is	O
an	O
illegal	O
date	O
.	O

This	O
usually	O
occurs	O
because	O
you	O
have	O
not	O
informed	O
the	O
axis	O
that	O
it	O
is	O
plotting	O
dates	O
,	O
e.g.	O
,	O
with	O
ax.xaxis_date()	O
.	O

It's	O
the	O
same	O
for	O
if	O
I	O
put	O
it	O
before	O
ax.xaxis_date()	O
or	O
after	O
.	O

oof	O
--	O
this	O
is	O
why	O
i	O
hate	O
plotting	O
with	O
pandas	O
.	O
can	O
you	O
make	O
your	O
example	O
reproducible	O
(	O
i.e.	O
,	O
add	O
code	O
that	O
creates	O
`	O
basisDF	O
`	O
without	O
any	O
external	O
files	O
)	O
and	O
I'll	O
try	O
to	O
take	O
a	O
look	O
.	O

@USER	O
-	O
reproducible	O
code	O
up	O
!	O

pandas	O
just	O
doesn't	O
work	O
well	O
with	O
custom	O
date-time	O
formats	O
.	O

You	O
need	O
to	O
just	O
use	O
raw	O
matplotlib	O
in	O
cases	O
like	O
this	O
.	O

#CODE	O

And	O
that	O
gives	O
me	O
:	O

ah	O
gotcha	O
.	O
thanks	O
Paul	O
!	O

pandas	O
series	B-API
/	O
frame	O
quantile	B-API
function	O
taking	O
multiple	O
probabilities	O
?	O

Is	O
there	O
a	O
way	O
to	O
call	O
frame.quantile	O
(	O
or	O
series.quantile	B-API
)	O
and	O
provide	O
a	O
list	O
of	O
probabilities	O
?	O

It	O
looks	O
like	O
this	O
is	O
simply	O
an	O
omission	O
in	O
the	O
code	O
as	O
it	O
relies	O
on	O
scipy.stats.scoreatpercentile	O
which	O
takes	O
both	O
a	O
list	O
of	O
probabilities	O
and	O
an	O
axis	O
argument	O
.	O

#CODE	O

Compare	O
to	O
:	O
#CODE	O

You	O
could	O
write	O
one	O
:	O
#CODE	O

Example	O
use	O
:	O
#CODE	O

+1	O
for	O
``	O
type	O
(	O
df	O
)``	O
as	O
a	O
constructor	O
.	O

Wish	O
I'd	O
thought	O
of	O
that	O
or	O
seen	O
it	O
a	O
year	O
ago	O
!	O

Just	O
use	O
the	O
built	O
in	O
quantiles	O
in	O
scipy.stats.mstats	O
or	O
pencentile	O
in	O
numpy	O
.	O

@USER	O
lol	O
,	O
considering	O
the	O
OP	O
is	O
using	O
it	O
in	O
their	O
question	O
!!	O

Summarize	O
grouped	O
data	O
in	O
Pandas	O
while	O
filtering	O
after	O
the	O
group	O
part	O

I	O
am	O
stumbling	O
over	O
the	O
exact	O
(	O
or	O
at	O
least	O
most	O
elegant	O
)	O
steps	O
to	O
group	O
and	O
aggregate	O
some	O
data	O
in	O
Pandas	O
.	O

Let's	O
say	O
I	O
have	O
a	O
DataFrame	B-API
that	O
looks	O
something	O
like	O
this	O
-	O
#CODE	O

I'd	O
like	O
to	O
get	O
the	O
sum	O
of	O
datacount	O
while	O
grouping	O
by	O
system	O
and	O
sub_system	O
,	O
as	O
long	O
as	O
the	O
datatype	O
does	O
not	O
equal	O
bar	O
,	O
and	O
then	O
put	O
those	O
totals	O
back	O
into	O
the	O
original	O
dataframe	B-API
.	O

If	O
I	O
try	O
non_bar_totals	O
=	O
df	O
[	O
df.datatype	O
!	O
=	O
'	O
bar	O
']	O
.groupby	B-API
([	O
'	O
system	O
'	O
,	O
'	O
sub_sytem	O
'])	O
.agg	O
(	O
np.sum	O
)	O
,	O
it'll	O
get	O
me	O
something	O
like	O
-	O
#CODE	O

But	O
now	O
I'm	O
not	O
sure	O
how	O
to	O
push	O
that	O
count	O
value	O
back	O
into	O
the	O
original	O
DataFrame	B-API
.	O

What	O
is	O
the	O
right	O
syntax	O
to	O
get	O
those	O
counts	O
to	O
be	O
pushed	O
back	O
into	O
the	O
original	O
Dataframe	B-API
?	O

The	O
end	O
product	O
should	O
look	O
like	O
-	O
#CODE	O

Thanks	O
,	O
I	O
know	O
this	O
is	O
something	O
simple	O
,	O
I'm	O
just	O
missing	O
the	O
right	O
keyword	O
to	O
find	O
an	O
example	O
of	O
someone	O
doing	O
it	O
.	O

Feels	O
like	O
you	O
should	O
be	O
able	O
to	O
use	O
a	O
transform	O
like	O
`	O
g.transform	O
(	O
lambda	O
x	O
:	O
x	O
[	O
'	O
datacount	O
']	O
.where	B-API
(	O
x	O
[	O
'	O
datatype	O
']	O
!	O
=	O
'	O
bar	O
')	O
.sum()	B-API
)`	O
but	O
not	O
quite	O
.	O

You	O
can	O
go	O
by	O
using	O
the	O
power	O
of	O
apply	B-API
function	O
:	O
#CODE	O

Superb	O
!	O

Thanks	O
for	O
the	O
quick	O
and	O
simple	O
answer	O
!	O

Pandas	O
sparse	O
dataframe	B-API
larger	O
on	O
disk	O
than	O
dense	O
version	O

I	O
find	O
that	O
the	O
sparse	O
versions	O
of	O
a	O
dataframe	B-API
are	O
actually	O
much	O
larger	O
when	O
saved	O
to	O
disk	O
than	O
dense	O
versions	O
.	O

What	O
am	O
I	O
doing	O
wrong	O
?	O

#CODE	O

Using	O
version	O
0.12.0	O

I	O
would	O
ultimately	O
like	O
to	O
efficiently	O
store	O
10^7	O
by	O
60	O
arrays	O
,	O
with	O
about	O
10%	O
density	O
,	O
then	O
pull	O
them	O
into	O
Pandas	O
dataframes	O
and	O
play	O
with	O
them	O
.	O

Edit	O
:	O
Thanks	O
to	O
Jeff	O
for	O
answering	O
the	O
original	O
question	O
.	O

Follow-up	O
question	O
:	O
This	O
appears	O
to	O
only	O
give	O
savings	O
for	O
pickling	O
,	O
and	O
not	O
when	O
using	O
other	O
formats	O
like	O
HDF5	O
.	O

Is	O
pickling	O
my	O
best	O
route	O
?	O

#CODE	O

This	O
is	O
data	O
that	O
,	O
as	O
a	O
list	O
of	O
indices	O
in	O
a	O
Matlab	O
.mat	O
file	O
,	O
is	O
less	O
than	O
12M	O
.	O

I	O
was	O
eager	O
to	O
get	O
it	O
into	O
an	O
HDF5	O
/	O
Pytables	O
format	O
so	O
that	O
I	O
could	O
grab	O
just	O
specific	O
indices	O
(	O
other	O
files	O
are	O
much	O
larger	O
,	O
and	O
take	O
much	O
longer	O
to	O
load	O
into	O
memory	O
)	O
,	O
and	O
then	O
readily	O
do	O
Pandasy	O
things	O
to	O
them	O
.	O

Perhaps	O
I	O
am	O
not	O
going	O
about	O
this	O
the	O
right	O
way	O
?	O

add	O
a	O
compression	O
filter	O
,	O
see	O
here	O
:	O
#URL	O

With	O
a	O
dense	O
dataframe	B-API
and	O
complevel=9	O
and	O
complib=	O
'	O
blosc	O
'	O
,	O
that	O
drops	O
us	O
from	O
544M	O
to	O
26M	O
.	O

Far	O
better	O
,	O
but	O
still	O
not	O
keeping	O
up	O
with	O
12M	O
.	O

Trying	O
compression	O
with	O
the	O
sparse	O
dataframe	B-API
throws	O
a	O
TypeError	O
:	O

`	O
TypeError	O
:	O
cannot	O
properly	O
create	O
the	O
storer	O
for	O
:	O
[	O
_TABLE_MAP	O
]	O
[	O
group	O
->	O
/	O
test_sparse	O
(	O
Group	O
)	O
''	O
,	O
value	O
->	O
,	O
table	O
->	O
True	O
,	O
append	B-API
->	O
True	O
,	O
kwargs	O
->	O
{	O
'	O
encoding	O
'	O
:	O
None}	O
]`	O

hmm	O
....	O

that's	O
not	O
the	O
correct	O
format	O
;	O
it	O
should	O
save	O
it	O
with	O
table=False	O
;	O
but	O
that's	O
the	O
default	O
too	O
.	O
let	O
me	O
take	O
a	O
look	O
.	O

can	O
you	O
post	O
the	O
frame	O
that	O
you	O
saved	O
(	O
in	O
dense	O
format	O
is	O
ok	O
)	O
,	O
compressed	O
pls	O
!	O
on	O
say	O
a	O
dropbox	O
link	O
?	O

Here	O
you	O
go	O
:	O
#URL	O

you	O
are	O
creating	O
a	O
frame	O
that	O
has	O
4000	O
columns	O
,	O
and	O
only	O
4	O
rows	O
;	O
sparse	O
is	O
dealt	O
with	O
rows-wise	O
,	O
so	O
reverse	O
the	O
dimensions	O
.	O

#CODE	O

Followup	O
.	O

Your	O
store	O
that	O
you	O
supplied	O
was	O
written	O
in	O
`	O
table	O
`	O
format	O
,	O
and	O
as	O
a	O
result	O
saved	O
the	O
dense	O
version	O
(	O
Sparse	O
is	O
not	O
supported	O
for	O
table	O
format	O
which	O
are	O
very	O
flexible	O
and	O
queryable	O
,	O
see	O
docs	O
.	O

Furthermore	O
,	O
you	O
may	O
want	O
to	O
experiment	O
with	O
saving	O
your	O
file	O
using	O
2	O
different	O
representations	O
of	O
the	O
sparse	O
format	O
.	O

so	O
,	O
here's	O
a	O
sample	O
session	O
:	O
#CODE	O

IIRC	O
their	O
is	O
a	O
bug	O
in	O
0.12	O
in	O
that	O
`	O
to_hdf	B-API
`	O
doesn't	O
pass	O
all	O
the	O
arguments	O
thru	O
,	O
so	O
you	O
prob	O
want	O
to	O
use	O
:	O
#CODE	O

These	O
are	O
stored	O
basically	O
as	O
a	O
collection	O
of	O
`	O
SparseSeries	O
`	O
so	O
if	O
the	O
density	O
is	O
low	O
and	O
non-contiguous	O
then	O
it	O
will	O
not	O
be	O
as	O
minimal	O
as	O
far	O
as	O
size	O
goes	O
.	O

Pandas	O
sparse	O
suite	O
deals	O
better	O
with	O
a	O
smaller	O
number	O
of	O
contiguous	O
blocks	O
,	O
though	O
YMMV	O
.	O
scipy	O
provides	O
some	O
sparse	O
handling	O
tools	O
as	O
well	O
.	O

Though	O
IMHO	O
,	O
these	O
are	O
pretty	O
trivial	O
sizes	O
for	O
HDF5	O
files	O
anyhow	O
,	O
you	O
can	O
handle	O
gigantic	O
number	O
of	O
rows	O
;	O
and	O
files	O
sizes	O
into	O
the	O
10's	O
and	O
100's	O
of	O
gigabytes	O
can	O
easily	O
be	O
handled	O
(	O
though	O
recommend	O
)	O
.	O

Furthermore	O
you	O
might	O
to	O
consider	O
using	O
a	O
table	O
format	O
if	O
this	O
is	O
indeed	O
a	O
lookup	O
table	O
as	O
you	O
can	O
query	O
.	O

Difficulty	O
importing	O
.dat	O
file	O

I	O
am	O
somehow	O
having	O
difficulty	O
reading	O
in	O
this	O
file	O
into	O
python	O
with	O
pandas	O
read_table	B-API
function	O
.	O

#URL	O

This	O
is	O
my	O
code	O
:	O
#CODE	O

Which	O
yields	O
error	O
:	O
#CODE	O

Dont	O
know	O
about	O
read_table	B-API
,	O
but	O
you	O
can	O
read	O
this	O
file	O
directly	O
as	O
follows	O
:	O
#CODE	O

Prints	O
:	O
#CODE	O

The	O
same	O
can	O
be	O
obtained	O
as	O
follows	O
:	O
#CODE	O

Just	O
thought	O
it	O
might	O
be	O
more	O
efficient	O
to	O
do	O
so	O
with	O
built-in	O
functions	O
.	O

Do	O
you	O
know	O
of	O
anyway	O
to	O
do	O
it	O
with	O
built-in	O
functions	O
?	O

you	O
can	O
simply	O
use	O
``	O
skiprows=0	O
``	O

Thanks	O
a	O
ton	O
.	O

I	O
think	O
the	O
trick	O
is	O
to	O
use	O
regular	O
expression	O
in	O
the	O
sep	O
argument	O
.	O

Cause	O
when	O
I	O
use	O
"	O
\s+	O
"	O
,	O
even	O
with	O
read_table	B-API
,	O
it	O
works	O
.	O

Good	O
to	O
hear	O
its	O
ok	O
now	O
:-)	O

Pandas	O
Grouping	O
and	O
Reducing	O
DataFrame	B-API

I	O
am	O
rather	O
new	O
to	O
Python	O
,	O
and	O
VERY	O
new	O
to	O
Pandas	O
(	O
I	O
am	O
having	O
a	O
more	O
difficult	O
time	O
learning	O
Pandas	O
than	O
Python	O
)	O
.	O

I	O
am	O
trying	O
to	O
transform	O
a	O
large	O
dataset	O
,	O
and	O
I	O
am	O
stuck	O
.	O

I	O
upload	O
data	O
from	O
a	O
CSV	O
that	O
has	O
the	O
following	O
structure	O
.	O

#CODE	O

My	O
end	O
goal	O
is	O
find	O
a	O
way	O
to	O
group	O
this	O
into	O
form	O
where	O
I	O
can	O
get	O
the	O
series	B-API
of	O
categories	O
leading	O
up	O
to	O
a	O
success	O
flag	O
for	O
a	O
specific	O
ID	O
,	O
then	O
an	O
array	O
of	O
the	O
time	O
elapsed	O
during	O
from	O
the	O
previous	O
row	O
the	O
same	O
ID	O
.	O

So	O
a	O
result	O
would	O
something	O
like	O
:	O
#CODE	O

I	O
am	O
not	O
sure	O
if	O
Pandas	O
'	O
or	O
NumPy's	O
multidimensional	O
arrays	O
would	O
be	O
better	O
suited	O
for	O
the	O
task	O
.	O

I	O
am	O
also	O
not	O
sure	O
what	O
functions	O
to	O
play	O
around	O
with	O
more	O
in	O
Pandas	O
to	O
accomplish	O
this	O
.	O

A	O
point	O
in	O
the	O
right	O
direction	O
would	O
be	O
greatly	O
helpful	O
.	O

I	O
do	O
not	O
100%	O
understand	O
the	O
question	O
.	O

I	O
am	O
unsure	O
what	O
the	O
(	O
0	O
,	O
2	O
,	O
4	O
)	O
means	O
.	O

Ok	O
let's	O
make	O
a	O
start	O
.	O

This	O
is	O
a	O
non	O
pandas-esque	O
way	O
,	O
what	O
with	O
all	O
the	O
dataframe	B-API
looping	O
.	O

I	O
have	O
your	O
data	O
in	O
csv	O
so	O
load	O
it	O
as	O
follows	O
:	O
#CODE	O

and	O
looks	O
like	O
:	O
#CODE	O

And	O
now	O
the	O
code	O
:	O
#CODE	O

produces	O
#CODE	O

wow	O
,	O
that	O
worked	O
.	O

To	O
clarify	O
,	O
the	O
second	O
array	O
is	O
a	O
time	O
delta	O
.	O

I	O
updated	O
your	O
code	O
to	O
give	O
the	O
day	O
delta	O
from	O
the	O
first	O
instance	O
of	O
the	O
unique	O
ID	O
,	O
then	O
to	O
reset	O
after	O
a	O
success	O
.	O

Thanks	O
!	O

the	O
real	O
data	O
file	O
is	O
pretty	O
huge	O
,	O
so	O
I	O
have	O
to	O
figure	O
out	O
how	O
to	O
make	O
this	O
fit	O
into	O
memory	O
.	O

But	O
this	O
is	O
awesome	O
,	O
I	O
now	O
have	O
a	O
direction	O
to	O
keep	O
learning	O
toward	O
.	O

Pandas	O
Python	O
:	O
sort	O
dataframe	B-API
but	O
don't	O
include	O
given	O
row	O

I	O
have	O
df	O
which	O
looks	O
like	O
this	O
:	O
#CODE	O

I	O
would	O
like	O
to	O
sort	O
this	O
in	O
acsending	O
order	O
but	O
I	O
dont	O
want	O
"	O
A	O
gauche	O
"	O
and	O
"	O
A	O
droite	O
"	O
included	O
in	O
the	O
sorting	O
.	O

The	O
code	O
below	O
does	O
what	O
I	O
want	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
exclude	O
"	O
A	O
gauche	O
"	O
and	O
"	O
A	O
droite	O
"	O
from	O
the	O
sorting	O
.	O

#CODE	O

expected	O
output	O
#CODE	O

Thanks	O

You	O
probably	O
want	O
to	O
filter	O
out	O
the	O
rows	O
you	O
don't	O
want	O
included	O
in	O
your	O
sort	O
operation	O
:	O
#CODE	O

Which	O
can	O
then	O
be	O
sorted	O
#CODE	O

And	O
if	O
you	O
want	O
the	O
excluded	O
rows	O
appended	O
to	O
the	O
end	O
of	O
your	O
data	O
frame	O
,	O
you	O
could	O
do	O
this	O
:	O
#CODE	O

Thanks	O
for	O
this	O
.	O

Q	O
-	O
What	O
would	O
I	O
do	O
if	O
the	O
rows	O
I	O
didn't	O
want	O
sorted	O
were	O
in	O
the	O
middle	O
,	O
say	O
row	O
3	O
and	O
5	O
?	O

You'd	O
either	O
have	O
to	O
do	O
more	O
splitting	O
and	O
concatenation	O
,	O
or	O
maybe	O
you	O
could	O
introduce	O
some	O
kind	O
of	O
weighting	O
function	O
.	O

It	O
would	O
probably	O
depend	O
on	O
whether	O
you	O
mean	O
'	O
put	O
this	O
row	O
at	O
position	O
3	O
when	O
I'm	O
done	O
sorting	O
'	O
or	O
'	O
put	O
this	O
row	O
after	O
this	O
other	O
row	O
when	O
I'm	O
done	O
sorting	O
'	O

Pandas	O
filter	O
rows	O
by	O
substring	O
within	O
text	O
column	O

I	O
have	O
a	O
list	O
of	O
keywords	O
as	O
well	O
as	O
a	O
DF	O
that	O
contains	O
a	O
text	O
column	O
.	O

I	O
am	O
trying	O
to	O
filter	O
out	O
every	O
row	O
where	O
the	O
text	O
in	O
the	O
text	O
field	O
contains	O
one	O
of	O
the	O
keywords	O
.	O

I	O
believe	O
what	O
am	O
I	O
looking	O
for	O
is	O
something	O
like	O
the	O
`	O
.isin	B-API
`	O
method	O
but	O
that	O
would	O
be	O
able	O
to	O
take	O
a	O
regex	O
argument	O
as	O
I	O
am	O
searching	O
for	O
substrings	O
within	O
the	O
text	O
not	O
exact	O
matches	O
.	O

What	O
I	O
have	O
:	O
#CODE	O

And	O
I	O
would	O
like	O
to	O
remove	O
any	O
rows	O
that	O
contain	O
a	O
key	O
in	O
the	O
text	O
so	O
I	O
would	O
end	O
up	O
with	O
:	O
#CODE	O

use	O
`	O
str.contains	B-API
`	O
and	O
join	O
the	O
keys	O
using	O
`	O
|	O
`	O
to	O
create	O
a	O
regex	O
pattern	O
and	O
negate	O
the	O
boolean	O
mask	O
`	O
~	O
`	O
to	O
filter	O
your	O
df	O
:	O
#CODE	O

Convert	O
pandas	O
multi-index	O
to	O
pandas	O
timestamp	O

I'm	O
trying	O
to	O
convert	O
an	O
unstacked	O
,	O
multi-indexed	O
data-frame	O
back	O
to	O
a	O
single	O
pandas	O
datetime	O
index	O
.	O

The	O
index	O
of	O
my	O
original	O
data-frame	O
,	O
i.e.	O
before	O
multi-indexing	O
and	O
unstacking	O
,	O
looks	O
like	O
this	O
:	O
#CODE	O

then	O
I	O
apply	B-API
the	O
multi-indexing	O
and	O
unstacking	O
so	O
I	O
can	O
plot	O
the	O
yearly	O
data	O
on	O
top	O
of	O
each	O
other	O
like	O
this	O
:	O
#CODE	O

My	O
new	O
data-frame	O
for	O
the	O
first	O
two	O
days	O
of	O
May	O
looks	O
like	O
this	O
:	O
#CODE	O

The	O
index	O
for	O
the	O
new	O
data	O
frame	O
shown	O
above	O
now	O
looks	O
like	O
this	O
:	O
#CODE	O

which	O
doesn't	O
produce	O
a	O
very	O
nice	O
plot	O
with	O
respect	O
to	O
the	O
xticks	O
(	O
major	O
and	O
minor	O
)	O
.	O

If	O
I	O
can	O
convert	O
this	O
multi-index	O
back	O
to	O
a	O
single	O
pandas	O
datetime	O
index	O
,	O
using	O
only	O
the	O
month	O
,	O
day	O
and	O
hour	O
data	O
,	O
then	O
the	O
major	O
/	O
minor	O
ticks	O
will	O
be	O
plotted	O
automagically	O
the	O
way	O
I	O
would	O
like	O
(	O
I	O
think	O
)	O
.	O

For	O
example	O
:	O

current	O
solution	O
:	O
#CODE	O

required	O
solution	O
:	O
#CODE	O

Even	O
a	O
little	O
hint	O
would	O
be	O
greatly	O
appreciated	O
.	O

How	O
do	O
I	O
go	O
about	O
bumping	O
this	O
up	O
for	O
some	O
support	O
?	O

There	O
are	O
some	O
questions	O
on	O
here	O
over	O
a	O
year	O
old	O
without	O
any	O
answers	O
.	O

Another	O
month	O
?	O

Anything	O
at	O
all	O
will	O
help	O
...	O

Is	O
there	O
a	O
reason	O
you	O
want	O
to	O
do	O
this	O
"	O
auto-magically	O
"	O
?	O

I	O
would	O
probably	O
just	O
write	O
a	O
function	O
to	O
custom	O
generate	O
the	O
x-labels	O
.	O

That	O
sounds	O
faster	O
than	O
what	O
you	O
want	O
.	O

Thanks	O
for	O
he	O
reply	O
.	O

Maybe	O
you're	O
right	O
,	O
it's	O
just	O
I	O
need	O
to	O
maintain	O
a	O
sensible	O
scale	O
when	O
zooming	O
in	O
.	O

I	O
know	O
this	O
would	O
be	O
taken	O
care	O
of	O
using	O
this	O
method	O
.	O

#CODE	O

I	O
think	O
this	O
is	O
a	O
better	O
way	O
to	O
accomplish	O
your	O
goal	O
than	O
re-indexing	O
.	O

What	O
do	O
you	O
think	O
?	O

Hey	O
!,	O
thanks	O
very	O
much	O
for	O
the	O
reply	O
.	O

Ok	O
,	O
I've	O
just	O
given	O
this	O
a	O
go	O
.	O

Yes	O
,	O
this	O
appears	O
to	O
be	O
a	O
much	O
easier	O
way	O
of	O
stacking	O
/	O
sorting	O
yearly	O
data	O
on	O
top	O
of	O
each	O
other	O
into	O
one	O
plot	O
,	O
so	O
thanks	O
for	O
that	O
.	O

However	O
,	O
it	O
isn't	O
a	O
solution	O
to	O
the	O
question	O
.	O

Instead	O
of	O
my	O
xticks	O
,	O
minor	O
/	O
major	O
,	O
being	O
yearly	O
coded	O
(	O
e.g.	O
day	O
month	O
hour	O
)	O
,	O
they	O
are	O
now	O
just	O
broken	O
down	O
into	O
arbitrary	O
chunks	O
of	O
single	O
data	O
points	O
,	O
scaling	O
from	O
0	O
to	O
n-1	O
,	O
where	O
n	O
is	O
the	O
number	O
datapoint	O
in	O
my	O
measurement	O
sample	O
set	O
.	O

Right	O
,	O
I	O
would	O
imagine	O
at	O
that	O
point	O
it's	O
an	O
x_axis	O
tick	O
manipulation	O
...	O
but	O
I	O
am	O
unable	O
to	O
figure	O
out	O
how	O
exactly	O
to	O
do	O
that	O
.	O

Could	O
you	O
perhaps	O
load	O
the	O
data	O
up	O
to	O
a	O
csv	O
somewhere	O
so	O
that	O
I	O
could	O
play	O
with	O
it	O
and	O
maybe	O
create	O
another	O
post	O
on	O
this	O
?	O

Would	O
hte	O
best	O
term	O
for	O
this	O
be	O
a	O
'	O
Seasonality	O
Plot	O
'	O
-	O
take	O
information	O
from	O
multiple	O
years	O
and	O
plot	O
them	O
on	O
one	O
Jan-Dec	O
axis	O
?	O

I	O
can't	O
find	O
any	O
documentation	O
on	O
how	O
to	O
do	O
this	O
which	O
is	O
surprising	O
to	O
me	O

Hey	O
!	O

I've	O
been	O
away	O
,	O
sorry	O
for	O
the	O
delay	O
.	O

Let	O
me	O
get	O
back	O
to	O
you	O
on	O
this	O
.	O

I'll	O
get	O
a	O
csv	O
to	O
you	O
also	O
.	O

Yes	O
to	O
your	O
question	O
also	O
.	O

That's	O
exactly	O
what	O
the	O
plot	O
is	O
all	O
about	O
.	O

Ok	O
,	O
here's	O
a	O
[	O
link	O
to	O
the	O
source	O
files	O
]	O
(	O
#URL	O
)	O
.	O

I've	O
included	O
a	O
small	O
program	O
too	O
,	O
so	O
that	O
you	O
can	O
have	O
a	O
real	O
example	O
to	O
play	O
with	O
.	O

If	O
you	O
launch	O
the	O
script	O
,	O
you	O
will	O
see	O
two	O
figures	O
.	O

Figure.1	O
is	O
the	O
requested	O
stacked	O
yearly	O
data	O
,	O
but	O
the	O
horrible	O
xticks	O
.	O

Figure.2	O
is	O
the	O
requested	O
xticks	O
but	O
without	O
the	O
yearly	O
stacking	O
.	O

Converting	O
data	O
back	O
and	O
forth	O
in	O
pandas	O
gets	O
messy	O
very	O
fast	O
,	O
as	O
you	O
seem	O
to	O
have	O
experienced	O
.	O

My	O
recommendation	O
in	O
general	O
concerning	O
pandas	O
and	O
indexing	O
,	O
is	O
to	O
never	O
just	O
set	O
the	O
index	O
,	O
but	O
to	O
copy	O
it	O
first	O
.	O

Make	O
sure	O
you	O
have	O
a	O
column	O
which	O
contains	O
the	O
index	O
,	O
since	O
pandas	O
does	O
not	O
allow	O
all	O
operations	O
on	O
the	O
index	O
,	O
and	O
intense	O
setting	O
and	O
resetting	O
of	O
the	O
index	O
can	O
cause	O
columns	O
to	O
dissapear	O
.	O

TLDR	O
;	O

Don't	O
convert	O
the	O
index	O
back	O
.	O

Keep	O
a	O
copy	O
.	O

This	O
also	O
ahears	O
to	O
the	O
open	O
/	O
closed	O
principle	O
:	O
#URL	O

Sort	O
Pandas	O
Dataframe	B-API
by	O
Date	O

I	O
have	O
a	O
pandas	O
dataframe	B-API
as	O
follows	O
:	O
#CODE	O

I	O
want	O
to	O
sort	O
it	O
by	O
`	O
Date	B-API
`	O
,	O
but	O
the	O
column	O
is	O
just	O
an	O
`	O
object	O
`	O
.	O

I	O
tried	O
to	O
make	O
the	O
column	O
a	O
date	O
object	O
,	O
but	O
I	O
ran	O
into	O
an	O
issue	O
where	O
that	O
format	O
is	O
not	O
the	O
format	O
needed	O
.	O

The	O
format	O
needed	O
is	O
`	O
2015-02-20	O
,	O
`	O
etc	O
.	O

So	O
now	O
I'm	O
trying	O
to	O
figure	O
out	O
how	O
to	O
have	O
numpy	O
convert	O
the	O
'	O
American	O
'	O
dates	O
into	O
the	O
ISO	O
standard	O
,	O
so	O
that	O
I	O
can	O
make	O
them	O
date	O
objects	O
,	O
so	O
that	O
I	O
can	O
sort	O
by	O
them	O
.	O

How	O
would	O
I	O
convert	O
these	O
american	O
dates	O
into	O
ISO	O
standard	O
,	O
or	O
is	O
there	O
a	O
more	O
straight	O
forward	O
method	O
I'm	O
missing	O
within	O
pandas	O
?	O

You	O
can	O
use	O
`	O
pd.to_datetime()	B-API
`	O
to	O
convert	O
to	O
a	O
datetime	O
object	O
.	O

It	O
takes	O
a	O
format	O
parameter	O
,	O
but	O
in	O
your	O
case	O
I	O
don't	O
think	O
you	O
need	O
it	O
.	O

#CODE	O

I	O
also	O
have	O
a	O
df	O
[	O
'	O
Date	O
']	O
.unique()	B-API
before	O
the	O
sort	O
,	O
which	O
returns	O
a	O
series	B-API
instead	O
of	O
a	O
Dataframe	B-API
.	O

This	O
makes	O
02	O
/	O
20	O
/	O
2015	O
into	O
2015-02-19T18	O
:	O
00:00	O
.000000000	O
-0600	O
which	O
then	O
gets	O
split	O
into	O
2015-02-19	O
.	O

Is	O
there	O
a	O
way	O
to	O
add	O
a	O
day	O
?	O

Or	O
a	O
more	O
formal	O
way	O
to	O
correct	O
this	O
?	O

`	O
df.Date.astype	O
(	O
np.int64	O
)`	O
should	O
work	O
for	O
epoch	O
time	O

Turns	O
out	O
that	O
epoch	O
would	O
be	O
wrong	O
since	O
its	O
assuming	O
times	O
of	O
18:00	O
hours	O
etc	O
.	O

I	O
need	O
them	O
to	O
be	O
00:00	O
hours	O
.	O

I	O
have	O
a	O
way	O
to	O
convert	O
to	O
epoch	O
if	O
I	O
could	O
just	O
get	O
the	O
date	O
objects	O
to	O
not	O
have	O
a	O
time	O
,	O
or	O
the	O
wrong	O
time	O
.	O

for	O
me	O
`	O
pd.to_datetime	B-API
(	O
df.Date	O
)	O
[	O
0	O
]`	O
returns	O
`	O
Timestamp	O
(	O
'	O
2015-02-20	O
00:00	O
:	O
00	O
')`	O

Starting	O
new	O
question	O
with	O
more	O
formal	O
description	O
of	O
issue	O

It	O
looks	O
like	O
there	O
may	O
actually	O
be	O
[	O
a	O
faster	O
way	O
]	O
(	O
#URL	O
)	O
of	O
converting	O
strings	O
into	O
dates	O
.	O

@USER	O
'	O
s	O
answer	O
is	O
fast	O
and	O
concise	O
.	O

But	O
it	O
changes	O
the	O
`	O
DataFrame	B-API
`	O
you	O
are	O
trying	O
to	O
sort	O
,	O
which	O
you	O
may	O
or	O
may	O
not	O
want	O
.	O

(	O
Note	O
:	O
You	O
almost	O
certainly	O
will	O
want	O
it	O
,	O
because	O
your	O
date	O
columns	O
should	O
be	O
dates	O
,	O
not	O
strings	O
!	O
)	O

In	O
the	O
unlikely	O
event	O
that	O
you	O
don't	O
want	O
to	O
change	O
the	O
dates	O
into	O
dates	O
,	O
you	O
can	O
also	O
do	O
it	O
a	O
different	O
way	O
.	O

First	O
,	O
get	O
the	O
index	O
from	O
your	O
sorted	O
`	O
Date	B-API
`	O
column	O
:	O
#CODE	O

Then	O
use	O
it	O
to	O
index	O
your	O
original	O
`	O
DataFrame	B-API
`	O
,	O
leaving	O
it	O
untouched	O
:	O
#CODE	O

Magic	O
!	O

Python	O
-	O
Pandas	O
'	O
.isin	B-API
'	O
on	O
a	O
list	O

I'm	O
using	O
Python	O
2.7	O
on	O
Mac	O
OSX	O
Lion	O
and	O
Pandas	O
0.11.0	O
with	O
the	O
IPython	O
shell	O
.	O

I	O
have	O
a	O
brief	O
issue	O
,	O
using	O
the	O
data	O
selection	O
method	O
`	O
.isin	B-API
`	O
.	O

The	O
issue	O
is	O
that	O
I	O
would	O
like	O
to	O
use	O
`	O
.isin	B-API
`	O
on	O
a	O
list	O
of	O
items	O
,	O
so	O
:	O
#CODE	O

I	O
get	O
the	O
following	O
error	O
when	O
I	O
do	O
this	O
:	O
`	O
KeyError	O
:	O
u'no	O
item	O
named	O
'`	O

I	O
generate	O
the	O
initial	O
list	O
by	O
calling	O
a	O
previously	O
developed	O
function	O
.	O

I	O
tried	O
using	O
`	O
eval	B-API
`	O
on	O
the	O
list	O
,	O
which	O
seems	O
to	O
solve	O
an	O
issue	O
that	O
comes	O
about	O
when	O
using	O
`	O
raw_input	O
`	O
and	O
iterating	O
over	O
items	O
within	O
it	O
-	O
kinda	O
trying	O
to	O
work	O
out	O
some	O
of	O
the	O
issues	O
I've	O
been	O
having	O
when	O
transitioning	O
to	O
`	O
IPython	O
`	O
and	O
`	O
Python	O
2.7	O
`	O
(	O
originally	O
used	O
`	O
Python	O
3.3	O
`)	O
.	O

I	O
also	O
tried	O
iterating	O
over	O
the	O
list	O
,	O
by	O
first	O
doing	O
:	O
#CODE	O

But	O
that	O
also	O
returns	O
:	O
`	O
KeyError	O
:	O
u'no	O
item	O
named	O
'`	O

UPDATE	O
:	O

Here	O
is	O
the	O
header	O
:	O
#CODE	O

Also	O
,	O
I	O
have	O
a	O
function	O
I	O
use	O
to	O
get	O
the	O
header	O
,	O
which	O
makes	O
things	O
easier	O
for	O
me	O
,	O
the	O
output	O
looks	O
like	O
this	O
:	O
#CODE	O

Which	O
,	O
actually	O
,	O
now	O
that	O
I	O
think	O
about	O
it	O
,	O
may	O
be	O
what	O
is	O
causing	O
the	O
problem-	O
although	O
`	O
eval	B-API
`	O
still	O
would	O
not	O
fix	O
it	O
.	O

UPDATE	O
2	O
:	O

So	O
,	O
initially	O
,	O
as	O
you	O
can	O
see	O
in	O
the	O
above	O
`	O
.isin	B-API
`	O
,	O
I	O
was	O
using	O
`	O
header	O
[	O
0	O
]`	O
,	O
which	O
was	O
not	O
right	O
.	O

I	O
tried	O
again	O
using	O
`	O
header	O
[	O
1	O
]`	O
,	O
which	O
is	O
appropriate	O
.	O

I	O
get	O
the	O
following	O
error	O
:	O
#CODE	O

I	O
also	O
tried	O
the	O
regular	O
list	O
again	O
and	O
got	O
this	O
error	O
:	O
#CODE	O

Which	O
,	O
I	O
guess	O
,	O
speaks	O
more	O
definitively	O
to	O
the	O
issue	O
....	O

Is	O
your	O
`	O
header	O
`	O
a	O
DataFrame	B-API
?,	O
What's	O
the	O
difference	O
between	O
your	O
`	O
df	O
`	O
and	O
`	O
header	O
`	O
?	O

Within	O
the	O
`	O
df	O
[	O
df	O
[	O
header	O
[	O
0	O
]]	O
.isin	B-API
(	O
list	O
)]`	O
,	O
header	O
is	O
not	O
a	O
`	O
DataFrame	B-API
`	O
.	O

It	O
is	O
a	O
list	O
of	O
the	O
column	O
names	O
,	O
which	O
compose	O
the	O
header	O
.	O

How	O
did	O
you	O
get	O
the	O
header	O
?	O

By	O
`	O
df.columns	O
`	O
?	O

I	O
got	O
the	O
header	O
by	O
calling	O
a	O
function	O
I	O
wrote	O
called	O
`	O
getHeader	O
`	O
,	O
which	O
literally	O
just	O
returns	O
the	O
name	O
of	O
the	O
columns	O
,	O
in	O
the	O
form	O
of	O
a	O
list	O
,	O
from	O
a	O
CSV	O
file	O
.	O

Although	O
,	O
I	O
did	O
also	O
put	O
the	O
result	O
of	O
calling	O
`	O
DataFrame.columns	O
`	O
,	O
which	O
is	O
right	O
below	O
where	O
it	O
says	O
"	O
UPDATE	O
"	O
...	O

let	O
us	O
[	O
continue	O
this	O
discussion	O
in	O
chat	O
]	O
(	O
#URL	O
)	O

Try	O
to	O
use	O
df.columns	O
as	O
your	O
header	O
instead	O
:	O
#CODE	O

Pandas	O
:	O
Quickly	O
joining	O
on	O
a	O
MultiIndex	O
or	O
reindexing	O

I	O
have	O
some	O
very	O
sparse	O
,	O
multidimensional	O
time	O
series	B-API
,	O
with	O
activity	O
at	O
certain	O
times	O
and	O
zero	O
activity	O
at	O
other	O
times	O
.	O

I'm	O
representing	O
the	O
data	O
in	O
Pandas	O
as	O
a	O
`	O
SparseDataframe	O
`	O
with	O
a	O
`	O
MultiIndex	O
`	O
.	O

The	O
work	O
flow	O
is	O
to	O
perform	O
calculations	O
on	O
the	O
small	O
set	O
of	O
data	O
that	O
are	O
non-zero	O
,	O
then	O
put	O
the	O
results	O
into	O
the	O
large	O
sparse	O
dataframe	B-API
.	O

Later	O
I	O
will	O
do	O
calculations	O
on	O
that	O
sparse	O
dataframe	B-API
(	O
namely	O
tracking	O
the	O
change	O
in	O
activity	O
over	O
time	O
,	O
including	O
the	O
zero	O
activity	O
areas	O
)	O
.	O

The	O
problem	O
is	O
in	O
putting	O
the	O
small	O
set	O
of	O
data	O
into	O
the	O
sparse	O
dataframe	B-API
.	O

Below	O
is	O
a	O
much	O
smaller	O
dataset	O
than	O
what	O
I	O
will	O
eventually	O
use	O
.	O

With	O
a	O
regular	O
index	O
it's	O
ok	O
:	O
#CODE	O

With	O
a	O
`	O
MultiIndex	O
`	O
it's	O
much	O
slower	O
!	O

#CODE	O

I	O
thought	O
the	O
issue	O
might	O
be	O
in	O
using	O
`	O
join	B-API
`	O
,	O
so	O
I	O
tried	O
another	O
route	O
.	O

It	O
was	O
faster	O
but	O
did	O
not	O
solve	O
the	O
problem	O
.	O

#CODE	O

It	O
is	O
indeed	O
faster	O
to	O
use	O
`	O
reindex	B-API
`	O
instead	O
of	O
`	O
join	B-API
`	O
,	O
but	O
now	O
`	O
MultiIndex	O
`	O
is	O
even	O
slower	O
,	O
comparatively	O
!	O

What	O
are	O
my	O
options	O
?	O

Is	O
there	O
a	O
way	O
to	O
achieve	O
the	O
speed	O
of	O
a	O
regular	O
index	O
with	O
the	O
`	O
MultiIndex	O
`	O
?	O

Is	O
there	O
an	O
elegant	O
way	O
to	O
make	O
a	O
regular	O
index	O
function	O
like	O
the	O
`	O
MultiIndex	O
`	O
?	O

Should	O
I	O
be	O
rethinking	O
how	O
to	O
do	O
all	O
of	O
this	O
?	O

Pandas	O
dataframe	B-API
:	O
representing	O
variable	O
length	O
3D	O
data	O
?	O

column	O
with	O
variable	O
length	O
list	O
?	O

There's	O
been	O
a	O
couple	O
times	O
where	O
I've	O
had	O
a	O
timeseries	O
,	O
where	O
one	O
of	O
the	O
columns	O
is	O
a	O
variable	O
length	O
array	O
of	O
information	O
.	O

One	O
example	O
would	O
be	O
image	O
statistics	O
,	O
where	O
the	O
index	O
is	O
a	O
datetime	O
,	O
and	O
the	O
columns	O
are	O
statistics	O
.	O

There	O
is	O
also	O
some	O
global	O
information	O
for	O
each	O
image	O
(	O
location	O
,	O
size	O
,	O
average	O
intensity	O
,	O
etc	O
)	O
,	O
but	O
also	O
a	O
variable	O
number	O
of	O
features	O
are	O
detected	O
,	O
and	O
is	O
some	O
information	O
for	O
each	O
of	O
those	O
features	O
(	O
e.g.	O
response	O
,	O
distance	O
,	O
angle	O
)	O
.	O

I'd	O
want	O
to	O
be	O
able	O
to	O
plot	O
and	O
explore	O
both	O
global	O
frame	O
stats	O
along	O
with	O
the	O
feature	O
stats	O
.	O

For	O
example	O
,	O
plotting	O
average	O
intensity	O
vs	O
location	O
.	O

However	O
,	O
I'd	O
also	O
want	O
to	O
be	O
able	O
to	O
do	O
histograms	O
or	O
violin	O
plots	O
across	O
all	O
of	O
the	O
features	O
:	O
e.g.	O
density	O
plots	O
of	O
feature	O
responses	O
based	O
on	O
time	O
of	O
day	O
.	O

Idealy	O
I	O
could	O
groupby	B-API
and	O
have	O
all	O
of	O
those	O
variable	O
length	O
lists	O
(	O
feature	O
responses	O
)	O
appended	O
to	O
the	O
same	O
group	O
.	O

I'd	O
love	O
to	O
be	O
able	O
to	O
represent	O
as	O
much	O
as	O
I	O
can	O
natively	O
pandas	O
.	O

Of	O
course	O
I	O
could	O
have	O
a	O
tuple	O
or	O
np.array	O
,	O
and	O
groupby	B-API
manually	O
,	O
but	O
then	O
I	O
couldn't	O
serialize	O
to	O
a	O
table	O
format	O
,	O
unless	O
I	O
convert	O
to	O
a	O
string	O
,	O
etc	O
.	O

did	O
you	O
consider	O
using	O
HDF	O
?	O

It	O
ties	O
in	O
well	O
with	O
numpy	O
and	O
pandas	O
,	O
allows	O
you	O
to	O
have	O
a	O
bunch	O
of	O
attributes	O
that	O
describe	O
the	O
timeseries	O
and	O
has	O
2	O
good	O
python	O
modules	O
H5PY	O
and	O
PyTables	O
.	O

Can	O
you	O
explain	O
how	O
to	O
tie	O
it	O
in	O
with	O
reference	O
to	O
my	O
question	O
?	O

I	O
use	O
HDF	O
to	O
store	O
the	O
entire	O
dataframe	B-API
(	O
in	O
fixed	O
format	O
,	O
not	O
table	O
format	O
)	O
,	O
but	O
are	O
you	O
saying	O
I	O
can	O
reference	O
a	O
HDF	O
as	O
a	O
column	O
for	O
a	O
row	O
?	O

pandas	O
handle	O
NaN	O
/	O
None	O
inserts	O
into	O
sybase	O

is	O
there	O
already	O
a	O
working	O
solution	O
to	O
insert	B-API
NaN	O
/	O
None	O
values	O
from	O
a	O
pandas	O
dataframe	B-API
into	O
sybase-ASE	O
tables	O
?	O

I	O
tried	O
the	O
suggested	O
solution	O
after	O
researching	O
online	O
(	O
for	O
pandas	O
side	O
):	O

df.where	B-API
(	O
pd.notnull	B-API
(	O
df	O
)	O
,	O
None	O
)	O

However	O
,	O
when	O
I	O
try	O
to	O
insert	B-API
this	O
into	O
sybase-ASE	O
using	O
bulk_copy	O
/	O
bcp	O
,	O
the	O
None	O
gets	O
inserted	O
as	O
'	O
nan.0	O
'	O
for	O
some	O
reason	O
.	O

Any	O
ideas	O
why	O
this	O
would	O
happen	O
or	O
anyone	O
knows	O
of	O
a	O
workaround	O
to	O
accomplish	O
these	O
insertions	O
of	O
NaN	O
/	O
None	O
as	O
NULL	O
into	O
sybase	O
?	O

[	O
sybase	O
supports	O
NULL	O
]	O

full	O
stacktrace	O
for	O
the	O
DatabaseError	O
:	O
#CODE	O

As	O
Sybase	O
is	O
supported	O
by	O
sqlalchemy	O
(	O
#URL	O
)	O
,	O
this	O
should	O
just	O
work	O
out	O
of	O
the	O
box	O
with	O
`	O
to_sql	B-API
`	O
(	O
no	O
need	O
to	O
convert	O
to	O
Nones	O
with	O
`	O
where	O
`)	O
.	O

What	O
version	O
of	O
pandas	O
are	O
you	O
using	O
?	O

And	O
can	O
you	O
provide	O
a	O
small	O
code	O
sample	O
that	O
you	O
use	O
to	O
insert	B-API
the	O
data	O
?	O

Thank	O
you	O
for	O
your	O
response	O
.	O

My	O
understanding	O
(	O
from	O
a	O
brief	O
previous	O
attempt	O
)	O
was	O
that	O
to_sql	B-API
or	O
pd.io.sql.write_frame	O
does	O
not	O
work	O
for	O
sybase	O
,	O
but	O
I	O
will	O
test	O
this	O
out	O
again	O
with	O
to_sql	B-API
.	O

I	O
am	O
using	O
0.12.0	O
version	O
of	O
pandas	O
.	O

Here	O
is	O
a	O
code	O
sample	O
of	O
how	O
I	O
convert	O
the	O
dataframe	B-API
to	O
a	O
list	O
and	O
then	O
do	O
the	O
bulk	O
copy	O
to	O
insert	B-API
this	O
data	O
into	O
sybase	O
ase	O
:	O
inList	O
=	O
df.values.tolist()	O
blk	O
=	O
self.sybase_conn.blkcursor()	O
blk.copy	O
(	O
table	O
,	O
direction=	O
'	O
in	O
')	O
blk.rowxfermany	O
(	O
inList	O
)	O

You	O
will	O
have	O
to	O
update	O
your	O
pandas	O
version	O
to	O
at	O
least	O
0.15	O
to	O
be	O
able	O
to	O
try	O
if	O
it	O
works	O
with	O
sybase	O
(	O
in	O
previous	O
versions	O
only	O
mysql	O
/	O
sqlite	O
were	O
supported	O
)	O

ok	O
,	O
thanks	O
.	O

I	O
am	O
trying	O
to	O
test	O
this	O
with	O
pandas	O
0.15.2-16	O
now	O
.	O

The	O
connection	O
to	O
sybase	O
and	O
sqlalchemy	O
engine	O
creation	O
looks	O
good	O
.	O

However	O
,	O
I	O
am	O
running	O
into	O
the	O
following	O
error	O
when	O
trying	O
to	O
execute	O
the	O
to_sql	B-API
:	O
dataframe.to_sql	B-API
(	O
'	O
sybase_table_name	O
'	O
,	O
engine	O
,	O
if_exists=	O
'	O
append	B-API
'	O
,	O
index=False	O
)	O
sqlalchemy.exc.DatabaseError	O
:	O
(	O
DatabaseError	O
)	O
Msg	O
102	O
,	O
Level	O
15	O
,	O
State	O
181	O
,	O
Line	O
1	O

Incorrect	O
syntax	O
near	O
'	O
,	O
'	O
.	O

can't	O
see	O
anything	O
obvious	O
as	O
to	O
the	O
root	O
cause	O
of	O
the	O
above	O
DatabaseError	O
.	O

Can	O
you	O
post	O
the	O
full	O
error	O
stacktrace	O
in	O
your	O
question	O
?	O

File	O
"	O
/	O
six2r9cj6gx8yhdpjygflakgnxyjxj2y-sybase-15.0-jump1.00-3	O
/	O
lib-python	O
/	O
Sybase.py	O
"	O
,	O
line	O
753	O
,	O
in	O
_raise_error	O

raise	O
exc	O

sqlalchemy.exc.DatabaseError	O
:	O
(	O
DatabaseError	O
)	O
Msg	O
102	O
,	O
Level	O
15	O
,	O
State	O
181	O
,	O
Line	O
1	O

Incorrect	O
syntax	O
near	O
'	O
,	O
'	O
.	O

Does	O
this	O
help	O
?	O

Unable	O
to	O
post	O
the	O
full	O
trace	O
due	O
to	O
size	O
limitation	O
here	O
.	O

you	O
can	O
update	O
the	O
original	O
question	O
to	O
include	O
it	O
.	O

Let	O
us	O
[	O
continue	O
this	O
discussion	O
in	O
chat	O
]	O
(	O
#URL	O
)	O
.	O

This	O
seems	O
a	O
bug	O
in	O
sqlalchemy	O
.	O

But	O
,	O
you	O
have	O
a	O
rather	O
old	O
version	O
of	O
sqlalchemy	O
(	O
0.7.9	O
,	O
while	O
the	O
most	O
recent	O
is	O
1.0.x	O
)	O
.	O

Can	O
you	O
first	O
try	O
to	O
update	O
sqlalchemy	O

ok	O
,	O
tried	O
with	O
the	O
latest	O
version	O
of	O
sqlalchemy	O
and	O
encountered	O
similar	O
error	O
:	O
In	O
[	O
9	O
]:	O
sqlalchemy.__version__	O

Out	O
[	O
9	O
]:	O
'	O
1.0.6	O
'	O
dataframe.to_sql	B-API
(	O
'	O
sybase_table_name	O
'	O
,	O
engine	O
,	O
if_exists=	O
'	O
append	B-API
'	O
,	O
index=False	O
)	O

DatabaseError	O
:	O
(	O
Sybase.DatabaseError	O
)	O
Msg	O
102	O
,	O
Level	O
15	O
,	O
State	O
181	O
,	O
Line	O
1	O

Can	O
you	O
try	O
with	O
only	O
a	O
couple	O
of	O
columns	O
first	O
?	O

Do	O
you	O
then	O
get	O
the	O
same	O
error	O
then	O
?	O

(	O
or	O
try	O
only	O
a	O
couple	O
of	O
rows	O
,	O
some	O
different	O
things	O
to	O
see	O
what	O
triggers	O
the	O
error	O
)	O

possible	O
bug	O
in	O
pandas	O
sort	O
with	O
NaN	O
values	O

If	O
I	O
make	O
a	O
dataframe	B-API
like	O
the	O
following	O
:	O
#CODE	O

basic	O
sorts	O
perform	O
as	O
expected	O
.	O

Sorting	O
on	O
column	O
c	O
appropriately	O
segregates	O
the	O
nan	O
values	O
.	O

Doing	O
a	O
multi-level	O
sort	O
on	O
columns	O
a	O
and	O
b	O
orders	O
them	O
as	O
expected	O
:	O
#CODE	O

But	O
doing	O
a	O
multi-level	O
sort	O
with	O
columns	O
b	O
and	O
c	O
does	O
not	O
give	O
the	O
expected	O
result	O
:	O
#CODE	O

And	O
,	O
in	O
fact	O
,	O
even	O
sorting	O
just	O
on	O
column	O
c	O
but	O
using	O
the	O
multi-level	O
sort	O
nomenclature	O
fails	O
:	O
#CODE	O

I	O
would	O
think	O
that	O
this	O
should	O
have	O
given	O
the	O
exact	O
same	O
result	O
as	O
line	O
133	O
above	O
.	O

Is	O
this	O
a	O
pandas	O
bug	O
or	O
is	O
there	O
something	O
I'm	O
not	O
getting	O
?	O

(	O
FYI	O
,	O
pandas	O
v0.11.0	O
,	O
numpy	O
v1.7.1	O
,	O
python	O
2.7.2.5	O
32bit	O
on	O
windows	O
7	O
)	O

possible	O
duplicate	O
of	O
[	O
Pandas	O
nested	O
sort	O
and	O
NaN	O
]	O
(	O
#URL	O
)	O

I	O
noticed	O
that	O
test.sort	O
(	O
columns=	O
'	O
c	O
'	O
,	O
ascending=False	O
)	O
.sort	B-API
(	O
columns=	O
'	O
b	O
'	O
,	O
ascending=False	O
)	O
does	O
give	O
the	O
correct	O
answer	O
in	O
this	O
case	O
.	O

But	O
I	O
don't	O
know	O
if	O
that's	O
a	O
robust	O
solution	O
.	O

Anyone	O
have	O
a	O
thought	O
?	O

That	O
will	O
only	O
work	O
if	O
pandas	O
sorting	O
algorithm	O
is	O
stable	O
.	O

I	O
didn't	O
find	O
anything	O
in	O
the	O
docs	O
(	O
and	O
numpy's	O
sorting	O
algorithm	O
is	O
not	O
stable	O
by	O
default	O
)	O
.	O

I'm	O
trying	O
to	O
find	O
the	O
source	O
now	O
....	O

@USER	O
checkout	O
this	O
[	O
bug	O
report	O
]	O
(	O
#URL	O
)	O
on	O
this	O

it	O
calls	O
`	O
k.argsort	O
`	O
...	O
where	O
`	O
k	O
`	O
is	O
a	O
column	O
of	O
the	O
dataframe	B-API
--	O
Presumably	O
this	O
is	O
a	O
numpy	O
array	O
which	O
gives	O
the	O
indices	O
to	O
tell	O
pandas	O
how	O
to	O
re-order	O
the	O
data	O
.	O

Unfortunatetly	O
,	O
np.argsort	O
uses	O
(	O
by	O
default	O
)	O
the	O
`	O
quicksort	O
`	O
algorithm	O
which	O
isn't	O
stable	O
,	O
so	O
your	O
solution	O
isn't	O
100%	O
robust	O
.	O

@USER	O
--	O
I'm	O
glad	O
unutbu's	O
on	O
it	O
.	O

:)	O

This	O
is	O
an	O
interesting	O
corner	O
case	O
.	O

Note	O
that	O
even	O
vanilla	O
python	O
doesn't	O
get	O
this	O
"	O
correct	O
"	O
:	O
#CODE	O

The	O
reason	O
here	O
is	O
because	O
`	O
NaN	O
`	O
is	O
neither	O
greater	O
nor	O
less	O
than	O
the	O
other	O
elements	O
--	O
So	O
there	O
is	O
no	O
strict	O
ordering	O
defined	O
.	O

Because	O
of	O
this	O
,	O
`	O
python	O
`	O
leaves	O
them	O
alone	O
.	O

#CODE	O

Pandas	O
must	O
make	O
an	O
explicit	O
check	O
in	O
the	O
single	O
column	O
case	O
--	O
probably	O
using	O
`	O
np.argsort	O
`	O
or	O
`	O
np.sort	O
`	O
as	O
starting	O
at	O
numpy	O
1.4	O
,	O
`	O
np.sort	O
`	O
puts	O
`	O
NaN	O
`	O
values	O
at	O
the	O
end	O
.	O

Thanks	O
for	O
the	O
heads	O
up	O
above	O
.	O

I	O
guess	O
this	O
is	O
already	O
a	O
known	O
issue	O
.	O

One	O
stopgap	O
solution	O
I	O
came	O
up	O
with	O
is	O
:	O
#CODE	O

This	O
method	O
wouldn't	O
work	O
in	O
regular	O
numpy	O
since	O
.min()	B-API
would	O
return	O
nan	O
,	O
but	O
in	O
pandas	O
it	O
works	O
fine	O
.	O

Numpy	O
does	O
have	O
a	O
`	O
nanmin	O
`	O
function	O
I	O
believe	O
:)	O
.	O

pandas	O
:	O
filter	O
intraday	O
df	O
by	O
non-consecutive	O
list	O
of	O
dates	O

I	O
have	O
dataframes	O
of	O
1	O
minute	O
bars	O
going	O
back	O
years	O
(	O
the	O
datetime	O
is	O
the	O
index	O
)	O
.	O

I	O
need	O
to	O
get	O
a	O
set	O
of	O
bars	O
covering	O
an	O
irregular	O
(	O
non-consecutive	O
)	O
long	O
list	O
of	O
dates	O
.	O

For	O
daily	O
bars	O
,	O
I	O
could	O
do	O
something	O
like	O
this	O
:	O
#CODE	O

However	O
if	O
I	O
try	O
that	O
on	O
1	O
minute	O
bar	O
data	O
,	O
it	O
only	O
gives	O
me	O
the	O
bars	O
with	O
time	O
00:00	O
:	O
00	O
,	O
e.g.	O
in	O
this	O
case	O
it	O
gives	O
me	O
two	O
bars	O
for	O
20140101	O
00:00	O
:	O
00	O
and	O
20140205	O
00:00	O
:	O
00	O
.	O

My	O
actual	O
source	O
df	O
will	O
look	O
something	O
like	O
:	O
#CODE	O

Is	O
there	O
any	O
better	O
way	O
to	O
get	O
all	O
the	O
bars	O
for	O
each	O
day	O
in	O
the	O
list	O
than	O
looping	O
over	O
the	O
list	O
?	O

Thanks	O
in	O
advance	O
.	O

One	O
way	O
is	O
to	O
add	O
a	O
date	O
column	O
based	O
on	O
the	O
index	O
#CODE	O

Then	O
use	O
that	O
column	O
when	O
filtering	O
#CODE	O

Thank	O
you	O
-	O
simple	O
and	O
effective	O
.	O

I	O
was	O
actually	O
able	O
to	O
do	O
without	O
the	O
extra	O
column	O
by	O
just	O
directly	O
doing	O
:	O
`	O
df1m	O
[	O
pd.to_datetime	B-API
(	O
df1m.index.date	O
)	O
.isin	B-API
(	O
datelist	O
)]`	O

Constructing	O
3D	O
Pandas	O
DataFrame	B-API

I'm	O
having	O
difficulty	O
constructing	O
a	O
3D	O
DataFrame	B-API
in	O
Pandas	O
.	O

I	O
want	O
something	O
like	O
this	O
#CODE	O

Where	O
`	O
A	O
`	O
,	O
`	O
B	O
`	O
,	O
etc	O
are	O
the	O
top-level	O
descriptors	O
and	O
`	O
start	O
`	O
and	O
`	O
end	O
`	O
are	O
subdescriptors	O
.	O

The	O
numbers	O
that	O
follow	O
are	O
in	O
pairs	O
and	O
there	O
aren't	O
the	O
same	O
number	O
of	O
pairs	O
for	O
`	O
A	O
`	O
,	O
`	O
B	O
`	O
etc	O
.	O

Observe	O
that	O
`	O
A	O
`	O
has	O
four	O
such	O
pairs	O
,	O
`	O
B	O
`	O
has	O
only	O
1	O
,	O
and	O
`	O
C	O
`	O
has	O
3	O
.	O

I'm	O
not	O
sure	O
how	O
to	O
proceed	O
in	O
constructing	O
this	O
DataFrame	B-API
.	O

Modifying	O
this	O
example	O
didn't	O
give	O
me	O
the	O
designed	O
output	O
:	O
#CODE	O

yielded	O
:	O
#CODE	O

Is	O
there	O
any	O
way	O
of	O
breaking	O
up	O
the	O
lists	O
in	O
C	O
into	O
their	O
own	O
columns	O
?	O

EDIT	O
:	O
The	O
structure	O
of	O
my	O
`	O
C	O
`	O
is	O
important	O
.	O

It	O
looks	O
like	O
the	O
following	O
:	O
#CODE	O

And	O
the	O
desired	O
output	O
is	O
the	O
one	O
at	O
the	O
top	O
.	O

It	O
represents	O
the	O
starting	O
and	O
ending	O
points	O
of	O
subsequences	O
within	O
a	O
certain	O
sequence	O
(	O
`	O
A	O
`	O
,	O
`	O
B	O
`	O
.	O
`	O
C	O
`	O
are	O
the	O
different	O
sequences	O
)	O
.	O

Depending	O
on	O
the	O
sequence	O
itself	O
,	O
there	O
are	O
a	O
differing	O
number	O
of	O
subsequences	O
that	O
satisfy	O
a	O
given	O
condition	O
I'm	O
looking	O
for	O
.	O

As	O
a	O
result	O
,	O
there	O
are	O
a	O
differing	O
number	O
of	O
#URL	O
pairs	O
for	O
`	O
A	O
`	O
,	O
`	O
B	O
`	O
,	O
etc	O

First	O
,	O
I	O
think	O
you	O
need	O
to	O
fill	O
C	O
to	O
represent	O
missing	O
values	O
#CODE	O

Then	O
,	O
convert	O
to	O
a	O
numpy	O
array	O
,	O
transpose	B-API
,	O
and	O
pass	O
to	O
the	O
DataFrame	B-API
constructor	O
along	O
with	O
the	O
columns	O
.	O

#CODE	O

My	O
data	O
is	O
organized	O
as	O
a	O
list	O
of	O
lists	O
so	O
that	O
`	O
C	O
=[[	O
...	O
]	O
,	O
[	O
...	O
]	O
,	O
[	O
...	O
]	O
...	O
]`	O
since	O
each	O
nested	O
list	O
has	O
a	O
different	O
length	O
.	O

How	O
could	O
I	O
handle	O
this	O
situation	O
?	O

This	O
implementation	O
is	O
giving	O
me	O
an	O
error	O
because	O
the	O
length	O
of	O
the	O
nested	O
lists	O
within	O
`	O
C	O
`	O
is	O
not	O
equal	O
to	O
length	O
of	O
`	O
A	O
`	O
and	O
`	O
B	O
`	O

What	O
does	O
each	O
list	O
represent	O
,	O
rows	O
or	O
columns	O
?	O

Why	O
are	O
they	O
different	O
lengths	O
?	O

Are	O
the	O
shorter	O
lists	O
supposed	O
to	O
be	O
missing	O
certain	O
elements	O
?	O

See	O
edited	O
answer	O
for	O
a	O
guess	O
.	O

The	O
values	O
in	O
each	O
nested	O
list	O
are	O
the	O
rows	O
and	O
the	O
nested	O
list	O
themselves	O
are	O
the	O
columns	O
.	O

The	O
length	O
of	O
the	O
columns	O
is	O
different	O
because	O
`	O
one	O
`	O
has	O
a	O
different	O
number	O
of	O
#URL	O
pairs	O
than	O
`	O
two	O
`	O

I	O
think	O
we're	O
getting	O
tangled	O
on	O
terminology	O
-	O
can	O
you	O
edit	O
your	O
question	O
to	O
provide	O
some	O
data	O
that	O
matches	O
what	O
you're	O
talking	O
about	O
,	O
and	O
then	O
show	O
what	O
output	O
you	O
want	O
?	O

I	O
added	O
the	O
structure	O
of	O
my	O
`	O
C	O
`	O
to	O
the	O
question	O
.	O

The	O
desired	O
output	O
was	O
what	O
was	O
shown	O
at	O
the	O
top	O
.	O

Thanks	O
for	O
the	O
help	O
!	O

I	O
added	O
an	O
extra	O
couple	O
clarifying	O
sentences	O
to	O
the	O
description	O
as	O
well	O
.	O

I'm	O
open	O
to	O
redesigning	O
`	O
C	O
`'	O
s	O
structure	O
,	O
but	O
I'm	O
not	O
aware	O
of	O
a	O
better	O
way	O
to	O
represent	O
the	O
data	O
.	O

Thanks	O
,	O
try	O
the	O
latest	O
edit	O
.	O

It	O
looks	O
like	O
it	O
worked	O
!	O

Is	O
there	O
no	O
better	O
way	O
of	O
making	O
a	O
2d	O
numpy	O
array	O
from	O
arrays	O
of	O
non-identical	O
lengths	O
?	O

Can't	O
you	O
just	O
use	O
a	O
panel	B-API
?	O

#CODE	O

It's	O
likely	O
that	O
my	O
dataset	O
will	O
be	O
higher	O
dimensional	O
in	O
the	O
future	O
.	O

Isn't	O
panel	B-API
limited	O
to	O
3	O
dimensions	O
?	O

Resample	B-API
error	O
:	O
ValueError	O
:	O
month	O
must	O
be	O
in	O
1	O
..	O

12	O

I	O
have	O
a	O
.csv	O
file	O
that	O
I	O
would	O
like	O
to	O
resample	B-API
at	O
1	O
minute	O
granularity	O
.	O

I	O
do	O
this	O
in	O
the	O
following	O
way	O
:	O
#CODE	O

But	O
I	O
get	O
the	O
following	O
error	O
:	O

ValueError	O
:	O
month	O
must	O
be	O
in	O
1	O
..	O

12	O

I	O
got	O
confused	O
,	O
because	O
when	O
I	O
print	O
main	O
to	O
see	O
how	O
it	O
looks	O
like	O
,	O
the	O
time	O
stamp	O
is	O
in	O
the	O
following	O
format	O
:	O

Timestamp	O

2014-04-15	O
00:00	O
:	O
00	O

Just	O
what	O
it	O
says	O
:	O
you	O
try	O
to	O
create	O
a	O
date	O
from	O
incorrect	O
input	O
.	O

The	O
traceback	O
should	O
tell	O
you	O
where	O
this	O
is	O
happening	O
.	O

With	O
little	O
information	O
to	O
go	O
on	O
,	O
but	O
a	O
decent	O
amount	O
of	O
experience	O
working	O
with	O
dates	O
in	O
programming	O
,	O
I	O
would	O
guess	O
that	O
you	O
likely	O
have	O
one	O
of	O
two	O
problems	O
:	O

Your	O
data	O
is	O
bad	O
and	O
you	O
are	O
going	O
to	O
have	O
to	O
find	O
out	O
where	O
your	O
month	O
is	O
out	O
of	O
bounds	O
.	O

Your	O
timestamp	O
format	O
needs	O
to	O
be	O
specified	O
when	O
you	O
parse	O
it	O
.	O

Your	O
program	O
is	O
reading	O
2014	O
and	O
trying	O
turn	O
it	O
into	O
a	O
month	O
.	O

infer_datetime_format	O
:	O
boolean	O
,	O
default	O
False	O

If	O
True	O
and	O
parse_dates	O
is	O
enabled	O
for	O
a	O
column	O
,	O
attempt	O
to	O
infer	O
the	O
datetime	O
format	O
to	O
speed	O
up	O
the	O
processing	O

Since	O
you	O
believe	O
you	O
have	O
eliminated	O
both	O
of	O
the	O
above	O
possibilities	O
,	O
maybe	O
this	O
will	O
help	O
.	O

All	O
of	O
the	O
examples	O
I	O
see	O
for	O
this	O
function	O
have	O
this	O
format	O
for	O
max	O
in	O
how	O
:	O
#CODE	O

Thank	O
you	O
for	O
your	O
answer	O
.	O

I'm	O
very	O
new	O
to	O
python	O
so	O
I	O
have	O
zero	O
experience	O
.	O

How	O
do	O
I	O
specify	O
the	O
timestamp	O
format	O
?	O

I	O
checked	O
the	O
data	O
and	O
it	O
seems	O
to	O
me	O
that	O
the	O
month	O
is	O
not	O
out	O
of	O
bounds	O
.	O

#URL	O
Try	O
using	O
the	O
intialization	O
part	O
of	O
the	O
documentation	O
examples	O
with	O
your	O
resample	B-API
method	O
.	O

Print	O
their	O
data	O
after	O
it	O
is	O
initialized	O
and	O
compare	O
it	O
to	O
yours	O
for	O
formatting	O
.	O

Thank	O
you	O
!	O

I	O
solved	O
it	O
!	O

No	O
problem	O
.	O

If	O
you	O
are	O
satisfied	O
with	O
an	O
answer	O
,	O
you	O
should	O
mark	O
it	O
as	O
accepted	O
though	O
.	O
